Dataset,System,Bug ID,Creation Date,Title,Description,Ground Truth
CLASS,tika-1.3,TIKA-1070,2013-01-31T05:43:33.000-06:00,StackOverflow error in org.apache.tika.sax.ToXMLContentHandler$ElementInfo.getPrefix(ToXMLContentHandler.java:58),"new ElementInfo(currentElement, namespaces);
The error occurs when parsing big ""XLS"" files and is caused by the ElementInfo stored in ""currentElement"".
Each time a new element is started (method startElement) the current elment is newly overwritten with
currentElement = new ElementInfo(currentElement, namespaces);
where the existing element is used as the parent element.
Since the currentElement is not reset to the parent element after finishing the element (method: endElement) the method getPrefix recursively traverses the parents and finally causes the StackOverFlowError
For my understanding: something like:
currentElement = currentElement.parent;
in the endElement method solves the issue!
Best",tika-core.src.main.java.org.apache.tika.sax.ToXMLContentHandler
CLASS,tika-1.3,TIKA-1152,2013-07-23T08:45:11.000-05:00,Process loops infinitely on parsing of a CHM file,"{code}
 
    
     
    
    
    
    
    
    
    
    
 {code}
By parsing [the attachment CHM file|^eventcombmt.chm] (MS Microsoft Help Files), Java process stuck.
{code}
Thread[main,5,main]
org.apache.tika.parser.chm.lzx.ChmLzxBlock.extractContent(ChmLzxBlock.java:203)
org.apache.tika.parser.chm.lzx.ChmLzxBlock.<init>(ChmLzxBlock.java:77)
org.apache.tika.parser.chm.core.ChmExtractor.extractChmEntry(ChmExtractor.java:338)
org.apache.tika.parser.chm.CHMDocumentInformation.getContent(CHMDocumentInformation.java:72)
org.apache.tika.parser.chm.CHMDocumentInformation.getText(CHMDocumentInformation.java:141)
org.apache.tika.parser.chm.CHM2XHTML.process(CHM2XHTML.java:34)
org.apache.tika.parser.chm.ChmParser.parse(ChmParser.java:51)
org.apache.tika.parser.ParserDecorator.parse(ParserDecorator.java:91)
org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:242)
org.apache.tika.parser.AbstractParser.parse(AbstractParser.java:53)
com.polyspot.document.converter.DocumentConverter.realizeConversion(DocumentConverter.java:192)
...
{code}",tika-parsers.src.main.java.org.apache.tika.parser.chm.lzx.ChmLzxBlock
CLASS,tika-1.3,TIKA-1192,2013-11-06T15:31:41.000-06:00,ArrayIndexOutOfBoundsException: 9 parsing RTF,"{noformat}
  
    
    
    
    
    
    
  
    
    
  
  
  
    
  
  
  
    
  
  
  
    
    
 {noformat}
When trying to parse an RTF file I'm getting the following exception.
I am not able to attach the file for privacy reasons:
{noformat}
java.lang.ArrayIndexOutOfBoundsException: 9
TextExtractor.java:872 org.apache.tika.parser.rtf.TextExtractor.processControlWord
TextExtractor.java:566 org.apache.tika.parser.rtf.TextExtractor.parseControlWord
TextExtractor.java:492 org.apache.tika.parser.rtf.TextExtractor.parseControlToken
TextExtractor.java:459 org.apache.tika.parser.rtf.TextExtractor.extract
TextExtractor.java:448 org.apache.tika.parser.rtf.TextExtractor.extract
RTFParser.java:56 org.apache.tika.parser.rtf.RTFParser.parse
(Unknown Source) sun.reflect.NativeMethodAccessorImpl.invoke0
NativeMethodAccessorImpl.java:57 sun.reflect.NativeMethodAccessorImpl.invoke
DelegatingMethodAccessorImpl.java:43 sun.reflect.DelegatingMethodAccessorImpl.invoke
Method.java:606 java.lang.reflect.Method.invoke
Reflector.java:93 clojure.lang.Reflector.invokeMatchingMethod
Reflector.java:28 clojure.lang.Reflector.invokeInstanceMethod
tika_parser.clj:20 rtf-parser.tika-parser/parse
form-init2921349737948661927.clj:1 rtf-parser.tika-parser/eval4200
Compiler.java:6619 clojure.lang.Compiler.eval
Compiler.java:6582 clojure.lang.Compiler.eval
core.clj:2852 clojure.core/eval
main.clj:259 clojure.main/repl[fn]
main.clj:259 clojure.main/repl[fn]
main.clj:277 clojure.main/repl[fn]
main.clj:277 clojure.main/repl
RestFn.java:1096 clojure.lang.RestFn.invoke
interruptible_eval.clj:56 clojure.tools.nrepl.middleware.interruptible-eval/evaluate[fn]
AFn.java:159 clojure.lang.AFn.applyToHelper
AFn.java:151 clojure.lang.AFn.applyTo
core.clj:617 clojure.core/apply
core.clj:1788 clojure.core/with-bindings*
RestFn.java:425 clojure.lang.RestFn.invoke
interruptible_eval.clj:41 clojure.tools.nrepl.middleware.interruptible-eval/evaluate
interruptible_eval.clj:171 clojure.tools.nrepl.middleware.interruptible-eval/interruptible-eval[fn]
core.clj:2330 clojure.core/comp[fn]
interruptible_eval.clj:138 clojure.tools.nrepl.middleware.interruptible-eval/run-next[fn]
AFn.java:24 clojure.lang.AFn.run
ThreadPoolExecutor.java:1145 java.util.concurrent.ThreadPoolExecutor.runWorker
ThreadPoolExecutor.java:615 java.util.concurrent.ThreadPoolExecutor$Worker.run
Thread.java:724 java.lang.Thread.run
{noformat}","tika-parsers.src.test.java.org.apache.tika.parser.rtf.RTFParserTest
tika-parsers.src.main.java.org.apache.tika.parser.rtf.TextExtractor"
FILE,DATAMONGO,DATAMONGO-315,2011-11-09T10:21:33.000-06:00,MongoTemplate.findOne(query) methods ignore SortOrder on query,"Query query = query(where(""type"").is(""ad""));
query.sort().on(""rawBidPrice"", Order.DESCENDING);
Ad ad = mongoTemplate.findOne(query, Ad.class);
 
 query.getSortOrder() 
 Query query = query(where(""type"").is(""ad""));
query.sort().on(""rawBidPrice"", Order.DESCENDING);
query.limit(1);
List<Ad> ads = mongoTemplate.find(query, Ad.class);
Ad ad = ads.isEmpty() ? null : ads.get(0);
Query query = query(where(""type"").
is(""ad""));
query.sort().
on(""rawBidPrice"", Order.DESCENDING);
Ad ad = mongoTemplate.findOne(query, Ad.class);
This does not sort the results before returning the first item.
Looking at the code, it doesn't even call query.getSortOrder().
--------------
Workaround
Query query = query(where(""type"").
is(""ad""));
query.sort().
on(""rawBidPrice"", Order.DESCENDING);
query.limit(1);
List<Ad> ads = mongoTemplate.find(query, Ad.class);
Ad ad = ads.isEmpty() ? null : ads.get(0);","org.springframework.data.mongodb.core.MongoTemplateTests
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-260,2011-09-05T01:06:36.000-05:00,MapReduce fails when using with Long as key-type.,"class Foo {




  String id;




  Long number;




  Long version;




} 






 
 function()  
 emit(this.number, this.version)




 
 function(key, values)  {




	return Math.max.apply(Math, values);




}
MapReduce will fail calling emit with Long as key-type.
class Foo {
String id;
Long number;
Long version;
}
Map:
function() {
emit(this.number, this.version)
}
Reduce:
function(key, values) {
return Math.max.apply(Math, values);
}
(see http://cookbook.mongodb.org/patterns/finding_max_and_min/)
outputcollection
{
""_id"": 1,
""value"": 2
}
then it tries to convert _id to objectid which fails:
org.springframework.core.convert.ConverterNotFoundException: No converter found capable of converting from 'java.lang.Long' to 'java.lang.String'
at org.springframework.core.convert.support.GenericConversionService.convert(GenericConversionService.java:155)
at org.springframework.core.convert.support.GenericConversionService.convert(GenericConversionService.java:127)
at org.springframework.data.mapping.model.BeanWrapper.getPotentiallyConvertedValue(BeanWrapper.java:221)
at org.springframework.data.mapping.model.BeanWrapper.setProperty(BeanWrapper.java:155)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter$2.doWithPersistentProperty(MappingMongoConverter.java:260)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter$2.doWithPersistentProperty(MappingMongoConverter.java:248)
at org.springframework.data.mapping.model.BasicPersistentEntity.doWithProperties(BasicPersistentEntity.java:160)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:248)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:193)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:161)
at org.springframework.data.mongodb.core.MongoTemplate$ReadDbObjectCallback.doWith(MongoTemplate.java:1462)
at org.springframework.data.mongodb.core.MongoTemplate.mapReduce(MongoTemplate.java:885)
at org.springframework.data.mongodb.core.MongoTemplate.mapReduce(MongoTemplate.java:841)","org.springframework.data.mongodb.core.convert.AbstractMongoConverter
org.springframework.data.mongodb.core.mapreduce.MapReduceTests"
FILE,DATAMONGO,DATAMONGO-385,2012-01-26T05:13:31.000-06:00,MongoRepositoryFactory does not support id classes of type java.lang.Long,"public interface TestRepository extends MongoRepository<TestEntity, Long> {  }












 @Document




public class TestEntity




{




  @Id




  private Long id;




  




}
It is not possible to use a MongoRepository with Long id class:
public interface TestRepository extends MongoRepository<TestEntity, Long> {  }
@Document
public class TestEntity
{
@Id
private Long id;
}",org.springframework.data.mongodb.repository.support.MongoRepositoryFactoryUnitTests
FILE,DATAMONGO,DATAMONGO-413,2012-03-09T17:21:02.000-06:00,"Using ""Or"" in repository query yields a ClassCastException","List<User> findByEmailOrAlias(String email, String alias) 
        
 
 List<User> findByEmailAndAlias(String email, String alias)
List<User> findByEmailOrAlias(String email, String alias);
Gives:
2012-03-09 17:19:55,057 [main] DEBUG org.springframework.data.mongodb.repository.query.MongoQueryCreator - Created query { ""email"" : ""a@b.c"" , ""alias"" : ""abc"" , ""$or"" : { }}
2012-03-09 17:19:55,062 [main] DEBUG org.springframework.data.mongodb.core.MongoTemplate - find using query: { ""email"" : ""a@b.c"" , ""$or"" : { }} fields: null for class: class com.musicalabs.api.model.User in collection: user
Exception in thread ""main"" java.lang.ClassCastException: com.mongodb.BasicDBObject cannot be cast to java.lang.Iterable
at org.springframework.data.mongodb.core.QueryMapper.getMappedObject(QueryMapper.java:92)
at org.springframework.data.mongodb.core.MongoTemplate.doFind(MongoTemplate.java:1259)
at org.springframework.data.mongodb.core.MongoTemplate.doFind(MongoTemplate.java:1248)
at org.springframework.data.mongodb.core.MongoTemplate.find(MongoTemplate.java:471)
at org.springframework.data.mongodb.repository.query.AbstractMongoQuery$Execution.readCollection(AbstractMongoQuery.java:125)
at org.springframework.data.mongodb.repository.query.AbstractMongoQuery$CollectionExecution.execute(AbstractMongoQuery.java:142)
at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.execute(AbstractMongoQuery.java:88)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.invoke(RepositoryFactorySupport.java:302)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)
at $Proxy22.findByEmailOrAlias(Unknown Source)
at com.acme.Fake.main(Fake.java:23)
While that:
List<User> findByEmailAndAlias(String email, String alias);
works fine.","org.springframework.data.mongodb.core.query.OrQuery
org.springframework.data.mongodb.repository.query.MongoQueryCreator
org.springframework.data.mongodb.repository.query.MongoQueryCreatorUnitTests"
FILE,DATAMONGO,DATAMONGO-423,2012-03-29T06:03:26.000-05:00,Criteria.regex should use java.util.Pattern instead of $regex,"c.find( new BasicDBObject( ""x"" ,




                new BasicDBObject(""$not"", new BasicDBObject(""$regex"", ""b"") ) ) );






  
  
 c.find( new BasicDBObject( ""x"" ,




                new BasicDBObject(""$not"", Pattern.compile( ""b"" , Pattern.CASE_INSENSITIVE ) ) ) );
mongod complains about $regex in some cases.
DBCollection c = ...
c.find( new BasicDBObject( ""x"" ,
new BasicDBObject(""$not"", new BasicDBObject(""$regex"", ""b"") ) ) );
throws this exception:
com.mongodb.MongoException: can't use $not with $regex, use BSON regex type instead
at com.mongodb.MongoException.parse(MongoException.java:82)
at com.mongodb.DBApiLayer$MyCollection.
__find(DBApiLayer.java:312)
at com.mongodb.DBCursor.
_check(DBCursor.java:369)
at com.mongodb.DBCursor.
_hasNext(DBCursor.java:504)
at com.mongodb.DBCursor.hasNext(DBCursor.java:529)
DBCollection c = ...
c.find( new BasicDBObject( ""x"" ,
new BasicDBObject(""$not"", Pattern.compile( ""b"" , Pattern.CASE_INSENSITIVE ) ) ) );","org.springframework.data.mongodb.core.MongoTemplateTests
org.springframework.data.mongodb.core.query.QueryTests
org.springframework.data.mongodb.core.query.Criteria"
FILE,DATAMONGO,DATAMONGO-462,2012-06-19T08:57:02.000-05:00,findAll() fails with NPE - discovering the root cause,"@PersistenceConstructor
This bug report is based on a forum thread(see Reference URL).
I do not want to duplicate the original posts.
Here is my response.
Hello Oliver,
This morning I built spring data from source which provided a more informative error (see below).
My code doesn't use the  @PersistenceConstructor annotation.
I'll investigate.
My source is open source.
It is pre-alpha at this time.
You'll find it on github (https://github.com/kern3020/harbinger).
Exception in thread ""main"" org.springframework.data.mapping.model.MappingInstantiationException: Could not instantiate bean class [java.net.URL]: No default constructor_ found; nested exception is java.lang.NoSuchMethodException: java.net.URL.
<init>()
at org.springframework.data.convert.ReflectionEntityInstantiator.createInstance(ReflectionEntityInstantiator.java:63)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:230)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:210)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter$MongoDbPropertyValueProvider.getPropertyValue(MappingMongoConverter.java:953)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.getValueInternal(MappingMongoConverter.java:708)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter$1.doWithPersistentProperty(MappingMongoConverter.java:246)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter$1.doWithPersistentProperty(MappingMongoConverter.java:236)
at org.springframework.data.mapping.model.BasicPersistentEntity.doWithProperties(BasicPersistentEntity.java:183)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:236)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:210)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:174)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:170)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:73)
at org.springframework.data.mongodb.core.MongoTemplate$ReadDbObjectCallback.doWith(MongoTemplate.java:1700)
at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:1451)
at org.springframework.data.mongodb.core.MongoTemplate.findAll(MongoTemplate.java:959)
at org.john.app.InstituteRepository.dump(InstituteRepository.java:58)
at org.john.app.InstituteRepository$$FastClassByCGLIB$$7799dab9.
invoke(<generated>)
at net.sf.cglib.proxy.MethodProxy.invoke(MethodProxy.java:191)
at org.springframework.aop.framework.Cglib2AopProxy$CglibMethodInvocation.invokeJoinpoint(Cglib2AopProxy.java:689)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150)
at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:622)
at org.john.app.InstituteRepository$$EnhancerByCGLIB$$a998483c.dump(<generated>)
at org.john.app.ReaperApp.main(ReaperApp.java:49)
Caused by: org.springframework.beans.BeanInstantiationException: Could not instantiate bean class [java.net.URL]: No default constructor_ found; nested exception is java.lang.NoSuchMethodException: java.net.URL.<init>()
at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:107)
at org.springframework.data.convert.ReflectionEntityInstantiator.createInstance(ReflectionEntityInstantiator.java:60)
... 25 more
Caused by: java.lang.NoSuchMethodException: java.net.URL.<init>()
at java.lang.Class.getConstructor0(Class.java:2723)
at java.lang.Class.getDeclaredConstructor(Class.java:2002)
at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:104)","org.springframework.data.mongodb.core.convert.MongoConverters
org.springframework.data.mongodb.core.convert.MappingMongoConverterUnitTests
org.springframework.data.mongodb.core.convert.CustomConversionsUnitTests
org.springframework.data.mongodb.core.convert.CustomConversions"
FILE,DATAMONGO,DATAMONGO-467,2012-06-24T08:58:49.000-05:00,"String @id field is not mapped to ObjectId when using QueryDSL "".id"" path","@Document 
 @Id String id;






 
 QUser.id.eq(""4f43b6a384aea4e77d403709"")
User.class
...
@Id String id;
QUser.id.eq(""4f43b6a384aea4e77d403709"")
Always returns null for a repository find.
Looking at the mongoDb query log (mongod -v) it appears that the spring-data-mongodb/QueryDSL layers are not translating the String 4f43b6a384aea4e77d403709 to ObjectId(""4f43b6a384aea4e77d403709"") as one would normally do in the mongo shell.",org.springframework.data.mongodb.repository.support.SpringDataMongodbSerializerUnitTests
FILE,DATAMONGO,DATAMONGO-505,2012-08-14T03:07:56.000-05:00,Conversion of associations doesn't work for collection values,"class Entity {









  Long id;




  @DBRef




  Property property;




}









 class Property {




  Long id;




}









 interface EntityRepository extends Repository<Entity, Long> {









  Entity findByPropertyIn(Property... property);




}






  findByProperty()
class Entity {
Long id;
@DBRef
Property property;
}
class Property {
Long id;
}
interface EntityRepository extends Repository<Entity, Long> {
Entity findByPropertyIn(Property... property);
}
The execution of findByProperty() will fail as the given array (or collection) is not correctly translated into a collection of DBRefs.
The reason is that ConvertingIterator treats the value as is and wants to create a DBRef from it.","org.springframework.data.mongodb.repository.query.ConvertingParameterAccessor
org.springframework.data.mongodb.repository.query.ConvertingParameterAccessorUnitTests"
FILE,DATAMONGO,DATAMONGO-523,2012-09-01T03:39:51.000-05:00,@TypeAlias annotation not used with AbstractMongoConfiguration,"@TypeAlias      @Document  @TypeAlias
When using the AbstractMongoConfiguration without any further modifications regarding the converter (afterMappingMongoConverterCreation) the @TypeAlias annotation is not used when writing the _class property.
Seems like it always uses the SimpleTypeInformationMapper.
The documentation suggests that you just annotate your @Document classes with the @TypeAlias annotations and everything should be fine.",org.springframework.data.mongodb.core.convert.MappingMongoConverterUnitTests
FILE,DATAMONGO,DATAMONGO-585,2012-12-01T08:28:43.000-06:00,Exception during authentication in multithreaded access,"class which implements Runnable.  
Those
Bug & further details are here:
http://forum.springsource.org/showthread.php?132878-can-t-authenticate-twice-on-same-database
thanks",org.springframework.data.mongodb.core.MongoDbUtils
FILE,DATAMONGO,DATAMONGO-629,2013-03-22T04:08:25.000-05:00,Different results when using count and find with the same criteria with 'id' field,"Query q = query 
    
  
 
 
 {




		""id"" : /zzz/




	} 
 
 
 
 
 
  
  
 
 
 {




		""count"" : ""test"",




		""query"" : {




			""_id"" : /zzz/




		}




	 
 
 
 
 
 
     find()     count()
Query q = query(where('id').
regex('zzz'))
mongoTemplate.find(q,java.util.HashMap.class,'test') gives following query (peeked in mongo console):
{ ""ts"" : ISODate(""2013-03-22T10:00:51.685Z""),
""op"" : ""query"",
""ns"" : ""test.test"",
""query"" : {
""id"" : /zzz/
},
""nscanned"" : 1,
""responseLength"" : 20,
""millis"" : 0,
""client"" : ""127.0.0.1"",
""user"" : """"
}
The same query, when used in count (mongoTemplate.count(q,'test')) gives:
{
""ts"" : ISODate(""2013-03-22T10:00:36.299Z""),
""op"" : ""command"",
""ns"" : ""test.
$cmd"",
""command"" : {
""count"" : ""test"",
""query"" : {
""_id"" : /zzz/
}
},
""ntoreturn"" : 1,
""responseLength"" : 48,
""millis"" : 0,
""client"" : ""127.0.0.1"",
""user"" : """"
}
This is inconsistent since we could have records with field id and they will be retrieved properly from the db.
Count on the other hand will give bad results since it uses _id field.
In org.springframework.data.mongodb.core.convert.QueryMapper the method determineKey, for some reason treats id and _id as the same field.
This is probably the cause of the strange behaviour because find() method does not use QueryMapper and count() does.","org.springframework.data.mongodb.core.mapping.MongoMappingContext
org.springframework.data.mongodb.core.MongoTemplateTests
org.springframework.data.mongodb.core.convert.QueryMapper
org.springframework.data.mongodb.core.convert.QueryMapperUnitTests"
FILE,DATAMONGO,DATAMONGO-571,2012-11-09T08:00:10.000-06:00,Spring Data for MongoDb doesn't save null values when @Version is added to domain class,"Scenario 
 CrudRepository.findOne()  
 @Version 
 CrudRepository.save()  
 @Version
Scenario:
Important: The problem doesnt occur when @Version annotation is not used in the domain class definition.","org.springframework.data.mongodb.core.MongoTemplateTests
org.springframework.data.mongodb.core.query.Update"
FILE,DATAMONGO,DATAMONGO-663,2013-04-24T03:21:19.000-05:00,org.springframework.data.mongodb.core.query.Field needs an equals method,"class Field   equals()  
  
 boolean fieldsEqual = this.fieldSpec == null ? that.fieldSpec == null : this.fieldSpec.equals(that.fieldSpec);
The above class Field does not has an equals() method.
But org.springframework.data.mongodb.core.query.Query has an equals method which is using the equals method of the Field class.
boolean fieldsEqual = this.fieldSpec == null ? that.fieldSpec == null : this.fieldSpec.equals(that.fieldSpec);
Please implement an equals on the Field method.
Purpose: For unit testing the equals method is needed.",org.springframework.data.mongodb.core.query.Field
FILE,DATAMONGO,DATAMONGO-392,2012-02-07T04:28:15.000-06:00,Updating an object does not write type information for objects to be updated,"MappingMongoConverter.writeInternal(...)   addCustomTypeIfNecessary(...)     convertToMongoType(...)   removeTypeInfoRecursively(...)
I used 1.0.0.
M5 version, and the type information (under _class key) was stored with object when it was necessary to be able to read it from database later.
That worked perfectly for me till my upgrade to 1.0.0.
RELEASE version that broke my application as it saves the objects without type information and later it is impossible to read it back to java model.
What I found is that MappingMongoConverter.writeInternal(...) method that in turn calls addCustomTypeIfNecessary(...) (line 330) which puts type information into DBObject.
During execution of convertToMongoType(...) (at line 851) removeTypeInfoRecursively(...) is called which clears type data saved earlier under _class key.
I had to comment out this call in order to
The first point is that there is a contradiction: why to save type information to DBObject if it is later removed by other method?","org.springframework.data.mongodb.core.MongoTemplateTests
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-717,2013-07-10T11:13:46.000-05:00,Application context is not properly distributed to persistent entities,"@Override




	protected <T> BasicMongoPersistentEntity<T> createPersistentEntity(TypeInformation<T> typeInformation) {









		BasicMongoPersistentEntity<T> entity = new BasicMongoPersistentEntity<T>(typeInformation);









		if (context != null) {




			entity.setApplicationContext(context);




		}









		return entity;




	}









	




	 @Override




	public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {









		this.context = applicationContext;




		super.setApplicationContext(applicationContext);




	}






 
  
 @Override




	public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {









		this.context = applicationContext;




		super.setApplicationContext(applicationContext);




                // Send the application context to ALL the PersistentEntities, not just ones created after this point




               for (BasicMongoPersistentEntity entity : getPersistentEntities()) {




                   entity.setApplicationContext(applicationContext);




               }




	}






      testMultiTenantSave()  
   initialize()    
 
 @Bean




	public MongoMappingContext mongoMappingContext() throws ClassNotFoundException {









		MongoMappingContext mappingContext = new MongoMappingContext();




		mappingContext.setInitialEntitySet(getInitialEntitySet());




		mappingContext.setSimpleTypeHolder(customConversions().getSimpleTypeHolder());




		mappingContext.initialize(); // <----









		return mappingContext;




	}
The MongoMappingContext does not properly distribute the application context when set to persistent entities that have already been added.
MongoMappingContext.java
@Override
protected <T> BasicMongoPersistentEntity<T> createPersistentEntity(TypeInformation<T> typeInformation) {
BasicMongoPersistentEntity<T> entity = new BasicMongoPersistentEntity<T>(typeInformation);
if (context !
= null) {
entity.setApplicationContext(context);
}
return entity;
}
@Override
public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {
this.context = applicationContext;
super.setApplicationContext(applicationContext);
}
Possible fix:
MongoMappingContext.java
@Override
public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {
this.context = applicationContext;
super.setApplicationContext(applicationContext);
// Send the application context to ALL the PersistentEntities, not just ones created after this point
for (BasicMongoPersistentEntity entity : getPersistentEntities()) {
entity.setApplicationContext(applicationContext);
}
}
See referenced URL PoC, no_indexes branch, test: MultiTenantTest::testMultiTenantSave() for example.
UPDATE:
AbstractMongoConfiguration is calling initialize() on MongoMappingContext before it returns the object.
AbstractMongoConfiguration
@Bean
public MongoMappingContext mongoMappingContext() throws ClassNotFoundException {
MongoMappingContext mappingContext = new MongoMappingContext();
mappingContext.setInitialEntitySet(getInitialEntitySet());
mappingContext.setSimpleTypeHolder(customConversions().
getSimpleTypeHolder());
mappingContext.initialize(); // <----
return mappingContext;
}",org.springframework.data.mongodb.config.AbstractMongoConfigurationUnitTests
FILE,DATAMONGO,DATAMONGO-721,2013-07-11T11:36:06.000-05:00,Polymorphic attribute type not persisted on update operations,"@Document
public class ParentClass {
   private List<ChildClass> list;
}
    @Document   
        
  
 mongoTemplate.updateFirst(Query.query(criteria), 
  new Update().push(""list"", child));
We found a problem with Spring Data for Mongo DB.
@Document public class ParentClass { private List<ChildClass> list;
} the ChildClass is annotated with @Document too, but we want to store it's content as an embed document of ParentClass.
When using MongoTemplate class with code such as below, the _class attribute is not inserted on the embedded document, so, if one of the items of the list attribute is a subclass of ChildClass, and ChildClass is an abstract class, we begin to face instantiation problems.
mongoTemplate.updateFirst(Query.query(criteria), new Update().
push(""list"", child));
If child is a subclass of ChildClass, the _class attribute is not added to the embedded document.",org.springframework.data.mongodb.core.convert.QueryMapper
FILE,DATAMONGO,DATAMONGO-602,2013-01-30T02:22:53.000-06:00,Querying with $in operator on the id field of type BigInteger returns zero results,"List<BigInteger> profileIds = findProfileIds();




Predicate predicate = QProfileDocument.profileDocument.id.in(profileIds);




Iterable<ProfileDocument> profiles = profileRepository.findAll(predicate);
Id field is mapped as a BigInteger.
List<BigInteger> profileIds = findProfileIds();
Predicate predicate = QProfileDocument.profileDocument.id.in(profileIds);
Iterable<ProfileDocument> profiles = profileRepository.findAll(predicate);
The underlying MongodbQuery is different if there is only one item in profileIds.
The query looks like this for a profileIds with multiple elements
{ ""_id"" : { ""$in"" : [ ""25069473312490162649510603609"" , ""25045916045544535958655878835""]}}
and it looks like this when there is only one item in the list.
{ ""_id"" : { ""$oid"" : ""5100fb776c67e7e092be6b59""}}
In the first case, query will return no results and in the second it will work and return an Iterable with one item.
As you can see, the problem is with the representation of the BigInteger.
using decimal format will not work with MongoDB.",org.springframework.data.mongodb.core.MongoTemplateTests
FILE,DATAMONGO,DATAMONGO-805,2013-12-02T06:34:36.000-06:00,Excluding DBRef field in a query causes a MappingException,"Query query = new Query(Criteria.where(""parentField"").is(""test""));
        query.fields().exclude(""children"");
        ParentClass parentClass = mongoOperations.findOne(query, ParentClass.class);
Excluding a field in a query where the field is a DBRef as below throws a MappingException.
Query query = new Query(Criteria.where(""parentField"").
is(""test""));
query.fields().
exclude(""children"");
ParentClass parentClass = mongoOperations.findOne(query, ParentClass.class);
Exception trace:
org.springframework.data.mapping.model.MappingException: No mapping metadata found for class java.lang.Integer
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.createDBRef(MappingMongoConverter.java:729)
at com.digitalshadows.collation.persistence.impl.CollectionNameProvidedMongoConverter.createDBRef(CollectionNameProvidedMongoConverter.java:28)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.toDBRef(MappingMongoConverter.java:288)
at org.springframework.data.mongodb.core.convert.QueryMapper.convertAssociation(QueryMapper.java:273)
at org.springframework.data.mongodb.core.convert.QueryMapper.getMappedValue(QueryMapper.java:204)
at org.springframework.data.mongodb.core.convert.QueryMapper.getMappedObject(QueryMapper.java:113)
at org.springframework.data.mongodb.core.MongoTemplate.doFindOne(MongoTemplate.java:1439)
at org.springframework.data.mongodb.core.MongoTemplate.findOne(MongoTemplate.java:489)
at org.springframework.data.mongodb.core.MongoTemplate.findOne(MongoTemplate.java:484)
at ExcludeDBRefFieldTest.testExcludeChildren(ExcludeDBRefFieldTest.java:28)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
at java.lang.reflect.Method.invoke(Unknown Source)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:74)
at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:83)
at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:72)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:231)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:88)
at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:174)
at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
The workaround for this I can currently see is to use include for all the other fields instead.","org.springframework.data.mongodb.core.convert.QueryMapper
org.springframework.data.mongodb.core.mapping.MappingTests
org.springframework.data.mongodb.core.convert.QueryMapperUnitTests"
FILE,DATAMONGO,DATAMONGO-887,2014-03-20T21:01:31.000-05:00,Repository not instantiated when entity contains field of type TreeMap,"public interface SourceRepository extends PagingAndSortingRepository<MyEntity, ObjectId> {




}









// Entity




 @Document(""test_collection"")




public class MyEntity {




private TreeMap<String,MyClass> treeMap;




}









// TreeMap value class




 public class MyClass {




private String foo = ""bar"";




}
Repository fails to instantiate when the entity contains a TreeMap with value class that does not have a convertor.
I've tested with HashMap, HashSet, TreeSet but this only seems to affect TreeMap.
// Repository
public interface SourceRepository extends PagingAndSortingRepository<MyEntity, ObjectId> {
}
// Entity
@Document(""test_collection"")
public class MyEntity {
private TreeMap<String,MyClass> treeMap;
}
// TreeMap value class
public class MyClass {
private String foo = ""bar"";
}
This succeeds if i build a convertor for MyClass but it really shouldn't need one.
This is working in 1.4.0.
RELEASE but fails in version 1.4.1.
RELEASE and beyond.
Throws: java.lang.ArrayIndexOutOfBoundsException: 0
In: org.springframework.data.util.ParameterizedTypeInformation.getComponentType(ParameterizedTypeInformation.java:148)",org.springframework.data.mongodb.core.convert.MappingMongoConverterUnitTests
FILE,DATAMONGO,DATAMONGO-897,2014-04-01T04:38:51.000-05:00,FindAndUpdate broken when using @DbRef and interface as target,"MongoTemplate.findAndModify(...)   @DbRef  @DbRef
NullPointerException is thrown when using MongoTemplate.findAndModify(...) with @DbRef and interface as @DbRef target.
See attached project for more details.
Probably regression issue since same test is passing with Spring Data Commons 1.6.3.
RELEASE and Spring Data MongoDB 1.3.3.
RELEASE.","org.springframework.data.mongodb.core.convert.UpdateMapperUnitTests
org.springframework.data.mongodb.core.convert.QueryMapper"
FILE,DATAMONGO,DATAMONGO-892,2014-03-28T09:08:03.000-05:00,<mongo:mapping-converter> can't be configured as nested bean definition,"parserContext.isNested()
<beans:bean id=""messageStore"" class=""org.springframework.integration.mongodb.store.ConfigurableMongoDbMessageStore"">
<beans:constructor-arg ref=""mongoDbFactory""/>
<beans:constructor-arg>
<mongo:mapping-converter>
<mongo:custom-converters>
<mongo:converter>
<beans:bean class=""org.springframework.integration.mongodb.store.ConfigurableMongoDbMessageGroupStoreTests$MessageReadConverter""/>
</mongo:converter>
</mongo:custom-converters>
</mongo:mapping-converter>
</beans:constructor-arg>
<beans:constructor-arg value=""testConfigurableMongoDbMessageStore""/>
</beans:bean>
That's because MappingMongoConverterParser doesn't check if the parserContext.isNested(), registers BeanDefinition and returns null","org.springframework.data.mongodb.config.MappingMongoConverterParser
org.springframework.data.mongodb.config.MappingMongoConverterParserIntegrationTests"
FILE,DATAMONGO,DATAMONGO-647,2013-04-09T17:29:02.000-05:00,"Using ""OrderBy"" in ""query by method name"" ignores the @Field annotation for field alias.","@Field(""sr"")
 
 List<Answer> findByQuestionIdOrderByScoreDesc(String questionId)
@Field(""sr"")
int Score
List<Answer> findByQuestionIdOrderByScoreDesc(String questionId)
When the query is run, the database attempts to sort the results by ""score"" rather than my ""sr"" field name.",org.springframework.data.mongodb.core.convert.QueryMapperUnitTests
FILE,DATAMONGO,DATAMONGO-745,2013-09-03T02:15:08.000-05:00,@Query($in) and Pageable in result Page total = 0,"@Query(""{'snapshotId' : ?0 ,'defects.id':{ $in:?1}}"")
Page<Test> findBySnapshotIdAndDefects(ObjectId snapshotId, List<Integer> defectIds, Pageable pageable) 
 {5225a5ece4b0a01629fce9c6={ ""_id"" : 
{ ""$oid"" : ""5225a5ece4b0a01629fce9c6""}
Hi If I used MongoRepository and anotation Quary and Pageable in response I get true result but getTotalElements == 0
@Query(""{'snapshotId' : ?
0 ,'defects.id':{ $in:?
1}}"")
Page<Test> findBySnapshotIdAndDefects(ObjectId snapshotId, List<Integer> defectIds, Pageable pageable);
Base Struct
{5225a5ece4b0a01629fce9c6={ ""_id"" :
{ ""$oid"" : ""5225a5ece4b0a01629fce9c6""}
, ""snapshotId"" :
{ ""$oid"" : ""5225a5ece4b0a01629fce9c5""}
, ""defects"" : [
{ ""_id"" : 1 }
]}","org.springframework.data.mongodb.repository.Person
org.springframework.data.mongodb.repository.AbstractPersonRepositoryIntegrationTests
org.springframework.data.mongodb.repository.PersonRepository"
FILE,DATAMONGO,DATAMONGO-938,2014-05-21T06:09:48.000-05:00,Exception when creating geo within Criteria using MapReduce,"Criteria.where(""location"")  within(new Box(lowerLeft, upperRight));
I am getting an IllegalArgumentException when I try to query a MongoDB collection using a Criteria.within and a Box.
Criteria.where(""location"").
within(new Box(lowerLeft, upperRight));
The exception reads:
java.lang.IllegalArgumentException: can't serialize class org.springframework.data.mongodb.core.query.GeoCommand","org.springframework.data.mongodb.core.mapreduce.MapReduceTests
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-952,2014-06-10T22:45:47.000-05:00,@Query annotation does not work with only field restrictions,"@Query 
 @Query(fields = ""{ 'email' : 1 }"")




User findByEmail(String email)






  @Query
If you are using repository based queries and try to use @Query annotation to limit the fetched fields, it has zero effect.
@Query(fields = ""{ 'email' : 1 }"")
User findByEmail(String email)
The query above returns all fields of the User and the fields definition has no effect at all.
If you are using @Query with value attribute to define the query, then the fields limitation is applied though.",org.springframework.data.mongodb.repository.query.PartTreeMongoQuery
FILE,DATAMONGO,DATAMONGO-969,2014-06-26T16:28:13.000-05:00,String @id field is not mapped to ObjectId when using QueryDSL .id.in(Collection<String>),"eq()   in() 
 @Document




public class User {




    @Id String id;




}









 Collection<String> collection = new ArrayList<>();




collection.add(""abcdef....."");




Iterable<User> user = userRepository.findAll(QUser.user.id.in(collection));
This is similar to DATAMONGO-467 which was resolved a while back.
But in this case instead of .
eq() I am using .
in().
@Document
public class User {
@Id String id;
}
Collection<String> collection = new ArrayList<>();
collection.add(""abcdef....."");
Iterable<User> user = userRepository.findAll(QUser.user.id.in(collection));
This is translating to $in clause with empty collection","org.springframework.data.mongodb.repository.support.SpringDataMongodbSerializerUnitTests
org.springframework.data.mongodb.repository.AbstractPersonRepositoryIntegrationTests
org.springframework.data.mongodb.repository.support.SpringDataMongodbSerializer"
FILE,DATAMONGO,DATAMONGO-987,2014-07-14T12:01:52.000-05:00,Problem with lazy loading in @DBRef when getting data using MongoTemplate,"@Document 
 @Document




class Parent {




     @Id




     private String id;




     private String name;




     @DBref(lazy=true)




     private Child child;









    // getters and setters ommited




}






 
 @Document




class Child {




      @Id




       private String id;




       private String name;




      //getters and setters ommited




}






 
 Parent parent = new Parent();




parent.setName(""Daddy"");




mongoTemplate.save(parent); //ok, it is persisted like we expected.




// Than we try to load this same entity from the database




Criteria criteria = Criteria.where(""_id"").is(parent.getId());




Parent persisted = mongoTemplate.findOne(new Query(criteria), Parent.class);




// The child attribute should be null, right?




assertNull(persisted.getChild()); // it fails
@Document
class Parent {
@Id
private String id;
private String name;
@DBref(lazy=true)
private Child child;
// getters and setters ommited
}
and the Child class
@Document
class Child {
@Id
private String id;
private String name;
//getters and setters ommited
}
Parent parent = new Parent();
parent.setName(""Daddy"");
Criteria criteria = Criteria.where(""_id"").
is(parent.getId());
Parent persisted = mongoTemplate.findOne(new Query(criteria), Parent.class);
assertNull(persisted.getChild()); // it fails
The null attribute is actually an enhanced class generated by CGLib.
It should not be.
This brings a lot of problems when you, by accident, persist the same entity.
I attached a project with the JUnit test which reproduces the problem for you.","org.springframework.data.mongodb.core.convert.MappingMongoConverter
org.springframework.data.mongodb.core.convert.DbRefMappingMongoConverterUnitTests"
FILE,DATAMONGO,DATAMONGO-420,2012-03-22T10:09:35.000-05:00,Extra quotes being added to @Query values and fields,"@Query 
 @Query 
 { ?0 }
 
 { ?1 }
 
 someMethod( String values, String fields ) 
 String values = ""value : 'things'"";
   
 { ""value : 'things'"" }
   
 String values = ""field : 0"";
   
 { ""field : 0"" }
   
 String values = ""field\"" : \""0"";
Quotes are being added to values passed into @Query annotations.
@Query( value = ""
{ ?
0 }
"", fields = ""
{ ?
1 }
"" )
someMethod( String values, String fields );
Whatever I pass into ""values"" or ""fields"" gets wrapped in quotes when inserted into the query sent to MongoDB.
String values = ""value : 'things'"";
-> rendered as -
{ ""value : 'things'"" }
-> This is not a valid query - the double quotes around it break it.
String values = ""field : 0"";
-> rendered as -
{ ""field : 0"" }
-> This is not a valid projection - the double quotes around it break it.
String values = ""field\"" : \""0"";
-> rendered as -
{ ""field"" : ""0"" }
-> This is not a valid projection - the double quotes around zero turn it into a string so it renders as ""true"" instead of 0/undefined.
Thanks.","org.springframework.data.mongodb.repository.query.StringBasedMongoQuery
org.springframework.data.mongodb.repository.query.StringBasedMongoQueryUnitTests"
FILE,DATAMONGO,DATAMONGO-1053,2014-09-12T12:14:49.000-05:00,"In 1.6, any field in a mapped object named ""language"" will fail to map if it is a type other than String","package com.instantly.pipeline.engine.model;









import javax.persistence.Id;









public class Foobar {









    @Id




    String id;




    




    private Number language;









    public String getId() {




        return id;




    }









    public void setId(String id) {




        this.id = id;




    }









    public Number getLanguage() {




        return language;




    }









    public void setLanguage(Number language) {




        this.language = language;




    }




}
In 1.6, there is now a restriction that a field named ""language"" must be a String.
So, in 1.5, the following will map but will not map in 1.6:
package com.instantly.pipeline.engine.model;
import javax.persistence.Id;
public class Foobar {
@Id
String id;
private Number language;
public String getId() {
return id;
}
public void setId(String id) {
this.id = id;
}
public Number getLanguage() {
return language;
}
public void setLanguage(Number language) {
this.language = language;
}
}","org.springframework.data.mongodb.core.mapping.BasicMongoPersistentEntity
org.springframework.data.mongodb.core.mapping.BasicMongoPersistentEntityUnitTests"
FILE,DATAMONGO,DATAMONGO-1068,2014-10-08T19:43:32.000-05:00,elemMatch of Class Criteria fails to build special cirteria,"public class Room {




		private String name;




		private List<Date> occupied;




	}






 
 {




		occupied : {




			$not : {




				$elemMatch : {




					$gte : start,




					$lte : end




				}




			}




		}




	}






 
 Criteria c1 = new Criteria().gte(start).lte(end);




	Criteria c = Criteria.where(""occupied"").not().elemMatch(c1);






 
 {




	occupied : {




		$not : {




			$elemMatch : {




			}




		}




	}




}






  elemMatch(Criteria)
public class Room {
private String name;
private List<Date> occupied;
}
{
occupied : {
$not : {
$elemMatch : {
$gte : start,
$lte : end
}
}
}
}
Criteria c1 = new Criteria().
gte(start).
lte(end);
Criteria c = Criteria.where(""occupied"").
not().
elemMatch(c1);
But the serialization to JSON for c is:
{
occupied : {
$not : {
$elemMatch : {
}
}
}
}
It seems that c1 will be explained to empty Map by invoking elemMatch(Criteria) because I haven't assign a key to it.
But really no key I can assign to it.","org.springframework.data.mongodb.core.query.CriteriaTests
org.springframework.data.mongodb.core.query.Criteria"
FILE,DATAMONGO,DATAMONGO-1050,2014-09-09T03:41:12.000-05:00,"SimpleMongoRepository.findById(id, class)  don't return ids for nested documents.","class A {




 private String id; //stored in mongo as ""id""




 private String name;




}









 class B {




  private String id; // stored in mongo as ""_id""




  private List<A> innerDocs;




}






     
  
 @Data  @NoArgsConstructor
SimpleMongoRepository.findById(id, class)  don't return ids for nested documents.
class A {
private String id; //stored in mongo as ""id""
private String name;
}
class B {
private String id; // stored in mongo as ""_id""
private List<A> innerDocs;
}
When it return B documents, innerDocs A objects have id == null.
If i refactor A.id to A.myId, then it start working correctly.
Saving data (save, updateFirst, etc) always save fields correctly.
A and B objects are pojos (only lombok @Data and @NoArgsConstructor is used to provide getters and setters).
Ids are created by mongo.
Could it related somehow  to ids that have 24 characters, but stored not as ""_id""?
Easy workaround is to have different field name (not ""id"").","org.springframework.data.mongodb.core.mapping.BasicMongoPersistentProperty
org.springframework.data.mongodb.core.convert.MappingMongoConverterUnitTests
org.springframework.data.mongodb.core.mapping.BasicMongoPersistentPropertyUnitTests
org.springframework.data.mongodb.core.convert.QueryMapperUnitTests"
FILE,DATAMONGO,DATAMONGO-1078,2014-10-28T02:23:26.000-05:00,@Query annotated repository query fails to map complex Id structure.,"@Query(""{'_id': {$in: ?0}}"")




List<User> findByUserIds(Collection<MyUserId> userIds) 
 {$in: [ {_class:""com.sampleuser.MyUserId"", userId:""...."", sampleId:""....""}
StringBasedMongoQuery converts any complex object to the according mongo type including type restrictions via _class.
@Query(""{'_id': {$in: ?
0}}"")
List<User> findByUserIds(Collection<MyUserId> userIds);
end up being converted to:
{_id:  {$in: [ {_class:""com.sampleuser.MyUserId"", userId:""...."", sampleId:""....""}, ...","org.springframework.data.mongodb.core.convert.MappingMongoConverter
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-1088,2014-11-07T03:08:58.000-06:00,"@Query $in does not remove ""_class"" property on collection of embedded objects","@Query(value = ""{ embedded : { $in : ?0} }"")




	List<Foo> findByEmbeddedIn2(Collection<EmbeddedObject> c)
@Query(value = ""{ embedded : { $in : ?
0} }"")
List<Foo> findByEmbeddedIn2(Collection<EmbeddedObject> c);
generates incorrect query.
{ ""embedded"" : { ""$in"" : [ {  ""_class"" : ""demo.EmbeddedObject"" , ""s"" : ""hello""}]}}
{ ""embedded"" : { ""$in"" : [ { ""s"" : ""hello""}]}}
This bug is related to https://jira.spring.io/browse/DATAMONGO-893","org.springframework.data.mongodb.core.convert.MappingMongoConverter
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-1043,2014-09-01T05:30:48.000-05:00,SpEL Expressions in @Document annotations are not re-evaluated for query executions,"@Document
Based on the idea of Oliver Gierke in https://jira.spring.io/browse/DATAMONGO-525 I followed some post like the ones below http://stackoverflow.com/questions/18129291/mongodb-and-spel-expressions-in-document-annotations and http://stackoverflow.com/questions/19807733/mongodb-multi-tenacy-spel-with-document?rq=1 but in the end I realized that the problem is that AbstractMongoQuery is cached between requests(maybe a problem in my config?)
, and its query-method object of type MongoQueryMethod, which holds the metadata, MongoEntityMetadata.
And thus make this approach (use SpEL in @Document annotation) not fully working.
AbstractMongoQuery deals with different kind of executions.
All of them but SingleEntityExecution suffers from this problem, and it's because in SingleEntityExecution mongoOperations is called without passing collectionName and thus letting, in the end, BasicMongoPersistentEntity.getCollection apply SpEL over entity class to obtain the runtime collection name.","org.springframework.data.mongodb.repository.query.SimpleMongoEntityMetadata
org.springframework.data.mongodb.repository.query.MongoQueryMethod"
FILE,DATAMONGO,DATAMONGO-1123,2014-12-17T09:39:36.000-06:00,"geoNear, does not return all matching elements, it returns only a max of 100 documents","public GeoResults<MyObject> findByTypeAndLocationNear(MyObjectType type, Point p, Distance distance) {




   final NearQuery nearQuery = NearQuery.near(p).maxDistance(distance);




   log.info(""{}"",nearQuery.toDBObject());




   return mongoTemplate.geoNear(nearQuery, MyObject.class);




}






   
 {@link GeoResults}   {@link NearQuery}
Aloha,
public GeoResults<MyObject> findByTypeAndLocationNear(MyObjectType type, Point p, Distance distance) {
final NearQuery nearQuery = NearQuery.near(p).
maxDistance(distance);
log.info(""{}"",nearQuery.toDBObject());
return mongoTemplate.geoNear(nearQuery, MyObject.class);
}
The geoNear method is documented like this:
Returns {@link GeoResults} for all entities matching the given {@link NearQuery}.
I expect 1000 ""matching"" documents But i only get 100.
There is some default being set, that restricts the result to 100.
That should be stated in the method.
And another method having a pageable should be added.
What do you think?",org.springframework.data.mongodb.core.MongoOperations
FILE,DATAMONGO,DATAMONGO-1126,2014-12-21T06:03:21.000-06:00,Repository keyword query findByInId with pageable not returning correctly,"getTotalElements()   getTotalPages()  
 @Document




public class Item {









    @Id




    private String id;




    private String type;




}












 public interface ItemRepository extends MongoRepository<Item, String> {









    Page<Item> findByIdIn(Collection ids, Pageable pageable);




    Page<Item> findByTypeIn(Collection types, Pageable pageable);




}












 @RunWith(SpringJUnit4ClassRunner.class)




@ContextConfiguration(classes = {MongoDbConfig.class})




@TransactionConfiguration(defaultRollback = false)




public class TestPageableIdIn {









    @Autowired




    private ItemRepository itemRepository;




    




    private List<String> allIds = new LinkedList<>();









    @Before




    public void setUp() {




        itemRepository.deleteAll();




        String[] types = {""SWORD"", ""SHIELD"", ""ARMOUR""};









        // 10 items per type




        for (String type : types) {




            for (int i = 0; i < 10; i++) {




                String id = UUID.randomUUID().toString();




                allIds.add(id);




                itemRepository.save(new Item(id, type));




            }




        }




    }









    @Test




    public void testPageableIdIn() {




        




        Pageable pageable = new PageRequest(0, 5);




        




        // expect 5 Items returned, total of 10 Items(SWORDS) in 2 Pages




        Page<Item> results = itemRepository.findByTypeIn(Arrays.asList(""SWORD""), pageable);




        Assert.assertEquals(5, results.getContent().size());




        Assert.assertEquals(10, results.getTotalElements());




        Assert.assertEquals(2, results.getTotalPages());




        




        // expect 5 Items returned, total of 30 Items in 6 Pages




        results = itemRepository.findByIdIn(allIds, pageable);




        Assert.assertEquals(5, results.getContent().size());




        Assert.assertEquals(30, results.getTotalElements()); // this is returning 0




        Assert.assertEquals(6, results.getTotalPages());     // this is returning 0




    }




}
The query returns results but getTotalElements() and getTotalPages() always returns 0.
Also when you try to get any other page than 0, no results return.
I've tried using In with another member other than id and it works as expected.
@Document
public class Item {
@Id
private String id;
private String type;
}
public interface ItemRepository extends MongoRepository<Item, String> {
Page<Item> findByIdIn(Collection ids, Pageable pageable);
Page<Item> findByTypeIn(Collection types, Pageable pageable);
}
@RunWith(SpringJUnit4ClassRunner.class)
@ContextConfiguration(classes = {MongoDbConfig.class})
@TransactionConfiguration(defaultRollback = false)
public class TestPageableIdIn {
@Autowired
private ItemRepository itemRepository;
private List<String> allIds = new LinkedList<>();
@Before
public void setUp() {
itemRepository.deleteAll();
String[] types = {""SWORD"", ""SHIELD"", ""ARMOUR""};
// 10 items per type
for (String type : types) {
for (int i = 0; i < 10; i++) {
String id = UUID.randomUUID().
toString();
allIds.add(id);
itemRepository.save(new Item(id, type));
}
}
}
@Test
public void testPageableIdIn() {
Pageable pageable = new PageRequest(0, 5);
Page<Item> results = itemRepository.findByTypeIn(Arrays.asList(""SWORD""), pageable);
Assert.assertEquals(5, results.getContent().
size());
Assert.assertEquals(10, results.getTotalElements());
Assert.assertEquals(2, results.getTotalPages());
results = itemRepository.findByIdIn(allIds, pageable);
Assert.assertEquals(5, results.getContent().
size());
Assert.assertEquals(30, results.getTotalElements()); // this is returning 0
Assert.assertEquals(6, results.getTotalPages());     // this is returning 0
}
}","org.springframework.data.mongodb.repository.Person
org.springframework.data.mongodb.repository.query.AbstractMongoQueryUnitTests
org.springframework.data.mongodb.core.MongoOperations
org.springframework.data.mongodb.core.MongoTemplate
org.springframework.data.mongodb.repository.query.AbstractMongoQuery"
FILE,DATAMONGO,DATAMONGO-1202,2015-04-14T02:36:40.000-05:00,Indexed annotation problems under generics,"@Indexed
There is a problem with the @Indexed annotation with the model classes.
Under simple scenarios with reflexive DBRef relations works as expected, but if used in conjunction with generics it doesn't create the index expected.
This test runs without a Mongo server because it uses embedmongo-spring (https://github.com/jirutka/embedmongo-spring) at a random port each time the test runs.
If you run Application it will just create indexes and put some data in customer collection assuming a MongoD is running locally at 27017","org.springframework.data.mongodb.core.index.MongoPersistentEntityIndexResolver
org.springframework.data.mongodb.core.index.MongoPersistentEntityIndexCreator
org.springframework.data.mongodb.core.index.MongoPersistentEntityIndexCreatorIntegrationTests
org.springframework.data.mongodb.core.index.IndexResolver"
FILE,DATAMONGO,DATAMONGO-1250,2015-07-03T21:07:44.000-05:00,Custom converter implementation not used in updates,"@Document 
 
 
 @Document




public class MyPersistantObject  
 public Allocation allocation;




     public BigDecimal value;









     
 private final String code;









         Allocation(String code) {




            this.code = code;




        }









         public static Converter<Allocation, String> writer() {




            return new Converter<Allocation, String>() {




                public String convert(Allocation allocation) {




                    return allocation.getCode();




                }




            };




        }









         public static Converter<String, Allocation> reader() {




            return new Converter<String, Allocation>() {




                public Allocation convert(String source) {




                    return Allocation.getByCode(source);




                }




            };




        }









         public static Allocation getByCode(String code)  
 return AVAILABLE;




                 
 return ALLOCATED;




             
 throw new IllegalArgumentException(""Unable to get Allocation from: "" + code);




         
 public String getCode() {




            return code;




        }




     
 @Bean




    public CustomConversions customConversions() {




        return new CustomConversions(Arrays.asList(




                MyPersistantObject.Allocation.reader(),




                MyPersistantObject.Allocation.writer()




        ));




    }






 
 @Test




    public void testConversion() {




        Update update;




        Query query;




        MyPersistantObject returned;




        MyPersistantObject myPersistantObject = new MyPersistantObject();




        myPersistantObject.allocation = AVAILABLE;




        myPersistantObject.value = new BigDecimal(1234567);









        mongoTemplate.save(myPersistantObject);









        // Check it was saved correctly - first with invalid allocation to confirm conversion in query




        query = query(where(""allocation"").is(ALLOCATED));




        assertThat(mongoTemplate.findOne(query, MyPersistantObject.class), is(nullValue()));









        // Check it was saved correctly - now with valid allocation to confirm conversion in query




        query = query(where(""allocation"").is(AVAILABLE));




        returned = mongoTemplate.findOne(query, MyPersistantObject.class);




        assertThat(returned.allocation, is(AVAILABLE));




        assertThat(returned.value.longValue(), is(1234567L));









        try {




            // Update allocation from constant - will fail




            update = update(""allocation"", ALLOCATED);




            mongoTemplate.updateMulti(query, update, MyPersistantObject.class);




        } catch (Exception e) {




            System.err.println(""failed to convert allocation: java.lang.IllegalArgumentException: can't serialize class converter_test.MyPersistantObject$Allocation"");




        }









        // Update allocation from string value - succeeds




        update = update(""allocation"", ALLOCATED.getCode());




        mongoTemplate.updateMulti(query, update, MyPersistantObject.class);




        // Check allocation update




        query = query(where(""allocation"").is(ALLOCATED));




        returned = mongoTemplate.findOne(query, MyPersistantObject.class);




        assertThat(returned.allocation, is(ALLOCATED));









        // Update value only - will fail: Caused by: java.lang.IllegalArgumentException: Unable to get MyPersistantObject.Allocation from: 54321




        // Tries to use MyPersistantObject.Allocation converter to String




        update = update(""value"", new BigDecimal(54321));




        mongoTemplate.updateMulti(query, update, MyPersistantObject.class);




        // Check value update




        returned = mongoTemplate.findAll(MyPersistantObject.class).get(0);




        assertThat(returned.value.longValue(), is(54321L));




    }
There does seem to be an issue with the use of customer converters when used in mongoTemplate.update* via an Update object.
It also works when building and executing a Query object.
However when used in an Update, it is either ignored, or called in situations where it shouldn't.
@Document
public class MyPersistantObject {
public Allocation allocation;
public BigDecimal value;
public enum Allocation {
AVAILABLE(""V""),
ALLOCATED(""A"");
private final String code;
Allocation(String code) {
this.code = code;
}
public static Converter<Allocation, String> writer() {
return new Converter<Allocation, String>() {
public String convert(Allocation allocation) {
return allocation.getCode();
}
};
}
public static Converter<String, Allocation> reader() {
return new Converter<String, Allocation>() {
public Allocation convert(String source) {
return Allocation.getByCode(source);
}
};
}
public static Allocation getByCode(String code) {
switch (code) {
case ""V"":
return AVAILABLE;
case ""A"":
return ALLOCATED;
}
throw new IllegalArgumentException(""Unable to get Allocation from: "" + code);
}
public String getCode() {
return code;
}
}
}
It simply converts back and forward using a short code rather than the full Enum name.
These are registered in the Spring Boot application entry point:
@Bean
public CustomConversions customConversions() {
return new CustomConversions(Arrays.asList(
MyPersistantObject.Allocation.reader(),
MyPersistantObject.Allocation.writer()
));
}
@Test
public void testConversion() {
Update update;
Query query;
MyPersistantObject returned;
MyPersistantObject myPersistantObject = new MyPersistantObject();
myPersistantObject.allocation = AVAILABLE;
myPersistantObject.value = new BigDecimal(1234567);
mongoTemplate.save(myPersistantObject);
// Check it was saved correctly - first with invalid allocation to confirm conversion in query
query = query(where(""allocation"").
is(ALLOCATED));
assertThat(mongoTemplate.findOne(query, MyPersistantObject.class), is(nullValue()));
// Check it was saved correctly - now with valid allocation to confirm conversion in query
query = query(where(""allocation"").
is(AVAILABLE));
returned = mongoTemplate.findOne(query, MyPersistantObject.class);
assertThat(returned.allocation, is(AVAILABLE));
assertThat(returned.value.longValue(), is(1234567L));
try {
// Update allocation from constant - will fail
update = update(""allocation"", ALLOCATED);
mongoTemplate.updateMulti(query, update, MyPersistantObject.class);
} catch (Exception e) {
System.err.println(""failed to convert allocation: java.lang.IllegalArgumentException: can't serialize class converter_test.
MyPersistantObject$Allocation"");
}
// Update allocation from string value - succeeds
update = update(""allocation"", ALLOCATED.getCode());
mongoTemplate.updateMulti(query, update, MyPersistantObject.class);
// Check allocation update
query = query(where(""allocation"").
is(ALLOCATED));
returned = mongoTemplate.findOne(query, MyPersistantObject.class);
assertThat(returned.allocation, is(ALLOCATED));
// Update value only - will fail: Caused by: java.lang.IllegalArgumentException: Unable to get MyPersistantObject.Allocation from: 54321
// Tries to use MyPersistantObject.Allocation converter to String
update = update(""value"", new BigDecimal(54321));
mongoTemplate.updateMulti(query, update, MyPersistantObject.class);
// Check value update
returned = mongoTemplate.findAll(MyPersistantObject.class).
get(0);
assertThat(returned.value.longValue(), is(54321L));
}
Hopefully that makes sense.
Firstly it saves and queries for the object to demonstrate that the converters are called correctly on the document.
I have confirmed that the document in the database correctly stores the Enum code rather than the name.
By use of a positive and negative case, it appears that the converter is being called correctly when used in the Query builder.
When it comes to an Update, the Enum is unable to be serialised correctly, and an exception is thrown to that effect.
If I change it to use the code (a String), it works and we confirm that by Querying it back from the DB.
So it appears that the customer converter for converting from my Enum is not called in this situation.
Next I try and update the other value in the Document.
The BigDecimal is converted to a String by an existing converter I assume, but then my customer converter is called to try and convert the numeric String into an Allocation Enum which of course fails.
I tried to debug the code and it seems that there is an overloaded method in CustomConversions: getCustomWriteTarget that takes one or two arguments, the second being a requestedTargetType.
That second variant never seems to be called in MappingMongoConverter, but perhaps if that type information was passed then it would not use my Allocation converter.
Without type information it seems the default is just to use the first converter that can handle the input type, in this case a String.
It is my custom one which is picked up first but can't actually handle it.
Please advise if there is something I am missing, as I can't find a workaround either - I have resorted to the Mongo Driver itself to do the update.","org.springframework.data.mongodb.core.convert.UpdateMapperUnitTests
org.springframework.data.mongodb.core.convert.UpdateMapper"
FILE,DATAMONGO,DATAMONGO-1269,2015-08-04T23:04:39.000-05:00,QueryMapper drops numeric keys in Maps.,"@Test




public void SO_31799474() {









	SomeContent content = new SomeContent();




	content.text = ""foo"";









	SO31799474 entity = new SO31799474();




	entity.id = ""id-1"";









	entity.map = Collections.singletonMap(Integer.valueOf(1), content);









	template.save(entity);









	assertThat(template.findOne(query(where(""map.1.text"").is(""foo"")), SO31799474.class), notNullValue());




}









 static class SO31799474 {




	String id;




	Map<Integer, SomeContent> map;









	@Override




	public String toString() {




		return ""SO31799474 [id="" + id + "", map="" + map + ""]"";




	}









}
As of 1.7.1 numeric keys get dropped in query mapping.
@Test
public void SO_31799474() {
SomeContent content = new SomeContent();
content.text = ""foo"";
SO31799474 entity = new SO31799474();
entity.id = ""id-1"";
entity.map = Collections.singletonMap(Integer.valueOf(1), content);
template.save(entity);
assertThat(template.findOne(query(where(""map.1.
text"").
is(""foo"")), SO31799474.class), notNullValue());
}
static class SO31799474 {
String id;
Map<Integer, SomeContent> map;
@Override
public String toString() {
return ""SO31799474 [id="" + id + "", map="" + map + ""]"";
}
}","org.springframework.data.mongodb.core.convert.QueryMapper
org.springframework.data.mongodb.core.convert.UpdateMapper
org.springframework.data.mongodb.core.convert.QueryMapperUnitTests"
FILE,DATAMONGO,DATAMONGO-1307,2015-10-20T12:33:45.000-05:00,Stop converting user-defined runtime exceptions to NPEs,"throw exceptionTranslator.translateExceptionIfPossible(ex);
  
 
 
 
 return null;
MongoTemplate has code like this in many places:
} catch (RuntimeException ex) { throw exceptionTranslator.translateExceptionIfPossible(ex);
MongoExceptionTranslator, however, often does NOT return an exception.
If it encounters an unknown exception it does this:
// If we get here, we have an exception that resulted from user code,
// rather than the persistence provider, so we return null to indicate
// that translation should not occur.
return null;
MongoTemplate then ""eats"" the original exception and throws a null-pointer exception instead.",org.springframework.data.mongodb.core.MongoTemplate
FILE,DATAMONGO,DATAMONGO-1263,2015-07-30T09:03:41.000-05:00,Missing indexes in associations involving generic types,"class Book  
 class AbstractProduct  
 class ProductWrapper    
 class Catalog
When an association between documents involves generic types, the type information is not correctly inferred at startup time resulting in missing indexes.
Please, see https://github.com/agustisanchez/SpringDataMongoDBBug, for code samples.
class Book with index on ""ISBN"" attribute super class AbstractProduct with index on ""name"" attribute class ProductWrapper holding attribute ""content"" of generic type ""T extends AbstractProduct""
List<ProductWrapper<Book>> books2 = new ArrayList<>
The index ""name"" inherited from AbstractProduct is created (book2.content.name) inside ""catalog"" , but the index defined on the Book class itself (isbn) is not created as Spring Data Mongo is only inferring type infromation from the ProductWrapper class definition (ProductWrapper <T extends AbstractProduct>).
If the wrapper class is defined as ProductWrapper<T>, then no indexes are created at all on Catalog.books2.content.","org.springframework.data.mongodb.core.index.MongoPersistentEntityIndexResolver
org.springframework.data.mongodb.core.index.MongoPersistentEntityIndexResolverUnitTests"
FILE,DATAMONGO,DATAMONGO-1290,2015-09-17T15:30:23.000-05:00,@Query annotation with byte[] parameter does not work,"Optional<SampleDomainObject> findBySampleData(byte[] sampleDate) 
 @Query(""{ 'sampleData' : ?0 }"")




Optional<SampleDomainObject> findBySampleDateWithAnnotation(byte[] sampleData)
Optional<SampleDomainObject> findBySampleData(byte[] sampleDate);
@Query(""{ 'sampleData' : ?
0 }"")
Optional<SampleDomainObject> findBySampleDateWithAnnotation(byte[] sampleData);
... but only the first works.","org.springframework.data.mongodb.repository.query.StringBasedMongoQuery
org.springframework.data.mongodb.repository.query.StringBasedMongoQueryUnitTests"
FILE,DATAMONGO,DATAMONGO-1360,2016-01-16T07:47:34.000-06:00,Cannot query with JSR310,"query.addCriteria(where(""createdDate"").lte(LocalDateTime.now()));
{
""_id"" : ""1"",
""_class"" : ""SomeClass"",
""createdDate"" : ISODate(""2016-01-16T07:05:45.656Z""),
""lastUpdate"" : ISODate(""2016-01-16T07:05:45.656Z"")
}
query.addCriteria(where(""createdDate"").
lte(LocalDateTime.now()));
The resulting MongoDb query looks like this:
{ ""createdDate"" : { ""$lte"" : { $java : 2016-01-16T14:36:50.656 } } }
It consequently fails with this message:
java.lang.IllegalArgumentException: can't serialize class java.time.LocalDateTime at org.bson.BasicBSONEncoder.
_putObjectField(BasicBSONEncoder.java:299)
It does not fail when I use a java.util.Date in my query even though I have stilled persisted my document with a java.time.LocalDateTime object.
The query then looks slightly different like this:
{ ""createdDate"" : { ""$lte"" : { ""$date"" : ""2016-01-16T07:35:19.985Z""}}}
I'm hoping there is a way to not have to convert my LocalDateTime objects to Date objects for querying.
Please advise.
Cheers,
Bjorn","org.springframework.data.mongodb.core.Venue
org.springframework.data.mongodb.core.geo.AbstractGeoSpatialTests
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-1438,2016-05-26T14:01:14.000-05:00,I get a warning in my logs since switched to Spring Data MongoDB Hopper-SR1 Release Train in Spring Boot 1.3.5,"@Document
When I start my Spring Boot 1.3.5 application with no custom conversions and with Spring Data MongoDB Release Train Hopper-SR1 I get following warning in my logs:
Registering converter from class java.lang.Number to class java.lang.Number as writing converter although it doesn't convert to a Mongo supported type!
You might wanna check you annotation setup at the converter implementation.
With the in Spring Boot 1.3.5 integrated version the warning is not exists.
.","org.springframework.data.mongodb.core.convert.MongoConvertersUnitTests
org.springframework.data.mongodb.core.convert.MongoConverters"
FILE,DATAMONGO,DATAMONGO-1394,2016-03-09T10:36:46.000-06:00,References not handled correctly when using QueryDSL,"public class Book {




     @DBRef




     private Library library;




} 












 
 public class Library {




     @Id




     private String id;




}












  
   ;




QBook book = QBook.book;




BooleanExpression exp = book.library.id.eq(library_id);




    




List<Book> list = bookRepository.findAll(exp);  // EMPTY






 
  
 Library library = libraryRepository.findById(library_id);




QBook book = QBook.book;




BooleanExpression exp = book.library.eq(library);









List<Book> list = bookRepository.findAll(exp);  // EXPECTED ITEMS






 
  
 List<Book> list = bookRepository.findByLibraryId(library_id) // EXPECTED ITEMS
Book.java
public class Book {
@DBRef
private Library library;
}
Library.java
public class Library {
@Id
private String id;
}
BookService.java
String library_id = [SOME_ID];
QBook book = QBook.book;
BooleanExpression exp = book.library.id.eq(library_id);
List<Book> list = bookRepository.findAll(exp);  // EMPTY
BookService.java
Library library = libraryRepository.findById(library_id);
QBook book = QBook.book;
BooleanExpression exp = book.library.eq(library);
List<Book> list = bookRepository.findAll(exp);  // EXPECTED ITEMS
BookService.java
List<Book> list = bookRepository.findByLibraryId(library_id) // EXPECTED ITEMS","org.springframework.data.mongodb.repository.support.SpringDataMongodbSerializer
org.springframework.data.mongodb.repository.support.QuerydslRepositorySupportTests"
FILE,DATAMONGO,DATAMONGO-1406,2016-04-04T18:59:49.000-05:00,Query mapper does not use @Field field name when querying nested fields in combination with nested keywords,";






@Document(collection = ""Computer"")




public class Computer




{




   @Id




   private String _id;









   private String batchId;









  @Field(""stat"")




   private String status;









   @Field(""disp"")




   private List<Monitor> displays;









   //setters and getters




}









public class Monitor {




   @Field(""res"")




   private String resolution;









  // setters/getters




}






   
 protected <S, T> List<T> doFind(String collectionName, DBObject query, DBObject fields, Class<S> entityClass,




			CursorPreparer preparer, DbObjectCallback<T> objectCallback)









 DBObject mappedQuery = queryMapper.getMappedObject(query, entity);






  @Field   
  
  
 
  
  @Field
@Document(collection = ""Computer"")
public class Computer
{
@Id
private String _id;
private String batchId;
@Field(""stat"")
private String status;
@Field(""disp"")
private List<Monitor> displays;
//setters and getters
}
public class Monitor {
@Field(""res"")
private String resolution;
// setters/getters
}
protected <S, T> List<T> doFind(String collectionName, DBObject query, DBObject fields, Class<S> entityClass,
CursorPreparer preparer, DbObjectCallback<T> objectCallback)
DBObject mappedQuery = queryMapper.getMappedObject(query, entity);
resolves the fields to the input query to the ones in the @Field annotations, except for these in embedded arrays.
So, in the example above, resolution fields in DBObject remains resolution.
While, the status field resolves to stat.
Note the queries in the inner list, are setup as elemMatch.
{ ""$and"" : [ { ""stat"" : ""A""} , { ""disp"" : { ""$elemMatch"" : { ""$and"" : [ { ""resolution"" : { ""$ne"" :  null }} , { ""resolution"" : { ""$ne"" : """"}}]}}}] , ""batchId"" : ""5d0f1c53-92a2-48cb-8c84-1061769962c1""}
Which doesn't get any data, because there is no field called resolution (the field in mongo is res).
{ ""$and"" : [ { ""status"" : ""A""} , { ""displays"" : { ""$elemMatch"" : { ""$and"" : [ { ""resolution"" : { ""$ne"" :  null }} , { ""resolution"" : { ""$ne"" : """"}}]}}}] , ""batchId"" : ""5d0f1c53-92a2-48cb-8c84-1061769962c1""}
Notice the status and displays fields correctly get converted to the value in the @Field annotation.
{ ""$and"" : [ { ""stat"" : ""A""} , { ""disp"" : { ""$elemMatch"" : { ""$and"" : [ { ""res"" : { ""$ne"" :  null }} , { ""res"" : { ""$ne"" : """"}}]}}}] , ""batchId"" : ""5d0f1c53-92a2-48cb-8c84-1061769962c1""}
This basically means that any queries that operate on fields (with a name different from the peristed name) in the inner list will fail.","org.springframework.data.mongodb.core.convert.QueryMapper
org.springframework.data.mongodb.core.convert.QueryMapperUnitTests"
FILE,DATAMONGO,DATAMONGO-1486,2016-09-07T16:46:53.000-05:00,Changes to MappingMongoConverter Result in Class Cast Exception,"Map<Integer, Map<Platform, String>> descriptions = new HashMap<>();






 
 public void setAlternateDescriptionMap(int compositeId, Map<Integer, Map<Platform, String>> alternateDescriptionsMap) {




		Query query = new Query();




		query.addCriteria(Criteria.where(""_id"").is(compositeId));




		Update update = new Update();




		update.set(""alternateDescriptionMap"", alternateDescriptionsMap);









		coreMongoTemplate.updateFirst(query, update, ""product"");




	}






   
    
 
 MappingMongoConverter.convertMongoType()
I am upgrading our software to use Spring Boot 1.4 + Spring 4.3.
As part of this upgrade, we are also using Spring Data Mongo 1.9.2.
RELEASE.
I am assuming that is 1.9.2 (Hopper SR2)?
Map<Integer, Map<Platform, String>> descriptions = new HashMap<>();
Where ""Platform is Enum"", although this is not the core issue.
public void setAlternateDescriptionMap(int compositeId, Map<Integer, Map<Platform, String>> alternateDescriptionsMap) {
Query query = new Query();
query.addCriteria(Criteria.where(""_id"").
is(compositeId));
Update update = new Update();
update.set(""alternateDescriptionMap"", alternateDescriptionsMap);
coreMongoTemplate.updateFirst(query, update, ""product"");
}
We end up getting the following exception:
java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.String
at com.mongodb.DBObjectCodec.encodeMap(DBObjectCodec.java:222)
at com.mongodb.DBObjectCodec.writeValue(DBObjectCodec.java:199)
at com.mongodb.DBObjectCodec.encodeMap(DBObjectCodec.java:223)
at com.mongodb.DBObjectCodec.writeValue(DBObjectCodec.java:199)
at com.mongodb.DBObjectCodec.encode(DBObjectCodec.java:131)
at com.mongodb.DBObjectCodec.encode(DBObjectCodec.java:62)
at org.bson.codecs.BsonDocumentWrapperCodec.encode(BsonDocumentWrapperCodec.java:63)
at org.bson.codecs.BsonDocumentWrapperCodec.encode(BsonDocumentWrapperCodec.java:29)
at com.mongodb.connection.RequestMessage.addDocument(RequestMessage.java:253)
at com.mongodb.connection.RequestMessage.addDocument(RequestMessage.java:205)
at com.mongodb.connection.UpdateMessage.encodeMessageBodyWithMetadata(UpdateMessage.java:80)
at com.mongodb.connection.RequestMessage.encodeWithMetadata(RequestMessage.java:160)
at com.mongodb.connection.WriteProtocol.execute(WriteProtocol.java:89)
at com.mongodb.connection.UpdateProtocol.execute(UpdateProtocol.java:67)
at com.mongodb.connection.UpdateProtocol.execute(UpdateProtocol.java:42)
at com.mongodb.connection.DefaultServer$DefaultServerProtocolExecutor.execute(DefaultServer.java:168)
at com.mongodb.connection.DefaultServerConnection.executeProtocol(DefaultServerConnection.java:289)
at com.mongodb.connection.DefaultServerConnection.update(DefaultServerConnection.java:88)
at com.mongodb.operation.UpdateOperation.executeProtocol(UpdateOperation.java:66)
at com.mongodb.operation.BaseWriteOperation$1.call(BaseWriteOperation.java:144)
at com.mongodb.operation.BaseWriteOperation$1.call(BaseWriteOperation.java:134)
at com.mongodb.operation.OperationHelper.withConnectionSource(OperationHelper.java:232)
at com.mongodb.operation.OperationHelper.withConnection(OperationHelper.java:223)
at com.mongodb.operation.BaseWriteOperation.execute(BaseWriteOperation.java:134)
at com.mongodb.operation.BaseWriteOperation.execute(BaseWriteOperation.java:61)
at com.mongodb.Mongo.execute(Mongo.java:827)
at com.mongodb.Mongo$2.execute(Mongo.java:810)
at com.mongodb.DBCollection.executeWriteOperation(DBCollection.java:333)
at com.mongodb.DBCollection.updateImpl(DBCollection.java:495)
at com.mongodb.DBCollection.update(DBCollection.java:455)
at com.mongodb.DBCollection.update(DBCollection.java:432)
at org.springframework.data.mongodb.core.MongoTemplate$12.doInCollection(MongoTemplate.java:1153)
at org.springframework.data.mongodb.core.MongoTemplate$12.doInCollection(MongoTemplate.java:1132)
at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:462)
at org.springframework.data.mongodb.core.MongoTemplate.doUpdate(MongoTemplate.java:1132)
at org.springframework.data.mongodb.core.MongoTemplate.updateFirst(MongoTemplate.java:1110)
at com.build.dao.product.ProductStorageDaoImpl.setAlternateDescriptionMap(ProductStorageDaoImpl.java:1170)
at com.build.dao.product.ProductStorageDaoImpl$$FastClassBySpringCGLIB$$4e03147e.
invoke(<generated>)
at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:720)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:136)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:655)
at com.build.dao.product.ProductStorageDaoImpl$$EnhancerBySpringCGLIB$$8602f8b4.
setAlternateDescriptionMap(<generated>)
at com.build.dao.product.ProductStorageDaoIT.testSaveAlternateDescriptionsToCacheAndFetch(ProductStorageDaoIT.java:335)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:497)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:252)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:94)
at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:191)
at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
We do not get this exception in spring-data-mongodb-1.9.1-RELEASE.
After a lot of debugging, It appears to be related to the code in MappingMongoConverter.convertMongoType().
It looks like the Issue DATAMONGO-1423 may have introduced this issue:
https://github.com/spring-projects/spring-data-mongodb/commit/0e60630393980cf2bb4634c8a9c1a5a50407c471
I am going to work on just overriding this default method with a custom mapper.
I suspect this code will also break in other cases where the key is mapped into anything other than a string.
Let me know if you need any further input.","org.springframework.data.mongodb.core.convert.MappingMongoConverter
org.springframework.data.mongodb.core.convert.UpdateMapperUnitTests"
FILE,DATAMONGO,DATAMONGO-1498,2016-09-25T22:21:26.000-05:00,"MongoMappingContext doesn't know about types usually auto-detected (JodaTime, JDK 8 date time types)","@JsonProperty(""myDate"")




    private DateTime myDate;






 
 
 
  
 
  @JsonUnwrapped 
 @JsonProperty(""myDate"")




    @JsonUnwrapped




    private DateTime myDate;






  @JsonUnwrapped
(not sure if this issue should be opened for Spring Data REST or Spring Data Mongo, since the problem manifests itself in the contents rendered by SDR but the fix might probably go to the SD MongoDB)
As described in this SO thread, in Spring Boot 1.3.6, Spring Data 1.8.4, Spring Data REST 2.4.4 the Spring Data MongoDB entities that have a property of Joda DateTime type:
@JsonProperty(""myDate"")
private DateTime myDate;
gets rendered into in the REST representation of my Spring Data entity as
""myDate"": ""2016-09-25T15:58:37.486Z""
With Spring Boot 1.4.1, Spring Data MongoDB 1.9.3, Spring Data REST 2.5.3 same properties suddenly get represented as
""myDate"": {
""content"": ""2016-09-25T15:58:37.486Z""
},
It looks like Joda's DateTime started to get treated as data entity again:
https://jira.spring.io/browse/DATAMONGO-624
Adding Jackson2 @JsonUnwrapped annotation to the property helps to get representation back:
@JsonProperty(""myDate"")
@JsonUnwrapped
private DateTime myDate;
But this cannot be a solution since in case of auto-generated properties, e.g. from JSON schema.
there is only limited options to control generated annotations, especially since the @JsonUnwrapped must be set on all child/empbedded objects.
The Javadoc for the CustomConversions class states that
These types will be considered simple ones (which means they neither need deeper inspection nor nested conversion.
Thus the
CustomConversions also act as factory for SimpleTypeHolder
Which is in fact not true for Spring Data REST [any more], from what I can tell debugging my code.
The types that are added via default CustomConversions are not treated as simple ones when rendering JSON and properties of those types get serialised as embedded entity objects.
Here is the place in the Spring Data REST PersistentEntityJackson2Module that calls to Spring Data MongoDB PersistentEntity implementation to check whether the property type is simple or not.
And since the simpleTypeHolder in the Spring Data Commons AbstractMappingContext does not contain the types for which Spring Boot auto-configuration adds Joda DateTime converters, the DateTime field is treated as complex object.
This one presents a major problem upgrading from Spring Boot 1.3 to 1.4, since it breaks REST APIs by default with no generic solution known so far for all Joda DateTime properties in the project.","org.springframework.data.mongodb.repository.config.MongoRepositoryConfigurationExtension
org.springframework.data.mongodb.config.AuditingViaJavaConfigRepositoriesTests
org.springframework.data.mongodb.config.MongoAuditingRegistrar"
CLASS,derby-10.7.1.1,DERBY-4624,2010-04-21T05:30:55.000-05:00,Broken logic for avoiding testing across midnight in TimestampArithTest,"while (calendar.get(Calendar.HOUR) == 23
						&& calendar.get(Calendar.MINUTE) >= 58) {
					try {
						Thread.sleep((60 - calendar.get(Calendar.SECOND)) * 1000);
					} catch (InterruptedException ie) {
						// ignore it
					}
				}

 
 calendar.get(Calendar.HOUR)   calendar.get(Calendar.HOUR)
TimestampArithTest's decorator has this code to avoid failures in case the test starts close to midnight:
/*
* Make sure that we are not so close to midnight that TODAY
* might be yesterday before we are finished using it.
*/
while (calendar.get(Calendar.HOUR) == 23
&& calendar.get(Calendar.MINUTE) >= 58) {
try {
Thread.sleep((60 - calendar.get(Calendar.SECOND)) * 1000);
} catch (InterruptedException ie) {
// ignore it
}
}
There are at least three problems with this code:
1 (calendar.get(Calendar.HOUR) == 23) never evaluates to true, because calendar.get(Calendar.HOUR) returns values in the range 0-11.
Calendar.HOUR_OF_DAY should be used instead.
2 If the current time is after 23:58 and before 23:59, the code sleeps until 23:59, the test will wait until 23:59 before it starts, making it even more likely that it will cross midnight while running.
3 The code is executed after the Calendar object has been initialized, so if this code is ever triggered and waits until after midnight, the TODAY field is guaranteed to be yesterday when the test starts executing.",org.apache.derbyTesting.functionTests.tests.lang.TimestampArithTest
CLASS,derby-10.7.1.1,DERBY-4654,2010-05-12T05:27:40.000-05:00,Restriction.toSQL() doesn't escape special characters,"org.apache.derby.vti.Restriction.toSQL()  
 Restriction.doubleQuote()   IdUtil.normalToDelimited()
org.apache.derby.vti.Restriction.toSQL() adds double quotes around column names, but it does not escape the special characters (like double quotes) in the column names, so the returned string may not be valid SQL.
This could cause problems when using the restriction to generate a query against an external database.","org.apache.derbyTesting.functionTests.tests.lang.RestrictedVTITest
org.apache.derby.vti.Restriction"
CLASS,derby-10.7.1.1,DERBY-4664,2010-05-18T18:56:12.000-05:00,"Change Derby internal stored procedures to avoid DriverManager.getConnection(""jdbc:default:connection"") as it may be recognized by other Drivers","DriverManager.getConnection(""jdbc:default:connection"");    
  
   
    SystemProcedures.getDefaultConn()   InternalDriver.activeDriver()
Some Derby internal Stored procedures and functions call DriverManager.getConnection(""jdbc:default:connection""); and this url can be recognized by another Driver in the same classpath that is used for server side JDBC for another product.
For example the below occurred in NetworkServer when JCC was also loaded because the JCC Type 2 driver is used for server side JDBC:
java.lang.UnsatisfiedLinkError:
db2jcct2 (Not found in java.library.path):  ERRORCODE=-4472, SQLSTATE=null
com.ibm.db2.jcc.b.SqlException
at com.ibm.db2.jcc.b.bd.a(bd.java:660)
at com.ibm.db2.jcc.b.bd.a(bd.java:60)
at com.ibm.db2.jcc.b.bd.a(bd.java:94)
at com.ibm.db2.jcc.t2.a.a(a.java:37)
at com.ibm.db2.jcc.t2.T2Configuration.<clinit>(T2Configuration.java:94)
at java.lang.J9VMInternals.initializeImpl(Native Method)
at java.lang.J9VMInternals.initialize(J9VMInternals.java:196)
at com.ibm.db2.jcc.DB2Driver.connect(DB2Driver.java:211)
at java.sql.DriverManager.getConnection(DriverManager.java:572)
at java.sql.DriverManager.getConnection(DriverManager.java:218)
at org.apache.derby.impl.jdbc.LOBStoredProcedure.getEmbedConnection(Unknown Source)
at org.apache.derby.impl.jdbc.LOBStoredProcedure.getClobObjectCorrespondingtoLOCATOR(Unknown Source)
at org.apache.derby.impl.jdbc.LOBStoredProcedure.CLOBGETLENGTH(Unknown Source)
at org.apache.derby.exe.acf81e0010x0128x864dxbe82x00004c9b380d12.e0(Unknown Source)
at org.apache.derby.impl.services.reflect.DirectCall.invoke(Unknown Source)
at org.apache.derby.impl.sql.execute.RowResultSet.getNextRowCore(Unknown Source)
at org.apache.derby.impl.sql.execute.BasicNoPutResultSetImpl.getNextRow(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedResultSet.movePosition(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedResultSet.next(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedCallableStatement.executeStatement(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedPreparedStatement.execute(Unknown Source)
at org.apache.derby.impl.drda.DRDAStatement.execute(Unknown Source)
at org.apache.derby.impl.drda.DRDAConnThread.parseEXCSQLSTTobjects(Unknown Source)
at org.apache.derby.impl.drda.DRDAConnThread.parseEXCSQLSTT(Unknown Source)
at org.apache.derby.impl.drda.DRDAConnThread.processCommands(Unknown Source)
at org.apache.derby.impl.drda.DRDAConnThread.run(Unknown Source)
I think we can avoid this specific error by changing LobStoredProcedure (and perhaps other internal procedures)  to  use the code in  SystemProcedures.getDefaultConn() which always connects to Derby by using = InternalDriver.activeDriver()
This of course will not solve the general problem for any user created procedure or function that performs SQL.
I am not sure if there is a good solution for that.
I asked the JCC Driver team to see if there is a way they can determine if they are running inside the DB2 process or not.
but regardless of these product workarounds I think the basic problem is design flaw in the specification.
DriverManager cannot differentiate the URL if all database products use the same one for server side JDBC.",org.apache.derby.impl.jdbc.LOBStoredProcedure
CLASS,derby-10.7.1.1,DERBY-4665,2010-05-19T03:12:33.000-05:00,Unidiomatic error handling in TimestampArithTest,"printStackTrace(sqle);
					fail(""Unexpected exception from statement '"" + sql + ""'"");

 
 {
			System.out.println(s + "" is not a proper timestamp string."");
			System.out.println(e.getClass().getName() + "": "" + e.getMessage());
			e.printStackTrace();
			System.exit(1);
			return null;
		}
TimestampArithTest contains some error handling code that prevents the underlying error from being reported to the JUnit framework, and it may even terminate the JVM running the tests on some errors.
Examples:
This code prints the stack trace of the underlying error to the terminal, but it won't be included in the report from the JUnit framework:
printStackTrace(sqle);
					fail(""Unexpected exception from statement '"" + sql + ""'"");
This code terminates the JVM on error, preventing subsequent tests from running, and also preventing the JUnit framework to report the results from the tests that did run:
} catch (Exception e) {
			System.out.println(s + "" is not a proper timestamp string."")
;
			System.out.println(e.getClass().
getName() + "": "" + e.getMessage());
			e.printStackTrace();
			System.exit(1);
			return null;
		}","org.apache.derbyTesting.functionTests.tests.lang.TimestampArithTest.OneTest
org.apache.derbyTesting.functionTests.tests.lang.TimestampArithTest"
CLASS,derby-10.7.1.1,DERBY-4835,2010-10-06T11:05:13.000-05:00,Trigger plan does not recompile with upgrade from 10.5.3.0 to 10.6.1.0 causing  java.lang.NoSuchMethodError,"tidlggls(blt_number,create_date,update_date,propagation_date,glossary_status,
     time_stamp,min_max_size )
    
      
 
  
 tidlrblt(BLT,BLT_SIZE,MIN_MAX_SIZE)  
 
     
  
   GeneratedMe
thod;    
  
  
 if (fromVersion.majorVersionNumber >= DataDictionary.DD_VERSION_DERBY_10_5)
				bootingDictionary.updateMetadataSPSes(tc);
			else
				bootingDictionary.clearSPSPlans();

  clearSPSPlans()
Trigger plan does not recompile on upgrade from 10.5.3.0 to 10.6.1.0  causing the following exception  the first time the trigger is fired after upgrade.
ATABASE = wombat), (DRDAID = null), Failed Statement is: INSERT INTO tidlggls(blt_number,create_date,update_date,propagation_date,glossary_status,
     time_stamp,min_max_size )
 VALUES ( (select max(blt_number) from tidlrblt), CURRENT_DATE,
CURRENT_DATE, CURRENT_DATE, '00' , CURRENT_TIMESTAMP, (select min_max_size from tidlrblt where blt_number = (select max(blt_number) from tidlrblt)))
java.lang.NoSuchMethodError: org/apache/derby/iapi/sql/execute/ResultSetFactory.getProjectRestrictResultSet(Lorg/apache/derby/iapi/sql/execute/NoPutResultSet;Lorg/apache/derby/iapi/services/loader/GeneratedMethod;Lorg/apache/derby/iapi/services/loader/GeneratedMethod;ILorg/apache/derby/iapi/services/loader/GeneratedMethod;IZZDD)Lorg/apache/derby/iapi/sql/execute/NoPutResultSet;
at org.apache.derby.exe.acf81e0010x012bx823cxd0d3x00000026c4a00.g0(Unknown Source)
at org.apache.derby.exe.acf81e0010x012bx823cxd0d3x00000026c4a00.execute(Unknown Source)
at org.apache.derby.impl.sql.GenericActivationHolder.execute(Unknown Source)
at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
at org.apache.derby.impl.sql.GenericPreparedStatement.executeSubStatement(Unknown Source)
at org.apache.derby.impl.sql.execute.GenericTriggerExecutor.executeSPS(Unknown Source)
at org.apache.derby.impl.sql.execute.StatementTriggerExecutor.fireTrigger(Unknown Source)
at org.apache.derby.impl.sql.execute.TriggerEventActivator.notifyEvent(Unknown Source)
at org.apache.derby.impl.sql.execute.InsertResultSet.normalInsertCore(Unknown Source)
at org.apache.derby.impl.sql.execute.InsertResultSet.open(Unknown Source)
at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)
at org.apache.derby.impl.tools.ij.ij.executeImmediate(Unknown Source)
at org.apache.derby.impl.tools.ij.utilMain.doCatch(Unknown Source)
at org.apache.derby.impl.tools.ij.utilMain.runScriptGuts(Unknown Source)
at org.apache.derby.impl.tools.ij.utilMain.go(Unknown Source)
at org.apache.derby.impl.tools.ij.Main.go(Unknown Source)
at org.apache.derby.impl.tools.ij.Main.mainCore(Unknown Source)
at org.apache.derby.impl.tools.ij.Main.main(Unknown Source)
at org.apache.derby.tools.ij.main(Unknown Source)
Cleanup action completed
connect 'jdbc:derby:wombat;upgrade=true';
 
INSERT INTO tidlrblt(BLT,BLT_SIZE,MIN_MAX_SIZE) VALUES('Mamatha Testing2', 15, 20);
ERROR XJ001: Java exception: 'org/apache/derby/iapi/sql/execute/ResultSetFactory
.
getProjectRestrictResultSet(Lorg/apache/derby/iapi/sql/execute/NoPutResultSet;L
org/apache/derby/iapi/services/loader/GeneratedMethod;Lorg/apache/derby/iapi/ser
vices/loader/GeneratedMethod;ILorg/apache/derby/iapi/services/loader/GeneratedMe
thod;IZZDD)Lorg/apache/derby/iapi/sql/execute/NoPutResultSet;: java.lang.NoSuchM
ethodError'.
I think this may be related to the DERBY-1107 change in handleMinorRevisionChange which has the code:
if (fromVersion.majorVersionNumber >= DataDictionary.DD_VERSION_DERBY_10_5)
				bootingDictionary.updateMetadataSPSes(tc);
			else
				bootingDictionary.clearSPSPlans();
Likely, clearSPSPlans() should not be in the else clause but rather executed unconditionally.
To work around the issue, after connecting with 10.6.1, drop and recreate the trigger as in workaround.sql","org.apache.derby.impl.sql.catalog.DD_Version
org.apache.derbyTesting.functionTests.tests.upgradeTests.BasicSetup"
CLASS,derby-10.7.1.1,DERBY-4873,2010-10-28T18:45:13.000-05:00,NullPointerException in testBoundaries with ibm jvm 1.6,"testBoundaries(org.apache.derbyTesting.functionTests.tests.jdbcapi.InternationalConnectTest)
With the line skipping the testBoundaries fixture of the InternationalConnectTest commented out, I get the following stack when I run the test with ibm 1.6:
1 testBoundaries(org.apache.derbyTesting.functionTests.tests.jdbcapi.InternationalConnectTest)java.sql.SQLException: DERBY SQL error: SQLCODE: -1, SQLSTATE: XJ001, SQLERRMC: java.lang.NullPointerExceptionXJ001.U
at org.apache.derby.client.am.SQLExceptionFactory40.getSQLException(SQLExceptionFactory40.java:96)
at org.apache.derby.client.am.SqlException.getSQLException(SqlException.java:358)
at org.apache.derby.jdbc.ClientDriver.connect(ClientDriver.java:149)
at java.sql.DriverManager.getConnection(DriverManager.java:322)
at java.sql.DriverManager.getConnection(DriverManager.java:273)
at org.apache.derbyTesting.functionTests.tests.jdbcapi.InternationalConnectTest.testBoundaries(InternationalConnectTest.java:111)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:48)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:109)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
Caused by: org.apache.derby.client.am.SqlException: DERBY SQL error: SQLCODE: -1, SQLSTATE: XJ001, SQLERRMC: java.lang.NullPointerExceptionXJ001.U
at org.apache.derby.client.am.Connection.completeSqlca(Connection.java:2117)
at org.apache.derby.client.net.NetConnectionReply.parseRdbAccessFailed(NetConnectionReply.java:541)
at org.apache.derby.client.net.NetConnectionReply.parseAccessRdbError(NetConnectionReply.java:434)
at org.apache.derby.client.net.NetConnectionReply.parseACCRDBreply(NetConnectionReply.java:297)
at org.apache.derby.client.net.NetConnectionReply.readAccessDatabase(NetConnectionReply.java:121)
at org.apache.derby.client.net.NetConnection.readSecurityCheckAndAccessRdb(NetConnection.java:846)
at org.apache.derby.client.net.NetConnection.flowSecurityCheckAndAccessRdb(NetConnection.java:769)
at org.apache.derby.client.net.NetConnection.flowUSRIDONLconnect(NetConnection.java:601)
at org.apache.derby.client.net.NetConnection.flowConnect(NetConnection.java:408)
at org.apache.derby.client.net.NetConnection.<init>(NetConnection.java:218)
at org.apache.derby.client.net.NetConnection40.<init>(NetConnection40.java:77)
at org.apache.derby.client.net.ClientJDBCObjectFactoryImpl40.newNetConnection(ClientJDBCObjectFactoryImpl40.java:269)
at org.apache.derby.jdbc.ClientDriver.connect(ClientDriver.java:140)
... 35 more
This is after the latest check in for DERBY-4836 (revision 1028035).
I'll attach derby.log.",org.apache.derby.impl.store.raw.data.BaseDataFileFactory
CLASS,derby-10.7.1.1,DERBY-4889,2010-11-05T20:06:56.000-05:00,Different byte to boolean conversion on embedded and client,"PreparedStatement ps = c.prepareStatement(""values cast(? as boolean)"");
        ps.setByte(1, (byte) 32);
        ResultSet rs = ps.executeQuery();
        rs.next();
        System.out.println(rs.getBoolean(1));

 If setByte()   setInt()
The following code prints ""true"" with the embedded driver and ""false"" with the client driver:
PreparedStatement ps = c.prepareStatement(""values cast(?
as boolean)"");
        ps.setByte(1, (byte) 32);
        ResultSet rs = ps.executeQuery();
        rs.next();
        System.out.println(rs.getBoolean(1));
If setByte() is replaced with setInt(), they both print ""true"".","org.apache.derbyTesting.functionTests.tests.jdbcapi.ParameterMappingTest
org.apache.derby.impl.drda.DRDAConnThread"
CLASS,derby-10.7.1.1,DERBY-4892,2010-11-06T04:14:51.000-05:00,Unsafe use of BigDecimal constructors,"test_06_casts(org.apache.derbyTesting.functionTests.tests.lang.UDTTest)
We have some code that's supposed to work on Java 1.4, but that uses BigDecimal constructors that were not added until Java 5.
The problematic constructors are the ones that take a single int or long.
The constructors are used in the following classes:
org.apache.derby.client.am.Cursor
org.apache.derbyTesting.functionTests.tests.lang.Price
org.apache.derbyTesting.system.oe.client.Submitter
All of the classes are compiled against ${java14compile.classpath}, so one would expect the build to fail when java14compile.classpath pointed to proper Java 1.4 libraries.
However, there is a constructor with a double parameter in Java 1.4, and the compiler picks that constructor if it cannot find the ones for int and long.
If that happens, the compiled byte-code works on Java 1.4 and newer, and everything is fine.
The problem appears when the build does not use the Java 1.4 libraries.
This can easily happen if you build without a customized ant.properties, and PropertySetter ends up building java14compile.classpath based on the auto-detected java15compile.classpath.
In that case, the compiler finds the int and long variants of the constructor, even when building against java14compile.classpath.
The compiled byte-code will therefore use those Java 5 constructors, and the code will fail at run-time if ever executed on a Java 1.4 JVM.
You'll see two errors of this kind:
1 test_06_casts(org.apache.derbyTesting.functionTests.tests.lang.UDTTest)java.lang.NoSuchMethodError: java.math.BigDecimal.
<init>(I)V
at org.apache.derbyTesting.functionTests.tests.lang.Price.makePrice(Price.java:49)
at org.apache.derbyTesting.functionTests.tests.lang.UDTTest.test_06_casts(UDTTest.java:501)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:109)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)","org.apache.derbyTesting.functionTests.tests.lang.Price
org.apache.derby.client.am.Cursor
org.apache.derbyTesting.system.oe.client.Submitter"
CLASS,pig-0.11.1,PIG-2767,2012-06-25T09:11:20.000-05:00,Pig creates wrong schema after dereferencing nested tuple fields,"PigStorage()  
  
   ;
DESCRIBE dereferenced;

   nested_tuple.f3;
DESCRIBE uses_dereferenced;

  {f1: int, nested_tuple: (f2: int,
f3: int)}  {f1: int, f2: int}
data = LOAD 'test_data.
txt' USING PigStorage() AS (f1: int, f2: int, f3:
int, f4: int);
nested = FOREACH data GENERATE f1, (f2, f3, f4) AS nested_tuple;
dereferenced = FOREACH nested GENERATE f1, nested_tuple.
(f2, f3);
DESCRIBE dereferenced;
uses_dereferenced = FOREACH dereferenced GENERATE nested_tuple.
f3;
DESCRIBE uses_dereferenced;
DESCRIBE thinks it is {f1: int, f2: int} instead.
When dump is
used, the data is actually in form of the correct schema however, ex.
(1 (2,3))
(5 (6,7))
...
This is not just a problem with DESCRIBE.
Because the schema is incorrect,
the reference to ""nested_tuple"" in the ""uses_dereferenced"" statement is
considered to be invalid, and the script fails to run.
The error is:
Invalid field projection.
Projected field [nested_tuple] does not exist in
schema: f1:int,f2:int.","src.org.apache.pig.newplan.logical.expression.DereferenceExpression
test.org.apache.pig.test.TestPigServer"
CLASS,pig-0.11.1,PIG-2828,2012-07-19T05:03:16.000-05:00,Handle nulls in DataType.compare,"Object field1 = o1.get(fieldNum);
                Object field2 = o2.get(fieldNum);
                if (!typeFound) {
                    datatype = DataType.findType(field1);
                    typeFound = true;
                }
                return DataType.compare(field1, field2, datatype, datatype);
While using TOP, and if the DataBag contains null value to compare, it will generate the following exception:
Caused by: java.lang.NullPointerException
at org.apache.pig.data.DataType.compare(DataType.java:427)
at org.apache.pig.builtin.TOP$TupleComparator.compare(TOP.java:97)
at org.apache.pig.builtin.TOP$TupleComparator.compare(TOP.java:1)
at java.util.PriorityQueue.siftUpUsingComparator(PriorityQueue.java:649)
at java.util.PriorityQueue.siftUp(PriorityQueue.java:627)
at java.util.PriorityQueue.offer(PriorityQueue.java:329)
at java.util.PriorityQueue.add(PriorityQueue.java:306)
at org.apache.pig.builtin.TOP.updateTop(TOP.java:141)
at org.apache.pig.builtin.TOP.exec(TOP.java:116)
code: (TOP.java, starts with line 91)
Object field1 = o1.get(fieldNum);
Object field2 = o2.get(fieldNum);
if (! typeFound) { datatype = DataType.findType(field1);
typeFound = true;
} return DataType.compare(field1, field2, datatype, datatype);
The reason is that if the typeFound is true , and the dataType is not null, and field1 is null, the script failed.","src.org.apache.pig.data.DataType
src.org.apache.pig.builtin.TOP
test.org.apache.pig.test.TestNull"
CLASS,pig-0.11.1,PIG-2970,2012-10-12T15:58:03.000-05:00,Nested foreach getting incorrect schema when having unrelated inner query,"{noformat}
 
 {
     4          sym = daily.symbol;
     5          uniq_sym = distinct sym;
     6          --ignoring uniq_sym result
     7          generate group, daily;
     8  } 
  
  
 {noformat}
While looking at PIG-2968, hit a weird error message.
{noformat}
$ cat -n test/foreach2.
pig
     1  daily = load 'nyse' as (exchange, symbol);
     2  grpd = group daily by exchange;
     3  unique = foreach grpd {
     4          sym = daily.symbol;
     5          uniq_sym = distinct sym;
     6          --ignoring uniq_sym result
     7          generate group, daily;
     8  };
     9  describe unique;
    10  zzz = foreach unique generate group;
    11  explain zzz;
% pig -x local -t ColumnMapKeyPrune test/foreach2.
pig
...
unique: {symbol: bytearray}
2012-10-12 16:55:44,226 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1025: 
<file test/foreach2.
pig, line 10, column 30> Invalid field projection.
Projected field [group] does not exist in schema: symbol:bytearray.
...
{noformat}","src.org.apache.pig.PigServer
src.org.apache.pig.backend.hadoop.executionengine.HExecutionEngine
test.org.apache.pig.test.TestEvalPipelineLocal"
CLASS,pig-0.11.1,PIG-3060,2012-11-20T02:29:04.000-06:00,FLATTEN in nested foreach fails when the input contains an empty bag,"{code}
  {(t:chararray)} 
 {
  c1 = foreach A generate FLATTEN(a1);
  generate COUNT(c1);
} ;
{code}
FLATTEN inside a foreach statement produces wrong results, if the input contains an empty bag.
{code}
A = load 'flatten.txt' as (a0:int, a1:bag{(t:chararray)});
B = group A by a0;
C = foreach B {
  c1 = foreach A generate FLATTEN(a1);
  generate COUNT(c1);
};
{code}
The easy workaround is to filter out empty bags.","src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach
test.org.apache.pig.test.TestEvalPipelineLocal"
CLASS,pig-0.11.1,PIG-3114,2013-01-03T19:49:42.000-06:00,Duplicated macro name error when using pigunit,"{code:title=test.pig|borderStyle=solid}
    {
    $C = ORDER $QUERY BY total DESC, $A;
}  
  
     AS total;

queries_ordered = my_macro_1(queries_count, query);

    
   ;
{code}
Pig runs fine on cluster but getting parsing error with pigunit.
So I tried very basic pig script with macro and getting similar error.
org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1000: Error during parsing.
<line 9> null.
Reason: Duplicated macro name 'my_macro_1'
at org.apache.pig.PigServer$Graph.parseQuery(PigServer.java:1607)
at org.apache.pig.PigServer$Graph.registerQuery(PigServer.java:1546)
at org.apache.pig.PigServer.registerQuery(PigServer.java:516)
at org.apache.pig.tools.grunt.GruntParser.processPig(GruntParser.java:988)
at org.apache.pig.pigunit.pig.GruntParser.processPig(GruntParser.java:61)
at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:412)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:194)
at org.apache.pig.pigunit.pig.PigServer.registerScript(PigServer.java:56)
at org.apache.pig.pigunit.PigTest.registerScript(PigTest.java:160)
at org.apache.pig.pigunit.PigTest.assertOutput(PigTest.java:231)
at org.apache.pig.pigunit.PigTest.assertOutput(PigTest.java:261)
at FirstPigTest.MyPigTest.testTop2Queries(MyPigTest.java:32)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at junit.framework.TestCase.runTest(TestCase.java:176)
at junit.framework.TestCase.runBare(TestCase.java:141)
at junit.framework.TestResult$1.protect(TestResult.java:122)
at junit.framework.TestResult.runProtected(TestResult.java:142)
at junit.framework.TestResult.run(TestResult.java:125)
at junit.framework.TestCase.run(TestCase.java:129)
at junit.framework.TestSuite.runTest(TestSuite.java:255)
at junit.framework.TestSuite.run(TestSuite.java:250)
at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:84)
at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
Caused by: Failed to parse: <line 9> null.
Reason: Duplicated macro name 'my_macro_1'
at org.apache.pig.parser.QueryParserDriver.makeMacroDef(QueryParserDriver.java:406)
at org.apache.pig.parser.QueryParserDriver.expandMacro(QueryParserDriver.java:277)
at org.apache.pig.parser.QueryParserDriver.parse(QueryParserDriver.java:178)
at org.apache.pig.PigServer$Graph.parseQuery(PigServer.java:1599)
... 30 more
{code:title=test.pig|borderStyle=solid}
DEFINE my_macro_1 (QUERY, A) RETURNS C {
$C = ORDER $QUERY BY total DESC, $A;
} ;
data =  LOAD 'input' AS (query:CHARARRAY);
queries_group = GROUP data BY query;
queries_count = FOREACH queries_group GENERATE group AS query, COUNT(data) AS total;
queries_ordered = my_macro_1(queries_count, query);
queries_limit = LIMIT queries_ordered 2;
STORE queries_limit INTO 'output';
{code}
If I remove macro pigunit works fine.
Even just defining macro without using it results in parsing error.","src.org.apache.pig.PigServer
test.org.apache.pig.test.pigunit.TestPigTest
test.org.apache.pig.pigunit.PigTest
test.org.apache.pig.pigunit.pig.PigServer"
CLASS,pig-0.11.1,PIG-3267,2013-04-03T16:14:30.000-05:00,HCatStorer fail in limit query,"{code}
 
  
  
     ;
{code}

 
 {code}
  {code}
{code}
data = LOAD 'student.txt' as (name:chararray, age:int, gpa:double);
data_limited = limit data 10;
samples = foreach data_limited generate age as number;
store samples into 'samples' using org.apache.hcatalog.pig.HCatStorer('part_dt=20130101T010000T36');
{code}
Error happens before launching the second job. Error message:
{code}
Message: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:8020/user/hive/warehouse/samples/part_dt=20130101T010000T36 already exists
at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:121)
at org.apache.hcatalog.mapreduce.FileOutputFormatContainer.checkOutputSpecs(FileOutputFormatContainer.java:135)
at org.apache.hcatalog.mapreduce.HCatBaseOutputFormat.checkOutputSpecs(HCatBaseOutputFormat.java:72)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat.checkOutputSpecsHelper(PigOutputFormat.java:207)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat.checkOutputSpecs(PigOutputFormat.java:188)
at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:887)
at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:850)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:850)
at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:824)
at org.apache.hadoop.mapred.jobcontrol.Job.submit(Job.java:378)
at org.apache.hadoop.mapred.jobcontrol.JobControl.startReadyJobs(JobControl.java:247)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.pig.backend.hadoop20.PigJobControl.mainLoopAction(PigJobControl.java:157)
at org.apache.pig.backend.hadoop20.PigJobControl.run(PigJobControl.java:134)
at java.lang.Thread.run(Thread.java:680)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:257)
{code}","src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POStore
test.org.apache.pig.test.TestMRCompiler"
CLASS,pig-0.11.1,PIG-3290,2013-04-23T12:28:01.000-05:00,TestLogicalPlanBuilder.testQuery85 fail in trunk,"{noformat}
    
 {noformat}
I can reproduce it locally as well, the exception is
{noformat}
junit.framework.AssertionFailedError: org.apache.pig.impl.plan.PlanValidationException: ERROR 1108:
<line 1, column 79> Duplicate schema alias: group
at org.apache.pig.test.TestLogicalPlanBuilder.buildPlan(TestLogicalPlanBuilder.java:2211)
at org.apache.pig.test.TestLogicalPlanBuilder.testQuery85(TestLogicalPlanBuilder.java:1011)
{noformat}",src.org.apache.pig.newplan.logical.expression.DereferenceExpression
CLASS,pig-0.11.1,PIG-3292,2013-04-24T03:06:41.000-05:00,Logical plan invalid state: duplicate uid in schema during self-join to get cross product,"{code}
 
  
   {
  y = a.x;
  pair = cross a.x, y;
  generate flatten(pair);
}

 dump b;
{code}

 
 {code}
   
 {code}

 
 {code}
 
  
   {
  y = foreach a generate -(-x);
  pair = cross a.x, y;
  generate flatten(pair);
}

 dump b;
{code}
Hi.
Looks like PIG-3020
but works in a different way.
Our pig version is: 
Apache Pig version 0.10.0-cdh4.2.0 (rexported) 
compiled Feb 15 2013, 12:20:54
Accoring to release note, PIG-3020 is included into CDH 4.2 dist
http://archive.cloudera.com/cdh4/cdh/4/pig-0.10.0-cdh4.2.0.CHANGES.txt
a_group = group a by key;
b = foreach a_group {
  y = a.x;
  pair = cross a.x, y;
  generate flatten(pair);
}
dump b;
{code}
And an error:
{code}
ERROR org.apache.pig.tools.grunt.Grunt - ERROR 2270: Logical plan invalid state: duplicate uid in schema : 1-7::x#16:bytearray,y::x#16:bytearray
{code}
Here is workaround :)
{code}
a = load '/input' as (key, x:int);
a_group = group a by key;
b = foreach a_group {
  y = foreach a generate -(-x);
  pair = cross a.x, y;
  generate flatten(pair);
}
dump b;
{code}","test.org.apache.pig.test.TestEvalPipelineLocal
src.org.apache.pig.newplan.logical.relational.LOCross"
CLASS,pig-0.11.1,PIG-3310,2013-05-03T02:59:57.000-05:00,"ImplicitSplitInserter does not generate new uids for nested schema fields, leading to miscomputations","{code}
     
    
        
        
    
           as shop;

EXPLAIN K;
DUMP K;
{code}

 
 {code}
 
 {code}

 
 {code}
 
 {code}
 
        
      
  
 {code}
                  
              
              
              
              
              
 {code}

 
 {code}
                   
  
  
 {code}

     
 LOSplitOutput.getSchema()
Hi,
{code}
inp = LOAD '$INPUT' AS (memberId:long, shopId:long, score:int);
tuplified = FOREACH inp GENERATE (memberId, shopId) AS tuplify, score;
D1 = FOREACH tuplified GENERATE tuplify.memberId as memberId, tuplify.shopId as shopId, score AS score;
D2 = FOREACH tuplified GENERATE tuplify.memberId as memberId, tuplify.shopId as shopId, score AS score;
J = JOIN D1 By shopId, D2 by shopId;
K = FOREACH J GENERATE D1::memberId AS member_id1, D2::memberId AS member_id2, D1::shopId as shop;
EXPLAIN K;
DUMP K;
{code}
It is a bit weird written like that, but it provides a minimal reproduction case (in the real case, the ""tuplified"" phase came from a multi-key grouping).
This will give a wrongful output like .
.
{code}
(1 1001,1001)
(1 1002,1002)
(1 1002,1002)
(1 1002,1002)
{code}
In the initial case, there was a FILTER (member_id1 < member_id2) after K, and computation failed because of PushUpFilter optimization mistakenly moving the LOFilter operation before the join, at a place where it tried to work on a tuple and failed.
My understanding of the issue is that when the ImplicitSplitInserter creates the LOSplitOutputs, it will correctly reset the schema, and the LOSplitOutput will regenerate uids for the fields of D1 and D2 ... but will not do that on the tuple members.
The logical plan after the ImplicitSplitINserter will look like (simplified)
{code}
|---D1: (Name: LOForEach Schema: memberId#124:long,shopId#125:long)ColumnPrune:InputUids=[127]ColumnPrune:OutputUids=[125, 124]
|---tuplified: (Name: LOSplitOutput Schema: tuplify#127:tuple(memberId#124:long,shopId#125:long))ColumnPrune:InputUids=[123]ColumnPrune:OutputUids=[127]
|---tuplified: (Name: LOSplit Schema: tuplify#123:tuple(memberId#124:long,shopId#125:long))ColumnPrune:InputUids=[123]ColumnPrune:OutputUids=[123]
|---D2: (Name: LOForEach Schema: memberId#124:long,shopId#125:long)ColumnPrune:InputUids=[130]ColumnPrune:OutputUids=[125, 124]
|---tuplified: (Name: LOSplitOutput Schema: tuplify#130:tuple(memberId#124:long,shopId#125:long))ColumnPrune:InputUids=[123]ColumnPrune:OutputUids=[130]
|---tuplified: (Name: LOSplit Schema: tuplify#123:tuple(memberId#124:long,shopId#125:long))ColumnPrune:InputUids=[123]ColumnPrune:OutputUids=[123]
{code}
tuplified correctly gets a new uid (127 and 130) but the members of the tuple don't.
When they get reprojected, both branches have the same uid and the join looks like:
{code}
|---J: (Name: LOJoin(HASH) Schema: D1::memberId#124:long,D1::shopId#125:long,D2::memberId#139:long,D2::shopId#132:long)ColumnPrune:InputUids=[125, 124, 132]ColumnPrune:OutputUids=[125, 124, 132]
|   |
|   shopId:(Name: Project Type: long Uid: 125 Input: 0 Column: 1)
|   |
|   shopId:(Name: Project Type: long Uid: 125 Input: 1 Column: 1)
{code}
If for example instead of reprojecting ""memberId"", we project ""memberId+0"", a new node is created, and ultimately the two branches of the join will correctly get separate uids.
My understanding is that LOSplitOutput.getSchema() should recurse on nested schema fields.
However, I only have a light understanding of all of the logical plan handling, so I may be completely wrong.
Attached is a draft of patch and a test reproducing the issue.
Unfortunately, I haven't been able to run all unit tests with the ""fix"" (I have some weird hangs)
I'd be happy if you could indicate if that looks like completely the wrong way to fix the issue.",src.org.apache.pig.newplan.logical.relational.LOSplitOutput
CLASS,pig-0.11.1,PIG-3316,2013-05-08T14:01:36.000-05:00,Pig failed to interpret DateTime values in some special cases,";
dump A;
A = load 'date.txt' as ( f1:int, f2:datetime );
dump A;
pig generates the following output
(1 1970-01-01T00:00:00.000-01:00)
(2 1970-01-01T00:00:00.000-01:00)
which seemingly incorrectly interprets the day or month part as time zone.","test.org.apache.pig.test.TestDefaultDateTimeZone
src.org.apache.pig.builtin.ToDate"
CLASS,pig-0.11.1,PIG-3329,2013-05-16T22:44:41.000-05:00,RANK operator failed when working with SPLIT,"RANK b;
dump d;
job will fail with error message:
java.lang.RuntimeException: Unable to read counter pig.counters.counter_4929375455335572575_-1
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.PORank.addRank(PORank.java:161)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.PORank.getNext(PORank.java:134)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator.processInput(PhysicalOperator.java:308)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POSplit.getNext(POSplit.java:214)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.runPipeline(PigGenericMapBase.java:283)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.map(PigGenericMapBase.java:278)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.map(PigGenericMapBase.java:64)
at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:157)
at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:324)
at org.apache.hadoop.mapred.Child$4.run(Child.java:275)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1340)
at org.apache.hadoop.mapred.Child.main(Child.java:269)","src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceOper
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler"
CLASS,pig-0.11.1,PIG-3379,2013-07-16T13:37:26.000-05:00,Alias reuse in nested foreach causes PIG script to fail,"{code:title=temp.pig}
       
      
    
    {
  DistinctDevices = DISTINCT Events.deviceId;
  nbDevices = SIZE(DistinctDevices);

  DistinctDevices = FILTER Events BY eventName == 'xuaHeartBeat';
  nbDevicesWatching = SIZE(DistinctDevices);

  GENERATE $0*60000 as timeStamp, nbDevices as nbDevices, nbDevicesWatching as nbDevicesWatching;
}
        
  GENERATE timeStamp;
describe A;
{code}
 
 {code}
   
    
 {code}
{code:title=temp.pig}
Events = LOAD 'x' AS (eventTime:long, deviceId:chararray, eventName:chararray);
Events = FOREACH Events GENERATE eventTime, deviceId, eventName;
EventsPerMinute = GROUP Events BY (eventTime / 60000);
EventsPerMinute = FOREACH EventsPerMinute {
  DistinctDevices = DISTINCT Events.deviceId;
  nbDevices = SIZE(DistinctDevices);
DistinctDevices = FILTER Events BY eventName == 'xuaHeartBeat';
  nbDevicesWatching = SIZE(DistinctDevices);
GENERATE $0*60000 as timeStamp, nbDevices as nbDevices, nbDevicesWatching as nbDevicesWatching;
}
EventsPerMinute = FILTER EventsPerMinute BY timeStamp >= 0  AND timeStamp < 100000;
A = FOREACH EventsPerMinute GENERATE timeStamp;
describe A;
{code}
With the error:
{code}
2013-07-16 11:31:20,450 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1025: 
<file /home/xzhang/Documents/temp.pig, line 14, column 37> Invalid field projection.
Projected field [timeStamp] does not exist in schema: deviceId:chararray.
{code}
Using distinct alias name for the 2nd ""DistinctDevices"" fixes the problem.
As an observation, removing the last filter statement also fixes the problem.","src.org.apache.pig.parser.LogicalPlanBuilder
src.org.apache.pig.PigServer
test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.newplan.logical.relational.LOInnerLoad
src.org.apache.pig.newplan.logical.expression.ProjectExpression"
CLASS,pig-0.11.1,PIG-3510,2013-10-09T18:02:45.000-05:00,New filter extractor fails with more than one filter statement,";
{code}
{code:title=one filter}
      ;
{code}
This is a regression from PIG-3461 - rewrite of partition filter optimizer.
For the 1 filter case, the whole expression is pushed down whereas for the 2 filter case, only (event_id == 419 OR event_id == 418) is pushed down.",src.org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer
CLASS,mahout-0.8,MAHOUT-1261,2013-06-13T10:09:15.000-05:00,TasteHadoopUtils.idToIndex can return an int that has size Integer.MAX_VALUE,"Longs.hashCode(id)
I'm running ItemSimilarityJob on a very large (~600M by 4B) matrix that's very sparse (total set of associations is 630MB).
The job fails because of an IndexException in ToUserVectorsReducer.
TasteHadoopUtils.idToIndex(long id) hashes a long with:
0x7fffffff & Longs.hashCode(id) (line o.a.m.cf.taste.hadoop.TasteHadoopUtils:57).
For some id (I don't know what value), the result returned is Integer.MAX_VALUE.
This cannot be set in the userVector because the cardinality of that is also Integer.MAX_VALUE and it throws an exception.
So, the issue is that values from 0 to INT_MAX are returned by idToIndex but the vector only has 0 to INT_MAX - 1 possible entries.
It's a nasty little off-by-one bug.
I'm thinking of just % size when setting.
[~ssc] & everyone else, thoughts?
:)",core.src.main.java.org.apache.mahout.cf.taste.hadoop.TasteHadoopUtils
CLASS,mahout-0.8,MAHOUT-1314,2013-08-18T09:07:48.000-05:00,StreamingKMeansReducer throws NullPointerException when REDUCE_STREAMING_KMEANS is set to true,"return input.getCentroid();  
 input.getCentroid()  clone();
when REDUCE_STREAMING_KMEANS option is set to true (-rskm) the reducer fails with NullPointerException.
the problem is in the reduce method itself: on line 60 ( return input.getCentroid(); )
similar to line 81.
full stack trace:
java.lang.NullPointerException
at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:191)
at org.apache.mahout.math.random.WeightedThing.<init>(WeightedThing.java:31)
at org.apache.mahout.math.neighborhood.BruteSearch.searchFirst(BruteSearch.java:133)
at org.apache.mahout.clustering.ClusteringUtils.estimateDistanceCutoff(ClusteringUtils.java:100)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansThread.call(StreamingKMeansThread.java:64)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:66)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:1)
at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:176)
at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:650)
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:418)
at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:260)",core.src.main.java.org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer
CLASS,mahout-0.8,MAHOUT-1317,2013-08-23T13:05:58.000-05:00,Clarify some of the messages in Preconditions.checkArgument,"Preconditions.checkArgument(maxSimilaritiesPerRow > 0, ""Incorrect maximum number of similarities per row!"");
In experimenting with things, I was getting some errors from RowSimilarityJob, that in looking at the source I realized were a little incomplete as to what the true issue was.
In this case, they were of the form:
Preconditions.checkArgument(maxSimilaritiesPerRow > 0, ""Incorrect maximum number of similarities per row!"")
;
Here, it is known that the actual issue is that the parameter must be zero (or negative), not just that it's ""incorrect"", and a (trivial) change to the error message might save some folks some time... especially newbies like myself.
A quick grep of the code showed a few more cases like that across the code base that would be (apparently) easy to fix and maybe save folks time when they get the relevant error.","core.src.main.java.org.apache.mahout.cf.taste.impl.eval.GenericRecommenderIRStatsEvaluator
math.src.main.java.org.apache.mahout.math.CholeskyDecomposition
core.src.main.java.org.apache.mahout.cf.taste.impl.eval.IRStatisticsImpl
core.src.main.java.org.apache.mahout.cf.taste.impl.recommender.SamplingCandidateItemsStrategy
core.src.main.java.org.apache.mahout.cf.taste.hadoop.similarity.item.ItemSimilarityJob
core.src.main.java.org.apache.mahout.cf.taste.hadoop.als.SolveImplicitFeedbackMapper
integration.src.main.java.org.apache.mahout.cf.taste.impl.model.mongodb.MongoDBDataModel
core.src.main.java.org.apache.mahout.cf.taste.impl.similarity.GenericUserSimilarity
core.src.main.java.org.apache.mahout.math.neighborhood.ProjectionSearch
core.src.main.java.org.apache.mahout.cf.taste.impl.recommender.TopItems
math.src.main.java.org.apache.mahout.math.random.Empirical
core.src.main.java.org.apache.mahout.math.hadoop.similarity.cooccurrence.RowSimilarityJob
core.src.test.java.org.apache.mahout.math.neighborhood.SearchQualityTest
integration.src.main.java.org.apache.mahout.utils.SplitInput
core.src.test.java.org.apache.mahout.math.neighborhood.SearchQualityTest.StripWeight
core.src.main.java.org.apache.mahout.clustering.kmeans.RandomSeedGenerator
integration.src.main.java.org.apache.mahout.utils.vectors.lucene.LuceneIterator
core.src.main.java.org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansDriver
examples.src.main.java.org.apache.mahout.cf.taste.example.kddcup.KDDCupDataModel
math.src.main.java.org.apache.mahout.math.als.AlternatingLeastSquaresSolver
core.src.main.java.org.apache.mahout.cf.taste.hadoop.als.SolveExplicitFeedbackMapper
core.src.main.java.org.apache.mahout.cf.taste.impl.similarity.GenericItemSimilarity
core.src.main.java.org.apache.mahout.classifier.df.data.DataLoader
math.src.main.java.org.apache.mahout.math.random.ChineseRestaurant
core.src.main.java.org.apache.mahout.classifier.df.mapreduce.partial.TreeID
core.src.main.java.org.apache.mahout.classifier.df.data.DataConverter
core.src.main.java.org.apache.mahout.math.Varint
core.src.main.java.org.apache.mahout.math.neighborhood.BruteSearch
core.src.main.java.org.apache.mahout.cf.taste.impl.eval.AbstractDifferenceRecommenderEvaluator
core.src.main.java.org.apache.mahout.classifier.naivebayes.training.WeightsMapper
core.src.main.java.org.apache.mahout.math.neighborhood.FastProjectionSearch
core.src.main.java.org.apache.mahout.cf.taste.impl.common.SamplingLongPrimitiveIterator
core.src.main.java.org.apache.mahout.classifier.df.mapreduce.partial.Step1Mapper
core.src.main.java.org.apache.mahout.classifier.df.data.Dataset
integration.src.main.java.org.apache.mahout.cf.taste.impl.model.cassandra.CassandraDataModel
core.src.main.java.org.apache.mahout.common.iterator.SamplingIterator
core.src.main.java.org.apache.mahout.cf.taste.impl.common.WeightedRunningAverage"
CLASS,mahout-0.8,MAHOUT-1320,2013-08-29T04:07:09.000-05:00,BallKMeansTest.testClustering is unstable,"{noformat}
  
 testClustering(org.apache.mahout.clustering.streaming.cluster.BallKMeansTest)   
 {noformat}


 
 {noformat}
 
      
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 testClustering(org.apache.mahout.clustering.streaming.cluster.BallKMeansTest)   
 {noformat}
From time to time this test fails with following in build log:
{noformat}
Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 48.134 sec <<< FAILURE!
- in org.apache.mahout.clustering.streaming.cluster.BallKMeansTest testClustering(org.apache.mahout.clustering.streaming.cluster.BallKMeansTest)  Time elapsed: 2.051 sec  <<< FAILURE! java.lang.AssertionError: expected:<625.0> but was:<796.0>
at org.junit.Assert.fail(Assert.java:88)
at org.junit.Assert.failNotEquals(Assert.java:743)
at org.junit.Assert.assertEquals(Assert.java:494)
at org.junit.Assert.assertEquals(Assert.java:592)
at org.apache.mahout.clustering.streaming.cluster.BallKMeansTest.testClustering(BallKMeansTest.java:119)
{noformat}
Here is a bit more of build log output, which also shows other tests were running in parallel with this one:
{noformat}
[INFO] --- maven-surefire-plugin:2.15:test (default-test) @ mahout-core ---
[INFO] Surefire report directory: /home/jenkins/jenkins-slave/workspace/Mahout-Quality/trunk/core/target/surefire-reports
[INFO] parallel='classes', perCoreThreadCount=false, threadCount=1, useUnlimitedThreads=false
-------------------------------------------------------
T E S T S
-------------------------------------------------------
-------------------------------------------------------
T E S T S
-------------------------------------------------------
Running org.apache.mahout.common.distance.TestChebyshevMeasure
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.043 sec - in org.apache.mahout.common.distance.TestChebyshevMeasure
Running org.apache.mahout.common.distance.TestMinkowskiMeasure
Running org.apache.mahout.common.distance.TestMahalanobisDistanceMeasure
Running org.apache.mahout.common.distance.TestManhattanDistanceMeasure
Running org.apache.mahout.common.distance.CosineDistanceMeasureTest
Running org.apache.mahout.common.distance.TestTanimotoDistanceMeasure
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.143 sec - in org.apache.mahout.common.distance.TestMinkowskiMeasure
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.078 sec - in org.apache.mahout.common.distance.TestMahalanobisDistanceMeasure
Running org.apache.mahout.common.distance.TestWeightedManhattanDistanceMeasure
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.099 sec - in org.apache.mahout.common.distance.TestManhattanDistanceMeasure
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.075 sec - in org.apache.mahout.common.distance.CosineDistanceMeasureTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.094 sec - in org.apache.mahout.common.distance.TestTanimotoDistanceMeasure
Running org.apache.mahout.common.distance.TestWeightedEuclideanDistanceMeasureTest
Running org.apache.mahout.common.distance.TestEuclideanDistanceMeasure
Running org.apache.mahout.common.iterator.TestFixedSizeSampler
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.135 sec - in org.apache.mahout.common.distance.TestWeightedManhattanDistanceMeasure
Running org.apache.mahout.common.iterator.CountingIteratorTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.009 sec - in org.apache.mahout.common.iterator.CountingIteratorTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.073 sec - in org.apache.mahout.common.iterator.TestFixedSizeSampler
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.111 sec - in org.apache.mahout.common.distance.TestWeightedEuclideanDistanceMeasureTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.121 sec - in org.apache.mahout.common.distance.TestEuclideanDistanceMeasure
Running org.apache.mahout.common.iterator.TestSamplingIterator
Running org.apache.mahout.common.iterator.TestStableFixedSizeSampler
Running org.apache.mahout.common.DummyRecordWriterTest
Running org.apache.mahout.common.StringUtilsTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.093 sec - in org.apache.mahout.common.iterator.TestStableFixedSizeSampler
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.113 sec - in org.apache.mahout.common.DummyRecordWriterTest
Running org.apache.mahout.common.AbstractJobTest
Running org.apache.mahout.common.IntPairWritableTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.02 sec - in org.apache.mahout.common.IntPairWritableTest
Running org.apache.mahout.common.lucene.AnalyzerUtilsTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.07 sec - in org.apache.mahout.common.lucene.AnalyzerUtilsTest
Running org.apache.mahout.clustering.topdown.PathDirectoryTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.007 sec - in org.apache.mahout.clustering.topdown.PathDirectoryTest
Running org.apache.mahout.clustering.topdown.postprocessor.ClusterCountReaderTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.505 sec - in org.apache.mahout.common.StringUtilsTest
Running org.apache.mahout.clustering.classify.ClusterClassificationDriverTest
Running org.apache.mahout.clustering.topdown.postprocessor.ClusterOutputPostProcessorTest
Running org.apache.mahout.clustering.spectral.TestVectorCache
Running org.apache.mahout.clustering.spectral.TestVectorMatrixMultiplicationJob
Running org.apache.mahout.clustering.spectral.TestMatrixDiagonalizeJob
Running org.apache.mahout.clustering.lda.cvb.TestCVBModelTrainer
Running org.apache.mahout.clustering.spectral.TestAffinityMatrixInputJob
Running org.apache.mahout.clustering.spectral.TestUnitVectorizerJob
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.356 sec - in org.apache.mahout.common.AbstractJobTest
Running org.apache.mahout.clustering.canopy.TestCanopyCreation
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.046 sec - in org.apache.mahout.clustering.spectral.TestVectorMatrixMultiplicationJob
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.288 sec - in org.apache.mahout.clustering.spectral.TestMatrixDiagonalizeJob
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.624 sec - in org.apache.mahout.clustering.spectral.TestVectorCache
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.713 sec - in org.apache.mahout.common.iterator.TestSamplingIterator
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.054 sec - in org.apache.mahout.clustering.spectral.TestUnitVectorizerJob
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.518 sec - in org.apache.mahout.clustering.spectral.TestAffinityMatrixInputJob
Running org.apache.mahout.clustering.kmeans.TestRandomSeedGenerator
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.609 sec - in org.apache.mahout.clustering.topdown.postprocessor.ClusterCountReaderTest
Running org.apache.mahout.clustering.kmeans.TestEigenSeedGenerator
Running org.apache.mahout.clustering.kmeans.TestKmeansClustering
Running org.apache.mahout.clustering.TestGaussianAccumulators
Running org.apache.mahout.clustering.iterator.TestClusterClassifier
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.065 sec - in org.apache.mahout.clustering.topdown.postprocessor.ClusterOutputPostProcessorTest
Running org.apache.mahout.clustering.fuzzykmeans.TestFuzzyKmeansClustering
Running org.apache.mahout.clustering.TestClusterInterface
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.203 sec - in org.apache.mahout.clustering.TestClusterInterface
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.746 sec - in org.apache.mahout.clustering.kmeans.TestEigenSeedGenerator
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.897 sec - in org.apache.mahout.clustering.kmeans.TestRandomSeedGenerator
Running org.apache.mahout.clustering.streaming.cluster.StreamingKMeansTest
Running org.apache.mahout.clustering.streaming.cluster.BallKMeansTest
Running org.apache.mahout.math.stats.OnlineAucTest
Running org.apache.mahout.math.stats.SamplerTest
Running org.apache.mahout.math.VarintTest
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.031 sec - in org.apache.mahout.math.VarintTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.294 sec - in org.apache.mahout.math.stats.SamplerTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.821 sec - in org.apache.mahout.clustering.classify.ClusterClassificationDriverTest
Running org.apache.mahout.math.hadoop.stochasticsvd.SSVDCommonTest
Running org.apache.mahout.math.hadoop.stats.BasicStatsTest
Running org.apache.mahout.math.hadoop.TestDistributedRowMatrix
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.175 sec - in org.apache.mahout.math.hadoop.stochasticsvd.SSVDCommonTest
Running org.apache.mahout.math.hadoop.stochasticsvd.LocalSSVDPCASparseTest
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.366 sec - in org.apache.mahout.clustering.TestGaussianAccumulators
Running org.apache.mahout.math.hadoop.stochasticsvd.LocalSSVDSolverSparseSequentialTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.578 sec - in org.apache.mahout.math.stats.OnlineAucTest
Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.893 sec - in org.apache.mahout.clustering.iterator.TestClusterClassifier
Running org.apache.mahout.math.hadoop.stochasticsvd.LocalSSVDSolverDenseTest
Running org.apache.mahout.math.hadoop.solver.TestDistributedConjugateGradientSolverCLI
Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.419 sec - in org.apache.mahout.clustering.canopy.TestCanopyCreation
Running org.apache.mahout.math.hadoop.solver.TestDistributedConjugateGradientSolver
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.33 sec - in org.apache.mahout.math.hadoop.stats.BasicStatsTest
Running org.apache.mahout.math.hadoop.similarity.TestVectorDistanceSimilarityJob
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.475 sec - in org.apache.mahout.clustering.kmeans.TestKmeansClustering
Running org.apache.mahout.math.hadoop.similarity.cooccurrence.measures.VectorSimilarityMeasuresTest
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.076 sec - in org.apache.mahout.math.hadoop.similarity.cooccurrence.measures.VectorSimilarityMeasuresTest
Running org.apache.mahout.math.hadoop.similarity.cooccurrence.RowSimilarityJobTest
Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.855 sec - in org.apache.mahout.math.hadoop.TestDistributedRowMatrix
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.63 sec - in org.apache.mahout.math.hadoop.similarity.TestVectorDistanceSimilarityJob
Running org.apache.mahout.math.hadoop.decomposer.TestDistributedLanczosSolverCLI
Running org.apache.mahout.math.VectorWritableTest
Tests run: 100, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.046 sec - in org.apache.mahout.math.VectorWritableTest
Running org.apache.mahout.math.ssvd.SequentialOutOfCoreSvdTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.541 sec - in org.apache.mahout.math.hadoop.solver.TestDistributedConjugateGradientSolverCLI
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.658 sec - in org.apache.mahout.math.hadoop.solver.TestDistributedConjugateGradientSolver
Running org.apache.mahout.math.neighborhood.LocalitySensitiveHashSearchTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.045 sec - in org.apache.mahout.math.hadoop.stochasticsvd.LocalSSVDSolverSparseSequentialTest
Running org.apache.mahout.math.neighborhood.SearchSanityTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 33.918 sec - in org.apache.mahout.clustering.fuzzykmeans.TestFuzzyKmeansClustering
Running org.apache.mahout.math.MatrixWritableTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.944 sec - in org.apache.mahout.math.hadoop.similarity.cooccurrence.RowSimilarityJobTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.08 sec - in org.apache.mahout.math.MatrixWritableTest
Running org.apache.mahout.vectorizer.DocumentProcessorTest
Running org.apache.mahout.vectorizer.HighDFWordsPrunerTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.631 sec - in org.apache.mahout.vectorizer.HighDFWordsPrunerTest
Running org.apache.mahout.math.neighborhood.SearchQualityTest
Running org.apache.mahout.vectorizer.encoders.ContinuousValueEncoderTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.062 sec - in org.apache.mahout.vectorizer.encoders.ContinuousValueEncoderTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.581 sec - in org.apache.mahout.vectorizer.DocumentProcessorTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.304 sec - in org.apache.mahout.math.hadoop.stochasticsvd.LocalSSVDPCASparseTest
Running org.apache.mahout.vectorizer.encoders.ConstantValueEncoderTest
Running org.apache.mahout.vectorizer.encoders.InteractionValueEncoderTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.113 sec - in org.apache.mahout.vectorizer.encoders.ConstantValueEncoderTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.137 sec - in org.apache.mahout.vectorizer.encoders.InteractionValueEncoderTest
Running org.apache.mahout.vectorizer.encoders.WordLikeValueEncoderTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.174 sec - in org.apache.mahout.vectorizer.encoders.WordLikeValueEncoderTest
Running org.apache.mahout.vectorizer.encoders.TextValueEncoderTest
Running org.apache.mahout.vectorizer.SparseVectorsFromSequenceFilesTest
Running org.apache.mahout.vectorizer.collocations.llr.GramTest
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.082 sec - in org.apache.mahout.vectorizer.collocations.llr.GramTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.544 sec - in org.apache.mahout.vectorizer.encoders.TextValueEncoderTest
Running org.apache.mahout.vectorizer.collocations.llr.GramKeyGroupComparatorTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.069 sec - in org.apache.mahout.vectorizer.collocations.llr.GramKeyGroupComparatorTest
Running org.apache.mahout.vectorizer.collocations.llr.GramKeyPartitionerTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.061 sec - in org.apache.mahout.vectorizer.collocations.llr.GramKeyPartitionerTest
Running org.apache.mahout.vectorizer.collocations.llr.LLRReducerTest
Running org.apache.mahout.vectorizer.collocations.llr.CollocReducerTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.552 sec - in org.apache.mahout.vectorizer.collocations.llr.LLRReducerTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.369 sec - in org.apache.mahout.vectorizer.collocations.llr.CollocReducerTest
Running org.apache.mahout.vectorizer.collocations.llr.CollocMapperTest
Running org.apache.mahout.vectorizer.collocations.llr.GramKeyTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.081 sec - in org.apache.mahout.vectorizer.collocations.llr.GramKeyTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.693 sec - in org.apache.mahout.vectorizer.collocations.llr.CollocMapperTest
Running org.apache.mahout.vectorizer.DictionaryVectorizerTest
Running org.apache.mahout.vectorizer.EncodedVectorsFromSequenceFilesTest
Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 48.134 sec <<< FAILURE!
- in org.apache.mahout.clustering.streaming.cluster.BallKMeansTest testClustering(org.apache.mahout.clustering.streaming.cluster.BallKMeansTest)  Time elapsed: 2.051 sec  <<< FAILURE! java.lang.AssertionError: expected:<625.0> but was:<796.0>
at org.junit.Assert.fail(Assert.java:88)
at org.junit.Assert.failNotEquals(Assert.java:743)
at org.junit.Assert.assertEquals(Assert.java:494)
at org.junit.Assert.assertEquals(Assert.java:592)
at org.apache.mahout.clustering.streaming.cluster.BallKMeansTest.testClustering(BallKMeansTest.java:119)
{noformat}
Last time test failed it was on ubuntu-1 node, but it's also randomly successful on same node so it doesn't seem to be caused by something node specific.","core.src.test.java.org.apache.mahout.clustering.streaming.cluster.StreamingKMeansTest
core.src.test.java.org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansTestMR
core.src.test.java.org.apache.mahout.clustering.streaming.cluster.BallKMeansTest
core.src.test.java.org.apache.mahout.clustering.streaming.cluster.DataUtils"
CLASS,mahout-0.8,MAHOUT-1336,2013-09-16T23:35:54.000-05:00,HighDFWordsPrunerTest is failing silently,"{noformat}
 
        
        
      
         
      
 {noformat}
Apparently ToolRunner does not allow the --mapred option.
The validation is not very foolproof, so there is a resulting silent failure in HighDFWordsPrunerTest.
Error message:
{noformat} org.apache.commons.cli2.OptionException: Unexpected --mapred while processing Options
at org.apache.commons.cli2.commandline.Parser.parse(Parser.java:99)
at org.apache.mahout.vectorizer.SparseVectorsFromSequenceFiles.run(SparseVectorsFromSequenceFiles.java:154)
at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
at org.apache.mahout.vectorizer.HighDFWordsPrunerTest.runTest(HighDFWordsPrunerTest.java:111)
at org.apache.mahout.vectorizer.HighDFWordsPrunerTest.testHighDFWordsPruning(HighDFWordsPrunerTest.java:85)
...
Usage:
[--minSupport <minSupport> --analyzerName <analyzerName> --chunkSize
<chunkSize> --output <output> --input <input> --minDF <minDF> --maxDFSigma
<maxDFSigma> --maxDFPercent <maxDFPercent> --weight <weight> --norm <norm>
--minLLR <minLLR> --numReducers <numReducers> --maxNGramSize <ngramSize>
--overwrite --help --sequentialAccessVector --namedVector --logNormalize]
O
{noformat}",core.src.test.java.org.apache.mahout.vectorizer.HighDFWordsPrunerTest
CLASS,mahout-0.8,MAHOUT-1349,2013-11-01T07:59:17.000-05:00,Clusterdumper/loadTermDictionary crashes when highest index in (sparse) dictionary vector is larger than dictionary vector size?,"OpenObjectIntHashMap dict = new OpenObjectIntHashMap();
//...
  String [] dictionary = new String[dict.size()];
I'm not sure if I'm doing something wrong here, or if ClusterDumper does
not support my (fairly simple) use case
I had a repository of 500K documents, for which I generated the input
vectors and a dictionary using some custom code (not seq2sparse etc).
The kmeans ran fine and generate sensible looking results, but when I tried
to run ClusterDumper I got the following error:
#bash> bin/mahout clusterdump -dt sequencefile -d
completed/5159bba4e4b0718d03c8cf79_/EmailContentAnalytics_dict_5159bba4e4b0718d03c8cf79/part-*
-i test-kmeans/clusters-19 -b 10 -n 10 -sp 10 -o ~/test-kmeans-out
Running on hadoop, using /usr/bin/hadoop and HADOOP_CONF_DIR=
MAHOUT-JOB: /opt/mahout-distribution-0.7/mahout-examples-0.7-job.jar
13/05/17 08:26:41 INFO common.AbstractJob: Command line arguments:
{--dictionary=[completed/5159bba4e4b0718d03c8cf79_/EmailContentAnalytics_dict_5159bba4e4b0718d03c8cf79/part-*],
--dictionaryType=[sequencefile],
--distanceMeasure=[org.apache.mahout.common.distance.SquaredEuclideanDistanceMeasure],
--endPhase=[2147483647], --input=[test-kmeans/clusters-19],
--numWords=[10], --output=[/usr/share/tomcat6/test-kmeans-out],
--outputFormat=[TEXT], --samplePoints=[10], --startPhase=[0],
--substring=[10], --tempDir=[temp]}
Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 698948
at
org.apache.mahout.clustering.AbstractCluster.formatVector(AbstractCluster.java:350)
at
org.apache.mahout.clustering.AbstractCluster.asFormatString(AbstractCluster.java:306)
at
org.apache.mahout.utils.clustering.ClusterDumperWriter.write(ClusterDumperWriter.java:54)
at
org.apache.mahout.utils.clustering.AbstractClusterWriter.write(AbstractClusterWriter.java:169)
at
org.apache.mahout.utils.clustering.AbstractClusterWriter.write(AbstractClusterWriter.java:156)
at
org.apache.mahout.utils.clustering.ClusterDumper.printClusters(ClusterDumper.java:187)
at
org.apache.mahout.utils.clustering.ClusterDumper.run(ClusterDumper.java:153)
(...)
The error is when it tries to access the dictionary for the feature with
index 698948
Looking at the dictionary loading code (
http://grepcode.com/file/repo1.maven.org/maven2/org.apache.mahout/mahout-integration/0.7/org/apache/mahout/utils/vectors/VectorHelper.java#VectorHelper.loadTermDictionary%28java.io.File%29
-  checked 0.8 and it hasn't changed)
It looks like the dictionary array is sized for the number of unique
keywords, not the highest index:
OpenObjectIntHashMap dict = new OpenObjectIntHashMap();
//...
  String [] dictionary = new String[dict.size()];
After I ran my custom dictionary/feature generation code I discovered I
only had 517,327 unique features, therefore it is not surprising it would
die on an index >= 517327 (though I don't understand why it didn't die when trying to load the dictionary file)
Is there any reason why the VectorHelper code should not create a
dictionary array that has size the highest index read from the dictionary
sequence file (which can be easily calculated during the preceding loop)?
Or am I misunderstanding something?
It worked fine when I reduced the hash size to be <= than the total number
of features, but this is not desirable in general (for me) since I don't
know the number of features before I run the job (and if I guess too high
then ClusterDumper crashes)
Alex Piggott
IKANOW",integration.src.main.java.org.apache.mahout.utils.vectors.VectorHelper
CLASS,mahout-0.8,MAHOUT-1358,2013-11-18T01:58:22.000-06:00,StreamingKMeansThread throws IllegalArgumentException when REDUCE_STREAMING_KMEANS is set to true,"{Code}

 {Code}

  StreamingKMeansThread.call()

 {Code}
     Iterator<Centroid> datapointsIterator = datapoints.iterator();
    if (estimateDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
      List<Centroid> estimatePoints = Lists.newArrayListWithExpectedSize(NUM_ESTIMATE_POINTS);
      while (datapointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) {
        estimatePoints.add(datapointsIterator.next());
      }
      estimateDistanceCutoff = ClusteringUtils.estimateDistanceCutoff(estimatePoints, searcher.getDistanceMeasure());
    }

    StreamingKMeans clusterer = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);
    while (datapointsIterator.hasNext()) {
      clusterer.cluster(datapointsIterator.next());
    }
{Code}
Running StreamingKMeans Clustering with REDUCE_STREAMING_KMEANS = true and when no estimatedDistanceCutoff is specified, throws the following error
{Code}
java.lang.IllegalArgumentException: Must have nonzero number of training and test vectors.
Asked for %.1f %% of %d vectors for test [10.000000149011612, 0]
at com.google.common.base.Preconditions.checkArgument(Preconditions.java:120)
at org.apache.mahout.clustering.streaming.cluster.BallKMeans.splitTrainTest(BallKMeans.java:176)
at org.apache.mahout.clustering.streaming.cluster.BallKMeans.cluster(BallKMeans.java:192)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.getBestCentroids(StreamingKMeansReducer.java:107)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:73)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:37)
at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:177)
at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:649)
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:418)
at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:398)
{Code}
{Code}
Iterator<Centroid> datapointsIterator = datapoints.iterator();
if (estimateDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
List<Centroid> estimatePoints = Lists.newArrayListWithExpectedSize(NUM_ESTIMATE_POINTS);
while (datapointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) { estimatePoints.add(datapointsIterator.next());
} estimateDistanceCutoff = ClusteringUtils.estimateDistanceCutoff(estimatePoints, searcher.getDistanceMeasure());
}
StreamingKMeans clusterer = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);
while (datapointsIterator.hasNext()) { clusterer.cluster(datapointsIterator.next());
}
{Code}
The code is using the same iterator twice, and it fails on the second use for obvious reasons.",core.src.main.java.org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansThread
CLASS,mahout-0.8,MAHOUT-1396,2014-01-15T02:02:41.000-06:00,Accidental use of commons-math won't work with next Hadoop 2 release,"import org.apache.commons.math.special.Gamma;
The project uses commons-math3, since about a year ago.
However there is a use of old commons-math (2.2) lurking:
core/src/main/java/org/apache/mahout/classifier/sgd/TPrior.java:
import org.apache.commons.math.special.Gamma;
This happens to have worked since commons-math has been pulled in by hadoop-common.
But it no longer is in HEAD:
http://svn.apache.org/viewvc/hadoop/common/trunk/hadoop-common-project/hadoop-common/pom.xml?view=markup
So this will no longer compile against the latest Hadoop.
I believe it will also not actually run again the latest Hadoop, even if one were to use a version compiled versus older Hadoop 2, since the class that uses it is used in the context of Writables -- that is, outside the client environment that might happen to have packaged commons-math -- and so would fail on the cluster.
The change is trivial, to import the commons-math3 class.
I've verified that tests pass and a patch is attached.
Question is how much of a 'blocker' this should be for the pending release.
It would cause it to stop working with the next Hadoop 2 release, so would be useful to get in, IMHO.",core.src.main.java.org.apache.mahout.classifier.sgd.TPrior
CLASS,zookeeper-3.4.5,ZOOKEEPER-1535,2012-08-14T18:56:40.000-05:00,ZK Shell/Cli re-executes last command on exit,"{{ctrl+d}}   {{ls}}   {{ctrl+d}}   {{ls}}  
 {noformat}
 
 {noformat}
In the ZK 3.4.3 release's version of zkCli.sh, the last command that was executed is *re*-executed when you {{ctrl+d}} out of the shell.
In the snippet below, {{ls}} is executed, and then {{ctrl+d}} is triggered (inserted below to illustrate), the output from {{ls}} appears again, due to the command being re-run.
{noformat}
[zk: zookeeper.example.com:2181(CONNECTED) 0] ls /blah
[foo]
[zk: zookeeper.example.com:2181(CONNECTED) 1] <ctrl+d> [foo]
$
{noformat}",src.java.main.org.apache.zookeeper.ZooKeeperMain
CLASS,zookeeper-3.4.5,ZOOKEEPER-1619,2013-01-11T09:57:16.000-06:00,Allow spaces in URL,"{code}
 
 {code}

 
 {code}
 
 {code}
Currently, spaces are not allowed in the url.
{code}
10.10.1.1:2181,10.10.1.2:2181/usergrid
{code}
This format will not (notice the spaces around the comma)
{code}
10.10.1.1:2181 , 10.10.1.2:2181/usergrid
{code}",src.java.main.org.apache.zookeeper.client.ConnectStringParser
CLASS,zookeeper-3.4.5,ZOOKEEPER-1642,2013-02-08T04:30:06.000-06:00,Leader loading database twice,"getLastLoggedZxid()    
 loadData()
The leader server currently loads the database before running leader election when trying to figure out the zxid it needs to use for the election and again when it starts leading.
This is problematic for larger databases so we should remove the redundant load if possible.
The code references are:
# getLastLoggedZxid() in QuorumPeer;
# loadData() in ZooKeeperServer.",src.java.main.org.apache.zookeeper.server.ZooKeeperServer
CLASS,zookeeper-3.4.5,ZOOKEEPER-1700,2013-05-07T19:43:31.000-05:00,FLETest consistently failing - setLastSeenQuorumVerifier seems to be hanging,"{noformat}
   
  
    
    
          
      
    
    
  
  
  
  
      
  
  
     
      
      
    
    
 {noformat}
I'm consistently seeing a failure on my laptop when running the FLETest ""testJoin"" test.
What seems to be happening is that the call to setLastSeenQuorumVerifier is hanging.
See the following log from the test, notice 17:35:57 for the period in question.
Note that I turned on debug logging and added a few log messages around the call to setLastSeenQuorumVerifier (you can see the code enter but never leave)
Note: I've applied ZOOKEEPER-1324 to trunk code and then run this test but that doesn't seem to help.
Also note that this test is passing consistently when run against branch-3.4.
{noformat}
2013-05-07 17:35:57,859 [myid:] - INFO  [QuorumPeer[myid=0]/0:0:0:0:0:0:0:0:11221:Follower@65] - FOLLOWING - LEADER ELECTION TOOK - 16
2013-05-07 17:35:57,859 [myid:] - INFO  [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:Leader@436] - LEADING - LEADER ELECTION TOOK - 17
2013-05-07 17:35:57,863 [myid:] - INFO  [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:FileTxnSnapLog@270] - Snapshotting: 0x0 to /home/phunt/dev/zookeeper-trunk/build/test/tmp/test3690487600947307322.junit.dir/version-2/snapshot.0
2013-05-07 17:35:57,873 [myid:] - INFO  [LearnerHandler-/127.0.0.1:34262:LearnerHandler@269] - Follower sid: 0 : info : 0.0.0.0:11222:11223:participant;0.0.0.0:11221
2013-05-07 17:35:57,878 [myid:] - INFO  [LearnerHandler-/127.0.0.1:34262:LearnerHandler@328] - Synchronizing with Follower sid: 0 maxCommittedLog=0x0 minCommittedLog=0x0 peerLastZxid=0x0
2013-05-07 17:35:57,878 [myid:] - DEBUG [LearnerHandler-/127.0.0.1:34262:LearnerHandler@395] - committedLog is empty but leader and follower are in sync, zxid=0x0
2013-05-07 17:35:57,878 [myid:] - INFO  [LearnerHandler-/127.0.0.1:34262:LearnerHandler@404] - Sending DIFF
2013-05-07 17:35:57,879 [myid:] - DEBUG [LearnerHandler-/127.0.0.1:34262:LearnerHandler@411] - Sending NEWLEADER message to 0
2013-05-07 17:35:57,880 [myid:] - INFO  [QuorumPeer[myid=0]/0:0:0:0:0:0:0:0:11221:Learner@331] - Getting a diff from the leader 0x0
2013-05-07 17:35:57,885 [myid:] - INFO  [QuorumPeer[myid=0]/0:0:0:0:0:0:0:0:11221:Learner@457] - Learner received NEWLEADER message
2013-05-07 17:35:57,885 [myid:] - INFO  [QuorumPeer[myid=0]/0:0:0:0:0:0:0:0:11221:Learner@460] - NEWLEADER calling configfromstring
2013-05-07 17:35:57,885 [myid:] - INFO  [QuorumPeer[myid=0]/0:0:0:0:0:0:0:0:11221:Learner@462] - NEWLEADER setting quorum verifier
2013-05-07 17:35:57,886 [myid:] - WARN  [QuorumPeer[myid=0]/0:0:0:0:0:0:0:0:11221:QuorumPeer@1218] - setLastSeenQuorumVerifier called with stale config 0. Current version: 0
2013-05-07 17:36:01,880 [myid:] - INFO  [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:Leader@585] - Shutting down
2013-05-07 17:36:01,881 [myid:] - INFO  [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:Leader@591] - Shutdown called
java.lang.Exception: shutdown Leader! reason: Waiting for a quorum of followers, only synced with sids: [ [1] ]
at org.apache.zookeeper.server.quorum.Leader.shutdown(Leader.java:591)
at org.apache.zookeeper.server.quorum.Leader.lead(Leader.java:487)
at org.apache.zookeeper.server.quorum.QuorumPeer.run(QuorumPeer.java:949)
2013-05-07 17:36:01,881 [myid:] - INFO  [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:ZooKeeperServer@398] - shutting down
2013-05-07 17:36:01,881 [myid:] - INFO  [LearnerCnxAcceptor-0.0.0.0/0.0.0.0:11225:Leader$LearnerCnxAcceptor@398] - exception while shutting down acceptor: java.net.SocketException: Socket closed
2013-05-07 17:36:01,882 [myid:] - WARN  [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:QuorumPeer@979] - PeerState set to LOOKING
2013-05-07 17:36:01,882 [myid:] - INFO  [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:QuorumPeer@863] - LOOKING
2013-05-07 17:36:01,883 [myid:] - DEBUG [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:QuorumPeer@792] - Initializing leader election protocol...
{noformat}",src.java.test.org.apache.zookeeper.test.FLETest
CLASS,zookeeper-3.4.5,ZOOKEEPER-1753,2013-09-05T09:37:15.000-05:00,"ClientCnxn is not properly releasing the resources, which are used to ping RwServer","pingRwServer()
{code}
             try {
                Socket sock = new Socket(addr.getHostName(), addr.getPort());
                BufferedReader br = new BufferedReader(
                        new InputStreamReader(sock.getInputStream()));
                ......
                sock.close();
                br.close();
            } catch (ConnectException e) {
                // ignore, this just means server is not up
            } catch (IOException e) {
                // some unexpected error, warn about it
                LOG.warn(""Exception while seeking for r/w server "" +
                        e.getMessage(), e);
            }
 {code}
While pinging to the RwServer, ClientCnxn is opening a socket and using BufferedReader.
These are not properly closed in finally block and could cause leaks on exceptional cases.
ClientCnxn#pingRwServer()
{code}
            try {
                Socket sock = new Socket(addr.getHostName(), addr.getPort());
                BufferedReader br = new BufferedReader(
                        new InputStreamReader(sock.getInputStream()));
                ......
sock.close();
                br.close();
            } catch (ConnectException e) {
                // ignore, this just means server is not up
            } catch (IOException e) {
                // some unexpected error, warn about it
                LOG.warn(""Exception while seeking for r/w server "" +
                        e.getMessage(), e);
            }
{code}",src.java.main.org.apache.zookeeper.ClientCnxn
CLASS,zookeeper-3.4.5,ZOOKEEPER-1755,2013-09-07T13:12:11.000-05:00,Concurrent operations of four letter 'dump' ephemeral command and killSession causing NPE,"{code}
 {code}
Potential problem occurs, when executing four letter 'dump' command and at the meantime zkserver has triggered session closure and removing the related information from the DataTree.
Please see the exception:
{code}
java.lang.NullPointerException
at org.apache.zookeeper.server.DataTree.dumpEphemerals(DataTree.java:1278)
at org.apache.zookeeper.server.DataTreeTest$1.run(DataTreeTest.java:82)
{code}","src.java.test.org.apache.zookeeper.test.DataTreeTest
src.java.test.org.apache.zookeeper.server.DataTreeUnitTest
src.java.main.org.apache.zookeeper.server.DataTree"
CLASS,zookeeper-3.4.5,ZOOKEEPER-1774,2013-10-01T18:14:39.000-05:00,"QuorumPeerMainTest fails consistently with ""complains about host"" assertion failure","{noformat}
     
     
 {noformat}
QuorumPeerMainTest fails consistently with ""complains about host"" assertion failure.
{noformat}
2013-10-01 16:09:17,962 [myid:] - INFO  [main:JUnit4ZKTestRunner$LoggedInvokeMethod@54] - TEST METHOD FAILED testBadPeerAddressInQuorum
java.lang.AssertionError: complains about host
at org.junit.Assert.fail(Assert.java:91)
at org.junit.Assert.assertTrue(Assert.java:43)
at org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testBadPeerAddressInQuorum(QuorumPeerMainTest.java:434)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
at org.apache.zookeeper.JUnit4ZKTestRunner$LoggedInvokeMethod.evaluate(JUnit4ZKTestRunner.java:52)
at org.junit.rules.TestWatchman$1.evaluate(TestWatchman.java:48)
at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:76)
at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:518)
at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:1052)
at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:906)
2013-10-01 16:09:17,963 [myid:] - INFO  [main:ZKTestCase$1@65] - FAILED testBadPeerAddressInQuorum
java.lang.AssertionError: complains about host
at org.junit.Assert.fail(Assert.java:91)
at org.junit.Assert.assertTrue(Assert.java:43)
at org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testBadPeerAddressInQuorum(QuorumPeerMainTest.java:434)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
at org.apache.zookeeper.JUnit4ZKTestRunner$LoggedInvokeMethod.evaluate(JUnit4ZKTestRunner.java:52)
at org.junit.rules.TestWatchman$1.evaluate(TestWatchman.java:48)
at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:76)
at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:518)
at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:1052)
at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:906)
{noformat}",src.java.test.org.apache.zookeeper.server.quorum.QuorumPeerMainTest
CLASS,zookeeper-3.4.5,ZOOKEEPER-1781,2013-10-03T20:19:27.000-05:00,ZooKeeper Server fails if snapCount is set to 1,"int randRoll = r.nextInt(snapCount/2);
{code}
If snapCount is set to 1, ZooKeeper Server can start but it fails with the below error:
2013-10-02 18:09:07,600 [myid:1] - ERROR [SyncThread:1:SyncRequestProcessor@151] - Severe unrecoverable error, exiting java.lang.IllegalArgumentException: n must be positive
at java.util.Random.nextInt(Random.java:300)
at org.apache.zookeeper.server.SyncRequestProcessor.run(SyncRequestProcessor.java:93)
{code:title=org.apache.zookeeper.server.SyncRequestProcessor.java|borderStyle=solid}
91             // we do this in an attempt to ensure that not all ofthe servers
92             // in the ensemble take a snapshot at the same time
93             int randRoll = r.nextInt(snapCount/2);
{code}
I think this supposition is not bad because snapCount = 1 is not realistic setting...
But, it may be better to mention this restriction in documentation or add a validation in the source code.",src.java.main.org.apache.zookeeper.server.ZooKeeperServer
METHOD,bookkeeper-4.1.0,BOOKKEEPER-294,2012-06-12T23:56:56.000-05:00,Not able to start the bookkeeper before the ZK session timeout.,"{noformat}
         
 {noformat}
Not able to start the bookkeeper before the ZK session timeout.
Here i killed the bookie and started again.
{noformat}
2012-06-12 20:00:25,220 - INFO  [main:LedgerCache@65] - openFileLimit is 900, pageSize is 8192, pageLimit is 456781
2012-06-12 20:00:25,238 - ERROR [main:Bookie@453] - ZK exception registering ephemeral Znode for Bookie!
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /ledgers/available/10.18.40.216:3181
at org.apache.zookeeper.KeeperException.create(KeeperException.java:119)
at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:778)
at org.apache.bookkeeper.bookie.Bookie.registerBookie(Bookie.java:450)
at org.apache.bookkeeper.bookie.Bookie.<init>(Bookie.java:348)
at org.apache.bookkeeper.proto.BookieServer.<init>(BookieServer.java:64)
at org.apache.bookkeeper.proto.BookieServer.main(BookieServer.java:249)
{noformat}","org.apache.bookkeeper.bookie.Bookie:readJournal()
org.apache.bookkeeper.bookie.Bookie:registerBookie(int)
org.apache.bookkeeper.bookie.Bookie:start()
org.apache.bookkeeper.proto.BookieServer:start()"
METHOD,bookkeeper-4.1.0,BOOKKEEPER-327,2012-07-05T13:04:20.000-05:00,System.currentTimeMillis usage in BookKeeper,"{code}
 {code}


  System.nanoTime()  System.currentTimeMillis()
The following exception occured in the bookie statistics logic due to the System time changes. In our bookie cluster its running a periodic syncup scripts just to unify the SystemTime in all the machines. This is causing the problem and resulting ArrayIndexOutOfBoundException.
{code}
Exception in thread ""BookieJournal-3181"" java.lang.ArrayIndexOutOfBoundsException: -423
at org.apache.bookkeeper.proto.BKStats$OpStats.updateLatency(BKStats.java:126)
at org.apache.bookkeeper.proto.BookieServer.writeComplete(BookieServer.java:655)
at org.apache.bookkeeper.bookie.Journal.run(Journal.java:507)
{code}
This jira is raised to discuss whether to use ??
System.nanoTime()??
instead of ??
System.currentTimeMillis()??","org.apache.bookkeeper.proto.BKStats.OpStats:updateLatency(long)
org.apache.bookkeeper.util.MathUtils:signSafeMod(long, int)
org.apache.bookkeeper.proto.BKStats:getInstance()
org.apache.bookkeeper.proto.PerChannelBookieClient.CompletionKey:shouldTimeout()
org.apache.bookkeeper.util.LocalBookKeeper:waitForServerUp(String, long)
org.apache.bookkeeper.proto.ServerStats:updateLatency(long)"
METHOD,bookkeeper-4.1.0,BOOKKEEPER-355,2012-08-08T05:02:04.000-05:00,"Ledger recovery will mark ledger as closed with -1, in case of slow bookie is added to ensemble during  recovery add","doRecoveryRead()
Scenario:
------------
1 Ledger is created with ensemble and quorum size as 2, written with one entry
2 Now first bookie is in the ensemble is made down.
3 Another client fence and trying to recover the same ledger
4 During this time ensemble change will happen and new bookie will be added.
But this bookie is not able to connect.
5 This recovery will fail.
7 Now previously added bookie came up.
8 Another client trying to recover the same ledger.
9 Since new bookie is first in the ensemble, doRecoveryRead() is reading from that bookie and getting NoSuchLedgerException and closing the ledger with -1
i.e. Marking the ledger as empty, even though first client had successfully written one entry.","org.apache.bookkeeper.client.LedgerRecoveryOp:doRecoveryRead()
org.apache.bookkeeper.client.LedgerRecoveryOp:readComplete(int, LedgerHandle, Enumeration<LedgerEntry>, Object)
org.apache.bookkeeper.client.LedgerRecoveryOp:LedgerRecoveryOp(LedgerHandle, GenericCallback<Void>)
org.apache.bookkeeper.client.LedgerRecoveryOp:initiate()
org.apache.bookkeeper.client.PendingReadOp:readEntryComplete(int, long, long, ChannelBuffer, Object)"
METHOD,bookkeeper-4.1.0,BOOKKEEPER-371,2012-08-17T05:42:02.000-05:00,NPE in hedwig hub client causes hedwig hub to shut down.,"Channel topicSubscriberChannel = client.getSubscriber().getChannelForTopic(topicSubscriber);
        HedwigClientImpl.getResponseHandlerFromChannel(topicSubscriberChannel).getSubscribeResponseHandler()
        .messageConsumed(messageConsumeData.msg);


  getPipeline()  getLast()   channel.close()   messageConsumed()
The hedwig client was connected to a remote region hub that restarted resulting in the channel getting disconnected.
2012-08-15 17:47:42,443 - ERROR - [pool-20-thread-1:TerminateJVMExceptionHandler@28] - Uncaught exception in thread pool-20-thread-1
java.lang.NullPointerException
at org.apache.hedwig.client.netty.HedwigClientImpl.getResponseHandlerFromChannel(HedwigClientImpl.java:323)
at org.apache.hedwig.client.handlers.MessageConsumeCallback.operationFinished(MessageConsumeCallback.java:75)
at org.apache.hedwig.client.handlers.MessageConsumeCallback.operationFinished(MessageConsumeCallback.java:41)
at org.apache.hedwig.server.regions.RegionManager$1$1$1.operationFinished(RegionManager.java:208)
at org.apache.hedwig.server.regions.RegionManager$1$1$1.operationFinished(RegionManager.java:202)
at org.apache.hedwig.server.persistence.ReadAheadCache$PersistCallback.operationFinished(ReadAheadCache.java:194)
at org.apache.hedwig.server.persistence.ReadAheadCache$PersistCallback.operationFinished(ReadAheadCache.java:171)
at org.apache.hedwig.server.persistence.BookkeeperPersistenceManager$PersistOp$1.safeAddComplete(BookkeeperPersistenceManager.java:548)
at org.apache.hedwig.zookeeper.SafeAsynBKCallback$AddCallback.addComplete(SafeAsynBKCallback.java:93)
at org.apache.bookkeeper.client.PendingAddOp.submitCallback(PendingAddOp.java:165)
at org.apache.bookkeeper.client.LedgerHandle.sendAddSuccessCallbacks(LedgerHandle.java:643)
at org.apache.bookkeeper.client.PendingAddOp.writeComplete(PendingAddOp.java:159)
at org.apache.bookkeeper.proto.PerChannelBookieClient.handleAddResponse(PerChannelBookieClient.java:577)
at org.apache.bookkeeper.proto.PerChannelBookieClient$7.safeRun(PerChannelBookieClient.java:525)
at org.apache.bookkeeper.util.SafeRunnable.run(SafeRunnable.java:31)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
at java.util.concurrent.FutureTask.run(FutureTask.java:166)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
at java.lang.Thread.run(Thread.java:722)
At 2012-08-15 17:47:42,443, the channel was disconnected as well.
I believe the following code in the MessageConsumeCallback is causing this problem.
Channel topicSubscriberChannel = client.getSubscriber().
getChannelForTopic(topicSubscriber);
        HedwigClientImpl.getResponseHandlerFromChannel(topicSubscriberChannel).
getSubscribeResponseHandler()
        .
messageConsumed(messageConsumeData.msg);
The channel was retrieved without checking if it was closed and then getPipeline().
getLast() was called which returned a null value resulting in a NPE.
Moreover, we need to check if the returned Response handler is not null because there is a race here if channel.close() is called after we retrieve the channel and before we call messageConsumed().
I guess the same applies for other instances where we use this.
Does the above explanation seem right?","org.apache.hedwig.client.netty.HedwigClientImpl:getResponseHandlerFromChannel(Channel)
org.apache.hedwig.client.handlers.MessageConsumeCallback:operationFailed(Object, PubSubException)
org.apache.hedwig.client.handlers.MessageConsumeCallback.MessageConsumeRetryTask:run()"
METHOD,bookkeeper-4.1.0,BOOKKEEPER-387,2012-09-04T04:27:35.000-05:00,BookKeeper Upgrade is not working.,"{code}
     
 {code}
I am trying to upgrade BK from 4.1.0 to 4.2.0, but it will log as ""Directory is current, no need to upgrade�? even then it will continue and fail.
and throwing following exception.
{code}
2012-09-03 17:25:12,468 - ERROR - [main:FileSystemUpgrade@229] - Error moving upgraded directories into place /home/BK4.1/bookkeeper1/ledger/upgradeTmp.2433718456734190 -> /home/BK4.1/bookkeeper1/ledger/current org.apache.commons.io.FileExistsException: Destination '/home/BK4.1/bookkeeper1/ledger/current' already exists
at org.apache.commons.io.FileUtils.moveDirectory(FileUtils.java:2304)
at org.apache.bookkeeper.bookie.FileSystemUpgrade.upgrade(FileSystemUpgrade.java:225)
at org.apache.bookkeeper.bookie.FileSystemUpgrade.main(FileSystemUpgrade.java:367)
{code}",org.apache.bookkeeper.bookie.UpgradeTest:testCommandLine()
METHOD,bookkeeper-4.1.0,BOOKKEEPER-55,2011-08-25T05:52:23.000-05:00,SubscribeReconnectRetryTask might retry subscription endlessly when another subscription is already successfully created previously,"HedwigSubscriber.subscribe()
For channelDisconnected envent, we try to automatically recover the connection and subscription.
But when users call HedwigSubscriber.subscribe() at the same time, it might succeed before the auto recovery.
Then the auto recovery can never succeed as the server will report topic busy failure.
Then the SubscribeReconnectRetryTask will retry again and again endlessly.
We found this in our auto test.
Fix is easy, we just need to firstly check if the channel for this topic and subscribe id is null, if not it means some subscription is already created before, we don't need to bother recover.",org.apache.hedwig.client.handlers.SubscribeReconnectCallback.SubscribeReconnectRetryTask:run()
CLASS,argouml-0.22,3923,2006-02-07T13:17:48.000-06:00,Problem importing Poseidon activity diagrams from XMI,"Collection actionStates = getModel().getAllActionStates();
  Iterator iterActionState = actionStates.iterator();
iterActionState.hasNext(); 
 ActionStateFacade actionState =
(ActionStateFacade) iterActionState.next();
There is a bug in Beta 3 which prevents you using the activity diagram for AndroMDA.
Here is what I've done:
Everything went fine.
2) If I add my activity diagram under the use case diagram I always get a new activity graph, so I have 2 activity graphs alltogether.
I cannot add an activity diagram under the imported activity graph.
Please see the screenshot I attached.
See: http://argouml.tigris.org/servlets/ReadMsg?list=dev&msgNo=19267
Screenshot:
http://argouml.tigris.org/servlets/GetAttachment?list=dev&msgId=770688&attachId=1
Collection actionStates = getModel().
getAllActionStates();
for (Iterator iterActionState = actionStates.iterator();
iterActionState.hasNext();) {
ActionStateFacade actionState =
(ActionStateFacade) iterActionState.next();
actionState is always ""null"".
4) Importing the activity diagram from Poseidon works and the result can be processed by AndroMDA but if you are making the activity diagram from the beginning with ArgoUML, it won't work because of the error above
(nr.
3).
So, it seems that ArgoUML still has a problem with activity diagram...
Thanks,
Lofi.",org.argouml.persistence.XMIParser
METHOD,apache-nutch-1.8,NUTCH-1262,2012-01-31T03:15:33.000-06:00,Map `duplicating` content-types to a single type,"{code}
   
 {code}
Similar or duplicating content-types can end-up differently in an index.
With, for example, both application/xhtml+xml and text/html it is impossible to use a single filter to select `web pages`.
See also: http://lucene.472066.n3.nabble.com/application-xhtml-xml-gt-text-html-td3699942.html
Content-Type mapping is disabled by default and is enabled via moreIndexingFilter.mapMimeTypes.
Example mapping file is provided in conf/.
{code}
# target MIME-type <TAB> type1 [<TAB> type2 ...]
# Map XHTML to HTML
text/html       application/xhtml+xml
# Map XHTML and HTML to something else
Web page        text/html       application/xhtml+xml
# Map some office documents to each other
Office document application/vnd.
oasis.opendocument.text application/x-tika-msoffice
{code}","org.apache.nutch.indexer.more.MoreIndexingFilter:getConf()
org.apache.nutch.indexer.more.MoreIndexingFilter:setConf(Configuration)
org.apache.nutch.indexer.more.MoreIndexingFilter:filter(NutchDocument, Parse, Text, CrawlDatum, Inlinks)"
CLASS,lucene-4.0,LUCENE-4182,2012-06-29T06:45:34.000-05:00,DocumentsWriterFlushControl.assertMemory tripped by NGramTokenizerTest.testRandomStrings,"{noformat}

  
 
  
  
    
 
 
   
  
    
                                       
                                
    
          
     {0,5}     {0,5}      {0,5}         {1,5}  {0, & qgbiwn  < vyge acmvidw xbwgrppk \uf612p\u05f5^\u048f\u056d \ud6436\u9cde0\u274e\u0592 tamcca \ufd7b\ufbf9\ufb88\ufbae tusifiwj \u000f\u0600\uef93}                   {0,5}       
      
 @AfterClass 
         {dummy=DFR I(n)3(800.0)}   
                                                                                            
 {noformat}
{noformat}
Build: http://jenkins.sd-datasolutions.de/job/Lucene-Solr-trunk-Linux-Java6-64/1090/
1 tests failed.
REGRESSION:  org.apache.lucene.analysis.ngram.NGramTokenizerTest.testRandomStrings
Error Message:
some thread(s) failed
Stack Trace:
java.lang.RuntimeException: some thread(s) failed
at __randomizedtesting.SeedInfo.seed([256D0DE54BD0473A:ADE40D5BE8D4100F]:0)
at org.apache.lucene.analysis.BaseTokenStreamTestCase.checkRandomData(BaseTokenStreamTestCase.java:463)
at org.apache.lucene.analysis.ngram.NGramTokenizerTest.testRandomStrings(NGramTokenizerTest.java:106)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1969)
at com.carrotsearch.randomizedtesting.RandomizedRunner.access$1100(RandomizedRunner.java:132)
at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:814)
at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:875)
at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:889)
at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)
at org.apache.lucene.util.TestRuleFieldCacheSanity$1.evaluate(TestRuleFieldCacheSanity.java:32)
at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:45)
at com.carrotsearch.randomizedtesting.rules.SystemPropertiesInvariantRule$1.evaluate(SystemPropertiesInvariantRule.java:55)
at org.apache.lucene.util.TestRuleReportUncaughtExceptions$1.evaluate(TestRuleReportUncaughtExceptions.java:68)
at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:48)
at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)
at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:821)
at com.carrotsearch.randomizedtesting.RandomizedRunner.access$700(RandomizedRunner.java:132)
at com.carrotsearch.randomizedtesting.RandomizedRunner$3$1.run(RandomizedRunner.java:669)
at com.carrotsearch.randomizedtesting.RandomizedRunner$3.evaluate(RandomizedRunner.java:695)
at com.carrotsearch.randomizedtesting.RandomizedRunner$4.evaluate(RandomizedRunner.java:734)
at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:745)
at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:45)
at org.apache.lucene.util.TestRuleReportUncaughtExceptions$1.evaluate(TestRuleReportUncaughtExceptions.java:68)
at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:38)
at org.apache.lucene.util.TestRuleIcuHack$1.evaluate(TestRuleIcuHack.java:51)
at com.carrotsearch.randomizedtesting.rules.SystemPropertiesInvariantRule$1.evaluate(SystemPropertiesInvariantRule.java:55)
at org.apache.lucene.util.TestRuleNoInstanceHooksOverrides$1.evaluate(TestRuleNoInstanceHooksOverrides.java:53)
at org.apache.lucene.util.TestRuleNoStaticHooksShadowing$1.evaluate(TestRuleNoStaticHooksShadowing.java:52)
at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:36)
at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)
at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:56)
at com.carrotsearch.randomizedtesting.RandomizedRunner.runSuite(RandomizedRunner.java:605)
at com.carrotsearch.randomizedtesting.RandomizedRunner.access$400(RandomizedRunner.java:132)
at com.carrotsearch.randomizedtesting.RandomizedRunner$2.run(RandomizedRunner.java:551)
Build Log:
[...truncated 3668 lines...]
[junit4] Suite: org.apache.lucene.analysis.ngram.NGramTokenizerTest
[junit4] ERROR   3162s J1 | NGramTokenizerTest.testRandomStrings
[junit4]    > Throwable #1: java.lang.RuntimeException: some thread(s) failed
[junit4]    >        at __randomizedtesting.SeedInfo.seed([256D0DE54BD0473A:ADE40D5BE8D4100F]:0)
[junit4]    >        at org.apache.lucene.analysis.BaseTokenStreamTestCase.checkRandomData(BaseTokenStreamTestCase.java:463)
[junit4]    >        at org.apache.lucene.analysis.ngram.NGramTokenizerTest.testRandomStrings(NGramTokenizerTest.java:106)
[junit4]    >        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[junit4]    >        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
[junit4]    >        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
[junit4]    >        at java.lang.reflect.Method.invoke(Method.java:597)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1969)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner.access$1100(RandomizedRunner.java:132)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:814)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:875)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:889)
[junit4]    >        at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)
[junit4]    >        at org.apache.lucene.util.TestRuleFieldCacheSanity$1.evaluate(TestRuleFieldCacheSanity.java:32)
[junit4]    >        at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:45)
[junit4]    >        at com.carrotsearch.randomizedtesting.rules.SystemPropertiesInvariantRule$1.evaluate(SystemPropertiesInvariantRule.java:55)
[junit4]    >        at org.apache.lucene.util.TestRuleReportUncaughtExceptions$1.evaluate(TestRuleReportUncaughtExceptions.java:68)
[junit4]    >        at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:48)
[junit4]    >        at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:821)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner.access$700(RandomizedRunner.java:132)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner$3$1.run(RandomizedRunner.java:669)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner$3.evaluate(RandomizedRunner.java:695)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner$4.evaluate(RandomizedRunner.java:734)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:745)
[junit4]    >        at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:45)
[junit4]    >        at org.apache.lucene.util.TestRuleReportUncaughtExceptions$1.evaluate(TestRuleReportUncaughtExceptions.java:68)
[junit4]    >        at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:38)
[junit4]    >        at org.apache.lucene.util.TestRuleIcuHack$1.evaluate(TestRuleIcuHack.java:51)
[junit4]    >        at com.carrotsearch.randomizedtesting.rules.SystemPropertiesInvariantRule$1.evaluate(SystemPropertiesInvariantRule.java:55)
[junit4]    >        at org.apache.lucene.util.TestRuleNoInstanceHooksOverrides$1.evaluate(TestRuleNoInstanceHooksOverrides.java:53)
[junit4]    >        at org.apache.lucene.util.TestRuleNoStaticHooksShadowing$1.evaluate(TestRuleNoStaticHooksShadowing.java:52)
[junit4]    >        at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:36)
[junit4]    >        at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)
[junit4]    >        at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:56)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner.runSuite(RandomizedRunner.java:605)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner.access$400(RandomizedRunner.java:132)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner$2.run(RandomizedRunner.java:551)
[junit4]    > Throwable #2: java.lang.RuntimeException: Thread threw an uncaught exception, thread: Thread[Thread-548,5,]
[junit4]    >        at com.carrotsearch.randomizedtesting.RunnerThreadGroup.processUncaught(RunnerThreadGroup.java:96)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:857)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner.access$700(RandomizedRunner.java:132)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner$3$1.run(RandomizedRunner.java:669)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner$3.evaluate(RandomizedRunner.java:695)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner$4.evaluate(RandomizedRunner.java:734)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:745)
[junit4]    >        at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:45)
[junit4]    >        at org.apache.lucene.util.TestRuleReportUncaughtExceptions$1.evaluate(TestRuleReportUncaughtExceptions.java:68)
[junit4]    >        at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:38)
[junit4]    >        at org.apache.lucene.util.TestRuleIcuHack$1.evaluate(TestRuleIcuHack.java:51)
[junit4]    >        at com.carrotsearch.randomizedtesting.rules.SystemPropertiesInvariantRule$1.evaluate(SystemPropertiesInvariantRule.java:55)
[junit4]    >        at org.apache.lucene.util.TestRuleNoInstanceHooksOverrides$1.evaluate(TestRuleNoInstanceHooksOverrides.java:53)
[junit4]    >        at org.apache.lucene.util.TestRuleNoStaticHooksShadowing$1.evaluate(TestRuleNoStaticHooksShadowing.java:52)
[junit4]    >        at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:36)
[junit4]    >        at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)
[junit4]    >        at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:56)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner.runSuite(RandomizedRunner.java:605)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner.access$400(RandomizedRunner.java:132)
[junit4]    >        at com.carrotsearch.randomizedtesting.RandomizedRunner$2.run(RandomizedRunner.java:551)
[junit4]    > Caused by: java.lang.AssertionError: ram was 41605728 expected: 40986328 flush mem: 27371536 activeMem: 14234192 pendingMem: 0 flushingMem: 2 blockedMem: 0 peakDeltaMem: 3715948
[junit4]    >        at __randomizedtesting.SeedInfo.seed([256D0DE54BD0473A]:0)
[junit4]    >        at org.apache.lucene.index.DocumentsWriterFlushControl.assertMemory(DocumentsWriterFlushControl.java:114)
[junit4]    >        at org.apache.lucene.index.DocumentsWriterFlushControl.doAfterDocument(DocumentsWriterFlushControl.java:181)
[junit4]    >        at org.apache.lucene.index.DocumentsWriter.updateDocuments(DocumentsWriter.java:348)
[junit4]    >        at org.apache.lucene.index.IndexWriter.updateDocuments(IndexWriter.java:1174)
[junit4]    >        at org.apache.lucene.index.IndexWriter.addDocuments(IndexWriter.java:1134)
[junit4]    >        at org.apache.lucene.index.RandomIndexWriter.addDocument(RandomIndexWriter.java:157)
[junit4]    >        at org.apache.lucene.index.RandomIndexWriter.addDocument(RandomIndexWriter.java:145)
[junit4]    >        at org.apache.lucene.analysis.BaseTokenStreamTestCase.checkRandomData(BaseTokenStreamTestCase.java:555)
[junit4]    >        at org.apache.lucene.analysis.BaseTokenStreamTestCase.access$000(BaseTokenStreamTestCase.java:57)
[junit4]    >        at org.apache.lucene.analysis.BaseTokenStreamTestCase$AnalysisThread.run(BaseTokenStreamTestCase.java:414)
[junit4]    >
[junit4]   2> TEST FAIL: useCharFilter=false text='s z zxpw qu j jlpc \u10bd\u10bb\u10b4\u10c3\u10ab\u10a5 ag zuv vtjj \u0492\ue462\ue1b8\u02cd\uaf99\u026a cxv  xcyqyq m\ud9cbb \u1b84\u1ba7\u1b8c\u1b86 zq \u2059 fkg \u16f1\u16cf\u16f5\u16ca\u16ce\u16e4\u16a2 ya[ik \u0009^1  ;&# \uaa44\uaa13\uaa5b\uaa59\uaa12\uaa16 \ua965\ua97d\ua964\ua97d\ua968\ua974\ua966 \ue5db\uac21   \ue714\u6564et\u885d kjkqd .{ \ue932 \uf987 smyv bynhphqp kbv ] ]{1 qtrr \u2de6\u2df9\u2dfd \u042f$ twbpfnaz \uf12a\u8760c\uf242\u65dd ptwfoph [{1, t xmbvs OmFr \ua9d8\ua9c3\ua9a0\ua9c8\ua9db\ua9da\ua9c8\ua983 \u10431 \ud7c9\ud7d9\ud7e1\ud7fe\ud7d6\ud7b6 \u5649\uabdd~ e iceex hlglb ppcbklfa spq  \ua778\ua7ae \u258d\u2594\u2583\u259b\u2584\u258d\u2592\u259e \u034f jhbacf \u1ba7\u1b92\u1ba2\u1b88 yi q \ueab0\u9dc33\u065b\u0134\u0793 (h{0,5 cgg Swe \u0398\uf2c5[\u1920\ue5f9\u0589\u813a o \ua5ea\ua52f  r bWf  \u319c\u3198\u319d\u3193\u319e\u319a z|z.) \u24e3\u24de\u24d4\u2487\u24ce vqaaafd ? \u2bb9\u2b65\u2b3b\u2b9e  -yv.{0,5} \ue611\u01033\u0342\uea5c\u4164)\u0677  jnfaymol j \u2508 vvge \uf437\uc22d  pfoubst av \u26a3\u26b8\u266c\u2695\u269b \u4ddf \ua15d\ua3ef\ua2c2 </p  focqf \u014d\ub45ei -h \ua8fe\ua8f1\ua8ec\ua8fd\ua8f7 \u5ca7\u07cf ' \u02c0\u0342\ue884\u2890v\u9f78d oqsnpewn xbblilaf tndwtfqtj bjedbercm  By \u23f2 \u2df7\u2dfd\u2de2\u2de4 vdxdw \u6809\u9e9cf\ud632\uf524  \u10816  \ua800\ua81f\ua81a\ua821\ua80a\ua808 \ua73d\ua781\ua7ae all > \ua820\ua80b \u30d2\u30df\u30ff\u30f3 \u1008b vjijpdh </script> \u10164\u10183  myzcm \ua726 vkp iljo xetk athqzre fx juik \u0692  f(r 5\u7485\u6675 lvle  \u79300\u2370e\ufdab\uff94\uffb7\uf855T \u2618k ?{0,5}jn[?eh( qpawziia  ctb \u2b33\u2bad\u2bb6 uq  \ufe3c\u0794\uf225 \ua966\ue47a\u058a\ue094 hmb vef gunpnry \u0175 {0 lgr rspeigro \u0cf9\u0cfe dqg \u1b40\u1b03\u1b67\u1b08\u1b00\u1b22\u1b0f  acvfnq \u001e u \uf3c5\u29ff\uf172\u05e7\uf12f\u0651 fhb m lxjaa \u1c4d\u1c07\u1c3f\u1c09\u1c1b gdg \u1006\u105c\u1080\u1057\u1017\u1044\u1090 9\u043c\u523d5h\u0350 \u1d36a\u1d373 hxvvq hp ;--> 9\u4362f\ue6cab\\M\u0213 \u1c40\u1c2a\u1c40\u1c02 \u118a#\ueedb\uf9946 trm  \ue434dP\uffc9\ua0fe0\u001c \u24e0\u2468\u24c9\u24ba\u24e4\u2467 cylyAdr \u0455\u038e\uf37ak ggk hodch \u10850\u10850\u1085c\u10851\u10851 \u1103 vmbr \ub7963 \u0d5e\u0d6b\u0d39\u0d59\u0d1d\u0d0c\u0d3c \u015f\u01f0H\ucd55\u3fe0\u000e \ufe16\ufe1a\ufe18\ufe1e\ufe12\ufe11\ufe1e\ufe11\ufe1f )(]).{0,5}q \u0382\ud0047F\u5267\ue3c2 </ &# Tl\u0013\u6363\u11c61  gqftlg  S <!-- vy \u1fab vbe uth uep \u26a00\u25de5 \u07b2\ua5a2 pojdwa _\uad8b1b\u8d40 dzjra patxxtyk \u17ed\uff16o kvqyelu  \u31e6\u31ce\u31eb\u31e8 \ubcc2\u037ezH zx \u1e82\u1eca\u1ea9 zaki \u050c\u1b6e\uef15> \u2c60\u2c75\u2c78\u2c70\u2c65 x \u1fff\u1f27\u1fee \n\\\""\\' \uf0c7v\u3347Xy\uf83b \uebacd\u7a90f\ub5a7 rowfh \u1fe11\ufa3f\u0016\u96a6 pja euu \u8edc\ue07b\ubdf4\ub689\ub8b31h\u5a38 acqheoidhmu 7\u24f0\u087f\u8578\u4555 ksszgdl \u12d7\u12d8\u133b\u1211\u1280 kyfcnb ejnep \""p \u1968\u1967\u1950\u1956 ejinsu ohkiz  rcksdpve \ufcf7\u016a \ua5bd\ua504\ua5ea\ua540\ua5d5\ua627 \ue6a7\u7764\u7d60d\ub4cc\u5156\ufb49\u06b3\u0001 fervu  xn \u2d40\u2d5d\u2d3a\u2d7f\u2d4e vgs fsut {0,5}s \u10060\u10072\u10075 xxgks \u2813\u28a1  wusp ejjafxhc ihde zitwdlxavrh eh poh ri x\u667c6\u01f6 paie \ua8e6\ua8ef\ua8e0\ua8f5\ua8f2\ua8fa \u0685 pmacb jeo \uff52\uff77 zy '<p> ?rel \\' \u27d6\u27ce tu \ufe17\ufe13 zb shlkou K  zvjowv gy sl \uaac8\uaad1\uaab4\uaaac\uaa97\uaad7\uaab5\uaaa8\uaac7\uaad8\uaa9e 4  \u0003' \\\""\"" \u20e6\u20e3\u20f5 nfkwsd rwlw \uf41f ewv az  \u07bb qtc  ndUYsp  \u3160\u314e\u3136\u3139\u3185\u3133\u3175 debq   vdfd \u7d87f\u1983\ue1d4.- yeo \u0485ml z <?\n'\\'</s < u fhk \u07f2\u0325\u16a242 ptma \u0a85\u0ad8\u0a82\u0a90\u0ae0 \u6f84\u8a56\u1dec\u450e\u2d22c\u10da6f \u1d7c\u1d2f \ufa3c\u1430\u2b9be\u0770\u0018 lcgnclfdii ,\u54cf\u01ad\ubcfdf \u103cb\u103d9   \""  | \u00f0\u00c6\u00bb\u00cb\u00cc\u00dd\u00fb rmi \ufc97\ufd78\ufbce ynclv \ufcca\ufc0b\ufb6a\ufc25 hpnukxtjn ptuoqdda \u00e2\u597a\u0010\u2883\ub3cd\ue10f\uf3c8 j muwt bw \u37c3\ua4873 x \u87fe\u4a5f2\ufda5  \u2ad79\u2b5bf\u2b21c\u2ad13\u2b102 skrl rgepp \u1939\u1920\u1948\u1904\u194c \u07be \ueaef\uedfe\u0481\u010d \ubb01a\uce0a\u0668 </   ancxfe  fhgaca  nk 3\u45aa s]o]{0,  \u7152 tv \u044e\u02d6\u09e8 \u0a66\u0a69\u0a2e\u0a47\u0a62\u0a1c\u0a0b \u173f\u172b \u0504\u0515\u0504\u0520 \u9d67\uc6e0\ue13e\r\u6a67z \u02b3V\u6ff7\uf534\ueade\ue092\u06a2 b ebchlicd  \u04f9\u4141d\u0011\ue6ae \u0937\u097b\u092c\u096f\u0928\u0944\u0941 iwwrdqu  nkkz mu[[. \\'-->& ckbhwuat \u2e01\u2e2e\u2e12\u2e33\u2e30 >c \u1118\u1138\u1172\u1137\u11e8\u110a\u1147 \u0467 o \ue87ff  \u1090d\u10900  nreqyjvatc  \ued5a\uf44b udmc wnmg \u20da\u20d7\u20d4\u20ea\u20e4 \u2e2d\u2e33\u2e34 \u2ff9\u2ff1\u2ffd\u2ff3 \u1aa7\u1a28 wmwm \u2554\u2571\u250f\u2558\u2521\u250d\u252b o kjes uq \ufe1f\ufe13\ufe16\ufe14\ufe15\ufe13\ufe17\ufe1d aeebxvf o[hk][( veh \u06e2\u00ad\u0125\ued9c\u2223 rwf lcmtqev Ksvu \ue01c4\ue0146\ue0182 jtx ljpqre etzwnjnn BOmuXt bs \u0cac\u0cb7 lij eu   x \ufe2b\u1054\u0454\ue410 rd fscl  &#x& gkmrw \u2cd4\u2cfd\u2cf3\u2c88\u2cf1\u2c98 \u0c29\u0c09\u0c75\u0c4e zrhpfAdpax \u05477 &Ps  \ua6dc\ua6ae \u5b38e\ue7dbZ\ud038e\ua712b b{1,5})h rt \u185b \u31a9\u31ba\u31a9\u31bb\u31b7\u31b2\u31a9\u31ba \u2cf5\u2cfa\u2ca9\u2cfd ovxf xegi \uaec48\u09bb\ufd01\ua107\uf5c2 \u2f70\u2f9a cppxm zzi ?><! epsrs \u076e\u0761\u0754\u075e\u075f\u075a\u0754\u0763 \u1093f\u10922   ` ]{0, & qgbiwn  < vyge acmvidw xbwgrppk \uf612p\u05f5^\u048f\u056d \ud6436\u9cde0\u274e\u0592 tamcca \ufd7b\ufbf9\ufb88\ufbae tusifiwj \u000f\u0600\uef93}\u28e7\u599ab zk \u09ed\u09d1 > y \u013d\u0171\u011e\u0142\u012f irxvlpgbl xiw tjdelwn lxlojUEj  Ttik xtoxop dansms  \u29b5\u2983\u299a\u2988\u29b1 |(](|s[ tgllq vmuy ksizv \ua77f\ua74a\ua759\ua799\ua7f4\ua75b\ua7ee\ua770 vvm agcuehf syu f \ufe79\u001d raxj \u8f2aH \u207a\u2086\u207f\u208b\u207b\u2088\u2098 \ud813b\u1f70  vpawp hevp \u4436\ueace9\u2133 koaba mikat \u31fe\u31f8\u31f6\u31f2\u31f5\u31f3\u31f2\u31fd\u31ff \ue19b\u0424\u04f6K\ucab95 thmvy  \uffa6\uff6e\uff1c\uff98\uff82\uff44 \\'\\ pahfinz \uf650\ue338\u15b4\u0011\"" \uf9a3\ufac3\uf905\uf9d1\ufa80\uf976 ' \u1357\u1244\u1336\u1209\u124f\u1338 o pora   \u3107\u3106\u312e\u310e\u3126\u3115\u3108 \u0014 \ua92c\ua905\ua920 \u8dfe2\u31102\ue695\uf742 nxsxezzn quende \u2d6e\u2d72\u2d4a\u2d6f aqroaomb  w.b({0 wtx ot \u2116\u2120\u2131 \uff65\u25ed\u023e\u3389\uecca\u89590\ud4325\ua3e9dx vj \uec30\u06057 oiq sfncjcxm jkcycin  \u040e anrwz \u024c\u42e01 <!--# fe qnf lq 6;T awm huxr d)l \ue404\ucfb1 \ua557\ua5be\ua588\ua5f3\ua58a\ua57c\ua5a6  L0\uf8ed q pbyvjuqtq \u0c51\u0c50 hsjfsnig glgw \u4d2d\u0342T\ufb58D\u0ed5 fmft ?><! p \u3b83a\ue92b\uc2d0\u0c95\u0091 \u2565 \u0a8e\u0ab2\u0acc\u0ac6 \u10a06\u10a27  ke bromtk hoixcmuvf onmotohc m\uf434\u2451  pesvv glrugbidmi aRRrrF ofopzwucn \u32b8\u86f4\uf05b \u2c98\u2c82\u2c97  ?s|]ql \u13c3\u13e3\u13e2\u13ac  mrgslmse \uf717 )wlax]|[ atq \u03ea}\u105b9a\u0443  ck  \ufa368\u0e3a \u5cae4&\ua107\u8581\uf5d0 \uf2d03\u0005 <p>?><?-- \u2458\u2454\u2450\u2442\u2450\u2446\u2452\u2451\u2444 \u174f\u1741\u174f wksf gsunjwo \u10348\u10344 \u4a4e\u10e36a\uf305 ></s \u0dfa\u0dbb\u0df5\u0d81\u0dc1\u0db2\u0dd7  otfvyni vc x \u0816\u0833\u082b\u0822\u0829\u080e \u477f\u0652\u03c3\u0301 \ua1cac \u16c6\u001c \ufe9c\ufe92 zzTWohEr \u0e48\u0e25\u0e23\u0e1c\u0e6b tqff x.)mpp f \uf876W\uea505I\u72df\u8c470 kt| xkyjxh ujerwftr \u2e5a\u2e78\u2e19\u2e44\u2e4d\u2e55\u2e47  msllr 5\ueac9\ufc31o \u039d\u9a5b\uf61b\ue5d5\u07b0\ue641\ua924\u07e5 g \ua907\ua900\ua92e \ua0468\ue2fb\ue945\uceaf \u16ea\u16fd\u16ea\u16b3\u16e3\u16ee\u16b1\u16cb\u16e8\u16bf \u1941\u1908\u1911\u194d\u193d\u1936\u1935 \u20d9\u20d8\u20eb\u20ea\u20ea\u20fa\u20ed jdrslh \u2153\u2171\u2180\u2181\u2161\u2153\u2160 \u0921 \u001c\u032ak \u10485\u10487 rqxuf I\ufce8 \u703e\u964d\u80bb\u6647\u739c\u75b5\u5f5d yu guanyrd rwuue c wv \u1c0c\u1c39\u1c21\u1c38 giu \u592da\u0440\u82a2\ue661  aqxoj \uac3f\u0018\u001a\ue7a8  uaj qio \u1e78\u1ee1\u1e27\u1e33 \u0220\u0227\u0209\u0229\u023f zrt crjd  yh yzn nkndmyewfqzi \ud54a\uc064\u00dd\ucb2d\u4d6b jmohh \u0b3d\u0b0b\u0b0c\u0b10\u0b46\u0b45 pzwi \\\""- ahbbaye tiazuvfnfh Q\u0179 \u2c68\u2c77\u2c7c kbpre aobgk uzsxgtxp &;>< n r \u68ca0\u00b1 kaqtji ] yq =^ \u10a78\u10a6c\u10a60 \ufe64\ufe6e\ufe53 hjMQtFba swv \u1f193 &#x54c {0,5} qxj qeat \ufe52\ufe66\ufe65 \u069a\ued9c\u037a\u00e7\u0657|\u0400 rjc yaeqtzpgsu \u72bdO\u0517\u4d4fa\uc910\u5b30 @\u02f5 \ua726 y\ua148\uf2b4 oaq \u2325 \ue153X p zdb \ud6bbN\u218e} \u1033f\u10347\u10341 d \u10016\u10071 \u309b \u0da2\u0da9 {1 \u9ed2\u8b89\u0a42 wpv ot g  oedh L\ub94f9u;Q \u0539\uaa76\u9e9b\u31d4 qje neizli xzxgeh \u2413 \u033f\u001f &#x3 \u2e34\u2e28\u2e5d\u2e08 xpne \u1029d zhj  \u01ed\uf1f2a\ufca5# ]|yd{0  lgfxbowak  fyuv ymsh ervcv \u22fc\u22bb \ufeaf\ufee6\ufeeb\ufef1\ufe71 ogrkop  \u319d \ud4b6\u614db \u2a08\u2a1c\u2a2a\u2ace\u2a86\u2a10\u2af9\u2a58\u2a43\u2a3f\u2abb\u2acc <  \u008b\uf68de\u06e5 \u104a2\u10482 qxurjt \uf7db\uf352\ue29c \""<p \u10286\u10280 hasmw  lmga mu \ufd0f\ubee28\u0648\u9aea\u1013b6\u8174\u0006\ue2aed ` w mciod aysqvom qnrtdqmqu nf nexjvlz \u2182\u2154\u2154\u2184\u216c \u05d1\uf045\ucd7e5\u2af3\u16683 pw dva \\\""<    \uf151\u0016\u053fe Y\u0002\u7872 \ufe1a\ufe17\ufe14\ufe18 jidqkxf bbr \u3190\u3196\u319e\u3194\u319b\u3194\u3195\u3191 llizhg wnkzu  jfcz \u05349\u0011 \u5050l\u0391\u06a0 \u5ef8\u03bd\ubc21 \u001e  \u0013\ufcc7 \ua8bb\ua8da pqsuegc ihux zgxsqjzsckix olu iext  ptfvv A\u59c7\u050c  nf cnteyylh m \uf0e2\u97f9t\u31183 lrtv <p></   <?&s jhwuauv OfwV \uecbf^\u03e3\uc563\ued78\u584e\ue177 \u169f\u1691\u169a\u169c\u1681 n ahfejklim \u00b7-\ufea9 dbg bwdkew slxkv \uf723  fmntdq qjkfhl a fr[[ \u1041a\u1044b gu \u1d355 e |])cev \u1033b\u10333\u10332 Y \u3027\u300d\u3019 w \u0770\u076f\u0761\u0775\u0760\u076c\u0774 pvduh pstk mzh rg \ua8d6 gtex \u2335\u237b\u2344\u238e fyns uirr  \u0fc5\u0fad\u0f51 jwfpos bc \u03df\u03c5\u0395\u03b0\u0384 \u13186\u1302f\u1340e\u133e0 \u313b\u3136 oo{ upa \u19c2\u198f\u1998\u199e nko \u1d36a wro dpu \ua84f\ua878\ua852 Y\ucd66 btpml hefxu u \uf4fc\u0708\u0669\u9520 kkbiqh weecmoy gej xAm hn <   frge wuc &#1564800  zfi xon ozbtjdbnjqx \u04de\u0421\u047c\u04d1 iy \ufe35\ufe47\ufe3e tyrbgo czunk o\u05a1 <?<p oz igye \u24af\u24d0\u249c\u248e\u24cf\u24bf \ud7c3\uf4c0 xeqodif pyl(a ni \u12387\u122db mmibcrb  pboxwmy k ghtr lwqolgdvc \ud7e9\ud7ec\ud7d3\ud7cb\ud7ff &# \uaac1\uaa98\uaaba\uaab0\uaaa1 \u0c7d\uaa2d\u7302\u6246f\uce3e3 ixmms \uff1f\uff80\uffa4 \ue2d2\u01ed t?](k bai \u214e\u214b\u2143 npmzph \ua4fc\ua4e2\ua4d4\ua4d3\ua4d4  \ua82f\ua81e\ua82f\ua809 o \u2175\u216c sibzotjcl zwaoxf bchxwxe  w oes iz  rmiq cm  \uf1b5\u05b6\u74a80\u06a2\ufcbc \u458b  jbwscrrdaor pbra \ua7db\ua729\ua756\ua7f6\ua762\ua763 \uff64\ua5121\ue447\u05c6 akf suk lgpjc lixjys wjrf'
[junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=NGramTokenizerTest -Dtests.method=testRandomStrings -Dtests.seed=256D0DE54BD0473A -Dtests.multiplier=3 -Dtests.locale=es_AR -Dtests.timezone=Asia/Baku -Dargs=""-Dfile.encoding=UTF-8""
[junit4]   2>
[junit4]    > (@AfterClass output)
[junit4]   2> NOTE: test params are: codec=Lucene40: {dummy=MockFixedIntBlock(blockSize=1329)}, sim=RandomSimilarityProvider(queryNorm=true,coord=true): {dummy=DFR I(n)3(800.0)}, locale=es_AR, timezone=Asia/Baku
[junit4]   2> NOTE: Linux 2.6.32-41-server amd64/Sun Microsystems Inc. 1.6.0_32 (64-bit)/cpus=8,threads=1,free=222774808,total=419037184
[junit4]   2> NOTE: All tests run in this JVM: [TestWordlistLoader, TestTurkishLowerCaseFilter, TestGermanMinimalStemFilter, TestSpanishAnalyzer, TestCJKWidthFilter, HunspellStemmerTest, TestDutchStemmer, TokenTypeSinkTokenizerTest, TestCharFilter, TestStemmerOverrideFilter, TestSolrSynonymParser, DateRecognizerSinkTokenizerTest, ShingleFilterTest, TestItalianLightStemFilter, TestThaiAnalyzer, TestPortugueseMinimalStemFilter, TestCharArraySet, TestKeepWordFilter, TestSnowball, TestLengthFilter, TestLimitTokenCountAnalyzer, TestFrenchLightStemFilter, TestItalianAnalyzer, TestLatvianStemmer, TestNorwegianLightStemFilter, TestGermanNormalizationFilter, TestPathHierarchyTokenizer, TokenRangeSinkTokenizerTest, TestHungarianAnalyzer, TestCharArrayIterator, TestCzechAnalyzer, TestSynonymMapFilter, TestBulgarianStemmer, CommonGramsFilterTest, TestPortugueseStemFilter, WikipediaTokenizerTest, TestCharTokenizers, TestRussianLightStemFilter, TestTypeTokenFilter, TestGermanAnalyzer, TestFinnishLightStemFilter, TestHindiAnalyzer, TestMappingCharFilter, TestBugInSomething, TestPerFieldAnalzyerWrapper, NGramTokenizerTest]
[junit4]   2>
[junit4] Completed on J1 in 3162.49s, 8 tests, 1 error <<< FAILURES!
[...truncated 23 lines...]
BUILD FAILED
/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux-Java6-64/checkout/build.xml:29: The following error occurred while executing this line:
/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux-Java6-64/checkout/lucene/build.xml:456: The following error occurred while executing this line:
/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux-Java6-64/checkout/lucene/common-build.xml:1435: The following error occurred while executing this line:
/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux-Java6-64/checkout/lucene/analysis/build.xml:101: The following error occurred while executing this line:
/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux-Java6-64/checkout/lucene/analysis/build.xml:38: The following error occurred while executing this line:
/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux-Java6-64/checkout/lucene/module-build.xml:62: The following error occurred while executing this line:
/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux-Java6-64/checkout/lucene/common-build.xml:1037: The following error occurred while executing this line:
/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux-Java6-64/checkout/lucene/common-build.xml:760: There were test failures: 139 suites, 891 tests, 1 error, 1 ignored
Total time: 60 minutes 57 seconds
Build step 'Execute shell' marked build as failure
Archiving artifacts
Recording test results
Email was triggered for: Failure
Sending email for trigger: Failure
{noformat}",org.apache.lucene.index.DocumentsWriterFlushControl
CLASS,lucene-4.0,LUCENE-4461,2012-10-05T10:21:38.000-05:00,Multiple FacetRequest with the same path creates inconsistent results,"FacetSearchParams facetSearchParams = new FacetSearchParams();
		facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(""author""), 10));
		facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(""author""), 10));
Multiple FacetRequest are getting merged into one creating wrong results in this case:
FacetSearchParams facetSearchParams = new FacetSearchParams();
		facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(""author""), 10));
		facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(""author""), 10));
Problem can be fixed by defining hashcode and equals in certain way that Lucene recognize we are talking about different requests.
Attached test case.",org.apache.lucene.facet.search.StandardFacetsAccumulator
CLASS,lucene-4.0,LUCENE-4532,2012-11-04T02:51:37.000-06:00,TestDirectoryTaxonomyReader.testRefreshReadRecreatedTaxonomy failure,"{noformat}
  
 
  
 
     
                                          
 
         
  
 
     
                                                 {}    
 
                                                                              
  
  
  
  
  
  
  
 {noformat}
The following failure on Jenkins:
{noformat}
> Build: http://jenkins.sd-datasolutions.de/job/Lucene-Solr-4.x-Windows/1404/
> Java: 32bit/jdk1.6.0_37 -client -XX:+UseConcMarkSweepGC
>
> 1 tests failed.
> REGRESSION:  org.apache.lucene.facet.taxonomy.directory.TestDirectoryTaxonomyReader.testRefreshReadRecreatedTaxonomy
>
> Error Message:
>
>
> Stack Trace:
> java.lang.ArrayIndexOutOfBoundsException
>         at __randomizedtesting.SeedInfo.seed([6AB10D3E4E956CFA:BFB2863DB7E077E0]:0)
>         at java.lang.System.arraycopy(Native Method)
>         at org.apache.lucene.facet.taxonomy.directory.ParentArray.refresh(ParentArray.java:99)
>         at org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader.refresh(DirectoryTaxonomyReader.java:407)
>         at org.apache.lucene.facet.taxonomy.directory.TestDirectoryTaxonomyReader.doTestReadRecreatedTaxono(TestDirectoryTaxonomyReader.java:167)
>         at org.apache.lucene.facet.taxonomy.directory.TestDirectoryTaxonomyReader.testRefreshReadRecreatedTaxonomy(TestDirectoryTaxonomyReader.java:130)
>         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
>         at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
>         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
>         at java.lang.reflect.Method.invoke(Method.java:597)
>         at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1559)
>         at com.carrotsearch.randomizedtesting.RandomizedRunner.access$600(RandomizedRunner.java:79)
>         at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:737)
>         at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:773)
>         at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:787)
>         at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)
>         at org.apache.lucene.util.TestRuleFieldCacheSanity$1.evaluate(TestRuleFieldCacheSanity.java:51)
>         at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:45)
>         at com.carrotsearch.randomizedtesting.rules.SystemPropertiesInvariantRule$1.evaluate(SystemPropertiesInvariantRule.java:55)
>         at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:48)
>         at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:70)
>         at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)
>         at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
>         at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:358)
>         at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:782)
>         at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:442)
>         at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:746)
>         at com.carrotsearch.randomizedtesting.RandomizedRunner$3.evaluate(RandomizedRunner.java:648)
>         at com.carrotsearch.randomizedtesting.RandomizedRunner$4.evaluate(RandomizedRunner.java:682)
>         at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:693)
>         at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:45)
>         at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)
>         at com.carrotsearch.randomizedtesting.rules.SystemPropertiesInvariantRule$1.evaluate(SystemPropertiesInvariantRule.java:55)
>         at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39)
>         at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39)
>         at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
>         at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:43)
>         at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)
>         at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:70)
>         at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)
>         at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
>         at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:358)
>         at java.lang.Thread.run(Thread.java:662)
>
>
>
>
> Build Log:
> [...truncated 5664 lines...]
> [junit4:junit4] Suite: org.apache.lucene.facet.taxonomy.directory.TestDirectoryTaxonomyReader
> [junit4:junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestDirectoryTaxonomyReader -Dtests.method=testRefreshReadRecreatedTaxonomy -Dtests.seed=6AB10D3E4E956CFA -Dtests.slow=true -Dtests.locale=fr_CA -Dtests.timezone=Atlantic/Jan_Mayen -Dtests.file.encoding=US-ASCII
> [junit4:junit4] ERROR   0.06s | TestDirectoryTaxonomyReader.testRefreshReadRecreatedTaxonomy <<<
> [junit4:junit4]    > Throwable #1: java.lang.ArrayIndexOutOfBoundsException
> [junit4:junit4]    >    at __randomizedtesting.SeedInfo.seed([6AB10D3E4E956CFA:BFB2863DB7E077E0]:0)
> [junit4:junit4]    >    at java.lang.System.arraycopy(Native Method)
> [junit4:junit4]    >    at org.apache.lucene.facet.taxonomy.directory.ParentArray.refresh(ParentArray.java:99)
> [junit4:junit4]    >    at org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader.refresh(DirectoryTaxonomyReader.java:407)
> [junit4:junit4]    >    at org.apache.lucene.facet.taxonomy.directory.TestDirectoryTaxonomyReader.doTestReadRecreatedTaxono(TestDirectoryTaxonomyReader.java:167)
> [junit4:junit4]    >    at org.apache.lucene.facet.taxonomy.directory.TestDirectoryTaxonomyReader.testRefreshReadRecreatedTaxonomy(TestDirectoryTaxonomyReader.java:130)
> [junit4:junit4]    >    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
> [junit4:junit4]    >    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
> [junit4:junit4]    >    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
> [junit4:junit4]    >    at java.lang.reflect.Method.invoke(Method.java:597)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1559)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.RandomizedRunner.access$600(RandomizedRunner.java:79)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:737)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:773)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:787)
> [junit4:junit4]    >    at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50)
> [junit4:junit4]    >    at org.apache.lucene.util.TestRuleFieldCacheSanity$1.evaluate(TestRuleFieldCacheSanity.java:51)
> [junit4:junit4]    >    at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:45)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.rules.SystemPropertiesInvariantRule$1.evaluate(SystemPropertiesInvariantRule.java:55)
> [junit4:junit4]    >    at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:48)
> [junit4:junit4]    >    at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:70)
> [junit4:junit4]    >    at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:358)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:782)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:442)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:746)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.RandomizedRunner$3.evaluate(RandomizedRunner.java:648)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.RandomizedRunner$4.evaluate(RandomizedRunner.java:682)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:693)
> [junit4:junit4]    >    at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:45)
> [junit4:junit4]    >    at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.rules.SystemPropertiesInvariantRule$1.evaluate(SystemPropertiesInvariantRule.java:55)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
> [junit4:junit4]    >    at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:43)
> [junit4:junit4]    >    at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)
> [junit4:junit4]    >    at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:70)
> [junit4:junit4]    >    at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
> [junit4:junit4]    >    at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:358)
> [junit4:junit4]    >    at java.lang.Thread.run(Thread.java:662)
> [junit4:junit4]   2> NOTE: test params are: codec=SimpleText, sim=RandomSimilarityProvider(queryNorm=true,coord=crazy): {}, locale=fr_CA, timezone=Atlantic/Jan_Mayen
> [junit4:junit4]   2> NOTE: Windows 7 6.1 x86/Sun Microsystems Inc. 1.6.0_37 (32-bit)/cpus=2,threads=1,free=59103720,total=93417472
> [junit4:junit4]   2> NOTE: All tests run in this JVM: [ObjectToIntMapTest, UnsafeByteArrayInputStreamTest, IntArrayTest, EncodingTest, CustomAssociationPropertyTest, TestDirectoryTaxonomyWriter, FacetSearchParamsTest, DefaultEnhancementsIndexingParamsTest, TestCategoryListCache, TestTopKInEachNodeResultHandler, AdaptiveAccumulatorTest, Vint8Test, TestScoredDocIdCollector, IntToIntMapTest, AssociationPropertyTest, TestMultiCLExample, ArrayHashMapTest, CategoryListIteratorTest, TestTopKResultsHandlerRandom, TestTotalFacetCounts, SamplingWrapperTest, TestCharBlockArray, IntToDoubleMapTest, TestFacetsCollector, TestFacetsAccumulatorWithComplement, SamplingAccumulatorTest, TestTopKResultsHandler, CategoryAttributesIterableTest, CategoryAttributesStreamTest, TestFacetArrays, TestCompactLabelToOrdinal, CategoryListPayloadStreamTest, CategoryTokenizerTest, TestAddTaxonomy, TestTotalFacetCountsCache, TestTaxonomyCombined, FacetsPayloadProcessorProviderTest, OrdinalPolicyTest, PathPolicyTest, TestScoredDocIDsUtils, TestDirectoryTaxonomyReader]
> [junit4:junit4] Completed in 0.11s, 7 tests, 1 error <<< FAILURES!
>
> [...truncated 81 lines...]
> BUILD FAILED
> C:\Users\JenkinsSlave\workspace\Lucene-Solr-4.x-Windows\build.xml:335: The following error occurred while executing this line:
> C:\Users\JenkinsSlave\workspace\Lucene-Solr-4.x-Windows\build.xml:39: The following error occurred while executing this line:
> C:\Users\JenkinsSlave\workspace\Lucene-Solr-4.x-Windows\lucene\build.xml:519: The following error occurred while executing this line:
> C:\Users\JenkinsSlave\workspace\Lucene-Solr-4.x-Windows\lucene\common-build.xml:1691: The following error occurred while executing this line:
> C:\Users\JenkinsSlave\workspace\Lucene-Solr-4.x-Windows\lucene\module-build.xml:61: The following error occurred while executing this line:
> C:\Users\JenkinsSlave\workspace\Lucene-Solr-4.x-Windows\lucene\common-build.xml:1163: The following error occurred while executing this line:
> C:\Users\JenkinsSlave\workspace\Lucene-Solr-4.x-Windows\lucene\common-build.xml:827: There were test failures: 65 suites, 264 tests, 1 error, 2 ignored (1 assumption)
>
> Total time: 18 minutes 43 seconds
> Build step 'Invoke Ant' marked build as failure
> Archiving artifacts
> Recording test results
> Description set: Java: 32bit/jdk1.6.0_37 -client -XX:+UseConcMarkSweepGC
> Email was triggered for: Failure
> Sending email for trigger: Failure
{noformat}","org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader.ChildrenArraysImpl
org.apache.lucene.facet.taxonomy.directory.TestDirectoryTaxonomyWriter
org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader
org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter"
CLASS,lucene-4.0,LUCENE-4561,2012-11-15T10:06:09.000-06:00,DWPT assert tripped again,"{noformat}
   
 {noformat}

 
 {noformat}
   
  
    
    
    
            
    
    
            
    
    
               {field=DFR I(ne)1} 
                                                                                                                                                                                                                                                                                                                          
 {noformat}
TestBagOfPositions tripped the spooky DWPT ram used on flush assert in http://jenkins.sd-datasolutions.de/job/Lucene-Solr-4.x-Linux/2472/
{noformat}
ant test  -Dtestcase=TestBagOfPositions -Dtests.method=test -Dtests.seed=730E05D38A0E4AFA -Dtests.multiplier=3 -Dtests.slow=true -Dtests.locale=de_DE_PREEURO -Dtests.timezone=America/Metlakatla -Dtests.file.encoding=UTF-8
{noformat}
Full failure:
{noformat}
[junit4:junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestBagOfPositions -Dtests.method=test -Dtests.seed=730E05D38A0E4AFA -Dtests.multiplier=3 -Dtests.slow=true -Dtests.locale=de_DE_PREEURO -Dtests.timezone=America/Metlakatla -Dtests.file.encoding=UTF-8
[junit4:junit4] ERROR   63.2s J0 | TestBagOfPositions.test <<<
[junit4:junit4]    > Throwable #1: com.carrotsearch.randomizedtesting.UncaughtExceptionError: Captured an uncaught exception in thread: Thread[id=2163, name=Thread-1670, state=RUNNABLE, group=TGRP-TestBagOfPositions]
[junit4:junit4]    > Caused by: java.lang.AssertionError: actual mem: 33763152 byte, expected mem: 33755888 byte, flush mem: 33610208, active mem: 152944, pending DWPT: 0, flushing DWPT: 2, blocked DWPT: 0, peakDelta mem: 67152 byte
[junit4:junit4]    > 	at __randomizedtesting.SeedInfo.seed([730E05D38A0E4AFA]:0)
[junit4:junit4]    > 	at org.apache.lucene.index.DocumentsWriterFlushControl.assertMemory(DocumentsWriterFlushControl.java:120)
[junit4:junit4]    > 	at org.apache.lucene.index.DocumentsWriterFlushControl.doAfterDocument(DocumentsWriterFlushControl.java:187)
[junit4:junit4]    > 	at org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:384)
[junit4:junit4]    > 	at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1451)
[junit4:junit4]    > 	at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:1126)
[junit4:junit4]    > 	at org.apache.lucene.index.RandomIndexWriter.addDocument(RandomIndexWriter.java:201)
[junit4:junit4]    > 	at org.apache.lucene.index.RandomIndexWriter.addDocument(RandomIndexWriter.java:160)
[junit4:junit4]    > 	at org.apache.lucene.index.TestBagOfPositions$1.run(TestBagOfPositions.java:111)
[junit4:junit4]    > Throwable #2: com.carrotsearch.randomizedtesting.UncaughtExceptionError: Captured an uncaught exception in thread: Thread[id=2164, name=Thread-1671, state=RUNNABLE, group=TGRP-TestBagOfPositions]
[junit4:junit4]    > Caused by: java.lang.AssertionError: actual mem: 33763152 byte, expected mem: 33755888 byte, flush mem: 33610208, active mem: 152944, pending DWPT: 0, flushing DWPT: 2, blocked DWPT: 0, peakDelta mem: 67152 byte
[junit4:junit4]    > 	at __randomizedtesting.SeedInfo.seed([730E05D38A0E4AFA]:0)
[junit4:junit4]    > 	at org.apache.lucene.index.DocumentsWriterFlushControl.assertMemory(DocumentsWriterFlushControl.java:120)
[junit4:junit4]    > 	at org.apache.lucene.index.DocumentsWriterFlushControl.doAfterDocument(DocumentsWriterFlushControl.java:187)
[junit4:junit4]    > 	at org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:384)
[junit4:junit4]    > 	at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1451)
[junit4:junit4]    > 	at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:1126)
[junit4:junit4]    > 	at org.apache.lucene.index.RandomIndexWriter.addDocument(RandomIndexWriter.java:201)
[junit4:junit4]    > 	at org.apache.lucene.index.RandomIndexWriter.addDocument(RandomIndexWriter.java:160)
[junit4:junit4]    > 	at org.apache.lucene.index.TestBagOfPositions$1.run(TestBagOfPositions.java:111)
[junit4:junit4]    > Throwable #3: com.carrotsearch.randomizedtesting.UncaughtExceptionError: Captured an uncaught exception in thread: Thread[id=2166, name=Thread-1673, state=RUNNABLE, group=TGRP-TestBagOfPositions]
[junit4:junit4]    > Caused by: java.lang.AssertionError: actual mem: 33763152 byte, expected mem: 33755888 byte, flush mem: 33610208, active mem: 152944, pending DWPT: 0, flushing DWPT: 2, blocked DWPT: 0, peakDelta mem: 67152 byte
[junit4:junit4]    > 	at __randomizedtesting.SeedInfo.seed([730E05D38A0E4AFA]:0)
[junit4:junit4]    > 	at org.apache.lucene.index.DocumentsWriterFlushControl.assertMemory(DocumentsWriterFlushControl.java:120)
[junit4:junit4]    > 	at org.apache.lucene.index.DocumentsWriterFlushControl.doAfterDocument(DocumentsWriterFlushControl.java:187)
[junit4:junit4]    > 	at org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:384)
[junit4:junit4]    > 	at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1451)
[junit4:junit4]    > 	at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:1126)
[junit4:junit4]    > 	at org.apache.lucene.index.RandomIndexWriter.addDocument(RandomIndexWriter.java:201)
[junit4:junit4]    > 	at org.apache.lucene.index.RandomIndexWriter.addDocument(RandomIndexWriter.java:160)
[junit4:junit4]    > 	at org.apache.lucene.index.TestBagOfPositions$1.run(TestBagOfPositions.java:111)
[junit4:junit4]   2> NOTE: test params are: codec=SimpleText, sim=RandomSimilarityProvider(queryNorm=false,coord=no): {field=DFR I(ne)1}, locale=de_DE_PREEURO, timezone=America/Metlakatla
[junit4:junit4]   2> NOTE: Linux 3.2.0-32-generic amd64/IBM Corporation 1.6.0 (64-bit)/cpus=8,threads=1,free=55064736,total=63793152
[junit4:junit4]   2> NOTE: All tests run in this JVM: [Nested1, TestIndexWriterWithThreads, TestLevenshteinAutomata, TestBasicOperations, TestStressNRT, TestIndexWriterExceptions, TestConjunctions, TestMultiLevelSkipList, TestConcurrentMergeScheduler, TestIndexWriterOnDiskFull, TestBytesRef, TestThreadedForceMerge, TestDocument, TestCopyBytes, TestIndexWriterNRTIsCurrent, TestScoreCachingWrappingScorer, TestScorerPerf, TestDocValuesTypeCompatibility, TestPrefixCodedTerms, TestRollingBuffer, TestPhrasePrefixQuery, Test4GBStoredFields, TestCustomSearcherSort, TestExplanations, TestIndexInput, TestMultiThreadTermVectors, TestTermInfosReaderIndex, TestSearchAfter, Test2BPositions, TestField, TestSimpleAttributeImpl, TestFlushByRamOrCountsPolicy, TestSimilarityBase, TestByteSlices, TestFlex, TestRecyclingByteBlockAllocator, TestCrash, Test2BTerms, TestSearcherManager, TestDeterminism, TestDemo, TestSpanExplanationsOfNonMatches, TestSubScorerFreqs, TestDocIdSet, TestFieldValueFilter, TestSpanMultiTermQueryWrapper, TestTermVectors, TestSurrogates, TestSimilarity2, Nested1, TestParallelReaderEmptyIndex, TestShardSearching, TestBlockPostingsFormat3, TestPagedBytes, TestCustomNorms, Before3, Before3, TestSegmentReader, TestMatchAllDocsQuery, TestTopDocsCollector, TestNoMergeScheduler, TestDeletionPolicy, Nested1, ThrowInUncaught, TestMultiTermConstantScore, TestPhraseQuery, TestGraphTokenizers, TestBitVector, TestPerFieldPostingsFormat2, TestSegmentTermEnum, TestVersion, TestNGramPhraseQuery, TestBackwardsCompatibility3x, TestRegexpRandom2, TestDirectoryReaderReopen, TestCompoundFile, TestBlockPostingsFormat, TestNRTThreads, TestPayloads, TestTransactions, TestTermRangeQuery, TestSmallFloat, TestFSTs, TestNorms, TestLookaheadTokenFilter, TestDuelingCodecs, TestAtomicUpdate, TestTermsEnum, TestMultiMMap, TestTimeLimitingCollector, TestTopDocsMerge, TestNRTManager, TestArrayUtil, TestBufferedIndexInput, TestIndexWriterForceMerge, TestIndexWriterCommit, TestWeakIdentityMap, TestTypePromotion, TestSimpleExplanations, TestStressIndexing, TestSnapshotDeletionPolicy, TestNRTReaderWithThreads, TestTieredMergePolicy, TestConsistentFieldNumbers, TestCrashCausesCorruptIndex, TestNumericUtils, TestMultiValuedNumericRangeQuery, TestCharTermAttributeImpl, TestRollingUpdates, TestPrefixInBooleanQuery, TestBytesRefHash, TestRamUsageEstimatorOnWildAnimals, TestFieldCacheRangeFilter, TestPayloadSpans, TestMixedCodecs, TestSegmentTermDocs, TestFieldCacheSanityChecker, TestDoc, TestMergeSchedulerExternal, TestOmitTf, TestDisjunctionMaxQuery, TestSimpleSearchEquivalence, Nested, Nested, Nested, Nested, Nested, Nested, Nested, Nested, Nested, Nested, Nested, Nested, Nested, Nested, Nested, Nested, Nested, Nested, Nested, Nested, Nested, TestPayloadNearQuery, TestFilteredQuery, TestPayloadExplanations, TestDocsAndPositions, TestTransactionRollback, TestCompiledAutomaton, TestSentinelIntSet, TestIndexableField, TestBooleanQuery, TestAutomatonQuery, TestComplexExplanationsOfNonMatches, TestRegexpQuery, TestDocCount, TestSearchForDuplicates, TestFilteredSearch, NestedSetupChain, NestedTeardownChain, Nested, Nested, TestDateFilter, TestSpansAdvanced, TestConstantScoreQuery, TestDateTools, TestSearch, TestReaderClosed, TestElevationComparator, TestAutomatonQueryUnicode, TestDateSort, TestBinaryDocument, TestSpanFirstQuery, TestPriorityQueue, TestDocBoost, TestMockCharFilter, TestIsCurrent, TestPrefixFilter, TestBitUtil, TestVersionComparator, TestCachingTokenFilter, TestTermdocPerf, TestTerm, TestLucene40PostingsFormat, TestAllFilesHaveCodecHeader, TestBagOfPositions]
{noformat}",org.apache.lucene.index.DocumentsWriterFlushControl
CLASS,jedit-4.3,1193683,2005-05-02T09:22:25.000-05:00,"folding bug, text is in a black hole","{\{\{ test
aaaa
bbbb
cccc
\}
\{\{\{ test aaaa bbbb cccc
\}\}\}
Close it you'll get
\{\{\{ test \[4 lines\]
You'll have
\{\{ test
and no text fold anymore.
It seems really dangerous isn't it ?
But the weird thing is that the text is not completely lost because you can type another \{ \(no need to undo\)
and the fold will reappear magically.
So the text was still here but hidden by jEdit's text area",org.gjt.sp.jedit.textarea.BufferHandler
CLASS,jedit-4.3,1571752,2006-10-05T21:26:12.000-05:00,'Add Explicit Fold'  in PHP mode - wrong comments,"{

\} 
 {\{\{  --&gt;
function foo\(\) \{

\} //\}\}\}
jEdit version: 4.3pre7
Java version: 1.6.0-beta2
Before 'Add Explicit fold' the content of buffer looks like this \('X' means selection boundaries\):
&lt;? php
Xfunction foo\(\) \{
\}X
/\* :folding=explicit:\*/
?&gt;
After:
&lt;? php
&lt;\!
--\{\{\{  --&gt;
function foo\(\) \{
\} //\}\}\}
/\* :folding=explicit:\*/
?&gt;
If is between '&lt;? php' and 'function' empty line, then it works OK.",org.gjt.sp.jedit.textarea.TextArea
CLASS,jedit-4.3,1599709,2006-11-20T13:17:56.000-06:00,NPE with JEditBuffer and new indenting,"lt;ENTER&gt;
The indenting refactoring introduced some NullPointerExceptions.
I've ""catched"" one in r8096, but as stated in the commit message, it's probably an error further up.
r8096 should be reverted.
The problem seems to be that ctx.rules.getModeName\(\) returns null, while it should return the main rule name.
When pressing ENTER, after the ""'"", the following exception gets thrown:
java.lang.NullPointerException
at org.gjt.sp.jedit.buffer.JEditBuffer.getIdealIndentForLine\(JEditBuffer.java:991\)
at org.gjt.sp.jedit.buffer.JEditBuffer.indentLine\(JEditBuffer.java:907\)
at org.gjt.sp.jedit.textarea.TextArea.insertEnterAndIndent\(TextArea.java:4327\)
at sun.reflect.GeneratedMethodAccessor23.invoke\(Unknown Source\)
at sun.reflect.DelegatingMethodAccessorImpl.invoke\(Unknown Source\)
at java.lang.reflect.Method.invoke\(Unknown Source\)
at bsh.Reflect.invokeMethod\(Reflect.java:134\)
at bsh.Reflect.invokeObjectMethod\(Reflect.java:80\)
at bsh.Name.invokeMethod\(Name.java:858\)
at bsh.BSHMethodInvocation.eval\(BSHMethodInvocation.java:75\)
at bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:102\)
at bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:47\)
at bsh.BSHBlock.evalBlock\(BSHBlock.java:130\)
at bsh.BSHBlock.eval\(BSHBlock.java:80\)
at bsh.BshMethod.invokeImpl\(BshMethod.java:362\)
at bsh.BshMethod.invoke\(BshMethod.java:258\)
at bsh.BshMethod.invoke\(BshMethod.java:186\)
at org.gjt.sp.jedit.BeanShell.runCachedBlock\(BeanShell.java:509\)
at org.gjt.sp.jedit.BeanShellAction.invoke\(BeanShellAction.java:76\)
at org.gjt.sp.jedit.gui.InputHandler.invokeAction\(InputHandler.java:415\)
at org.gjt.sp.jedit.gui.InputHandler.invokeAction\(InputHandler.java:381\)
at org.gjt.sp.jedit.gui.DefaultInputHandler.handleKey\(DefaultInputHandler.java:373\)
at org.gjt.sp.jedit.input.AbstractInputHandler.processKeyEventKeyStrokeHandling\(AbstractInputHandler.java:116\)
at org.gjt.sp.jedit.gui.InputHandler.processKeyEvent\(InputHandler.java:184\)
at org.gjt.sp.jedit.textarea.TextArea.processKeyEvent\(TextArea.java:4572\)
at java.awt.Component.processEvent\(Unknown Source\)
at java.awt.Container.processEvent\(Unknown Source\)
at java.awt.Component.dispatchEventImpl\(Unknown Source\)
at java.awt.Container.dispatchEventImpl\(Unknown Source\)
at java.awt.Component.dispatchEvent\(Unknown Source\)
at java.awt.KeyboardFocusManager.redispatchEvent\(Unknown Source\)
at java.awt.DefaultKeyboardFocusManager.dispatchKeyEvent\(Unknown Source\)
at java.awt.DefaultKeyboardFocusManager.preDispatchKeyEvent\(Unknown Source\)
at java.awt.DefaultKeyboardFocusManager.typeAheadAssertions\(Unknown Source\)
at java.awt.DefaultKeyboardFocusManager.dispatchEvent\(Unknown Source\)
at java.awt.Component.dispatchEventImpl\(Unknown Source\)
at java.awt.Container.dispatchEventImpl\(Unknown Source\)
at java.awt.Window.dispatchEventImpl\(Unknown Source\)
at java.awt.Component.dispatchEvent\(Unknown Source\)
at java.awt.EventQueue.dispatchEvent\(Unknown Source\)
at java.awt.EventDispatchThread.pumpOneEventForFilters\(Unknown Source\)
at java.awt.EventDispatchThread.pumpEventsForFilter\(Unknown Source\)
at java.awt.EventDispatchThread.pumpEventsForHierarchy\(Unknown Source\)
at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
at java.awt.EventDispatchThread.run\(Unknown Source\)",org.gjt.sp.jedit.buffer.JEditBuffer
CLASS,jedit-4.3,1600401,2006-11-21T13:16:31.000-06:00,StringIndexOutOfBoundsException in TokenMarker,"lt;init&gt; 
    
    
    
    
    
    
    
    
    
    
    
  
  
  
  
  
  
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
   {12,39\} 
    
     lt;init&gt; 
      
      
      
      
      
      
      
      
    
    
    
      
    
    
    
    
    
    
    
    
    
    
    
    
    
   {12,39\} 
    
     lt;init&gt; 
      
      
      
      
      
      
      
    
  
    
    
    
      
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
     lt;init&gt; 
      
      
      
      
      
      
    
    
  
    
    
    
      
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
     lt;init&gt;
After pressing ENTER in a rather long line in a .
php file, I got the following exception.
The line appeared wrong highlighted in the first place, that why I wanted to see if splitting it would resolve the highlight issue.
After this the buffer window is not usable anymore \(e.g. I cannot enter it, nor does it get repainted\).
\[error\] Buffer: Exception while sending buffer event to org.gjt.sp.jedit.textarea.BufferHandler@1484a8a :
\[error\] Buffer: java.lang.StringIndexOutOfBoundsException: String index out of range: 103
\[error\] Buffer:  at java.lang.String.&lt;init&gt;\(Unknown Source\)
\[error\] Buffer:  at org.gjt.sp.jedit.syntax.TokenMarker.handleRule\(TokenMarker.java:343\)
\[error\] Buffer:  at org.gjt.sp.jedit.syntax.TokenMarker.markTokens\(TokenMarker.java:155\)
\[error\] Buffer:  at org.gjt.sp.jedit.buffer.JEditBuffer.markTokens\(JEditBuffer.java:1234\)
\[error\] Buffer:  at org.gjt.sp.jedit.textarea.ChunkCache.lineToChunkList\(ChunkCache.java:771\)
\[error\] Buffer:  at org.gjt.sp.jedit.textarea.ChunkCache.getLineSubregionCount\(ChunkCache.java:266\)
\[error\] Buffer:  at org.gjt.sp.jedit.textarea.DisplayManager.updateScreenLineCount\(DisplayManager.java:661\)
\[error\] Buffer:  at org.gjt.sp.jedit.textarea.BufferHandler.doDelayedUpdate\(BufferHandler.java:327\)
\[error\] Buffer:  at org.gjt.sp.jedit.textarea.BufferHandler.transactionComplete\(BufferHandler.java:287\)
\[error\] Buffer:  at org.gjt.sp.jedit.buffer.JEditBuffer.fireTransactionComplete\(JEditBuffer.java:2173\)
\[error\] Buffer:  at org.gjt.sp.jedit.buffer.JEditBuffer.endCompoundEdit\(JEditBuffer.java:1966\)
\[error\] Buffer:  at org.gjt.sp.jedit.textarea.TextArea.insertEnterAndIndent\(TextArea.java:4331\)
\[error\] Buffer:  at sun.reflect.NativeMethodAccessorImpl.invoke0\(Native Method\)
\[error\] Buffer:  at sun.reflect.NativeMethodAccessorImpl.invoke\(Unknown Source\)
\[error\] Buffer:  at sun.reflect.DelegatingMethodAccessorImpl.invoke\(Unknown Source\)
\[error\] Buffer:  at java.lang.reflect.Method.invoke\(Unknown Source\)
\[error\] Buffer:  at bsh.Reflect.invokeMethod\(Reflect.java:134\)
\[error\] Buffer:  at bsh.Reflect.invokeObjectMethod\(Reflect.java:80\)
\[error\] Buffer:  at bsh.Name.invokeMethod\(Name.java:858\)
\[error\] Buffer:  at bsh.BSHMethodInvocation.eval\(BSHMethodInvocation.java:75\)
\[error\] Buffer:  at bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:102\)
\[error\] Buffer:  at bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:47\)
\[error\] Buffer:  at bsh.BSHBlock.evalBlock\(BSHBlock.java:130\)
\[error\] Buffer:  at bsh.BSHBlock.eval\(BSHBlock.java:80\)
\[error\] Buffer:  at bsh.BshMethod.invokeImpl\(BshMethod.java:362\)
\[error\] Buffer:  at bsh.BshMethod.invoke\(BshMethod.java:258\)
\[error\] Buffer:  at bsh.BshMethod.invoke\(BshMethod.java:186\)
\[error\] Buffer:  at org.gjt.sp.jedit.BeanShell.runCachedBlock\(BeanShell.java:509\)
\[error\] Buffer:  at org.gjt.sp.jedit.BeanShellAction.invoke\(BeanShellAction.java:76\)
\[error\] Buffer:  at org.gjt.sp.jedit.gui.InputHandler.invokeAction\(InputHandler.java:415\)
\[error\] Buffer:  at org.gjt.sp.jedit.gui.InputHandler.invokeAction\(InputHandler.java:381\)
\[error\] Buffer:  at org.gjt.sp.jedit.gui.DefaultInputHandler.handleKey\(DefaultInputHandler.java:373\)
\[error\] Buffer:  at org.gjt.sp.jedit.input.AbstractInputHandler.processKeyEventKeyStrokeHandling\(AbstractInputHandler.java:116\)
\[error\] Buffer:  at org.gjt.sp.jedit.gui.InputHandler.processKeyEvent\(InputHandler.java:184\)
\[error\] Buffer:  at org.gjt.sp.jedit.textarea.TextArea.processKeyEvent\(TextArea.java:4572\)
\[error\] Buffer:  at java.awt.Component.processEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.Container.processEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.Component.dispatchEventImpl\(Unknown Source\)
\[error\] Buffer:  at java.awt.Container.dispatchEventImpl\(Unknown Source\)
\[error\] Buffer:  at java.awt.Component.dispatchEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.KeyboardFocusManager.redispatchEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.DefaultKeyboardFocusManager.dispatchKeyEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.DefaultKeyboardFocusManager.preDispatchKeyEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.DefaultKeyboardFocusManager.typeAheadAssertions\(Unknown Source\)
\[error\] Buffer:  at java.awt.DefaultKeyboardFocusManager.dispatchEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.Component.dispatchEventImpl\(Unknown Source\)
\[error\] Buffer:  at java.awt.Container.dispatchEventImpl\(Unknown Source\)
\[error\] Buffer:  at java.awt.Window.dispatchEventImpl\(Unknown Source\)
\[error\] Buffer:  at java.awt.Component.dispatchEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.EventQueue.dispatchEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.EventDispatchThread.pumpOneEventForFilters\(Unknown Source\)
\[error\] Buffer:  at java.awt.EventDispatchThread.pumpEventsForFilter\(Unknown Source\)
\[error\] Buffer:  at java.awt.EventDispatchThread.pumpEventsForHierarchy\(Unknown Source\)
\[error\] Buffer:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] Buffer:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] Buffer:  at java.awt.EventDispatchThread.run\(Unknown Source\)
\[error\] ExtensionManager: Error repainting line range \{12,39\}:
\[error\] ExtensionManager: java.lang.StringIndexOutOfBoundsException: String index out of range: 103
\[error\] ExtensionManager:  at java.lang.String.&lt;init&gt;\(Unknown Source\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.syntax.TokenMarker.handleRule\(TokenMarker.java:343\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.syntax.TokenMarker.markTokens\(TokenMarker.java:155\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.buffer.JEditBuffer.markTokens\(JEditBuffer.java:1234\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ChunkCache.lineToChunkList\(ChunkCache.java:771\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ChunkCache.updateChunksUpTo\(ChunkCache.java:646\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ChunkCache.getLineInfo\(ChunkCache.java:255\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ExtensionManager.paintScreenLineRange\(ExtensionManager.java:102\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.TextAreaPainter.paint\(TextAreaPainter.java:726\)
\[error\] ExtensionManager:  at javax.swing.JComponent.paintToOffscreen\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.BufferStrategyPaintManager.paint\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.paint\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.JComponent.\_paintImmediately\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.JComponent.paintImmediately\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.paintDirtyRegions\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.paintDirtyRegions\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.seqPaintDirtyRegions\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.SystemEventQueueUtilities$ComponentWorkRequest.run\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.event.InvocationEvent.dispatch\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventQueue.dispatchEvent\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpOneEventForFilters\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEventsForFilter\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEventsForHierarchy\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.run\(Unknown Source\)
\[error\] ExtensionManager: Error repainting line range \{12,39\}:
\[error\] ExtensionManager: java.lang.StringIndexOutOfBoundsException: String index out of range: 103
\[error\] ExtensionManager:  at java.lang.String.&lt;init&gt;\(Unknown Source\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.syntax.TokenMarker.handleRule\(TokenMarker.java:343\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.syntax.TokenMarker.markTokens\(TokenMarker.java:155\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.buffer.JEditBuffer.markTokens\(JEditBuffer.java:1234\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ChunkCache.lineToChunkList\(ChunkCache.java:771\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ChunkCache.updateChunksUpTo\(ChunkCache.java:646\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ChunkCache.getLineInfo\(ChunkCache.java:255\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ExtensionManager.paintScreenLineRange\(ExtensionManager.java:102\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.Gutter.paintComponent\(Gutter.java:131\)
\[error\] ExtensionManager:  at javax.swing.JComponent.paint\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.JComponent.paintToOffscreen\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.BufferStrategyPaintManager.paint\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.paint\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.JComponent.\_paintImmediately\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.JComponent.paintImmediately\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.paintDirtyRegions\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.paintDirtyRegions\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.seqPaintDirtyRegions\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.SystemEventQueueUtilities$ComponentWorkRequest.run\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.event.InvocationEvent.dispatch\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventQueue.dispatchEvent\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpOneEventForFilters\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEventsForFilter\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEventsForHierarchy\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.run\(Unknown Source\)
\[error\] AWT-EventQueue-0: Exception in thread ""AWT-EventQueue-0""
\[error\] AWT-EventQueue-0: java.lang.StringIndexOutOfBoundsException: String index out of range: 103
\[error\] AWT-EventQueue-0:  at java.lang.String.&lt;init&gt;\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.syntax.TokenMarker.handleRule\(TokenMarker.java:343\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.syntax.TokenMarker.markTokens\(TokenMarker.java:155\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.buffer.JEditBuffer.markTokens\(JEditBuffer.java:1234\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.ChunkCache.lineToChunkList\(ChunkCache.java:771\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.ChunkCache.updateChunksUpTo\(ChunkCache.java:646\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.ChunkCache.getLineInfo\(ChunkCache.java:255\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.Gutter.paintLine\(Gutter.java:544\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.Gutter.paintComponent\(Gutter.java:137\)
\[error\] AWT-EventQueue-0:  at javax.swing.JComponent.paint\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.JComponent.paintToOffscreen\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.BufferStrategyPaintManager.paint\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.RepaintManager.paint\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.JComponent.\_paintImmediately\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.JComponent.paintImmediately\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.RepaintManager.paintDirtyRegions\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.RepaintManager.paintDirtyRegions\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.RepaintManager.seqPaintDirtyRegions\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.SystemEventQueueUtilities$ComponentWorkRequest.run\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.event.InvocationEvent.dispatch\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventQueue.dispatchEvent\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpOneEventForFilters\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEventsForFilter\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEventsForHierarchy\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.run\(Unknown Source\)
\[error\] AWT-EventQueue-0: Exception in thread ""AWT-EventQueue-0""
\[error\] AWT-EventQueue-0: java.lang.StringIndexOutOfBoundsException: String index out of range: 103
\[error\] AWT-EventQueue-0:  at java.lang.String.&lt;init&gt;\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.syntax.TokenMarker.handleRule\(TokenMarker.java:343\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.syntax.TokenMarker.markTokens\(TokenMarker.java:155\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.buffer.JEditBuffer.markTokens\(JEditBuffer.java:1234\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.ChunkCache.lineToChunkList\(ChunkCache.java:771\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.ChunkCache.updateChunksUpTo\(ChunkCache.java:646\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.ChunkCache.getLineInfo\(ChunkCache.java:255\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.TextArea.invalidateLine\(TextArea.java:1145\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.TextArea.blinkCaret\(TextArea.java:2118\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.TextArea$CaretBlinker.actionPerformed\(TextArea.java:5907\)
\[error\] AWT-EventQueue-0:  at javax.swing.Timer.fireActionPerformed\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.Timer$DoPostEvent.run\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.event.InvocationEvent.dispatch\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventQueue.dispatchEvent\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpOneEventForFilters\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEventsForFilter\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEventsForHierarchy\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.run\(Unknown Source\)
\[debug\] PHPSideKickParser: Requesting sidekick complete
\[debug\] WorkThread: Running in work thread: \[id=265,run=org.gjt.sp.jedit.bufferio.BufferAutosaveRequest\[Y.php \(X\\\)\]\]
\[debug\] DockableWindowManager: Loading dockables from jeditresource:/ErrorList.jar\!/dockables.xml
\[debug\] EditBus: DockableWindowUpdate\[what=ACTIVATED,dockable=error-list,source=org.gjt.sp.jedit.gui.DockableWindowManager\[,0,0,1600x1081,invalid,layout=org.gjt.sp.jedit.gui.DockableLayout,alignmentX=0.0,alignmentY=0.0,border=,flags=9,maximumSize=,minimumSize=,preferredSize=\]\]",org.gjt.sp.jedit.syntax.TokenMarker
CLASS,jedit-4.3,1658252,2007-02-12T17:48:03.000-06:00,C mode: incorrect bracket matching in multi-line defines,"{ \
code;                         \
more code;                    \
even more code;               \
\}
\#define LONG\_MULTI\_LINE\_DEFINE \{ \
code;                         \
more code;                    \
even more code;               \
\}
The brackets don't match.","org.gjt.sp.jedit.syntax.ParserRule
org.gjt.sp.jedit.syntax.XModeHandler
org.gjt.sp.jedit.syntax.XModeHandler.TagDecl
org.gjt.sp.jedit.syntax.TokenMarker"
CLASS,jedit-4.3,1724940,2007-05-24T15:02:18.000-05:00,typing in multiple select,"lt;body&gt;
  lt;p&gt;
 
 the &lt;p&gt;  
 lt;body&gt;
  lt;d&gt;
If I highlight multiple selections of text in the text area and then begin typing, only the first character of what I type is inserted in the selected areas \(except for where the cursor ended up after making the selection\).
&lt;body&gt;
&lt;p&gt;
Some Text
&lt;/p&gt;
&lt;/body&gt;
and I highlight both p's in the &lt;p&gt; tags and then type ""div"" I end up with:
&lt;body&gt;
&lt;d&gt;
Some Text
&lt;/div&gt;
&lt;/body&gt;
I've attached a screenshot.",org.gjt.sp.jedit.textarea.BufferHandler
CLASS,jedit-4.3,1999448,2008-08-23T10:28:24.000-05:00,Unnecesarry fold expantion when folded lines are edited,"{\{\{ hello

something

\}
While testing the patch \#1999448, a problem was found.
But the patch was applied in r13404 to avoid more
serious black hole bugs.
This problem has now became a
bug.
\{\{\{ hello
something
\}\}\}
all folds are folded.","org.gjt.sp.jedit.textarea.BufferHandler
org.gjt.sp.jedit.textarea.DisplayManager
org.gjt.sp.jedit.textarea.TextArea"
CLASS,jedit-4.3,2129419,2008-09-25T23:53:11.000-05:00,NPE in EditPane.setBuffer when quitting jEdit,"lt;init&gt;
When trying to quit jEdit, I get the following Null-Pointer-Exception, which is probably related to some files being changed/deleted \(due to a ""cvs up"" in the background\).
Previously to trying to quit jEdit, the ""Files have changed.
Reload?""
dialog already failed, so that ""Close"" was the only option that worked.
The NPE:
java.lang.NullPointerException
at org.gjt.sp.jedit.EditPane.setBuffer\(EditPane.java:136\)
at org.gjt.sp.jedit.View.setBuffer\(View.java:1009\)
at org.gjt.sp.jedit.View.showBuffer\(View.java:1484\)
at org.gjt.sp.jedit.View.showBuffer\(View.java:1042\)
at org.gjt.sp.jedit.gui.CloseDialog$ListHandler.valueChanged\(CloseDialog.java:233\)
at javax.swing.JList.fireSelectionValueChanged\(JList.java:1765\)
at javax.swing.JList$ListSelectionHandler.valueChanged\(JList.java:1779\)
at javax.swing.DefaultListSelectionModel.fireValueChanged\(DefaultListSelectionModel.java:167\)
at javax.swing.DefaultListSelectionModel.fireValueChanged\(DefaultListSelectionModel.java:147\)
at javax.swing.DefaultListSelectionModel.fireValueChanged\(DefaultListSelectionModel.java:194\)
at javax.swing.DefaultListSelectionModel.changeSelection\(DefaultListSelectionModel.java:388\)
at javax.swing.DefaultListSelectionModel.changeSelection\(DefaultListSelectionModel.java:398\)
at javax.swing.DefaultListSelectionModel.setSelectionInterval\(DefaultListSelectionModel.java:442\)
at javax.swing.JList.setSelectedIndex\(JList.java:2179\)
at org.gjt.sp.jedit.gui.CloseDialog.&lt;init&gt;\(CloseDialog.java:96\)
at org.gjt.sp.jedit.jEdit.closeAllBuffers\(jEdit.java:1871\)
at org.gjt.sp.jedit.jEdit.exit\(jEdit.java:2621\)
at sun.reflect.NativeMethodAccessorImpl.invoke0\(Native Method\)
at sun.reflect.NativeMethodAccessorImpl.invoke\(NativeMethodAccessorImpl.java:39\)
at sun.reflect.DelegatingMethodAccessorImpl.invoke\(DelegatingMethodAccessorImpl.java:25\)
at java.lang.reflect.Method.invoke\(Method.java:597\)
at org.gjt.sp.jedit.bsh.Reflect.invokeMethod\(Reflect.java:134\)
at org.gjt.sp.jedit.bsh.Reflect.invokeStaticMethod\(Reflect.java:98\)
at org.gjt.sp.jedit.bsh.Name.invokeMethod\(Name.java:871\)
at org.gjt.sp.jedit.bsh.BSHMethodInvocation.eval\(BSHMethodInvocation.java:75\)
at org.gjt.sp.jedit.bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:102\)
at org.gjt.sp.jedit.bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:47\)
at org.gjt.sp.jedit.bsh.BSHBlock.evalBlock\(BSHBlock.java:130\)
at org.gjt.sp.jedit.bsh.BSHBlock.eval\(BSHBlock.java:80\)
at org.gjt.sp.jedit.bsh.BshMethod.invokeImpl\(BshMethod.java:362\)
at org.gjt.sp.jedit.bsh.BshMethod.invoke\(BshMethod.java:258\)
at org.gjt.sp.jedit.bsh.BshMethod.invoke\(BshMethod.java:186\)
at org.gjt.sp.jedit.BeanShellFacade.runCachedBlock\(BeanShellFacade.java:225\)
at org.gjt.sp.jedit.BeanShell.runCachedBlock\(BeanShell.java:441\)
at org.gjt.sp.jedit.BeanShellAction.invoke\(BeanShellAction.java:73\)
at org.gjt.sp.jedit.gui.InputHandler.invokeAction\(InputHandler.java:352\)
at org.gjt.sp.jedit.jEdit$4.invokeAction\(jEdit.java:3080\)
at org.gjt.sp.jedit.jEdit$4.invokeAction\(jEdit.java:3062\)
at org.gjt.sp.jedit.EditAction$Wrapper.actionPerformed\(EditAction.java:220\)
at javax.swing.AbstractButton.fireActionPerformed\(AbstractButton.java:1995\)
at javax.swing.AbstractButton$Handler.actionPerformed\(AbstractButton.java:2318\)
at javax.swing.DefaultButtonModel.fireActionPerformed\(DefaultButtonModel.java:387\)
at javax.swing.DefaultButtonModel.setPressed\(DefaultButtonModel.java:242\)
at javax.swing.AbstractButton.doClick\(AbstractButton.java:357\)
at javax.swing.plaf.basic.BasicMenuItemUI.doClick\(BasicMenuItemUI.java:1220\)
at javax.swing.plaf.basic.BasicMenuItemUI$Handler.mouseReleased\(BasicMenuItemUI.java:1261\)
at java.awt.AWTEventMulticaster.mouseReleased\(AWTEventMulticaster.java:272\)
at java.awt.Component.processMouseEvent\(Component.java:6041\)
at javax.swing.JComponent.processMouseEvent\(JComponent.java:3265\)
at java.awt.Component.processEvent\(Component.java:5806\)
at java.awt.Container.processEvent\(Container.java:2058\)
at java.awt.Component.dispatchEventImpl\(Component.java:4413\)
at java.awt.Container.dispatchEventImpl\(Container.java:2116\)
at java.awt.Component.dispatchEvent\(Component.java:4243\)
at java.awt.LightweightDispatcher.retargetMouseEvent\(Container.java:4322\)
at java.awt.LightweightDispatcher.processMouseEvent\(Container.java:3986\)
at java.awt.LightweightDispatcher.dispatchEvent\(Container.java:3916\)
at java.awt.Container.dispatchEventImpl\(Container.java:2102\)
at java.awt.Window.dispatchEventImpl\(Window.java:2440\)
at java.awt.Component.dispatchEvent\(Component.java:4243\)
at java.awt.EventQueue.dispatchEvent\(EventQueue.java:599\)
at java.awt.EventDispatchThread.pumpOneEventForFilters\(EventDispatchThread.java:273\)
at java.awt.EventDispatchThread.pumpEventsForFilter\(EventDispatchThread.java:183\)
at java.awt.EventDispatchThread.pumpEventsForHierarchy\(EventDispatchThread.java:173\)
at java.awt.EventDispatchThread.pumpEvents\(EventDispatchThread.java:168\)
at java.awt.EventDispatchThread.pumpEvents\(EventDispatchThread.java:160\)
at java.awt.EventDispatchThread.run\(EventDispatchThread.java:121\)",org.gjt.sp.jedit.gui.CloseDialog.ListHandler
CLASS,jedit-4.3,2759434,2009-04-13T17:19:22.000-05:00,indent related bug (svn rev 14922),"lt;ENTER&gt;
  lt;CARRET&gt;
Python mode
if True:&lt;ENTER&gt;
&lt;CARRET&gt;&lt;ENTER - the exception occures&gt;
java.lang.StringIndexOutOfBoundsException: String index out of range: 1
at java.lang.String.charAt\(String.java:687\)
at org.gjt.sp.util.StandardUtilities.getIndentString\(StandardUtilities.java:104\)
at org.gjt.sp.jedit.buffer.JEditBuffer.indentLine\(JEditBuffer.java:991\)
at org.gjt.sp.jedit.textarea.TextArea.insertEnterAndIndent\(TextArea.java:4292\)
at sun.reflect.GeneratedMethodAccessor17.invoke\(Unknown Source\)
at sun.reflect.DelegatingMethodAccessorImpl.invoke\(DelegatingMethodAccessorImpl.java:25\)
at java.lang.reflect.Method.invoke\(Method.java:597\)
at org.gjt.sp.jedit.bsh.Reflect.invokeMethod\(Reflect.java:134\)
at org.gjt.sp.jedit.bsh.Reflect.invokeObjectMethod\(Reflect.java:80\)
at org.gjt.sp.jedit.bsh.Name.invokeMethod\(Name.java:855\)
at org.gjt.sp.jedit.bsh.BSHMethodInvocation.eval\(BSHMethodInvocation.java:75\)
at org.gjt.sp.jedit.bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:102\)
at org.gjt.sp.jedit.bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:47\)
at org.gjt.sp.jedit.bsh.BSHBlock.evalBlock\(BSHBlock.java:130\)
at org.gjt.sp.jedit.bsh.BSHBlock.eval\(BSHBlock.java:80\)
at org.gjt.sp.jedit.bsh.BshMethod.invokeImpl\(BshMethod.java:362\)
at org.gjt.sp.jedit.bsh.BshMethod.invoke\(BshMethod.java:258\)
at org.gjt.sp.jedit.bsh.BshMethod.invoke\(BshMethod.java:186\)
at org.gjt.sp.jedit.BeanShellFacade.runCachedBlock\(BeanShellFacade.java:225\)
at org.gjt.sp.jedit.BeanShell.runCachedBlock\(BeanShell.java:423\)
at org.gjt.sp.jedit.BeanShellAction.invoke\(BeanShellAction.java:73\)
at org.gjt.sp.jedit.gui.InputHandler.invokeAction\(InputHandler.java:352\)
at org.gjt.sp.jedit.gui.InputHandler.invokeAction\(InputHandler.java:317\)
at org.gjt.sp.jedit.gui.DefaultInputHandler.handleKey\(DefaultInputHandler.java:197\)
at org.gjt.sp.jedit.input.AbstractInputHandler.processKeyEventKeyStrokeHandling\(AbstractInputHandler.java:405\)
at org.gjt.sp.jedit.gui.InputHandler.processKeyEvent\(InputHandler.java:151\)
at org.gjt.sp.jedit.textarea.TextArea.processKeyEvent\(TextArea.java:4525\)
at java.awt.Component.processEvent\(Component.java:5911\)
at java.awt.Container.processEvent\(Container.java:2023\)
at java.awt.Component.dispatchEventImpl\(Component.java:4501\)
at java.awt.Container.dispatchEventImpl\(Container.java:2081\)
at java.awt.Component.dispatchEvent\(Component.java:4331\)
at java.awt.KeyboardFocusManager.redispatchEvent\(KeyboardFocusManager.java:1848\)
at java.awt.DefaultKeyboardFocusManager.dispatchKeyEvent\(DefaultKeyboardFocusManager.java:704\)
at java.awt.DefaultKeyboardFocusManager.preDispatchKeyEvent\(DefaultKeyboardFocusManager.java:969\)
at java.awt.DefaultKeyboardFocusManager.typeAheadAssertions\(DefaultKeyboardFocusManager.java:841\)
at java.awt.DefaultKeyboardFocusManager.dispatchEvent\(DefaultKeyboardFocusManager.java:668\)
at java.awt.Component.dispatchEventImpl\(Component.java:4373\)
at java.awt.Container.dispatchEventImpl\(Container.java:2081\)
at java.awt.Window.dispatchEventImpl\(Window.java:2458\)
at java.awt.Component.dispatchEvent\(Component.java:4331\)
at java.awt.EventQueue.dispatchEvent\(EventQueue.java:599\)
at java.awt.EventDispatchThread.pumpOneEventForFilters\(EventDispatchThread.java:269\)
at java.awt.EventDispatchThread.pumpEventsForFilter\(EventDispatchThread.java:184\)
at java.awt.EventDispatchThread.pumpEventsForHierarchy\(EventDispatchThread.java:174\)
at java.awt.EventDispatchThread.pumpEvents\(EventDispatchThread.java:169\)
at java.awt.EventDispatchThread.pumpEvents\(EventDispatchThread.java:161\)
at java.awt.EventDispatchThread.run\(EventDispatchThread.java:122\)",org.gjt.sp.util.StandardUtilities
CLASS,jabref-2.6,1631548,2007-01-09T14:20:57.000-06:00,"""Open last edited DB at startup"" depends on the working dir","{HOME\}
Hi there,
another little bug/feature: The JabRef option ""Open last edited database at startup"" depends on the working directory at which JabRef is started.
pc03:~/at-work/Bibliography $ jabref my\_documents.bib
pc03:~/at-work/Bibliography $ cd .
.
pc03:~/at-work $ jabref
results in an empty JabRef not opening $\{HOME\}/at-work/Bibliography/my\_documents.bib.
I suggest that JabRef stores the absolute path for the ""Open last edited..."" feature, even if a relative path was provided.
Since this setting is stored in a machine dependent configuration file \(~/.
java/.
userPrefs/net/sf/jabref/prefs.
xml\), this should be okay.
Another, more sophisticated approach, would be to store the home directory, the relative path and the absolute path and try to open \(1\) the absolute, \(2\) the relative path to the home directory and \(3\) the relative path as provided when opening JabRef.
Current office tools \(MS and OO\) are doing it that fault tolerant way.
kind regards
Bernd
p.s. this bug is found in JabRef 2.1",net.sf.jabref.JabRefFrame
METHOD,apache-nutch-2.1,NUTCH-1393,2012-06-13T18:38:39.000-05:00,Display consistent usage of GeneratorJob with 1.X,"{code}
 
  
  
  
  
  
 {code}
If we pass the generate argument to the nutch script, the Generator auto-spings into action and begins generating fetchlists.
{code} lewis@lewis:~/ASF/nutchgora/runtime/local$ .
/bin/nutch generate
GeneratorJob: Selecting best-scoring urls due for fetch.
GeneratorJob: starting
GeneratorJob: filtering: true
GeneratorJob: done
GeneratorJob: generated batch id: 1339628223-1694200031
{code}
All I wanted to do was get the usage params printed to stdout but instead it generated my batch willy nilly.","org.apache.nutch.crawl.GeneratorJob:generate(long, long, boolean, boolean)
org.apache.nutch.crawl.GeneratorJob:run(String[])"
METHOD,apache-nutch-2.1,NUTCH-1484,2012-11-01T03:36:57.000-05:00,TableUtil unreverseURL fails on file:// URLs,"{code}
 {code}
(reported by Rogério Pereira Araújo, see NUTCH-1483)
When crawling the local filesystem TableUtil.unreverseURL fails for URLs with empty host part (file:///Documents/). StringUtils.split(String, char) does not preserve empty parts which causes:
{code}
java.lang.ArrayIndexOutOfBoundsException: 1
at org.apache.nutch.util.TableUtil.unreverseUrl(TableUtil.java:98)
{code}","org.apache.nutch.util.TestTableUtil:assertReverse(String, String)
org.apache.nutch.util.TestTableUtil:testReverseUrl()
org.apache.nutch.util.TestTableUtil:testUnreverseUrl()"
CLASS,openjpa-2.0.1,OPENJPA-1752,2010-07-29T23:33:45.000-05:00,TestPessimisticLocks JUNIT test produced inconsistent behavior with various backends,"testFindAfterQueryWithPessimisticLocks()
  testFindAfterQueryOrderByWithPessimisticLocks()
  testQueryAfterFindWithPessimisticLocks()
  testQueryOrderByAfterFindWithPessimisticLocks()


 
 testFindAfterQueryWithPessimisticLocks() 
  No exception;
TestPessimisticLocks JUNIT tests pass all assertions for Derby backend, but failures are seen on DB2, MySQL, Oracle.
It is likely that failures may also occur on other backends.
There could be some problem in OpenJPA code in handling pessimistic lock requests.
There is also inconsistency in reporting exceptions - lock timout or query timeout should be non-fatal; but with Derby the PessimisticLockException is reported  which is considered fatal.
It is also possible that the test scenarios are problematic.
TestPessisimiticLocks has 5 test cases, the last test case worked for all backend.
Problem test cases are listed as below:
1 testFindAfterQueryWithPessimisticLocks()
2 testFindAfterQueryOrderByWithPessimisticLocks()
3 testQueryAfterFindWithPessimisticLocks()
4 testQueryOrderByAfterFindWithPessimisticLocks()
The failure symptoms are summarized below -   Each test contains 2 variations.
The dot notation, for example, 1.1 is the first scenario in testFindAfterQueryWithPessimisticLocks() 
Each test scenario is either expecting an exception or No exception; if no exception is reported, the SELECT sql got results from database.
Tests       Derby                                        DB2V9.7                                 Oracle10gXE 10.2.0.1.0            MySQL 5.1.39/JDBC 5.1.7
====================================================================================================================================
1 1         PessimisticLockException      LockTimeoutException        LockTimeoutException              LockTimeoutException
1 2         No exception                              No exception                          No exception                                No exception
2 1         PessimisticLockException      LockTimeoutException        LockTimeoutException              LockTimeoutException
2 2         No  exception                             LockTimeoutException        No exception                                LockTimeoutException
3 1         No  exception                             QueryTimeoutException       process hang                            PersistenceException: Server shutdown [code=1053, state=08S01]
3 2         PessimisticLockException      QueryTimeoutException       process hang                            PersistenceException: Server shutdown [code=1053, state=08S01]
4 1         No  exception                             QueryTimeoutException       No exception                             QueryTimeoutException
4 2         PessimisticLockException      QueryTimeoutException       process hang                           QueryTimeoutException
NOTE: for Oracle, many test scenarios caused process to hang (test 3.1, 3.2, and 4.2) - ie.
test never run to completion
      for MySQL, Server shutdown (test 3.1 and 3.2)
      here is the  stack trace:
org.apache.openjpa.persistence.PersistenceException:Server shutdown in progress {prepstmnt 33525219 SELECT t1.id, t1.name FROM Employee t0 LEFT OUTER JOIN Department t1 ON t0.FK_DEPT = t1.id WHERE (t0.id < ?) LIMIT ?, ? FOR UPDATE [params=?, ?, ?]} [code=1053, state=08S01]
<openjpa-2.1.0-SNAPSHOT-rexported fatal general error> org.apache.openjpa.persistence.PersistenceException: Server shutdown in progress {prepstmnt 33525219 SELECT t1.id, t1.name FROM Employee t0 LEFT OUTER JOIN Department t1 ON t0.FK_DEPT = t1.id WHERE (t0.id < ?) LIMIT ?, ? FOR UPDATE [params=?, ?, ?]} [code=1053, state=08S01]
FailedObject: select e.department from Employee e where e.id < 10 [java.lang.String]
at org.apache.openjpa.jdbc.sql.DBDictionary.narrow(DBDictionary.java:4855)
at org.apache.openjpa.jdbc.sql.DBDictionary.newStoreException(DBDictionary.java:4815)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:137)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:118)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:70)
at org.apache.openjpa.jdbc.kernel.SelectResultObjectProvider.handleCheckedException(SelectResultObjectProvider.java:155)
at org.apache.openjpa.kernel.QueryImpl$PackingResultObjectProvider.handleCheckedException(QueryImpl.java:2109)
at org.apache.openjpa.lib.rop.EagerResultList.<init>(EagerResultList.java:40)
at org.apache.openjpa.kernel.QueryImpl.toResult(QueryImpl.java:1246)
at org.apache.openjpa.kernel.QueryImpl.execute(QueryImpl.java:1005)
at org.apache.openjpa.kernel.QueryImpl.execute(QueryImpl.java:861)
at org.apache.openjpa.kernel.QueryImpl.execute(QueryImpl.java:792)
at org.apache.openjpa.kernel.DelegatingQuery.execute(DelegatingQuery.java:542)
at org.apache.openjpa.persistence.QueryImpl.execute(QueryImpl.java:288)
at org.apache.openjpa.persistence.QueryImpl.getResultList(QueryImpl.java:302)
at org.apache.openjpa.persistence.lockmgr.TestPessimisticLocks.testQueryAfterFindWithPessimisticLocks(TestPessimisticLocks.java:271)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
at java.lang.reflect.Method.invoke(Unknown Source)
at junit.framework.TestCase.runTest(TestCase.java:154)
at org.apache.openjpa.persistence.test.AbstractPersistenceTestCase.runTest(AbstractPersistenceTestCase.java:516)
at junit.framework.TestCase.runBare(TestCase.java:127)
at org.apache.openjpa.persistence.test.AbstractPersistenceTestCase.runBare(AbstractPersistenceTestCase.java:503)
at org.apache.openjpa.persistence.test.AbstractPersistenceTestCase.runBare(AbstractPersistenceTestCase.java:479)
at junit.framework.TestResult$1.protect(TestResult.java:106)
at junit.framework.TestResult.runProtected(TestResult.java:124)
at junit.framework.TestResult.run(TestResult.java:109)
at junit.framework.TestCase.run(TestCase.java:118)
at org.apache.openjpa.persistence.test.AbstractPersistenceTestCase.run(AbstractPersistenceTestCase.java:179)
at junit.framework.TestSuite.runTest(TestSuite.java:208)
at junit.framework.TestSuite.run(TestSuite.java:203)
at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:128)
at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)
Caused by: org.apache.openjpa.lib.jdbc.ReportingSQLException: Server shutdown in progress {prepstmnt 33525219 SELECT t1.id, t1.name FROM Employee t0 LEFT OUTER JOIN Department t1 ON t0.FK_DEPT = t1.id WHERE (t0.id < ?) LIMIT ?, ? FOR UPDATE [params=?, ?, ?]} [code=1053, state=08S01]
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator.wrap(LoggingConnectionDecorator.java:274)
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator.wrap(LoggingConnectionDecorator.java:258)
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator.access$3(LoggingConnectionDecorator.java:257)
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator$LoggingConnection$LoggingPreparedStatement.executeQuery(LoggingConnectionDecorator.java:1176)
at org.apache.openjpa.lib.jdbc.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:278)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager$CancelPreparedStatement.executeQuery(JDBCStoreManager.java:1773)
at org.apache.openjpa.lib.jdbc.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:268)
at org.apache.openjpa.jdbc.sql.SelectImpl.executeQuery(SelectImpl.java:499)
at org.apache.openjpa.jdbc.sql.SelectImpl.execute(SelectImpl.java:424)
at org.apache.openjpa.jdbc.sql.SelectImpl.execute(SelectImpl.java:382)
at org.apache.openjpa.jdbc.kernel.SelectResultObjectProvider.open(SelectResultObjectProvider.java:94)
at org.apache.openjpa.kernel.QueryImpl$PackingResultObjectProvider.open(QueryImpl.java:2068)
at org.apache.openjpa.lib.rop.EagerResultList.<init>(EagerResultList.java:34)
... 30 more
NestedThrowables:
com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: Server shutdown in progress
at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
at sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)
at java.lang.reflect.Constructor.newInstance(Unknown Source)
at com.mysql.jdbc.Util.handleNewInstance(Util.java:406)
at com.mysql.jdbc.Util.getInstance(Util.java:381)
at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:984)
at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:956)
at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3515)
at com.mysql.jdbc.MysqlIO.nextRowFast(MysqlIO.java:1545)
at com.mysql.jdbc.MysqlIO.nextRow(MysqlIO.java:1401)
at com.mysql.jdbc.MysqlIO.readSingleRowSet(MysqlIO.java:2829)
at com.mysql.jdbc.MysqlIO.getResultSet(MysqlIO.java:468)
at com.mysql.jdbc.MysqlIO.readResultsForQueryOrUpdate(MysqlIO.java:2534)
at com.mysql.jdbc.MysqlIO.readAllResults(MysqlIO.java:1749)
at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2159)
at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2554)
at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1761)
at com.mysql.jdbc.PreparedStatement.executeQuery(PreparedStatement.java:1912)
at org.apache.commons.dbcp.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:93)
at org.apache.openjpa.lib.jdbc.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:280)
at org.apache.openjpa.lib.jdbc.JDBCEventConnectionDecorator$EventPreparedStatement.executeQuery(JDBCEventConnectionDecorator.java:270)
at org.apache.openjpa.lib.jdbc.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:278)
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator$LoggingConnection$LoggingPreparedStatement.executeQuery(LoggingConnectionDecorator.java:1174)
at org.apache.openjpa.lib.jdbc.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:278)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager$CancelPreparedStatement.executeQuery(JDBCStoreManager.java:1773)
at org.apache.openjpa.lib.jdbc.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:268)
at org.apache.openjpa.jdbc.sql.SelectImpl.executeQuery(SelectImpl.java:499)
at org.apache.openjpa.jdbc.sql.SelectImpl.execute(SelectImpl.java:424)
at org.apache.openjpa.jdbc.sql.SelectImpl.execute(SelectImpl.java:382)
at org.apache.openjpa.jdbc.kernel.SelectResultObjectProvider.open(SelectResultObjectProvider.java:94)
at org.apache.openjpa.kernel.QueryImpl$PackingResultObjectProvider.open(QueryImpl.java:2068)
at org.apache.openjpa.lib.rop.EagerResultList.<init>(EagerResultList.java:34)
at org.apache.openjpa.kernel.QueryImpl.toResult(QueryImpl.java:1246)
at org.apache.openjpa.kernel.QueryImpl.execute(QueryImpl.java:1005)
at org.apache.openjpa.kernel.QueryImpl.execute(QueryImpl.java:861)
at org.apache.openjpa.kernel.QueryImpl.execute(QueryImpl.java:792)
at org.apache.openjpa.kernel.DelegatingQuery.execute(DelegatingQuery.java:542)
at org.apache.openjpa.persistence.QueryImpl.execute(QueryImpl.java:288)
at org.apache.openjpa.persistence.QueryImpl.getResultList(QueryImpl.java:302)
at org.apache.openjpa.persistence.lockmgr.TestPessimisticLocks.testQueryAfterFindWithPessimisticLocks(TestPessimisticLocks.java:271)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
at java.lang.reflect.Method.invoke(Unknown Source)
at junit.framework.TestCase.runTest(TestCase.java:154)
at org.apache.openjpa.persistence.test.AbstractPersistenceTestCase.runTest(AbstractPersistenceTestCase.java:516)
at junit.framework.TestCase.runBare(TestCase.java:127)
at org.apache.openjpa.persistence.test.AbstractPersistenceTestCase.runBare(AbstractPersistenceTestCase.java:503)
at org.apache.openjpa.persistence.test.AbstractPersistenceTestCase.runBare(AbstractPersistenceTestCase.java:479)
at junit.framework.TestResult$1.protect(TestResult.java:106)
at junit.framework.TestResult.runProtected(TestResult.java:124)
at junit.framework.TestResult.run(TestResult.java:109)
at junit.framework.TestCase.run(TestCase.java:118)
at org.apache.openjpa.persistence.test.AbstractPersistenceTestCase.run(AbstractPersistenceTestCase.java:179)
at junit.framework.TestSuite.runTest(TestSuite.java:208)
at junit.framework.TestSuite.run(TestSuite.java:203)
at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:128)
at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)",org.apache.openjpa.persistence.lockmgr.TestPessimisticLocks
CLASS,openjpa-2.0.1,OPENJPA-1787,2010-09-10T11:23:51.000-05:00,Bean validation fails merging a new entity,"EntityManager em = entityManagerFactory.createEntityManager();
        Person person = new Person();
        person.setName(""Oliver"");                               // Employee.name is annotated @NotNull 
        person = em.merge(person);
The bean validation is not working correctly
EntityManager em = entityManagerFactory.createEntityManager();
        Person person = new Person();
        person.setName(""Oliver"");                               // Employee.name is annotated @NotNull 
        person = em.merge(person);
you get a ConstraintValidationException, although name is set.","org.apache.openjpa.kernel.BrokerImpl
org.apache.openjpa.kernel.AttachStrategy
org.apache.openjpa.integration.validation.TestValidationGroups"
CLASS,openjpa-2.0.1,OPENJPA-1903,2010-12-06T13:05:34.000-06:00,Some queries only work the first time they are executed,"@Entity
@IdClass(MandantAndNameIdentity.class)
public class Website {
    @Id
    private String mandant;
   
    @Id
    private String name;
...
}

 @Entity
@IdClass(WebsiteProduktDatumIdentity.class)
public class Preis {
    @Id
    @ManyToOne(cascade = CascadeType.MERGE)
    private Website website;

    @Id
    @Basic
    private String datum;
...
}

 
 em.getTransaction().begin();

        Website website = em.merge(new Website(""Mandant"", ""Website""));

        em.merge(new Preis(website, DATUM));
       
        em.getTransaction().commit();

 
 TypedQuery<Preis> q = em.createQuery(
                ""select m from Preis m "" +
                ""where m.website.name = :website "", Preis.class);
       q.setParameter(""website"", website.getName());

 
 TypedQuery<Preis> q = em.createQuery(
                ""select m from Preis m "" +
                ""where m.website = :website "", Preis.class);
        q.setParameter(""website"", website);
I have a problem in my application where a query that sometimes returns data and sometimes not.
I have reduced it to the code as much as I could into an Eclipse project available at http://ubuntuone.com/p/S9n/
This happens with OpenJPA 2.0.1 as well as the daily snapshot from 2010-12-05 and an out-of-process Derby database.
@Entity
@IdClass(MandantAndNameIdentity.class)
public class Website {
    @Id
    private String mandant;
   
    @Id
    private String name;
...
}
@Entity
@IdClass(WebsiteProduktDatumIdentity.class)
public class Preis {
    @Id
    @ManyToOne(cascade = CascadeType.MERGE)
    private Website website;
@Id
    @Basic
    private String datum;
...
}
em.getTransaction().
begin();
Website website = em.merge(new Website(""Mandant"", ""Website""));
em.merge(new Preis(website, DATUM));
       
        em.getTransaction().
commit();
TypedQuery<Preis> q = em.createQuery(
                ""select m from Preis m "" +
                ""where m.website.name = :website "", Preis.class);
       q.setParameter(""website"", website.getName());
this query works all the time, note that it uses website.name for matching, not the full Website-object.
TypedQuery<Preis> q = em.createQuery(
                ""select m from Preis m "" +
                ""where m.website = :website "", Preis.class);
        q.setParameter(""website"", website);
it only works ONCE and then does not return any results any more!!
See testcase DataAccessVerifyTest for details.
Discussion on the mailinglist seems to indicate that this is a bug.",org.apache.openjpa.jdbc.kernel.PreparedQueryImpl
CLASS,openjpa-2.0.1,OPENJPA-1912,2011-01-03T13:48:09.000-06:00,enhancer generates invalid code if fetch-groups is activated,"@Entity
public abstract class AbstractGroup {
   ...
    @Temporal(TemporalType.TIMESTAMP)
    @TrackChanges
    private Date applicationBegin;
 ...
}

 
 @Entity
public class Group extends AbstractGroup {
...
}

 
 public void writeExternal(ObjectOutput objectoutput)
        throws IOException
     
 pcWriteUnmanaged(objectoutput);
        if(pcStateManager != null)
        {
            if(pcStateManager.writeDetached(objectoutput))
                return;
        } else
        {
            objectoutput.writeObject(pcGetDetachedState());
            objectoutput.writeObject(null);
        }
        objectoutput.writeObject(applicationBegin);
        objectoutput.writeObject(applicationEnd);
        objectoutput.writeObject(applicationLocked);
        objectoutput.writeObject(approvalRequired);
If openjpa.DetachState =fetch-groups is used, the enhancer will add a 'implements Externalizable' + writeExternal + readExternal.
The problem is, that writeExternal and readExternal will also try to externalize the private members of any given superclass.
Thus we get a runtime Exception that we are not allowed to access those fields.
@Entity public abstract class AbstractGroup {
...
@Temporal(TemporalType.TIMESTAMP)
@TrackChanges private Date applicationBegin;
...
}
and
@Entity public class Group extends AbstractGroup {
...
}
will result in the following code (decompiled with jad):
public void writeExternal(ObjectOutput objectoutput)
throws IOException
{ pcWriteUnmanaged(objectoutput);
if(pcStateManager !
= null)
{ if(pcStateManager.writeDetached(objectoutput))
return;
} else
{ objectoutput.writeObject(pcGetDetachedState());
objectoutput.writeObject(null);
} objectoutput.writeObject(applicationBegin);
objectoutput.writeObject(applicationEnd);
objectoutput.writeObject(applicationLocked);
objectoutput.writeObject(approvalRequired);
...",org.apache.openjpa.enhance.PCEnhancer
CLASS,openjpa-2.0.1,OPENJPA-1918,2011-01-06T08:11:24.000-06:00,MetaDataRepository.preload() ignores class loader returned by PersistenceUnitInfo.getClassLoader(),"PersistenceUnitInfo.getClassLoader() 
 MetaDataRepository.preload()      
 PersistenceUnitInfo.getClassLoader()    
  
   PersistenceProvider.createContainerEntityManagerFactory()  MetaDatRepository.preload()
We are using openjpa inside an OSGi container together with
openjpa.MetaDataRepository"" value=""Preload=true""
However, the code in MetaDataRepository.preload() only uses the context class loader and not the class loader from PersistenceUnitInfo, which leades to ClassNotFoundExpcetions like mentioned at the end of this report.
A fix might be quite easily establihed by appending the return value of PersistenceUnitInfo.getClassLoader() to the list of claas loaders participating in the MultiClassLoader set up in
  
  MetaDataRepository.java:310ff
In the meanwhile, we are additionally setting our classloader as context loader during the creation of the EntityManagerFactory by PersistenceProvider.createContainerEntityManagerFactory(), but a fix in MetaDatRepository.preload() is highly appreciated.
TIA for fixing this,
Wolfgang
Stack trace:
org.osgi.service.blueprint.container.ComponentDefinitionException: Error when instantiating bean entityManagerFactory of class null
at org.apache.aries.blueprint.container.BeanRecipe.getInstance(BeanRecipe.java:233)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BeanRecipe.internalCreate(BeanRecipe.java:726)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.di.AbstractRecipe.create(AbstractRecipe.java:64)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintRepository.createInstances(BlueprintRepository.java:219)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintRepository.createAll(BlueprintRepository.java:147)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintContainerImpl.instantiateEagerComponents(BlueprintContainerImpl.java:624)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintContainerImpl.doRun(BlueprintContainerImpl.java:315)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintContainerImpl.run(BlueprintContainerImpl.java:213)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)[:1.6.0_20]
at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)[:1.6.0_20]
at java.util.concurrent.FutureTask.run(FutureTask.java:166)[:1.6.0_20]
at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$101(ScheduledThreadPoolExecutor.java:165)[:1.6.0_20]
at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:266)[:1.6.0_20]
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)[:1.6.0_20]
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)[:1.6.0_20]
at java.lang.Thread.run(Thread.java:636)[:1.6.0_20]
Caused by: <openjpa-2.0.1-r422266:989424 fatal user error> org.apache.openjpa.persistence.ArgumentException: Unexpected error during early loading of entity metadata during initialization. See nested stacktrace for details.
at org.apache.openjpa.meta.MetaDataRepository.preload(MetaDataRepository.java:331)
at org.apache.openjpa.persistence.PersistenceProviderImpl.preloadMetaDataRepository(PersistenceProviderImpl.java:280)
at org.apache.openjpa.persistence.PersistenceProviderImpl.createContainerEntityManagerFactory(PersistenceProviderImpl.java:211)
at org.apache.openjpa.persistence.PersistenceProviderImpl.createContainerEntityManagerFactory(PersistenceProviderImpl.java:65)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[:1.6.0_20]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)[:1.6.0_20]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[:1.6.0_20]
at java.lang.reflect.Method.invoke(Method.java:616)[:1.6.0_20]
at org.apache.aries.blueprint.container.AbstractServiceReferenceRecipe$JdkProxyFactory$1.invoke(AbstractServiceReferenceRecipe.java:632)
at $Proxy67.createContainerEntityManagerFactory(Unknown Source)
at org.clazzes.util.jpa.provider.EntityManagerFactoryFactory.newEntityManagerFactory(EntityManagerFactoryFactory.java:108)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[:1.6.0_20]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)[:1.6.0_20]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[:1.6.0_20]
at java.lang.reflect.Method.invoke(Method.java:616)[:1.6.0_20]
at org.apache.aries.blueprint.utils.ReflectionUtils.invoke(ReflectionUtils.java:221)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BeanRecipe.invoke(BeanRecipe.java:844)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BeanRecipe.getInstance(BeanRecipe.java:231)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
... 15 more
Caused by: java.security.PrivilegedActionException: java.lang.ClassNotFoundException: org.clazzes.fancymail.server.entities.EMail
at java.security.AccessController.doPrivileged(Native Method)[:1.6.0_20]
at org.apache.openjpa.meta.MetaDataRepository.preload(MetaDataRepository.java:326)
... 32 more
Caused by: java.lang.ClassNotFoundException: org.clazzes.fancymail.server.entities.EMail
at org.apache.openjpa.lib.util.MultiClassLoader.findClass(MultiClassLoader.java:216)
at java.lang.ClassLoader.loadClass(ClassLoader.java:321)[:1.6.0_20]
at java.lang.ClassLoader.loadClass(ClassLoader.java:266)[:1.6.0_20]
at java.lang.Class.forName0(Native Method)[:1.6.0_20]
at java.lang.Class.forName(Class.java:264)[:1.6.0_20]
at org.apache.openjpa.lib.util.J2DoPrivHelper$4.run(J2DoPrivHelper.java:233)
at org.apache.openjpa.lib.util.J2DoPrivHelper$4.run(J2DoPrivHelper.java:231)
... 34 more","org.apache.openjpa.meta.FieldMetaData
org.apache.openjpa.meta.MetaDataRepository
org.apache.openjpa.persistence.detach.NoVersionEntity"
CLASS,openjpa-2.0.1,OPENJPA-1928,2011-01-20T17:43:52.000-06:00,Resolving factory method does not allow method overriding,"@Factory 
 @Persistent(optional = false)
	@Column(name = ""STATUS"")
	@Externalizer(""getName"")
	@Factory(""valueOf"")
	public OrderStatus getStatus() {
		return this.status;
	}

 public class OrderStatus {
   public static OrderStatus valueOf(final int ordinal) {
        return valueOf(ordinal, OrderStatus.class);
    }
    
    public static OrderStatus valueOf(final String name) {
        return valueOf(name, OrderStatus.class);
    }
}

 
 valueOf(String)  
 valueOf(String)
If a get method is annotated with @Factory then the method cannot be overridden with a method which take different parameters.
The system randomly selects one of the several methods with the same name which may or may not take the type which will be provided.
public class OrderStatus {
   public static OrderStatus valueOf(final int ordinal) {
        return valueOf(ordinal, OrderStatus.class);
    }
    
    public static OrderStatus valueOf(final String name) {
        return valueOf(name, OrderStatus.class);
    }
}
Actual results:
valueOf(String) may or may not be selected.
The provided patches fix this defect by applying the method invocation conversion rules from the Java Language Specification, 3rd Ed.
This means that widening primitive, boxing and unboxing conversions are all respected.",org.apache.openjpa.meta.FieldMetaData
CLASS,openjpa-2.0.1,OPENJPA-1986,2011-04-27T11:44:53.000-05:00,Extra queries being generated when cascading a persist,"@Entity
public class CascadePersistEntity implements Serializable {
    private static final long serialVersionUID = -8290604110046006897L;

    @Id
    long id;

    @OneToOne(cascade = CascadeType.ALL)
    CascadePersistEntity other;
...
}

 
 CascadePersistEntity cpe1 = new CascadePersistEntity(1);
CascadePersistEntity cpe2 = new CascadePersistEntity(2);
cpe1.setOther(cpe2);
em.persist(cpe1);
I found a scenario where extra queries were being generated while cascading a persist to a new Entity.
@Entity
public class CascadePersistEntity implements Serializable {
    private static final long serialVersionUID = -8290604110046006897L;
@Id
    long id;
@OneToOne(cascade = CascadeType.ALL)
    CascadePersistEntity other;
...
}
This results in two inserts and one select.
The extra select is what I'm going to get rid of with this JIRA.","org.apache.openjpa.kernel.BrokerImpl
org.apache.openjpa.conf.Compatibility
org.apache.openjpa.kernel.SingleFieldManager"
CLASS,openjpa-2.0.1,OPENJPA-2132,2012-02-14T14:48:29.000-06:00,Traversal of a OneToMany relationship returns an empty list when InheritanceType.JOINED or SINGLE_TABLE is used.,"@Inheritance(strategy=InheritanceType.JOINED)
I will include a test, named 'OneManyJoinableTest.test' which recreates the issue of this JIRA.
Basically though, the test consists of a parent class defined with '@Inheritance(strategy=InheritanceType.JOINED)'.
One of the subclasses in the hierarchy contains a (bidirectional) OneToMany relationship.
When traversing the ManyToOne side of the relations, all works well.
But when traversing the OneToMany side an empty list is returned.
When running the test, it can be seen that OpenJPA generate incorrect SQL, as follows:
SELECT t1.id, t0.id, t2.id, t3.id, t1.name FROM UMLType t0, UMLNamed t1, UMLClass t2, UMLPrimitiveType t3 WHERE t0.OWNERPACKAGE_ID = ?
AND t2.id IS NULL AND t3.id IS NULL AND t0.id = t1.id AND t0.id = t2.id(+) AND t0.id = t3.id(+)
Note that the 't2.id IS NULL AND t3.id IS NULL' seems suspect.
This same test passes on OpenJPA 1.2.x but fails on OpenJPA 2.0.x on wards.",org.apache.openjpa.jdbc.kernel.JDBCStoreManager
CLASS,openjpa-2.0.1,OPENJPA-2289,2012-10-31T13:40:55.000-05:00,Additional SQL alias generated for query with subquery causes incorrect # of rows returned - Oracle only,"createQuery(""SELECT e FROM MaxQueryEntity e, MaxQueryMapEntity map ""
                    + ""WHERE map.selectCriteria = 'B3' AND map.refEntity = e ""
                    + ""  AND e.revision = ( SELECT MAX(e_.revision)""
                    + ""                     FROM MaxQueryEntity e_""
                    + ""                     WHERE e_.domainId = e.domainId )""
                    + ""  AND map.revision = ( SELECT MAX(map_.revision)""
                    + ""                       FROM MaxQueryMapEntity map_""
                    + ""                       WHERE map_.refEntity = map.refEntity )"");
.
createQuery(""SELECT e FROM MaxQueryEntity e, MaxQueryMapEntity map ""
                    + ""WHERE map.selectCriteria = 'B3' AND map.refEntity = e ""
                    + ""  AND e.revision = ( SELECT MAX(e_.
revision)""
                    + ""                     FROM MaxQueryEntity e_""
                    + ""                     WHERE e_.
domainId = e.domainId )""
                    + ""  AND map.revision = ( SELECT MAX(map_.
revision)""
                    + ""                       FROM MaxQueryMapEntity map_""
                    + ""                       WHERE map_.
refEntity = map.refEntity )"");
On Oracle we generate SQL like this on 2.0.
x+:
SELECT t1.id, t1.domainId, t1.revision FROM OPENJPA_MAXQUERY_MAPENTITY t0, OPENJPA_MAXQUERY_ENTITY t1, OPENJPA_MAXQUERY_MAPENTITY t4 WHERE (t0.selectCriteria = ?
AND t0.refEntity = t1.id AND t1.revision = (SELECT MAX(t2.revision) FROM OPENJPA_MAXQUERY_ENTITY t2 WHERE (t2.domainId = t1.domainId)) AND t0.revision = (SELECT MAX(t3.revision) FROM OPENJPA_MAXQUERY_MAPENTITY t3 WHERE (t3.refEntity = t4.refEntity))) [params=(String) B3]
The additional alias ""OPENJPA_MAXQUERY_MAPENTITY t4"" caused more unexpected rows to return.","org.apache.openjpa.jdbc.sql.SelectImpl
org.apache.openjpa.jdbc.sql.OracleDictionary
org.apache.openjpa.jdbc.sql.DBDictionary"
METHOD,lang,LANG-292,2006-10-31T01:45:01.000-06:00,"unescapeXml(""&12345678;"") should be ""&12345678;""","public void testNumberOverflow() throws Exception {
        doTestUnescapeEntity(""&#12345678;"", ""&#12345678;"");
        doTestUnescapeEntity(""x&#12345678;y"", ""x&#12345678;y"");
        doTestUnescapeEntity(""&#x12345678;"", ""&#x12345678;"");
        doTestUnescapeEntity(""x&#x12345678;y"", ""x&#x12345678;y"");
    }
Following test (in EntitiesTest.java) fails:
public void testNumberOverflow() throws Exception {
        doTestUnescapeEntity(""&#12345678;"", ""&#12345678;"");
        doTestUnescapeEntity(""x&#12345678;y"", ""x&#12345678;y"");
        doTestUnescapeEntity(""&#x12345678;"", ""&#x12345678;"");
        doTestUnescapeEntity(""x&#x12345678;y"", ""x&#x12345678;y"");
    }","org.apache.commons.lang.Entities:unescape(String)
org.apache.commons.lang.Entities:unescape(Writer, String)"
METHOD,lang,LANG-315,2007-02-06T13:52:59.000-06:00,"StopWatch: suspend() acts as split(), if followed by stop()","suspend()   split()  stop();  
 StopWatch sw = new StopWatch();

        sw.start();
        Thread.sleep(1000);
        sw.suspend();
        // Time 1 (ok)
        System.out.println(sw.getTime());

        Thread.sleep(2000);
        // Time 1 (again, ok)
        System.out.println(sw.getTime());

        sw.resume();
        Thread.sleep(3000);
        sw.suspend();
        // Time 2 (ok)
        System.out.println(sw.getTime());

        Thread.sleep(4000);
        // Time 2 (again, ok)
        System.out.println(sw.getTime());

        Thread.sleep(5000);
        sw.stop();
        // Time 2 (should be, but is Time 3 => NOT ok)
        System.out.println(sw.getTime());


  stop()
In my opinion, it is a bug that suspend() acts as split(), if followed by stop(); see below:
StopWatch sw = new StopWatch();
sw.start();
Thread.sleep(1000);
sw.suspend();
// Time 1 (ok)
System.out.println(sw.getTime());
Thread.sleep(2000);
// Time 1 (again, ok)
System.out.println(sw.getTime());
sw.resume();
Thread.sleep(3000);
sw.suspend();
// Time 2 (ok)
System.out.println(sw.getTime());
Thread.sleep(4000);
// Time 2 (again, ok)
System.out.println(sw.getTime());
Thread.sleep(5000);
sw.stop();
// Time 2 (should be, but is Time 3 => NOT ok)
System.out.println(sw.getTime());
suspend/resume is like a pause, where time counter doesn't continue.",org.apache.commons.lang.time.StopWatch:stop()
METHOD,lang,LANG-346,2007-07-06T20:06:55.000-05:00,Dates.round() behaves incorrectly for minutes and seconds,"public void testRound()
{
    Calendar testCalendar = Calendar.getInstance(TimeZone.getTimeZone(""GMT""));
    testCalendar.set(2007, 6, 2, 8, 9, 50);
    Date date = testCalendar.getTime();
    System.out.println(""Before round() "" + date);
    System.out.println(""After round()  "" + DateUtils.round(date, Calendar.MINUTE));
}

 
 Before round()  
 After round()   
 Before round()  
 After round()
Get unexpected output for rounding by minutes or seconds.
public void testRound()
{
Calendar testCalendar = Calendar.getInstance(TimeZone.getTimeZone(""GMT""));
testCalendar.set(2007, 6, 2, 8, 9, 50);
Date date = testCalendar.getTime();
System.out.println(""Before round() "" + date);
System.out.println(""After round()  "" + DateUtils.round(date, Calendar.MINUTE));
}
--2.1 produces
Before round() Mon Jul 02 03:09:50 CDT 2007
--2.2 and 2.3 produces
Before round() Mon Jul 02 03:09:50 CDT 2007
After round()  Mon Jul 02 03:01:00 CDT 2007 -- this appears to be wrong","org.apache.commons.lang.time.DateUtils:modify(Calendar, int, boolean)"
METHOD,lang,LANG-363,2007-10-23T07:12:48.000-05:00,"StringEscapeUtils.escapeJavaScript() method did not escape '/' into '\/', it will make IE render page uncorrectly","document.getElementById(""test"")   document.getElementById(""test"") 
  
 String s = ""<script>alert('aaa');</script>"";
  String str = org.springframework.web.util.JavaScriptUtils.javaScriptEscape(s);
  System.out.println(""Spring JS Escape : ""+str);
  str = org.apache.commons.lang.StringEscapeUtils.escapeJavaScript(s);
  System.out.println(""Apache Common Lang JS Escape : ""+ str);
value = '<script>alert(\'aaa\');</script>';this expression will make IE render page uncorrect, it should be document.getElementById(""test"").
value = '<script>alert(\'aaa\');<\/script>';
Btw, Spring's JavascriptEscape behavor is correct.","org.apache.commons.lang.StringEscapeUtils:escapeJavaStyleString(Writer, String, boolean)"
METHOD,lang,LANG-477,2009-01-09T10:05:53.000-06:00,ExtendedMessageFormat: OutOfMemory with custom format registry and a pattern containing single quotes,"{code:title=ExtendedMessageFormatTest.java|borderStyle=solid}

 private static Map<String, Object> formatRegistry = new HashMap<String, Object>();    
     static {
        formatRegistry.put(DummyFormatFactory.DUMMY_FORMAT, new DummyFormatFactory());
    }
    
     public static void main(String[] args) {
        ExtendedMessageFormat mf = new ExtendedMessageFormat(""it''s a {dummy} 'test'!"", formatRegistry);
        String formattedPattern = mf.format(new String[] {""great""});
        System.out.println(formattedPattern);
    }
 
 {code}

 
 {code:title=ExtendedMessageFormat.java|borderStyle=solid}
 
 if (escapingOn && c[start] == QUOTE) {
        return appendTo == null ? null : appendTo.append(QUOTE);
}

WORKING:
if (escapingOn && c[start] == QUOTE) {
        next(pos);
        return appendTo == null ? null : appendTo.append(QUOTE);
}
{code}
When using ExtendedMessageFormat with a custom format registry and a pattern conatining single quotes, an OutOfMemoryError will occur.
{code:title=ExtendedMessageFormatTest.java|borderStyle=solid}
private static Map<String, Object> formatRegistry = new HashMap<String, Object>();    
    static {
        formatRegistry.put(DummyFormatFactory.DUMMY_FORMAT, new DummyFormatFactory());
    }
    
    public static void main(String[] args) {
        ExtendedMessageFormat mf = new ExtendedMessageFormat(""it''s a {dummy} 'test'!""
, formatRegistry);
        String formattedPattern = mf.format(new String[] {""great""});
        System.out.println(formattedPattern);
    }
}
{code}
The following change starting at line 421 on the 2.4 release seems to fix the problem:
{code:title=ExtendedMessageFormat.java|borderStyle=solid}
CURRENT (Broken):
if (escapingOn && c[start] == QUOTE) {
        return appendTo == null ?
null : appendTo.append(QUOTE);
}
WORKING:
if (escapingOn && c[start] == QUOTE) {
        next(pos);
        return appendTo == null ?
null : appendTo.append(QUOTE);
}
{code}","org.apache.commons.lang.text.ExtendedMessageFormat:appendQuotedString(String, ParsePosition, StringBuffer, boolean)"
METHOD,lang,LANG-480,2009-01-20T17:36:44.000-06:00,StringEscapeUtils.escapeHtml incorrectly converts unicode characters above U+00FFFF into 2 characters,"import org.apache.commons.lang.*;

public class J2 {
    public static void main(String[] args) throws Exception {
        // this is the utf8 representation of the character:
        // COUNTING ROD UNIT DIGIT THREE
        // in unicode
        // codepoint: U+1D362
        byte[] data = new byte[] { (byte)0xF0, (byte)0x9D, (byte)0x8D, (byte)0xA2 };

        //output is: &amp;#55348;&amp;#57186;
        // should be: &amp;#119650;
        System.out.println(""'"" + StringEscapeUtils.escapeHtml(new String(data, ""UTF8"")) + ""'"");
    }
}
Characters that are represented as a 2 characters internaly by java are incorrectly converted by the function.
import org.apache.commons.lang.
*;
public class J2 {
    public static void main(String[] args) throws Exception {
        // this is the utf8 representation of the character:
        // COUNTING ROD UNIT DIGIT THREE
        // in unicode
        // codepoint: U+1D362
        byte[] data = new byte[] { (byte)0xF0, (byte)0x9D, (byte)0x8D, (byte)0xA2 };
//output is: &amp;#55348;&amp;#57186;
        // should be: &amp;#119650;
        System.out.println(""'"" + StringEscapeUtils.escapeHtml(new String(data, ""UTF8"")) + ""'"");
    }
}
Should be very quick to fix, feel free to drop me an email if you want a patch.","org.apache.commons.lang.Entities:escape(Writer, String)"
METHOD,lang,LANG-538,2009-10-16T16:47:39.000-05:00,DateFormatUtils.format does not correctly change Calendar TimeZone in certain situations,"Calenar.getTime()    
 {noformat}
   public void testFormat_CalendarIsoMsZulu() {
    final String dateTime = ""2009-10-16T16:42:16.000Z"";

    // more commonly constructed with: cal = new GregorianCalendar(2009, 9, 16, 8, 42, 16)
    // for the unit test to work in any time zone, constructing with GMT-8 rather than default locale time zone
    GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(""GMT-8""));
    cal.clear();
    cal.set(2009, 9, 16, 8, 42, 16);


    FastDateFormat format = FastDateFormat.getInstance(""yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"", TimeZone.getTimeZone(""GMT""));
    assertEquals(""dateTime"", dateTime, format.format(cal));
  }
 {noformat}

 
 {noformat}
   public void testFormat_CalendarIsoMsZulu() {
    final String dateTime = ""2009-10-16T16:42:16.000Z"";
    GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(""GMT-8""));
    cal.clear();
    cal.set(2009, 9, 16, 8, 42, 16);
    cal.getTime();

    FastDateFormat format = FastDateFormat.getInstance(""yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"", TimeZone.getTimeZone(""GMT""));
    assertEquals(""dateTime"", dateTime, format.format(cal));
  }
 {noformat}
If a Calendar object is constructed in certain ways a call to Calendar.setTimeZone does not correctly change the Calendars fields.
Calling Calenar.getTime() seems to fix this problem.
While this is probably a bug in the JDK, it would be nice if DateFormatUtils was smart enough to detect/resolve this problem.
For example, the following unit test fails:
{noformat}
  public void testFormat_CalendarIsoMsZulu() {
    final String dateTime = ""2009-10-16T16:42:16.000Z"";
// more commonly constructed with: cal = new GregorianCalendar(2009, 9, 16, 8, 42, 16)
    // for the unit test to work in any time zone, constructing with GMT-8 rather than default locale time zone
    GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(""GMT-8""));
    cal.clear();
    cal.set(2009, 9, 16, 8, 42, 16);
FastDateFormat format = FastDateFormat.getInstance(""yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"", TimeZone.getTimeZone(""GMT""));
    assertEquals(""dateTime"", dateTime, format.format(cal));
  }
{noformat}
However, this unit test passes:
{noformat}
  public void testFormat_CalendarIsoMsZulu() {
    final String dateTime = ""2009-10-16T16:42:16.000Z"";
    GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(""GMT-8""));
    cal.clear();
    cal.set(2009, 9, 16, 8, 42, 16);
    cal.getTime();
FastDateFormat format = FastDateFormat.getInstance(""yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"", TimeZone.getTimeZone(""GMT""));
    assertEquals(""dateTime"", dateTime, format.format(cal));
  }
{noformat}","org.apache.commons.lang3.time.FastDateFormat:format(Calendar, StringBuffer)"
METHOD,lang,LANG-552,2009-11-09T12:40:57.000-06:00,StringUtils replaceEach - Bug or Missing Documentation,"{code}
 import static org.junit.Assert.assertEquals;

import org.apache.commons.lang.StringUtils;
import org.junit.Test;


public class StringUtilsTest {

	@Test
	public void replaceEach(){
		String original = ""Hello World!"";
		String[] searchList = {""Hello"", ""World""};
		String[] replacementList = {""Greetings"", null};
		String result = StringUtils.replaceEach(original, searchList, replacementList);
		assertEquals(""Greetings !"", result);
		//perhaps this is ok as well
                //assertEquals(""Greetings World!"", result);
                //or even
		//assertEquals(""Greetings null!"", result);
	}

	
}
 {code}
The following Test Case for replaceEach fails with a null pointer exception.
The use case is that i will stuff Values into the replacementList of which I do not want to check whether they are null.
I admit the use case is not perfect, because it is unclear what happens on the replace.
I outlined three expectations in the test case, of course only one should be met.
If it is decided that none of them should be possible, I propose to update the documentation with what happens when null is passed as replacement string
{code} import static org.junit.Assert.assertEquals;
import org.apache.commons.lang.StringUtils;
import org.junit.Test;
public class StringUtilsTest {
@Test public void replaceEach(){
String original = ""Hello World!""
;
String[] searchList = {""Hello"", ""World""};
String[] replacementList = {""Greetings"", null};
String result = StringUtils.replaceEach(original, searchList, replacementList);
assertEquals(""Greetings !""
, result);
//perhaps this is ok as well
//assertEquals(""Greetings World!""
, result);
//or even
//assertEquals(""Greetings null!""
, result);
}
}
{code}","org.apache.commons.lang3.StringUtils:replaceEach(String, String[], String[], boolean, int)"
METHOD,lang,LANG-624,2010-05-27T21:09:29.000-05:00,SystemUtils.getJavaVersionAsFloat throws StringIndexOutOfBoundsException on Android runtime/Dalvik VM,"{noformat}

   
   
         
   
          {noformat}
Can be replicated in the Android emulator quite easily.
Stack trace:
{noformat}
at org.apache.commons.lang.builder.ToStringBuilder.<clinit>(ToStringBuilder.java:98)
E/AndroidRuntime( 1681): 	... 17 more
E/AndroidRuntime( 1681): Caused by: java.lang.ExceptionInInitializerError
E/AndroidRuntime( 1681): 	at org.apache.commons.lang.builder.ToStringStyle$MultiLineToStringStyle.<init>(ToStringStyle.java:2276)
E/AndroidRuntime( 1681): 	at org.apache.commons.lang.builder.ToStringStyle.<clinit>(ToStringStyle.java:94)
E/AndroidRuntime( 1681): 	... 18 more
E/AndroidRuntime( 1681): Caused by: java.lang.StringIndexOutOfBoundsException
E/AndroidRuntime( 1681): 	at java.lang.String.substring(String.java:1571)
E/AndroidRuntime( 1681): 	at org.apache.commons.lang.SystemUtils.getJavaVersionAsFloat(SystemUtils.java:1153)
E/AndroidRuntime( 1681): 	at org.apache.commons.lang.SystemUtils.<clinit>(SystemUtils.java:818)
{noformat}",org.apache.commons.lang3.SystemUtils:toJavaVersionInt(String)
METHOD,lang,LANG-645,2010-08-20T14:11:08.000-05:00,FastDateFormat.format() outputs incorrect week of year because locale isn't respected,"format()     
  
 {code}
 import java.util.Calendar;
import java.util.Date;
import java.util.Locale;
import java.text.SimpleDateFormat;

import org.apache.commons.lang.time.FastDateFormat;

public class FastDateFormatWeekBugDemo {
    public static void main(String[] args) {
        Locale.setDefault(new Locale(""en"", ""US""));
        Locale locale = new Locale(""sv"", ""SE"");

        Calendar cal = Calendar.getInstance(); // setting locale here doesn't change outcome
        cal.set(2010, 0, 1, 12, 0, 0);
        Date d = cal.getTime();
        System.out.println(""Target date: "" + d);

        FastDateFormat fdf = FastDateFormat.getInstance(""EEEE', week 'ww"", locale);
        SimpleDateFormat sdf = new SimpleDateFormat(""EEEE', week 'ww"", locale);
        System.out.println(""FastDateFormat:   "" + fdf.format(d)); // will output ""FastDateFormat:   fredag, week 01""
        System.out.println(""SimpleDateFormat: "" + sdf.format(d)); // will output ""SimpleDateFormat: fredag, week 53""
    }
}
 {code}
  Locale.setDefault()
FastDateFormat apparently doesn't respect the locale it was sent on creation when outputting week in year (e.g. ""ww"") in format().
It seems to use the settings of the system locale for firstDayOfWeek and minimalDaysInFirstWeek, which (depending on the year) may result in the incorrect week number being output.
Here is a simple test program to demonstrate the problem by comparing with SimpleDateFormat, which gets the week number right:
{code}
import java.util.Calendar;
import java.util.Date;
import java.util.Locale;
import java.text.SimpleDateFormat;
import org.apache.commons.lang.time.FastDateFormat;
public class FastDateFormatWeekBugDemo {
    public static void main(String[] args) {
        Locale.setDefault(new Locale(""en"", ""US""));
        Locale locale = new Locale(""sv"", ""SE"");
Calendar cal = Calendar.getInstance(); // setting locale here doesn't change outcome
        cal.set(2010, 0, 1, 12, 0, 0);
        Date d = cal.getTime();
        System.out.println(""Target date: "" + d);
FastDateFormat fdf = FastDateFormat.getInstance(""EEEE', week 'ww"", locale);
        SimpleDateFormat sdf = new SimpleDateFormat(""EEEE', week 'ww"", locale);
        System.out.println(""FastDateFormat:   "" + fdf.format(d)); // will output ""FastDateFormat:   fredag, week 01""
        System.out.println(""SimpleDateFormat: "" + sdf.format(d)); // will output ""SimpleDateFormat: fredag, week 53""
    }
}
{code}
If sv/SE is passed to Locale.setDefault() instead of en/US, both FastDateFormat and SimpleDateFormat output the correct week number.",org.apache.commons.lang3.time.FastDateFormat:format(Date)
METHOD,lang,LANG-662,2010-12-06T22:40:30.000-06:00,"org.apache.commons.lang3.math.Fraction does not reduce (Integer.MIN_VALUE, 2^k)","class Fraction    
    
 
  public void testReducedFactory_int_int()  
 
  f = Fraction.getReducedFraction(Integer.MIN_VALUE, 2);
		assertEquals(Integer.MIN_VALUE / 2, f.getNumerator());
		assertEquals(1, f.getDenominator());

	 public void testReduce()  
 
  f = Fraction.getFraction(Integer.MIN_VALUE, 2);
		result = f.reduce();
		assertEquals(Integer.MIN_VALUE / 2, result.getNumerator());
		assertEquals(1, result.getDenominator());
{code}
The greatestCommonDivisor method in class Fraction does not find the gcd of Integer.MIN_VALUE and 2^k, and this case can be triggered by taking Integer.MIN_VALUE as the numerator.
Note that the case of taking Integer.MIN_VALUE as the denominator is handled explicitly in the getReducedFraction factory method.
{code:title=FractionTest.java|borderStyle=solid}
	// additional test cases
	public void testReducedFactory_int_int() {
		// ...
		f = Fraction.getReducedFraction(Integer.MIN_VALUE, 2);
		assertEquals(Integer.MIN_VALUE / 2, f.getNumerator());
		assertEquals(1, f.getDenominator());
public void testReduce() {
		// ...
		f = Fraction.getFraction(Integer.MIN_VALUE, 2);
		result = f.reduce();
		assertEquals(Integer.MIN_VALUE / 2, result.getNumerator());
		assertEquals(1, result.getDenominator());
{code}","org.apache.commons.lang3.math.Fraction:greatestCommonDivisor(int, int)"
METHOD,lang,LANG-710,2011-07-01T20:57:30.000-05:00,"StringIndexOutOfBoundsException when calling unescapeHtml4(""&#03"")","unescapeHtml4()
When calling unescapeHtml4() on the String ""&#03"" (or any String that contains these characters) an Exception is thrown:
Exception in thread ""main"" java.lang.StringIndexOutOfBoundsException: String index out of range: 4
at java.lang.String.charAt(String.java:686)
at org.apache.commons.lang3.text.translate.NumericEntityUnescaper.translate(NumericEntityUnescaper.java:49)
at org.apache.commons.lang3.text.translate.AggregateTranslator.translate(AggregateTranslator.java:53)
at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:88)
at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:60)
at org.apache.commons.lang3.StringEscapeUtils.unescapeHtml4(StringEscapeUtils.java:351)","org.apache.commons.lang3.text.translate.NumericEntityUnescaper:translate(CharSequence, int, Writer)"
METHOD,lang,LANG-788,2012-02-11T12:36:48.000-06:00,SerializationUtils throws ClassNotFoundException when cloning primitive classes,"{noformat}
 import org.apache.commons.lang3.SerializationUtils;
import org.junit.Test;


public class SerializationUtilsTest {

	
	@Test
	public void primitiveTypeClassSerialization(){
		Class<?> primitiveType = int.class;
		
		Class<?> clone = SerializationUtils.clone(primitiveType);
		assertEquals(primitiveType, clone);
	}
}
 {noformat} 

  
         
    
  
 {noformat}
         protected Class<?> resolveClass(ObjectStreamClass desc) throws IOException, ClassNotFoundException {
            String name = desc.getName();
            try {
                return Class.forName(name, false, classLoader);
            } catch (ClassNotFoundException ex) {
            	try {
            	     return Class.forName(name, false, Thread.currentThread().getContextClassLoader());
            	} catch (Exception e) {
		     return super.resolveClass(desc);
		}
            }
        }
 {noformat}

   
 {noformat}
     protected Class<?> resolveClass(ObjectStreamClass desc)
	throws IOException, ClassNotFoundException
    {
	String name = desc.getName();
	try {
	    return Class.forName(name, false, latestUserDefinedLoader());
	} catch (ClassNotFoundException ex) {
	    Class cl = (Class) primClasses.get(name);
	    if (cl != null) {
		return cl;
	    } else {
		throw ex;
	    }
	}
    }
 {noformat}
If a serializable object contains a reference to a primitive class, e.g. int.class or int[].class, the SerializationUtils throw a ClassNotFoundException when trying to clone that object.
{noformat} import org.apache.commons.lang3.SerializationUtils;
import org.junit.Test;
public class SerializationUtilsTest {
@Test public void primitiveTypeClassSerialization(){
Class<?> primitiveType = int.class;
Class<?> clone = SerializationUtils.clone(primitiveType);
assertEquals(primitiveType, clone);
}
}
{noformat}
The problem was already reported as a java bug http://bugs.sun.com/view_bug.do?bug_id=4171142 and ObjectInputStream is fixed since java version 1.4.
The SerializationUtils problem arises because the SerializationUtils internally use the ClassLoaderAwareObjectInputStream that overrides the ObjectInputStream's resoleClass method without delegating to the super method in case of a ClassNotFoundException.
{noformat} protected Class<?> resolveClass(ObjectStreamClass desc) throws IOException, ClassNotFoundException {
String name = desc.getName();
try { return Class.forName(name, false, classLoader);
} catch (ClassNotFoundException ex) { try { return Class.forName(name, false, Thread.currentThread().
getContextClassLoader());
} catch (Exception e) { return super.resolveClass(desc);
}
}
}
{noformat}
Here is the code in ObjectInputStream that fixed the java bug.
{noformat} protected Class<?> resolveClass(ObjectStreamClass desc)
throws IOException, ClassNotFoundException
{
String name = desc.getName();
try { return Class.forName(name, false, latestUserDefinedLoader());
} catch (ClassNotFoundException ex) {
Class cl = (Class) primClasses.get(name);
if (cl !
= null) { return cl;
} else { throw ex;
}
}
}
{noformat}","org.apache.commons.lang3.SerializationUtils:ClassLoaderAwareObjectInputStream(InputStream, ClassLoader)
org.apache.commons.lang3.SerializationUtils:resolveClass(ObjectStreamClass)"
METHOD,lang,LANG-832,2012-09-27T00:27:58.000-05:00,FastDateParser does not handle unterminated quotes correctly,"{IsNd}
FDP does not handled unterminated quotes the same way as SimpleDateFormat
Format: 'd'd'
Date: d3
The format is parsed as:
Pattern: d(\p{IsNd}++)",org.apache.commons.lang3.time.FastDateParser:init()
METHOD,lang,LANG-857,2012-11-20T12:36:14.000-06:00,StringIndexOutOfBoundsException in CharSequenceTranslator,"{code:java}
 @Test
public void testEscapeSurrogatePairs() throws Exception {
    assertEquals(""\uD83D\uDE30"", StringEscapeUtils.escapeCsv(""\uD83D\uDE30""));
}
 {code}

 
 {code}
 {code}

 
 public final void translate(CharSequence input, Writer out) throws IOException
I found that there is bad surrogate pair handling in the CharSequenceTranslator
\uD83D\uDE30 is a surrogate pair.
{code:java}
@Test public void testEscapeSurrogatePairs() throws Exception { assertEquals(""\uD83D\uDE30"", StringEscapeUtils.escapeCsv(""\uD83D\uDE30""));
}
{code}
You'll get the exception as shown below.
{code} java.lang.StringIndexOutOfBoundsException: String index out of range: 2
at java.lang.String.charAt(String.java:658)
at java.lang.Character.codePointAt(Character.java:4668)
at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:95)
at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:59)
at org.apache.commons.lang3.StringEscapeUtils.escapeCsv(StringEscapeUtils.java:556)
{code}
Patch attached, the method affected:
# public final void translate(CharSequence input, Writer out) throws IOException","org.apache.commons.lang3.text.translate.CharSequenceTranslator:translate(CharSequence, Writer)"
METHOD,lang,LANG-879,2013-03-18T21:46:29.000-05:00,"LocaleUtils test fails with new Locale ""ja_JP_JP_#u-ca-japanese"" of JDK7","import static org.hamcrest.MatcherAssert.assertThat;
import static org.hamcrest.Matchers.equalTo;

import java.util.Locale;

import org.testng.annotations.Test;

import com.scispike.foundation.i18n.StringToLocaleConverter;

public class LocaleStringConverterTest {

	StringToLocaleConverter converter = new StringToLocaleConverter();

	public void testStringToLocale(Locale l) {
		String s = l.toString();

		assertThat(converter.convert(s), equalTo(l));
	}

	@Test
	public void testAllLocales() {

		Locale[] locales = Locale.getAvailableLocales();
		for (Locale l : locales) {
			testStringToLocale(l);
		}
	}
}


  
 import java.util.Locale;

import org.apache.commons.lang3.LocaleUtils;
import org.springframework.core.convert.converter.Converter;

public class StringToLocaleConverter implements Converter<String, Locale> {

	@Override
	public Locale convert(String source) {
		if (source == null) {
			return LocaleToStringConverter.DEFAULT;
		}
		return LocaleUtils.toLocale(source);
	}
}
The Test below fails with the following error on JDK7, but succeeds on JDK6:
testAllLocales
""java.lang.AssertionError:
Expected: <ja_JP_JP_#u-ca-japanese>
but: was <ja_JP_JP_#u-ca-japanese>
at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)
at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:8)
at com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testStringToLocale(LocaleStringConverterTest.java:20)
at com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testAllLocales(LocaleStringConverterTest.java:28)
at org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:76)
at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeMulti(TestNGDirectoryTestSuite.java:161)
at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.execute(TestNGDirectoryTestSuite.java:101)
at org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:115)
at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:103)
at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:74)
... Removed 25 stack frames
java.lang.AssertionError:
Expected: <ja_JP_JP_#u-ca-japanese>
but: was <ja_JP_JP_#u-ca-japanese>
at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)
at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:8)
at com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testStringToLocale(LocaleStringConverterTest.java:20)
at com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testAllLocales(LocaleStringConverterTest.java:28)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:601)
at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:80)
at org.testng.internal.Invoker.invokeMethod(Invoker.java:715)
at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:907)
at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1237)
at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:127)
at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:111)
at org.testng.TestRunner.privateRun(TestRunner.java:767)
at org.testng.TestRunner.run(TestRunner.java:617)
at org.testng.SuiteRunner.runTest(SuiteRunner.java:334)
at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:329)
at org.testng.SuiteRunner.privateRun(SuiteRunner.java:291)
at org.testng.SuiteRunner.run(SuiteRunner.java:240)
at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:51)
at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:85)
at org.testng.TestNG.runSuitesSequentially(TestNG.java:1197)
at org.testng.TestNG.runSuitesLocally(TestNG.java:1122)
at org.testng.TestNG.run(TestNG.java:1030)
at org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:76)
at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeMulti(TestNGDirectoryTestSuite.java:161)
at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.execute(TestNGDirectoryTestSuite.java:101)
at org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:115)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:601)
at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:103)
at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:74)
""
org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)
org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:8)
com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testStringToLocale(LocaleStringConverterTest.java:20)
com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testAllLocales(LocaleStringConverterTest.java:28)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:601)
org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:80)
org.testng.internal.Invoker.invokeMethod(Invoker.java:715)
org.testng.internal.Invoker.invokeTestMethod(Invoker.java:907)
org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1237)
org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:127)
org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:111)
org.testng.TestRunner.privateRun(TestRunner.java:767)
org.testng.TestRunner.run(TestRunner.java:617)
org.testng.SuiteRunner.runTest(SuiteRunner.java:334)
org.testng.SuiteRunner.runSequentially(SuiteRunner.java:329)
org.testng.SuiteRunner.privateRun(SuiteRunner.java:291)
org.testng.SuiteRunner.run(SuiteRunner.java:240)
org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:51)
org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:85)
org.testng.TestNG.runSuitesSequentially(TestNG.java:1197)
org.testng.TestNG.runSuitesLocally(TestNG.java:1122)
org.testng.TestNG.run(TestNG.java:1030)
org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:76)
org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeMulti(TestNGDirectoryTestSuite.java:161)
org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.execute(TestNGDirectoryTestSuite.java:101)
org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:115)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:601)
org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:103)
org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:74)
========== Test
import static org.hamcrest.MatcherAssert.assertThat;
import static org.hamcrest.Matchers.equalTo;
import java.util.Locale;
import org.testng.annotations.Test;
import com.scispike.foundation.i18n.StringToLocaleConverter;
public class LocaleStringConverterTest {
StringToLocaleConverter converter = new StringToLocaleConverter();
public void testStringToLocale(Locale l) {
		String s = l.toString();
assertThat(converter.convert(s), equalTo(l));
	}
@Test
	public void testAllLocales() {
Locale[] locales = Locale.getAvailableLocales();
		for (Locale l : locales) {
			testStringToLocale(l);
		}
	}
}
========== StringToLocaleConverter
import java.util.Locale;
import org.apache.commons.lang3.LocaleUtils;
import org.springframework.core.convert.converter.Converter;
public class StringToLocaleConverter implements Converter<String, Locale> {
@Override
	public Locale convert(String source) {
		if (source == null) {
			return LocaleToStringConverter.DEFAULT;
		}
		return LocaleUtils.toLocale(source);
	}
}",org.apache.commons.lang3.LocaleUtils:toLocale(String)
FILE,SWARM,SWARM-528,2016-06-22T02:53:46.000-05:00,swarm.http.port and swarm.port.offset do not work with @ArquillianResource URL baseURL,"@ArquillianResource 
  
 
 
 
 @ArquillianResource 
  
 
 
 
 @ArquillianResource
First Example
<container qualifier=""wildfly-swarm"" default=""true"">
<configuration>
<property name=""javaVmArguments"">
-Dswarm.port.offset=1
</property>
</configuration>
</container>
the arquillian swarm container is correctly started on the specified port/offset.
@ArquillianResource
private URL baseURL;
to retrieve the url the swarm container is accessible via it always returns http://localhost:8080.
Second Example
<container qualifier=""wildfly-swarm"" default=""true"">
<configuration>
<property name=""port"">8081</property>
</configuration>
</container>
it starts the swarm container on 8080 and
@ArquillianResource
private URL baseURL;
returns http://localhost:8081
Third Example
<container qualifier=""wildfly-swarm"" default=""true"">
<configuration>
<property name=""javaVmArguments"">
-Dswarm.port.offset=1
</property>
<property name=""port"">8081</property>
</configuration>
</container>
the port/offset is ignored and the container is started on 8080, while
@ArquillianResource
private URL baseURL;
returns http:localhost:8081 note: while the examples above use swarm.port.offset, the same issue occurs if you use swarm.http.port",org.wildfly.swarm.arquillian.resources.SwarmURLResourceProvider
FILE,SWARM,SWARM-486,2016-05-28T18:25:37.000-05:00,Can't load project-stages.yml on classpath with Arq,"classpath(src/main/resources)  
 
 
 container.withStageConfig(Paths.get(""/tmp"", ""external-project-stages.yml"").toUri().toURL())
problem project-stages.
yml on classpath(src/main/resources) is not loaded with Arquillian tests.
Though -swarm try to load it, apparently can't see it when Arq tests.
https://github.com/wildfly-swarm/wildfly-swarm-core/blob/1.0.0.CR3/container/api/src/main/java/org/wildfly/swarm/cli/CommandLine.java#L109 workaround
To load the yml explicitly like below.
container.withStageConfig(Paths.get(""/tmp"", ""external-project-stages.
yml"").
toUri().
toURL())",org.wildfly.swarm.container.ProjectStagesTest
FILE,SWARM,SWARM-863,2016-11-30T14:54:40.000-06:00,Version 2016.11.0 doesn't stop properly (with custom main class),"container = new Swarm(); // fractions being added here also




    container.start();




    container.deploy(...);






 
 container.stop();
private static org.wildfly.swarm.Swarm container
container = new Swarm(); // fractions being added here also
container.start();
container.deploy(...);
container.stop();
We now have the problem that stopping such a Swarm service in version 2016.11.0 does not properly shutdown the Swarm container (or better the underlying `Server`).
I did a debug session and found out that there remains one non-daemon thread blocking the JVM shutdown.
With version 2016.10.0 everything works fine.
The shutdown is clean and fast.
An example project can be found at https://github.com/seelenvirtuose/de.mwa.testing.wfs.
But I also have attached it as a zip.
de.mwa.testing.wfs-master.zip
Procrun can be downloaded at http://mirror.serversupportforum.de/apache//commons/daemon/binaries/windows/commons-daemon-1.0.15-bin-windows.zip
Steps to reproduce:
Tab Logging
Log path: <path-to-the-service-directory>\logs
Redirect Stdout: auto
Redirect Stderror: auto
Tab Java
Java Virtual Machine: Path to the ""jvm.dll"" of a JRE 8 (usually <path-to-jdk>\jre\bin\server\jvm.dll).Java Classpath: Full path to the uber-jar.Java Options: -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=7777 (to enable remote debugging).
Tab Startup
Class: org.wildfly.swarm.bootstrap.Main
Method: main
Arguments: start
Mode: jvm
Tab Shutdown
Class: org.wildfly.swarm.bootstrap.Main
Method: main
Arguments: stop
Mode:jvm
After a succesful start you can ""GET http://localhost:8080/hello"", which should result in a ""Hello World"" response.
6) The service has many threads running.
See first attached screenshot.
Windows will hang in that stopping attempt and spit out a failure message after some time.
The process is still running afterwards.
The log file shows some output that indeed a shutdown is initalized.
The GET does not work anymore.
8) The service still has many threads (especially non-daemon threads).
See second attached screenshot.
Note, that I have other services, which show only two non-deamon threads after a shutdown attempt.
9) Killing the task ""testing-wfs.exe"" is the only way to stop the process completely.
Switching the Wildfly Swarm version to 2016.10.0 (in the POM of ""swarm"" module) makes it work great.
Starting and stopping run both smoothly.",org.wildfly.swarm.container.runtime.ServerBootstrapImpl
METHOD,derby-10.9.1.0,DERBY-5424,2011-09-20T14:24:29.000-05:00,On z/OS testConnectWrongSubprotocolWithSystemProperty(org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest)junit.framework.Asserti ailedError,"testConnectWrongSubprotocolWithSystemProperty(org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest) 
    
  
  testConnectWrongSubprotoctestolWithoutSystemProperty(org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest)   
  
 
 String ijResult = runIjScript(ijScript, useSystemProperties);       
                assertTrue(ijResult.indexOf(""08001"") > -1);
With the release candidate  10.8.2.1 - (1170221) I saw the following two failures on z/OS in testConnectWrongSubprotoctestolWithoutSystemProperty
There were 2 failures:
1 testConnectWrongSubprotocolWithSystemProperty(org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest)junit.framework.Asserti
onFailedError
at org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest.checkConnectWrongSubprotocol(ConnectWrongSubprotocolTest.java
:82)
at org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest.testConnectWrongSubprotocolWithSystemProperty(ConnectWrongSub
protocolTest.java:68)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:60)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:37)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:113)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:16)
2 testConnectWrongSubprotoctestolWithoutSystemProperty(org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest)junit.framework.
AssertionFailedError
at org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest.checkConnectWrongSubprotocol(ConnectWrongSubprotocolTest.java
:82)
at org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest.testConnectWrongSubprotoctestolWithoutSystemProperty(ConnectW
rongSubprotocolTest.java:76)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:60)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:37)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:113)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:16)
FAILURES!!!
Tests run: 13984,  Failures: 2,  Errors: 0
The test is newly converted with DERBY-5084 so not likely a regression, but probably more likely an encoding issue related to this test:
       String ijResult = runIjScript(ijScript, useSystemProperties);       
                assertTrue(ijResult.indexOf(""08001"") > -1);","org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest:runIjScript(String, boolean)"
METHOD,derby-10.9.1.0,DERBY-5663,2012-03-17T23:45:11.000-05:00,Getting NPE when trying to set derby.language.logStatementText property to true inside a junit suite.,"patch(DERBY5663_patch1.txt)
Derby has a large data suite which runs LobLimitsTest with small data size, large data size and with embedded and network server configurations.
The large data suite is run as follows
time java  -Dderby.tests.trace=true -Dderby.infolog.append=true junit.textui.TestRunner org.apache.derbyTesting.functionTests.tests.largedata.
_Suite > runall.out 2>&1
I made a simple change to the suite to log statement text as shown in the attached patch(DERBY5663_patch1.
txt).
This causes the large data suite to run into NPE (NPE can be seen in runall.out) as shown below.
Not sure what I am doing wrong while trying to set the property, which results in NPE.
.
(emb)largedata.Derby5624Test.testDERBY_5624 used 411473 ms .
(emb)largedata.LobLimitsTest.test_01_Blob used 1555 ms .
(emb)largedata.LobLimitsTest.test_02_BlobNegative used 42 ms .
(emb)largedata.LobLimitsTest.test_03_Clob1 used 1436 ms .
(emb)largedata.LobLimitsTest.test_04_Clob2 used 1707 ms .
(emb)largedata.LobLimitsTest.test_05_ClobNegative used 967 ms E.
(emb)largedata.LobLimitsTest.test_01_Blob used 2929139 ms .
(emb)largedata.LobLimitsTest.test_02_BlobNegative used 154 ms .
(emb)largedata.LobLimitsTest.test_03_Clob1 used 2854121 ms .
(emb)largedata.LobLimitsTest.test_04_Clob2 used 656137 ms .
(emb)largedata.LobLimitsTest.test_05_ClobNegative used 331288 ms EF
Time: 7,589.168
There were 2 errors:
1 LobLimitsTestjava.lang.NullPointerException
at org.apache.derbyTesting.junit.SystemPropertyTestSetup.setProperties(SystemPropertyTestSetup.java:116)
at org.apache.derbyTesting.junit.SystemPropertyTestSetup.setUp(SystemPropertyTestSetup.java:87)
at junit.extensions.TestSetup$1.protect(TestSetup.java:18)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
2 LobLimitsTestjava.sql.SQLNonTransientConnectionException: DERBY SQL error: SQLCODE: -1, SQLSTATE: 08006, SQLERRMC: org.apache.derby.jdbc.EmbeddedDriver is not registered with the JDBC driver manager
at org.apache.derby.client.am.SQLExceptionFactory40.getSQLException(SQLExceptionFactory40.java:71)
at org.apache.derby.client.am.SqlException.getSQLException(SqlException.java:364)
at org.apache.derby.jdbc.ClientDriver.connect(ClientDriver.java:166)
at java.sql.DriverManager.getConnection(DriverManager.java:322)
at java.sql.DriverManager.getConnection(DriverManager.java:297)
at org.apache.derbyTesting.junit.DriverManagerConnector.openConnection(DriverManagerConnector.java:100)
at org.apache.derbyTesting.junit.DriverManagerConnector.openConnection(DriverManagerConnector.java:67)
at org.apache.derbyTesting.junit.DriverManagerConnector.openConnection(DriverManagerConnector.java:43)
at org.apache.derbyTesting.junit.TestConfiguration.openDefaultConnection(TestConfiguration.java:1633)
at org.apache.derbyTesting.junit.BaseJDBCTestSetup.getConnection(BaseJDBCTestSetup.java:72)
at org.apache.derbyTesting.junit.CleanDatabaseTestSetup.setUp(CleanDatabaseTestSetup.java:104)
at junit.extensions.TestSetup$1.protect(TestSetup.java:18)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
Caused by: org.apache.derby.client.am.SqlException: DERBY SQL error: SQLCODE: -1, SQLSTATE: 08006, SQLERRMC: org.apache.derby.jdbc.EmbeddedDriver is not registered with the JDBC driver manager
at org.apache.derby.client.am.Connection.completeSqlca(Connection.java:2125)
at org.apache.derby.client.net.NetConnectionReply.parseRdbAccessFailed(NetConnectionReply.java:538)
at org.apache.derby.client.net.NetConnectionReply.parseAccessRdbError(NetConnectionReply.java:431)
at org.apache.derby.client.net.NetConnectionReply.parseACCRDBreply(NetConnectionReply.java:294)
at org.apache.derby.client.net.NetConnectionReply.readAccessDatabase(NetConnectionReply.java:121)
at org.apache.derby.client.net.NetConnection.readSecurityCheckAndAccessRdb(NetConnection.java:826)
at org.apache.derby.client.net.NetConnection.flowSecurityCheckAndAccessRdb(NetConnection.java:762)
at org.apache.derby.client.net.NetConnection.flowUSRIDPWDconnect(NetConnection.java:591)
at org.apache.derby.client.net.NetConnection.flowConnect(NetConnection.java:406)
at org.apache.derby.client.net.NetConnection.<init>(NetConnection.java:220)
at org.apache.derby.client.net.NetConnection40.<init>(NetConnection40.java:74)
at org.apache.derby.client.net.ClientJDBCObjectFactoryImpl40.newNetConnection(ClientJDBCObjectFactoryImpl40.java:269)
at org.apache.derby.jdbc.ClientDriver.connect(ClientDriver.java:157)
... 43 more
There was 1 failure:
1 LobLimitsTestjunit.framework.ComparisonFailure: Engine shutdown expected:<XJ015> but was:<08001>
at org.apache.derbyTesting.junit.BaseJDBCTestCase.assertSQLState(BaseJDBCTestCase.java:790)
at org.apache.derbyTesting.junit.TestConfiguration.shutdownEngine(TestConfiguration.java:1751)
at org.apache.derbyTesting.junit.SystemPropertyTestSetup.tearDown(SystemPropertyTestSetup.java:108)
at junit.extensions.TestSetup$1.protect(TestSetup.java:20)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
Caused by: java.sql.SQLException: No suitable driver
at java.sql.DriverManager.getConnection(DriverManager.java:330)
at java.sql.DriverManager.getConnection(DriverManager.java:297)
at org.apache.derbyTesting.junit.DriverManagerConnector.getConnectionByAttributes(DriverManagerConnector.java:163)
at org.apache.derbyTesting.junit.DriverManagerConnector.shutEngine(DriverManagerConnector.java:140)
at org.apache.derbyTesting.junit.TestConfiguration.shutdownEngine(TestConfiguration.java:1748)
... 31 more
FAILURES!!!
Tests run: 11,  Failures: 1,  Errors: 2","org.apache.derbyTesting.functionTests.tests.largedata.LobLimitsTest:baseSuite(int, int)
org.apache.derbyTesting.junit.SystemPropertyTestSetup:setProperties(Properties)"
METHOD,derby-10.9.1.0,DERBY-5816,2012-06-13T15:12:35.000-05:00,store.ServicePropertiesFileTest fails on z/OS,"testSevicePropertiesFileWithBackup(org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest) 
 
   
  
  
  
  testSevicePropertiesFileCorruptedWithBackup(org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTe
st)   {```
@    @    k@   }
store.ServicePropertiesFileTest fails on z/OS with two failures below.
Looks like likely test encoding issue
1 testSevicePropertiesFileWithBackup(org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest)junit.
framework.AssertionFailedError
at org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest.assertEOFToken(ServicePropertiesF
ileTest.java:275)
at org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest.testSevicePropertiesFileWithBacku
p(ServicePropertiesFileTest.java:178)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:88)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:113)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBareOverridable(BaseJDBCTestCase.java:424)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBare(BaseJDBCTestCase.java:441)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
2 testSevicePropertiesFileCorruptedWithBackup(org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTe
st)junit.framework.ComparisonFailure: expected:<[#--- last line, don't put anything after this line ---]> but was:<[{```
@    @    k@   } @   @        @     @    @    @```§]>
at org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest.removeEOFToken(ServicePropertiesF
ileTest.java:301)
at org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest.testSevicePropertiesFileCorrupted
WithBackup(ServicePropertiesFileTest.java:199)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:88)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:113)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBareOverridable(BaseJDBCTestCase.java:424)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBare(BaseJDBCTestCase.java:441)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
FAILURES!!!
Tests run: 290,  Failures: 2,  Errors: 0","org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest:grepForToken(String, File)
org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest:assertEOFToken(File)
org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest:removeEOFToken(File)"
METHOD,derby-10.9.1.0,DERBY-5912,2012-08-28T19:43:59.000-05:00,testIsValidImplemented fails for NetworkServer in some slow running machines/configurations,"isValid()  
 testIsValidImplemented(org.apache.derbyTesting.functionTests.tests.jdbc4.ConnectionTest) 
 
  assertTrue(getConnection().isValid(1));
The following test has been seen to fail as below  in some runs where the machine is under heavy load  and slow running options are specified and the isValid() call takes more than a second to return.
1) testIsValidImplemented(org.apache.derbyTesting.functionTests.tests.jdbc4.ConnectionTest)junit.framework.AssertionFailedError
at org.apache.derbyTesting.functionTests.tests.jdbc4.ConnectionTest.testIsValidImplemented(ConnectionTest.java:168)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:60)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:37)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:113)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
The test does:
// Test with a 1 second timeout assertTrue(getConnection().
isValid(1));
assuming it will return in one second.
For embedded the int parameter is not implemented so indeed this always passes.
For the Network implementation in NetConnection40.java we actually do timeout and perform a query as part of the implementation so might indeed return false.",org.apache.derbyTesting.functionTests.tests.jdbc4.ConnectionTest:testIsValidImplemented()
METHOD,derby-10.9.1.0,DERBY-5951,2012-10-16T10:33:53.000-05:00,Missing method exception raised when using Clobs with territory based collation,"db;create=true; 
   varchar( 32672 )  
  
  
  
 clobTable( a )   makeClob( 'a' )  
   varchar( 32672 )  
  
  
 clobTable( a )   makeClob( 'a' )  
     Ljava/sql/Clob;Lorg/apache/derby/iapi/types/StringDataValue;   
   Ljava/sql/Clob;Lorg/apache/derby/iapi/types/StringDataValue;     
  
 clobTable( a )   makeClob( 'a' )
When using territory-based collation with Clobs, Derby raises an error trying to invoke a missing method.
connect 'jdbc:derby:memory:db;create=true;collation=TERRITORY_BASED';
create function makeClob( contents varchar( 32672 ) ) returns clob
language java parameter style java no sql deterministic
external name 'org.apache.derbyTesting.functionTests.tests.lang.UserDefinedAggregatesTest.makeClob';
create table clobTable( a clob );
-- fails with a java.lang.NoSuchMethodError exception
insert into clobTable( a ) values ( makeClob( 'a' ) );
connect 'jdbc:derby:memory:db1;create=true';
create function makeClob( contents varchar( 32672 ) ) returns clob
language java parameter style java no sql deterministic
external name 'org.apache.derbyTesting.functionTests.tests.lang.UserDefinedAggregatesTest.makeClob';
create table clobTable( a clob );
-- succeeds
insert into clobTable( a ) values ( makeClob( 'a' ) );
Here is the error:
ERROR 38000: The exception 'java.lang.NoSuchMethodError: org.apache.derby.iapi.types.DataValueFactory.getClobDataValue(Ljava/sql/Clob;Lorg/apache/derby/iapi/types/StringDataValue;I)Lorg/apache/derby/iapi/types/StringDataValue;' was thrown while evaluating an expression.
ERROR XJ001: Java exception: 'org.apache.derby.iapi.types.DataValueFactory.getClobDataValue(Ljava/sql/Clob;Lorg/apache/derby/iapi/types/StringDataValue;I)Lorg/apache/derby/iapi/types/StringDataValue;: java.lang.NoSuchMethodError'.
...and here is the stack trace:
Tue Oct 16 08:27:23 PDT 2012 Thread[main,5,main] (XID = 172), (SESSIONID = 1), (DATABASE = memory:db), (DRDAID = null), Failed Statement is: -- fails with a java.lang.NoSuchMethodError exception
insert into clobTable( a ) values ( makeClob( 'a' ) )
ERROR 38000: The exception 'java.lang.NoSuchMethodError: org.apache.derby.iapi.types.DataValueFactory.getClobDataValue(Ljava/sql/Clob;Lorg/apache/derby/iapi/types/StringDataValue;I)Lorg/apache/derby/iapi/types/StringDataValue;' was thrown while evaluating an expression.
at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
at org.apache.derby.iapi.error.StandardException.unexpectedUserException(Unknown Source)
at org.apache.derby.impl.services.reflect.DirectCall.invoke(Unknown Source)
at org.apache.derby.impl.sql.execute.RowResultSet.getNextRowCore(Unknown Source)
at org.apache.derby.impl.sql.execute.DMLWriteResultSet.getNextRowCore(Unknown Source)
at org.apache.derby.impl.sql.execute.InsertResultSet.open(Unknown Source)
at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)
at org.apache.derby.impl.tools.ij.ij.executeImmediate(Unknown Source)
at org.apache.derby.impl.tools.ij.utilMain.doCatch(Unknown Source)
at org.apache.derby.impl.tools.ij.utilMain.runScriptGuts(Unknown Source)
at org.apache.derby.impl.tools.ij.utilMain.go(Unknown Source)
at org.apache.derby.impl.tools.ij.Main.go(Unknown Source)
at org.apache.derby.impl.tools.ij.Main.mainCore(Unknown Source)
at org.apache.derby.impl.tools.ij.Main.main(Unknown Source)
at org.apache.derby.tools.ij.main(Unknown Source)
Caused by: java.lang.NoSuchMethodError: org.apache.derby.iapi.types.DataValueFactory.getClobDataValue(Ljava/sql/Clob;Lorg/apache/derby/iapi/types/StringDataValue;I)Lorg/apache/derby/iapi/types/StringDataValue;
at org.apache.derby.exe.ace50d80a4x013ax6a2fxb54bx00000467ed600.e0(Unknown Source)
... 17 more",org.apache.derby.iapi.types.CollatorSQLClob:getNewNull()
METHOD,derby-10.9.1.0,DERBY-6073,2013-02-15T10:11:27.000-06:00,Test ordering instability in StatementPoolingTest,"StatementPoolingTest.testPoolingEnabledByCheckingImplementationDetails()   testCacheOverflow()  If testPoolingEnabledByCheckingImplementationDetails()    testPoolingEnabledByCheckingImplementationDetails()
StatementPoolingTest.testPoolingEnabledByCheckingImplementationDetails() assumes that the client-side statement cache will have been primed by a previous test case, testCacheOverflow().
On Java 7 and Java 8 the test order is not deterministic.
If testPoolingEnabledByCheckingImplementationDetails() is the first test case to run, then it fails with this error:
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest.assertClassName(StatementPoolingTest.java:147)
at org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest.testPoolingEnabledByCheckingImplementationDetails(StatementPoolingTest.java:89)
I will attach a patch which forces testPoolingEnabledByCheckingImplementationDetails() to be first in the test order.
With this patch, StatementPoolingTest fails for me on Java 7 when run on the 10.9 branch as well as on trunk.","org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testIsolationLevelIsResetExplicitCloseQuery()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testPoolingEnabledByCheckingImplementationDetails()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testDeleteReferringTableWhenInCache()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testGetStatementCallable()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testGetStatementPrepared()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testIsolationLevelIsResetExplicitCloseNoQuery()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testPrepareCallPath()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testCachingLogicalConnectionCloseLeavesPhysicalStatementsOpen()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testHoldabilityIsResetNoExplicitClose()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testCacheOverflow()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testPrepareCallWithNoCallPath()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:suite()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testIsolationLevelIsResetNoExplicitCloseNoQuery()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testTemporaryTablesAreDeletedInNewLogicalConnection()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testClosingPSClosesRS()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testIsolationLevelIsResetNoExplicitCloseQuery()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testPrepareStatementPath()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testDeleteReferringTableWhenOpen()
org.apache.derbyTesting.functionTests.tests.jdbcapi.StatementPoolingTest:testHoldabilityIsResetExplicitClose()"
METHOD,derby-10.9.1.0,DERBY-6089,2013-02-21T22:39:19.000-06:00,CallableStatement#registerOutParameter on client lacks check of legal types.,"registerOutParameter(int parameterIndex,
int sqlType, String typeName)
Cf the attached negative test in a patch to PreparedStatement42.
In JDBC 4.2, the Javadoc for registerOutParameter(int parameterIndex, int sqlType, String typeName) reads:
:
@exception SQLFeatureNotSupportedException if sqlType is a ARRAY,
BLOB, CLOB, DATALINK, JAVA_OBJECT, NCHAR, NCLOB, NVARCHAR,
LONGNVARCHAR, REF, ROWID, SQLXML or STRUCT data type and the JDBC driver does not support this data type
:
For the new overloads, for embedded this is checked inside Util42#getTypeAsInt.
The similar client method, Utils42#getTypeAsInt does not do this checking.","org.apache.derby.impl.jdbc.EmbedPreparedStatement:setNull(int, int)
org.apache.derby.client.am.Agent:accumulateDeferredException(SqlException)
org.apache.derby.client.am.PreparedStatement:checkScaleForINOUTDecimal(int, int)
org.apache.derby.client.am.CallableStatement:registerOutParameterX(int, int, int)
org.apache.derby.impl.jdbc.ConnectionChild:newSQLException(String)
org.apache.derby.client.am.PreparedStatement:checkForSupportedDataType(int)
org.apache.derby.impl.sql.GenericParameterValueSet:registerOutParameter(int, int, int)"
METHOD,derby-10.9.1.0,DERBY-6092,2013-02-25T18:48:14.000-06:00,testPositionAgressive(org.apache.derbyTesting.functionTests.tests.jdbcapi.BlobClob4BlobTest)j fails with : 'The handle is invalid.: java.io.IOException'.,"testPositionAgressive(org.apache.derbyTesting.functionTests.tests.jdbcapi.BlobClob4BlobTest)
There was 1 error:
http://people.apache.org/~myrnavl/derby_test_results/main/windows/testlog/ibm15/1449432-suites.All_diff.txt
1 testPositionAgressive(org.apache.derbyTesting.functionTests.tests.jdbcapi.BlobClob4BlobTest)java.sql.SQLException: Java exception: 'The handle is invalid.: java.io.IOException'.
at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)
at org.apache.derby.impl.jdbc.Util.javaException(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedConnection.clearLOBMapping(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedConnection.commit(Unknown Source)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.commit(BaseJDBCTestCase.java:393)
at org.apache.derbyTesting.functionTests.tests.jdbcapi.BlobClob4BlobTest.testPositionAgressive(BlobClob4BlobTest.java:1070)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:79)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:117)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBareOverridable(BaseJDBCTestCase.java:424)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBare(BaseJDBCTestCase.java:441)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
Caused by: java.io.IOException: The handle is invalid.
at java.io.RandomAccessFile.close0(Native Method)
at java.io.RandomAccessFile.close(RandomAccessFile.java:573)
at org.apache.derby.impl.jdbc.LOBFile.close(Unknown Source)
at org.apache.derby.impl.jdbc.EncryptedLOBFile.close(Unknown Source)
... 53 more","org.apache.derbyTesting.functionTests.tests.jdbcapi.BlobClob4BlobTest:checkClob8(Statement, Clob)"
FILE,IO,IO-180,2008-09-08T18:03:20.000-05:00,LineIterator documentation,"LineIterator it = FileUtils.lineIterator(file, ""UTF-8"");
   try {
     while (it.hasNext()) 
{

       String line = it.nextLine();

       /// do something with line

     }
   } finally 
{

     LineIterator.closeQuietly(iterator);

   }
In the Javadoc for rg.apache.commons.io.LineIterator (in Commons IO 1.4), this code snippet is incorrect:  the last instance of ""iterator"" should be
LineIterator it = FileUtils.lineIterator(file, ""UTF-8"");
try { while (it.hasNext())
{
String line = it.nextLine();
/// do something with line
}
} finally
{
LineIterator.closeQuietly(iterator);
}",org.apache.commons.io.LineIterator
FILE,IO,IO-481,2015-06-19T18:19:48.000-05:00,org.apache.commons.io.FileUtils#waitFor waits too long,"public void testRealWallTime() 
{

        long start = System.currentTimeMillis();

        FileUtils.waitFor(new File(""""), 2);

        System.out.println(""elapsed = "" + (System.currentTimeMillis() - start));

    }
The timing algorithm is basically broken, since Thread.sleep is imprecise.
There is also a counter error in the looping code.
The following testcase will never run in less than 4 seconds on my machine public void testRealWallTime()
{
long start = System.currentTimeMillis();
FileUtils.waitFor(new File(""""), 2);
System.out.println(""elapsed = "" + (System.currentTimeMillis() - start));
}",org.apache.commons.io.FileUtils
FILE,eclipse-3.1,100137,2005-06-15T04:29:00.000-05:00,Variables view: code assist does not work in details pane,"public class A {
	String dog1 = ""Max"", dog2 = ""Bailey"", dog3 = ""Harriet"";
	public static void main(String[] args) {
		new A().foo();
	}
	
	void foo() {
		String p= """";
	}
}
3.1 RC2 and N20050615-0010
public class A {
String dog1 = ""Max"", dog2 = ""Bailey"", dog3 = ""Harriet"";
public static void main(String[] args) { new A().
foo();
} void foo() {
String p= """";
}
}
==> code runs, debugger shows correct values but:
- source is not found
- code assist does not work in Variables view's detail pane",org.eclipse.jdt.launching.StandardClasspathProvider
FILE,eclipse-3.1,100807,2005-06-20T09:30:00.000-05:00,Source not found,"JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile) 
  
 
 JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile) 
  
 
 JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile) 
  
 
 JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile) 
  
 
 JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile) 
  
 
  
 JavaModelManager.getZipFile(IPath) 
 
   
 JavaModelManager.closeZipFile(ZipFile) 
    
 
 JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile) 
  
 
 JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile) 
  
 
 JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile)
(from bug 99526)
I tried 3.1RC3 and the fix worked but it did result in a new failure.
The source files in the project are not being found.
I turned on the debug flags via .
options file and only the following archives were searched for the source file when a breakpoint was reached.
[reading    java/io/PrintStream.class]
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/rt.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/rt.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/rt.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/sunrsasign.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/sunrsasign.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/sunrsasign.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/jsse.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/jsse.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/jsse.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/jce.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/jce.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/jce.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/charsets.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/charsets.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/charsets.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/ext/sunjce_provider.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/sunjce_provider.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/sunjce_provider.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/ext/dnsns.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/dnsns.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/dnsns.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/ext/ldapsec.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/ldapsec.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/ldapsec.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/ext/localedata.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/localedata.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/localedata.jar",org.eclipse.debug.internal.core.sourcelookup.containers.ContainerSourceContainer
FILE,eclipse-3.1,102427,2005-06-30T20:45:00.000-05:00,Cannot inspect/display static import methods,"public class Helper {
    public static int getValue() {...}
}
  
import static Helper.*;

public class Doer {
    public void doit() {
        int i = getValue();
    }
}
 
 getValue() 
 getValue()
---
public class Helper {
public static int getValue() {...}
}
---
import static Helper.
*;
public class Doer {
public void doit() {
int i = getValue();
}
}
---
When debugging, if you select 'getValue()' in the method 'doit' and execute
display (or inspect) you get an error indicating that the method 'getValue()' is
not undefined for type Doer.",org.eclipse.jdt.internal.debug.eval.ast.engine.SourceBasedSourceGenerator
FILE,eclipse-3.1,102778,2005-07-05T15:40:00.000-05:00,Scrapbook page doesn't work with enhanced for statement,"int[] tab = new int[] {1, 2, 3, 4, 5, 6, 7, 8, 9 };
int sum = 0;
for (int i : tab) {
	sum += i;
}
int[] tab = new int[] {1, 2, 3, 4, 5, 6, 7, 8, 9 };
int sum = 0;
for (int i : tab) { sum += i;
} sum
You get an error about syntax error.",org.eclipse.jdt.internal.eval.CodeSnippetParser
FILE,eclipse-3.1,103379,2005-07-11T15:37:00.000-05:00,[MPE] [EditorMgmt] An editor instance is being leaked each time an editor is open and closed,"dispose()
Driver: eclipse-SDK-3.1-win32 with eclipse-test-framework-3.1
Every we open and close an editor.
That editor instance is being leaked.
We have a testcase that can demostrate the problem.
The testcase is really simple.
What's interesting is that the editor, upon open, will allocate a 200000 size
String array as a private field.
So this String array can be GC-ed if the editor itself can be GC-ed.
If you run this testcase with -Xmx256M, you will run out of memory.
However, if you explicitly set the String array to null in the dispose() method of the editor, then the same testcase will not run out of memory.
This leads us to believe that the editor instance is being leaked.",org.eclipse.ui.operations.OperationHistoryActionHandler
FILE,eclipse-3.1,103918,2005-07-14T17:25:00.000-05:00,100% CPU load while creating dynamic proxy in rich client app,"public void start(BundleContext context) throws Exception {
  super.start(context);
  XmlBeanFactory bf = new XmlBeanFactory(
     new ClassPathResource(""/bug/beans.xml""));
  bf.getBean(""hang"");
}

  bf.getBean(""hang"")  
 bf.getBean()
I've tried to integrate my ecplipse-rcp application with springframework.
I've
noticed that when spring tries to instantiate any dynamic proxy RCP falls into
infinit loop, CPU gets 100% load and the application needs to be killed.
public void start(BundleContext context) throws Exception {
  super.start(context);
  XmlBeanFactory bf = new XmlBeanFactory(
     new ClassPathResource(""/bug/beans.
xml""));
  bf.getBean(""hang"");
}
When bf.getBean(""hang"") is executed the application hangs.
The same code
executed outside eclipse-rcp works well and without problem.
bf.getBean() tries to create a proxy class for given interface with standard JDK
dynamic proxy facility (no cglib or any other byte code manipulation takes place).
I'm not sure but I think that this may be caused by classloaders.
My environment: 
  Eclipse Version: 3.1.0
  Build id: I20050627-1435
  OS: Linux 2.6.12
  Java: Sun jdk1.5.0_04
I attach a sample project which causes the 100% CPU load and rich client hang.",org.eclipse.core.runtime.internal.adaptor.ContextFinder
FILE,eclipse-3.1,106492,2005-08-09T11:01:00.000-05:00,NPE on console during debug session,"name.equals(""IResourceTest.testDelete"")  
  
  
          
       
  
       
  
       
   testDelete()  
  
   
    
 
  
   
  
   
    
 
   runTest()  
   runBare()  
   protect()
Build: I20050808-2000
While debugging, I noticed the attached stack trace on my Java console (not in the log file).
There was nothing in the log file.
I see from the stack that it occurred during evaluation of a conditional breakpoint.
name.equals(""IResourceTest.testDelete"") && count==83
After this error occurred, the debug process hung, and ""Terminate"" and
""Terminate All"" had no effect.
I was still able to ""Suspend"" the process, and it resulted in a debug view showing:
org.eclipse.core.launcher.Main at localhost:1250
Thread [main] (Suspended (breakpoint at line 69 in TestPerformer))
IResourceTest$6(TestPerformer).
performTestRecursiveLoop(Object[][], Object[], int) line: 69
<unknown receiving type>(TestPerformer).
performTestRecursiveLoop(Object[][],
Object[], int) line: 111
<unknown receiving type>(TestPerformer).
performTestRecursiveLoop(Object[][],
Object[], int) line: 111
<unknown receiving type>(TestPerformer).
performTest(Object[][]) line: 55
<unknown receiving type>(<unknown declaring type>).
testDelete() <unknown line number>
<unknown receiving type>(<unknown declaring type>).
invoke0(Method, Object,
Object[]) <unknown line number>
<unknown receiving type>(<unknown declaring type>).
invoke(Object, Object[])
<unknown line number>
<unknown receiving type>(<unknown declaring type>).
invoke(Method, Object,
Object[]) <unknown line number>
<unknown receiving type>(<unknown declaring type>).
invoke(Method, Object,
Object[]) <unknown line number>
<unknown receiving type>(<unknown declaring type>).
invoke(Object, Object[])
<unknown line number>
<unknown receiving type>(<unknown declaring type>).
runTest() <unknown line number>
<unknown receiving type>(<unknown declaring type>).
runBare() <unknown line number>
<unknown receiving type>(<unknown declaring type>).
protect() <unknown line number>
... etc ...
I had to shutdown Eclipse to remove this from the debug view.",org.eclipse.jdt.internal.debug.eval.ast.engine.ASTEvaluationEngine
FILE,eclipse-3.1,107031,2005-08-15T11:21:00.000-05:00,[content assist] SWTException in code assist,"SWTError (Widget disposed)
3 2M1-gtk
The fix for bug 31427 can cause an SWTError (Widget disposed) under gtk.
The
error is not noticable in the UI, but I found the following stack trace below in
the log (no steps).
Already fixed in HEAD, but since the fix went into the 3.1.1 stream, we should
consider backporting the trivial fix as well.
Will attach a patch.
org.eclipse.swt.SWTException: Widget is disposed
at org.eclipse.swt.SWT.error(SWT.java:3240)
at org.eclipse.swt.SWT.error(SWT.java:3163)
at org.eclipse.swt.SWT.error(SWT.java:3134)
at org.eclipse.swt.widgets.Widget.error(Widget.java:424)
at org.eclipse.swt.widgets.Widget.checkWidget(Widget.java:355)
at org.eclipse.swt.widgets.Table.getSelectionIndex(Table.java:1369)
at
org.eclipse.jface.text.contentassist.CompletionProposalPopup.getSelectedProposal(CompletionProposalPopup.java:437)
at
org.eclipse.jface.text.contentassist.CompletionProposalPopup.verifyKey(CompletionProposalPopup.java:841)
at
org.eclipse.jface.text.contentassist.ContentAssistant$InternalListener.verifyKey(ContentAssistant.java:630)
at
org.eclipse.jface.text.TextViewer$VerifyKeyListenersManager.verifyKey(TextViewer.java:414)
at
org.eclipse.swt.custom.StyledTextListener.handleEvent(StyledTextListener.java:55)
at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:66)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1036)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1060)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1045)
at org.eclipse.swt.widgets.Widget.notifyListeners(Widget.java:912)
at org.eclipse.swt.custom.StyledText.handleKeyDown(StyledText.java:5122)
at org.eclipse.swt.custom.StyledText$7.handleEvent(StyledText.java:4857)
at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:66)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1036)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1060)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1045)
at org.eclipse.swt.widgets.Widget.sendIMKeyEvent(Widget.java:1122)
at org.eclipse.swt.widgets.Control.gtk_commit(Control.java:1851)
at org.eclipse.swt.widgets.Widget.windowProc(Widget.java:1370)
at org.eclipse.swt.widgets.Display.windowProc(Display.java:3438)
at org.eclipse.swt.internal.gtk.OS._gtk_im_context_filter_keypress(Native Method)
at org.eclipse.swt.internal.gtk.OS.gtk_im_context_filter_keypress(OS.java:4345)
at org.eclipse.swt.widgets.Control.filterKey(Control.java:1428)
at org.eclipse.swt.widgets.Control.gtk_key_press_event(Control.java:1957)
at org.eclipse.swt.widgets.Composite.gtk_key_press_event(Composite.java:564)
at org.eclipse.swt.widgets.Widget.windowProc(Widget.java:1380)
at org.eclipse.swt.widgets.Display.windowProc(Display.java:3438)
at org.eclipse.swt.internal.gtk.OS._gtk_main_do_event(Native Method)
at org.eclipse.swt.internal.gtk.OS.gtk_main_do_event(OS.java:4795)
at org.eclipse.swt.widgets.Display.eventProc(Display.java:1063)
at org.eclipse.swt.internal.gtk.OS._g_main_context_iteration(Native Method)
at org.eclipse.swt.internal.gtk.OS.g_main_context_iteration(OS.java:1176)
at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2566)
at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:1734)
at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1698)
at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:367)
at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:143)
at org.eclipse.ui.internal.ide.IDEApplication.run(IDEApplication.java:103)
at
org.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:226)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:376)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:163)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:585)
at org.eclipse.core.launcher.Main.invokeFramework(Main.java:338)
at org.eclipse.core.launcher.Main.basicRun(Main.java:282)
at org.eclipse.core.launcher.Main.run(Main.java:977)
at org.eclipse.core.launcher.Main.main(Main.java:952)",org.eclipse.jface.text.contentassist.CompletionProposalPopup
FILE,eclipse-3.1,108466,2005-08-31T09:39:00.000-05:00,Dups from (Eclipse)ClassLoader.getResources(String),"EclipseClassLoader.getResources(String)  
   
 getClass()  getClassLoader()  getResources(""file.txt"")
When running runtime workspace, EclipseClassLoader.getResources(String) returns duplicate results for files found in plugin jarfiles (i.e. jar files listed in manifest.mf Bundle-ClassPath: entry or plugin.xml <library/> element).
Steps to reproduce
getClassLoader().
getResources(""file.txt"")
5. start eclipse application, see that getResources returns two entries
Apparently, eclipse adds the jar on plugin's classpath twice -- as a regular
OSGi classpath entry and as a development entry.",org.eclipse.pde.internal.core.ClasspathHelper
FILE,eclipse-3.1,110837,2005-09-27T13:16:00.000-05:00,javax.crypto.KeyAgreement.getInstance(String) throws exception in IDE,"KeyAgreement.getInstance(""DiffieHellman"")  
  
 
import java.security.NoSuchAlgorithmException;
import javax.crypto.KeyAgreement;

public class KeyAgreementProblem
{
    public static void main(String[] args) throws NoSuchAlgorithmException
    {
        KeyAgreement ka = KeyAgreement.getInstance(""DiffieHellman"");
        System.out.println(ka);
    }
}
 
 
  
  
 javax.crypto.KeyAgreement.getInstance(DashoA12275)
A call to KeyAgreement.getInstance(""DiffieHellman"") will throw a
NoSuchAlgorithmException if run from Eclipse but not if it's run directly from the command line.
(JDK 1.5.0_04 or 1.4.2_09)
--- import java.security.NoSuchAlgorithmException;
import javax.crypto.KeyAgreement;
public class KeyAgreementProblem
{ public static void main(String[] args) throws NoSuchAlgorithmException
{
KeyAgreement ka = KeyAgreement.getInstance(""DiffieHellman"");
System.out.println(ka);
}
}
---
Running from the command line goes like this (command line then output below):
C:\...\workspace\sandbox>java -classpath bin KeyAgreementProblem javax.crypto.KeyAgreement@141d683
---
Running in Eclipse with the same JDK and environment produces this exception:
Exception in thread ""main"" java.security.NoSuchAlgorithmException: Algorithm
DiffieHellman not available at javax.crypto.KeyAgreement.getInstance(DashoA12275)
at KeyAgreementProblem.main(KeyAgreementProblem.java:8)","org.eclipse.jdt.launching.AbstractJavaLaunchConfigurationDelegate
org.eclipse.jdt.internal.launching.JRERuntimeClasspathEntryResolver
org.eclipse.jdt.internal.launching.StandardVMType"
FILE,eclipse-3.1,113455,2005-10-22T11:32:00.000-05:00,[Markers] Some error markers do not appear,"problemView.getCurrentMarkers()
I20051018-0800, GTK+ 2.6.8, KDE 3.4.1, X.org 6.8.2, Linux 2.6.13
Even with all the code from HEAD, no errors showed up in my Problems view.
(ResourceMappingMarkersTest), and it had several errors in it.
Now one error appears in the
Problems view: ""ModelProvider cannot be resolved"" in CompositeResourceMapping.
The one error that was there previously then disappeared.
I had a hard time deciding whether to make this ""blocker"" or ""major"".
The big problem, as I see it, is that this can lead to broken builds (as we've seen).
So I marked it as a blocker.","org.eclipse.ui.views.markers.internal.Util
org.eclipse.ui.views.markers.internal.MarkerView"
FILE,eclipse-3.1,115363,2005-11-07T13:28:00.000-06:00,"java.lang.VerifyError in org.eclipse.ui.workbench from HEAD, using N20051107","Ljava/lang/String;Ljava/lang/String;Lorg/eclipse/jface/action/IContributionManager;
N20051107, fresh workspace, all ui plug-ins and test plug-ins from HEAD.
Got this stack trace:
java.lang.VerifyError: (class: org/eclipse/ui/internal/PluginActionSetBuilder,
method: findInsertionPoint signature:
(Ljava/lang/String;Ljava/lang/String;Lorg/eclipse/jface/action/IContributionManager;Z)Lorg/eclipse/jface/action/IContributionItem;)
Illegal target of jump or bran [5
at
org.eclipse.ui.internal.ActionPresentation.setActionSets(ActionPresentation.java:184)
at
org.eclipse.ui.internal.WorkbenchWindow.updateActionSets(WorkbenchWindow.java:2552)
at org.eclipse.ui.internal.WorkbenchWindow$5.run(WorkbenchWindow.java:2374)
at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:69)
at org.eclipse.ui.internal.WorkbenchWindow.setActivePage(WorkbenchWindow.java:2337)
at org.eclipse.ui.internal.WorkbenchWindow.busyOpenPage(WorkbenchWindow.java:678)
at org.eclipse.ui.internal.Workbench.busyOpenWorkbenchWindow(Workbench.java:680)
at org.eclipse.ui.internal.Workbench.doOpenFirstTimeWindow(Workbench.java:1321)
at org.eclipse.ui.internal.Workbench.openFirstTimeWindow(Workbench.java:1227)
at
org.eclipse.ui.internal.WorkbenchConfigurer.openFirstTimeWindow(WorkbenchConfigurer.java:190)
at
org.eclipse.ui.application.WorkbenchAdvisor.openWindows(WorkbenchAdvisor.java:706)
at org.eclipse.ui.internal.Workbench.init(Workbench.java:1039)
at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1707)
at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:376)
at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:143)
at snip.intro.Application.run(Application.java:18)
at
org.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:226)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:376)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:165)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
at java.lang.reflect.Method.invoke(Unknown Source)
at org.eclipse.core.launcher.Main.invokeFramework(Main.java:338)
at org.eclipse.core.launcher.Main.basicRun(Main.java:282)
at org.eclipse.core.launcher.Main.run(Main.java:977)
at org.eclipse.core.launcher.Main.main(Main.java:952)",org.eclipse.jdt.internal.compiler.codegen.Label
FILE,eclipse-3.1,117890,2005-11-24T06:38:00.000-06:00,JavaElement.getURLContents(...) leaves file open,"JavaElement.getURLContents(...)   tearDownSuite()  
 URLConnection.getContentEncoding()   URLConnection.getContentEncoding()
I20051123
The AttachedJavadocTests sometimes fail because JavaElement.getURLContents(...) leaves a file open and the test cannot delete the project in the tearDownSuite() method because of that.
More specifcally URLConnection.getContentEncoding() opens a file stream on the doc.zip and never closes it.
So this looks like a bug in the implementation of URLConnection.getContentEncoding().","org.eclipse.jdt.internal.compiler.util.Util
org.eclipse.jdt.core.IJavaElement
org.eclipse.jdt.internal.core.JavaElement"
FILE,eclipse-3.1,133072,2006-03-23T16:58:00.000-06:00,"Cannot launch an ""Eclipse Application"" without the -ws argument","package Fred;

import javax.swing.JFrame;
import javax.swing.SwingUtilities;

import org.eclipse.core.runtime.IPlatformRunnable;

public class Main implements IPlatformRunnable {

       public Object run(Object args) throws Exception {
               SwingUtilities.invokeLater(new Runnable() {
                       public void run() {
                               new JFrame(""Fred"").setVisible(true);
                       }
               });
               synchronized(this)
               {
                       wait();
               }
               return IPlatformRunnable.EXIT_OK;
       }

}
When trying to launch an Eclipse Application that does NOT use SWT under OSX from 3.1 or 3.2M5, you get the following problems:
When running against 1.4.2_09, you get the dreaded ""2006-03-23
15:35:27.340 java[1053] Apple AWT Java VM was loaded on first thread
-- can't start AWT.""
The application then stops.
When running against 1.5.0_06 you get these messages on startup:
2006-03-23 15:29:59.468 java[1047] [Java CocoaComponent compatibility
mode]: Enabled
2006-03-23 15:29:59.468 java[1047] [Java CocoaComponent compatibility
mode]: Setting timeout for SWT to 0.100000
Under 1.5.0_06, the app appears to run, but there is no menu-bar,
dock-icon, or window that shows up.
Basically nothing happens, but
the event thread is running and you have to kill it.
Under 3.0 (i think) you used to be able to tell Eclipse not to force
any ""first-thread"" flags by not passing the -ws carbon flag to the
application.
However, it appears that we no longer have the ability to suppress that flag.
We hacked around this by removing the check for the ""-ws"" flag in the  org.eclipse.jdt.internal.launching.macosx.MacOSXVMInstall.java class and rebuilding that plugin.
But this is not a good all-around solution.
Better would be to be able to override and not pass the -ws flag at all if we wanted to per Launch configuration.
package Fred;
import javax.swing.JFrame;
import javax.swing.SwingUtilities;
import org.eclipse.core.runtime.IPlatformRunnable;
public class Main implements IPlatformRunnable {
public Object run(Object args) throws Exception {
               SwingUtilities.invokeLater(new Runnable() {
                       public void run() {
                               new JFrame(""Fred"").
setVisible(true);
                       }
               });
               synchronized(this)
               {
                       wait();
               }
               return IPlatformRunnable.EXIT_OK;
       }
}","org.eclipse.pde.internal.ui.IPDEUIConstants
org.eclipse.pde.internal.ui.launcher.LaunchAction"
FILE,eclipse-3.1,133292,2006-03-26T06:15:00.000-06:00,[compiler] Compiler accepts spurious semicolon in array initialiser,"{
    /* On the next line, the first semicolon is a syntax error. 
     * The error is not reported, and the program will run and print ""Fail"".
     * Without the semicolon, it prints ""foo"" as expected. */
    public static Baz.C a[] =  { new Baz.C(""foo"") ; } 
 public static void main(String args[]) {
	if (a == null)
	    System.out.println(""Fail"");
	else
	    System.out.println(a[0]);
    }
 
 class Baz {
    public static class C {
	String name;
	public C(String name) { this.name = name; }
	public String toString() { return name; }
    }
}
public class Foo {
/* On the next line, the first semicolon is a syntax error.
* The error is not reported, and the program will run and print ""Fail"".
* Without the semicolon, it prints ""foo"" as expected.
*/
public static Baz.C a[] =  { new Baz.C(""foo"") ; };
public static void main(String args[]) {
if (a == null)
System.out.println(""Fail"");
else
System.out.println(a[0]);
}
}
class Baz {
    public static class C {
	String name;
	public C(String name) { this.name = name; }
	public String toString() { return name; }
    }
}","org.eclipse.jdt.internal.compiler.parser.RecoveredField
org.eclipse.jdt.internal.compiler.parser.RecoveredLocalVariable"
FILE,eclipse-3.1,300054,2010-01-19T10:12:00.000-06:00,Unexpected 'Save Resource' dialog appears when copying changes from right to left,"public class Bug {
	void bar() {
		System.out.println();
	}
}
  System.out.println();
R3.5, R3.5.x and I20100112-0800.
public class Bug {
void bar() {
System.out.println();
}
}
==> 'Save Resource' dialog appears which is a major interruption of my workflow.
NOTE: step 6 is crucial: it only happens when the compare editor is focused on a method.",org.eclipse.compare.internal.Utilities
FILE,eclipse-3.1,76472,2004-10-18T11:31:00.000-05:00,Duplicate entries in the constant pool for some methods,"public class X {
	public static void main(String[] args) {
		long[] tab = new long[] {};
		System.out.println(tab.clone());
		System.out.println(tab.clone());
	}
}

  clone()
public class X { public static void main(String[] args) { long[] tab = new long[] {};
System.out.println(tab.clone());
System.out.println(tab.clone());
}
}
Disassemble it and you can see that the call to clone() creates two entries in the constant pool.","org.eclipse.jdt.internal.compiler.ast.BreakStatement
org.eclipse.jdt.internal.compiler.flow.FlowContext
org.eclipse.jdt.internal.compiler.flow.LoopingFlowContext"
FILE,eclipse-3.1,76534,2004-10-18T22:57:00.000-05:00,Can't perform evaluations inside inner class with constructor_ parameters,"createViewer(...)
We currently disallow evaluations in inner classes that take parameters in the referenced constructor_.
Is there anything we can do to allow evaluations in these kinds of classes?",org.eclipse.jdt.internal.debug.eval.ast.engine.SourceBasedSourceGenerator
FILE,eclipse-3.1,76677,2004-10-20T13:18:00.000-05:00,Console Input incorrect,"public class ConsoleTest {
    public static void main(String[] args) {
        try {
	        byte[] b = new byte[100];
	        for(;;) {
	            int read = System.in.read(b);
	            System.out.write(b, 0, read);
	        }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
public class ConsoleTest { public static void main(String[] args) { try { byte[] b = new byte[100];
for(;;) { int read = System.in.read(b);
System.out.write(b, 0, read);
}
} catch (Exception e) { e.printStackTrace();
}
}
}
console output is 13x instead of 1x3.","org.eclipse.ui.internal.console.IOConsolePartition
org.eclipse.ui.internal.console.IOConsolePartitioner"
FILE,eclipse-3.1,76860,2004-10-22T15:30:00.000-05:00,watch expression tests fail,"testDeferredExpression()
  testNonDeferredExpression()
With the new support for varargs, the watch expression tests fail:
* testDeferredExpression()
* testNonDeferredExpression()
These exceptions appear in the log:
!ENTRY org.eclipse.jdt.debug 4 120 2004-10-22 14:12:50.78
!MESSAGE Exception processing async thread queue
!SUBENTRY 1 org.eclipse.jdt.debug 4 120 2004-10-22 14:12:50.78
!MESSAGE Exception processing async thread queue
!STACK 0
java.lang.ArrayIndexOutOfBoundsException
at java.lang.Throwable.<init>(Throwable.java)
at java.lang.Throwable.<init>(Throwable.java)
at java.lang.ArrayIndexOutOfBoundsException.<init>
(ArrayIndexOutOfBoundsException.java)
at
org.eclipse.jdt.internal.debug.eval.ast.engine.ASTInstructionCompiler.visit
(ASTInstructionCompiler.java:2435)
at org.eclipse.jdt.core.dom.MethodInvocation.accept0
(MethodInvocation.java)
at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java)
at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java)
at org.eclipse.jdt.core.dom.ReturnStatement.accept0
(ReturnStatement.java:135)
at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java)
at org.eclipse.jdt.core.dom.ASTNode.acceptChildren(ASTNode.java)
at org.eclipse.jdt.core.dom.Block.accept0(Block.java)
at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java)
at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java)
at org.eclipse.jdt.core.dom.MethodDeclaration.accept0
(MethodDeclaration.java:504)
at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java)
at org.eclipse.jdt.core.dom.ASTNode.acceptChildren(ASTNode.java)
at org.eclipse.jdt.core.dom.TypeDeclaration.accept0
(TypeDeclaration.java:477)
at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java)
at org.eclipse.jdt.core.dom.ASTNode.acceptChildren(ASTNode.java)
at org.eclipse.jdt.core.dom.CompilationUnit.accept0
(CompilationUnit.java:291)
at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java)
at
org.eclipse.jdt.internal.debug.eval.ast.engine.ASTEvaluationEngine.createExpres
sionFromAST(ASTEvaluationEngine.java:264)
at
org.eclipse.jdt.internal.debug.eval.ast.engine.ASTEvaluationEngine.getCompiledE
xpression(ASTEvaluationEngine.java:159)
at
org.eclipse.jdt.internal.debug.eval.ast.engine.ASTEvaluationEngine.evaluate
(ASTEvaluationEngine.java:76)
at
org.eclipse.jdt.internal.debug.ui.JavaWatchExpressionDelegate$EvaluationRunnabl
e.run(JavaWatchExpressionDelegate.java:144)
at org.eclipse.jdt.internal.debug.core.model.JDIThread$ThreadJob.run
(JDIThread.java:2514)
at org.eclipse.core.internal.jobs.Worker.run(Worker.java:66)",org.eclipse.jdt.internal.debug.eval.ast.engine.ASTInstructionCompiler
FILE,eclipse-3.1,77234,2004-10-28T15:41:00.000-05:00,Detail formatter doesn't see inherited method,"getTypeName() 
  
  
  
 getTypeName()   JavaExceptionBreakpoint

getTypeName()
I get the following in the details pane:
Detail formatter error:
The method getTypeName() is undefined for the type JavaExceptionBreakpoint
getTypeName() is declared on JavaBreakpoint, which JavaExceptionBreakpoint 
extends.",org.eclipse.jdt.internal.debug.ui.JavaDetailFormattersManager
FILE,eclipse-3.1,77249,2004-10-28T17:57:00.000-05:00,"Annotation on class cancels ""public"" modifier","@Jpf.Controller 
public class Foo {...} 
 @Jpf.Controller(
    catches={
       @Jpf.Catch(type=java.lang.Exception.class, method=""handleException""),
       @Jpf.Catch(type=PageFlowException.class, 
method=""handlePageFlowException"")
    }
)
public class Foo {
...
}
(This is in 3.1 M2.)
The org.eclipse.jdt.core.dom.CompilationUnit instance corresponding to the class Foo below has no ""public"" modifier, although it should.
Note that if the declaration is simplified to just ""@Jpf.
Controller public class Foo {...}"", then the instance does have a ""public"" modifier.
@Jpf.
Controller( catches={
@Jpf.
Catch(type=java.lang.Exception.class, method=""handleException""),
@Jpf.
Catch(type=PageFlowException.class, method=""handlePageFlowException"")
}
)
public class Foo {
...
}","org.eclipse.jdt.core.dom.ASTConverter
org.eclipse.swt.graphics.GC"
FILE,eclipse-3.1,77573,2004-11-03T04:43:00.000-06:00,[1.5][assist] Code assist does not propose static fields,"import static java.lang.Math
200411022000
Steps to reproduce:
->No proposals","org.eclipse.jdt.internal.codeassist.CompletionEngine
org.eclipse.jdt.core.CompletionProposal
org.eclipse.jdt.core.CompletionRequestor"
FILE,eclipse-3.1,78201,2004-11-09T13:43:00.000-06:00,ClassCastException on Refresh in the AntView,"RefreshBuildFilesAction$1.run(IProgressMonitor)  
 ModalContext$ModalContextThread.run()
Thread [ModalContext] (Suspended (exception ClassCastException))
RefreshBuildFilesAction$1.
run(IProgressMonitor) line: 77
ModalContext$ModalContextThread.run() line: 105",org.eclipse.ant.internal.ui.model.AntProjectNodeProxy
FILE,eclipse-3.1,78245,2004-11-09T18:34:00.000-06:00,Breakpoints in enums not correctly created.,"public enum TestEnum {
  a;
  public static void main(String[] args) {
    System.out.println();   // <- add a breakpoint here
  }
}
We are now able to add breakpoint in enum classes, but they're not correctly created, the associated type is wrong.
It's working OK if the enum is an inner type, but not if it's a top level type.
public enum TestEnum { a;
public static void main(String[] args) {
}
}
The breakpoint is created, but displayed in the breakpoint view as 'null [line
XX] - main(String[])', and the program doesn't stop on the breakpoint.",org.eclipse.jdt.internal.debug.ui.actions.ValidBreakpointLocationLocator
FILE,eclipse-3.1,78275,2004-11-10T07:22:00.000-06:00,[recovery] NPE in GoToNextPreviousMemberAction with syntax error,"public class K {
	void a() {
/*press Ctrl+Shift+Down here*/	}
	}
	 void m() {}
I200411090800
public class K {
void a() {
/*press Ctrl+Shift+Down here*/	}
}
void m() {}
}
Error Nov 10, 2004 13:06:05.553 The command for the key you pressed failed
java.lang.NullPointerException
at
org.eclipse.jdt.internal.ui.javaeditor.selectionactions.GoToNextPreviousMemberAction.firstOpeningBraceOffset(GoToNextPreviousMemberAction.java:224)
at
org.eclipse.jdt.internal.ui.javaeditor.selectionactions.GoToNextPreviousMemberAction.getOffset(GoToNextPreviousMemberAction.java:214)
at
org.eclipse.jdt.internal.ui.javaeditor.selectionactions.GoToNextPreviousMemberAction.addMemberOffsetList(GoToNextPreviousMemberAction.java:207)
at
org.eclipse.jdt.internal.ui.javaeditor.selectionactions.GoToNextPreviousMemberAction.createOffsetArray(GoToNextPreviousMemberAction.java:200)
at
org.eclipse.jdt.internal.ui.javaeditor.selectionactions.GoToNextPreviousMemberAction.getNewSelectionRange(GoToNextPreviousMemberAction.java:135)
at
org.eclipse.jdt.internal.ui.javaeditor.selectionactions.GoToNextPreviousMemberAction.run(GoToNextPreviousMemberAction.java:102)
at org.eclipse.jface.action.Action.runWithEvent(Action.java:988)
at org.eclipse.ui.commands.ActionHandler.execute(ActionHandler.java:188)
at org.eclipse.ui.internal.commands.Command.execute(Command.java:130)
at
org.eclipse.ui.internal.keys.WorkbenchKeyboard.executeCommand(WorkbenchKeyboard.java:445)
at org.eclipse.ui.internal.keys.WorkbenchKeyboard.press(WorkbenchKeyboard.java:724)
at
org.eclipse.ui.internal.keys.WorkbenchKeyboard.processKeyEvent(WorkbenchKeyboard.java:767)
at
org.eclipse.ui.internal.keys.WorkbenchKeyboard.filterKeySequenceBindings(WorkbenchKeyboard.java:536)
at
org.eclipse.ui.internal.keys.WorkbenchKeyboard.access$2(WorkbenchKeyboard.java:479)
at
org.eclipse.ui.internal.keys.WorkbenchKeyboard$1.handleEvent(WorkbenchKeyboard.java:221)
at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:82)
at org.eclipse.swt.widgets.Display.filterEvent(Display.java:752)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:817)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:842)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:827)
at org.eclipse.swt.widgets.Control.traverse(Control.java:2696)
at org.eclipse.swt.widgets.Control.translateTraversal(Control.java:2677)
at org.eclipse.swt.widgets.Composite.translateTraversal(Composite.java:799)
at org.eclipse.swt.widgets.Display.translateTraversal(Display.java:3241)
at org.eclipse.swt.widgets.Display.filterMessage(Display.java:766)
at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2444)
at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:1537)
at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1508)
at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:277)
at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:144)
at org.eclipse.ui.internal.ide.IDEApplication.run(IDEApplication.java:102)
at
org.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:335)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:273)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:129)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:85)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:58)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:60)
at java.lang.reflect.Method.invoke(Method.java:391)
at org.eclipse.core.launcher.Main.basicRun(Main.java:185)
at org.eclipse.core.launcher.Main.run(Main.java:704)
at org.eclipse.core.launcher.Main.main(Main.java:688)","org.eclipse.jdt.internal.compiler.parser.RecoveredUnit
org.eclipse.jdt.internal.compiler.parser.diagnose.RangeUtil
org.eclipse.pde.internal.build.tasks.IdReplaceTask"
FILE,eclipse-3.1,78315,2004-11-10T12:53:00.000-06:00,org.eclipes.team.ui plugin's startup code forces compare to be loaded,"Platform.getAdapterManager()  registerAdapters(factory, DiffNode.class);

   
 startup()
3.1 M3
I wrote tests that ensure plug-ins like Search and Compare aren't loaded when opening a Java editor.
The one for compare fails because org.eclipes.team.ui forces compare to be loaded in its start(BundleContext) method:
Platform.getAdapterManager().
registerAdapters(factory, DiffNode.class);
The direct reference to DiffNode causes the compare plug-in to be loaded even if it is not needed yet.
Test Case:",org.eclipse.team.internal.ui.TeamUIPlugin
FILE,eclipse-3.1,78647,2004-11-15T13:52:00.000-06:00,Breakpoint can be added on an invalid location,"public class Test {
  public static void main(String[] args) {
    int i= 
      2
      +
      (short)3;  // <-- breakpoint here
  }
}
public class Test {
  public static void main(String[] args) {
    int i= 
      2
      +
      (short)3;  // <-- breakpoint here
  }
}
The breakpoint will not be installed, the compiler replace the addition by a
single constant value, only the line with the '2' has bytecode associated to it.
The code to manage these constant expressions does not handle number casting (
(double)5, (char)6, ...).",org.eclipse.jdt.internal.debug.ui.actions.ValidBreakpointLocationLocator
FILE,eclipse-3.1,78740,2004-11-16T10:57:00.000-06:00,IDOMType.getFlags() fails to represent interface flags correctly.,"becomeDetailed()   

package org.example.jdom;

import org.eclipse.core.runtime.IPlatformRunnable;
import org.eclipse.jdt.core.Flags;
import org.eclipse.jdt.core.jdom.DOMFactory;
import org.eclipse.jdt.core.jdom.IDOMCompilationUnit;
import org.eclipse.jdt.core.jdom.IDOMType;

public class Test implements IPlatformRunnable
{
  public Object run(Object object)
  {
    DOMFactory factory = new DOMFactory();
    IDOMCompilationUnit jCompilationUnit =
factory.createCompilationUnit(""package x; /** @model */ interface X  {}"", ""NAME"");
    IDOMType jType = (IDOMType)jCompilationUnit.getFirstChild().getNextNode(); 
    System.err.println("""" + ((jType.getFlags() & Flags.AccInterface) != 0));
    jType.getComment();
    System.err.println("""" + ((jType.getFlags() & Flags.AccInterface) != 0));
    return new Integer(0);
  }
}
package org.example.jdom;
import org.eclipse.core.runtime.IPlatformRunnable;
import org.eclipse.jdt.core.Flags;
import org.eclipse.jdt.core.jdom.DOMFactory;
import org.eclipse.jdt.core.jdom.IDOMCompilationUnit;
import org.eclipse.jdt.core.jdom.IDOMType;
public class Test implements IPlatformRunnable
{ public Object run(Object object)
{
DOMFactory factory = new DOMFactory();
IDOMCompilationUnit jCompilationUnit = factory.createCompilationUnit(""package x; /** @model */ interface X  {}"", ""NAME"");
IDOMType jType = (IDOMType)jCompilationUnit.getFirstChild().
getNextNode();
System.err.println("""" + ((jType.getFlags() & Flags.AccInterface) !
= 0));
jType.getComment();
System.err.println("""" + ((jType.getFlags() & Flags.AccInterface) !
= 0));
return new Integer(0);
}
}
This bug completely breaks EMF's JavaEcoreBuilder, which is a blocking problem for our clients and hence we see this as a blocking problem.",org.eclipse.jdt.internal.compiler.DocumentElementParser
FILE,eclipse-3.1,78746,2004-11-16T11:50:00.000-06:00,[Contributions] [JFace] Compiler error message containing '& ' is rendered with '_' in status line,"interface I {
    static void m(/*caret_here*/);
}
I200411111200 + jdt.core and ui from HEAD:
In a java editor:
interface I { static void m(/*caret_here*/);
}
The compiler message is ""Illegal modifier for the interface method m in type I;
only public & abstract are permitted"".
In the workbench window status line, '& ' is rendered as '_' (a mnemonic Alt+Space ?
-).
The spec for IStatusLineManager#set*Message(.
.)
doesn't mention this behavior.
Solving bug 2135 would probably solve this problem, too.","org.eclipse.ui.texteditor.AbstractDecoratedTextEditor
org.eclipse.ui.internal.util.Util
org.eclipse.ui.internal.texteditor.quickdiff.QuickDiffRestoreAction
org.eclipse.ui.internal.editors.quickdiff.QuickDiffRestoreAction
org.eclipse.jface.action.StatusLine
org.eclipse.ui.internal.editors.quickdiff.CompositeRevertAction
org.eclipse.jface.util.Util"
FILE,eclipse-3.1,79091,2004-11-19T13:00:00.000-06:00,[compiler] Should report invalid type only on the name,"class X { Zork[] foo; }
Using latest,
class X { Zork[] foo; }
We report an error on Zork[] instead of Zork only.","org.eclipse.jdt.internal.compiler.problem.ProblemReporter
org.eclipse.jdt.internal.compiler.ast.ArrayTypeReference"
FILE,eclipse-3.1,79309,2004-11-23T12:04:00.000-06:00,"Nested interfaces aren't resolved correctly in import (with ""Open Declaration"" / F3)","import test.Testable;
import test.Testable.Types; // F3 leads to java.sql.Types

public class Test { 

	public static void main( String[] args ) {
		System.out.println(Testable.Types.TEST);
	}
}
 
 
package test;

public interface Testable {
	public interface Types {
		String TEST = ""test"";
	}
}
Using F3 on ""Types"" from the import statement ""Test.java"" leads to java.sql.Types.
Test.java
---------------------------------------- import test.Testable;
import test.Testable.Types; // F3 leads to java.sql.Types
public class Test {
public static void main( String[] args ) {
System.out.println(Testable.Types.TEST);
}
}
----------------------------------------
test/Testable.java
---------------------------------------- package test;
public interface Testable { public interface Types {
String TEST = ""test"";
}
}
----------------------------------------",org.eclipse.jdt.internal.codeassist.SelectionEngine
FILE,eclipse-3.1,79544,2004-11-26T05:48:00.000-06:00,ITypeBinding#isEqualTo(..) does not compare type arguments,"public class A<X> {
    List<Integer> i;
    List<Number> n;
    List<? extends Number> en;
    List<X> x;
}
JDT/Core from HEAD (including fix for bug 79271).
ITypeBinding#isEqualTo(.
.)
does not compare type arguments:
public class A<X> {
List<Integer> i;
List<Number> n;
List<? extends Number> en;
List<X> x;
}
Types of i, n, en, and x are not equal, even though ITypeBinding#isEqualTo(.
.)
says they are (in both directions).",org.eclipse.jdt.core.dom.BindingComparator
FILE,eclipse-3.1,79545,2004-11-26T05:58:00.000-06:00,Eclipse vs Sun JDK: different class files from the same source code,"public class CharIntTest
{
    /**
     * Eclipse value: "" ""
     * JDK value:     ""32""
     */
    public static String C = """" + +' ';
    /**
     * Eclipse value: ""32""
     * JDK value:     ""32""
     */
    public static String I = """" + +32;

    public static void main(String[] args)
    {
        System.out.println(C);
        System.out.println(I);
    }
}
The results are different.
The problem is connected with +' ': Eclipse treats it as ' ' but Sun JDK converts that space into 32 (+' ' => + (int) ' ' => +32 => 32) (which IMHO is correct).
PS.
I'm not sure if I picked the proper product (JDT)...
public class CharIntTest
{
/**
* Eclipse value: "" ""
* JDK value:     ""32""
*/ public static String C = """" + +' ';
/**
* Eclipse value: ""32""
* JDK value:     ""32""
*/ public static String I = """" + +32;
public static void main(String[] args)
{
System.out.println(C);
System.out.println(I);
}
}","org.eclipse.jdt.internal.compiler.impl.Constant
org.eclipse.jdt.internal.compiler.ast.EqualExpression"
FILE,eclipse-3.1,79690,2004-11-29T13:21:00.000-06:00,Find declaring node doesn't work for type variables,"public class A_test1105 {
	public <E> void foo(E param) {
		/*[*/E local= param;
		foo(local);/*]*/
	}
}
public class A_test1105 {
public <E> void foo(E param) {
/*[*/E local= param;
foo(local);/*]*/
}
}
- calling CompllationUnit#findDeclaringNode with the type binding representing
E doesn't return the node <E> (e.g. the one in the method declaration)","org.eclipse.jdt.core.dom.ASTConverter
org.eclipse.jdt.core.dom.CompilationUnit
org.eclipse.jdt.internal.corext.refactoring.code.ExtractMethodAnalyzer"
FILE,eclipse-3.1,79957,2004-12-02T00:47:00.000-06:00,[Viewers] NPE changing input usingTableViewer and virtual,"Table table=new Table(shell,SWT.VIRTUAL);
TableViewer tv=new TableViewer(table);
tv.setContentProvider(new NetworkContentProvider());
tv.setLabelProvider(new NetworkLabelProvider());
tv.setInput(model);
 
 tv.setInput(model1);
I'm using the latest code for Table viewer with a private virtual manager class
in table viewer.
.
.
in a selection event handler for a button, i've to reset the model input
.
.
tv.setInput(model1);
.
.
Same code works fine without the SWT.VIRTUAL style bit,but when VIRTUAL is set
it throws a null pointer exception...
the stack trace was
java.lang.NullPointerException
at org.eclipse.jface.viewers.TableViewer$1.handleEvent(TableViewer.java:103)
at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:82)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:796)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:820)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:805)
at org.eclipse.swt.widgets.Table.wmNotifyChild(Table.java:3158)
at org.eclipse.swt.widgets.Control.WM_NOTIFY(Control.java:4040)
at org.eclipse.swt.widgets.Composite.WM_NOTIFY(Composite.java:722)
at org.eclipse.swt.widgets.Control.windowProc(Control.java:3025)
at org.eclipse.swt.widgets.Decorations.windowProc(Decorations.java:1400)
at org.eclipse.swt.widgets.Display.windowProc(Display.java:3349)
at org.eclipse.swt.internal.win32.OS.CallWindowProcW(Native Method)
at org.eclipse.swt.internal.win32.OS.CallWindowProc(OS.java:1403)
at org.eclipse.swt.widgets.Table.callWindowProc(Table.java:137)
at org.eclipse.swt.widgets.Control.windowProc(Control.java:3056)
at org.eclipse.swt.widgets.Display.windowProc(Display.java:3349)
at org.eclipse.swt.internal.win32.OS.DispatchMessageW(Native Method)
at org.eclipse.swt.internal.win32.OS.DispatchMessage(OS.java:1479)
at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2440)
at jface.viewers.TestJfaceVirtual.main(TestJfaceVirtual.java:49)",org.eclipse.jface.viewers.TableViewer
FILE,eclipse-3.1,80384,2004-12-07T11:53:00.000-06:00,Cannot decode package signature from CompletionProposal,"getDeclarationSignature() 
 
 class Signature
From the javadoc of CompletionProposal#getDeclarationSignature():
* 	<li><code>PACKAGE_REF</code> - dot-based package
* signature of the package that is referenced</li>
...
* @see Signature
But class Signature does not offer methods to decode package signatures.",org.eclipse.jdt.core.CompletionProposal
FILE,eclipse-3.1,80672,2004-12-10T04:44:00.000-06:00,[1.5] Annotation change does not trigger recompilation,"package p;
@q.Ann
public class Use {
}
  
package q;
public @interface Ann {
}


 
 
package q;
import java.lang.annotation.*;
@Target(ElementType.METHOD)
public @interface Ann {
}
 
 
 @Ann
Build 20041207
java===================================
package p;
@q.
Ann
public class Use {
}
q/Ann.
java===================================
package q;
public @interface Ann {
}",org.eclipse.jdt.internal.compiler.classfmt.ClassFileReader
FILE,eclipse-3.1,80904,2004-12-14T03:26:00.000-06:00,"Quick Fix ""Assign parameter to new field"" doesn't appear with commented type","import java.util.List;
class A {
	public A (List/*<String>*/ list, Integer integer) {
	}
}
200412081200
import java.util.List;
class A {
	public A (List/*<String>*/ list, Integer integer) {
	}
}
Quick Fix ""Assign parameter to new field"" works correctly for ""integer"", but
does not appear for ""list"".",org.eclipse.jdt.internal.compiler.SourceElementParser
FILE,eclipse-3.1,81045,2004-12-14T20:13:00.000-06:00,ClassNotLoadedException when trying to change a value,"public class Test {
	static class Inner {
	}
	public static void main(String[] args) {
		Inner inner= null;
		System.out.println(1);  //  <- breakpoint here
	}
}
public class Test { static class Inner {
} public static void main(String[] args) {
Inner inner= null;
System.out.println(1);  //  <- breakpoint here
}
}
A ClassNotLoadedException dialog appears.","org.eclipse.jdt.internal.debug.ui.actions.JavaVariableValueEditor
org.eclipse.jdt.internal.debug.eval.ast.engine.ASTEvaluationEngine
org.eclipse.jdt.internal.debug.core.model.JDILocalVariable"
FILE,eclipse-3.1,82402,2005-01-07T16:13:00.000-06:00,[Memory View] Bad error message format,"DebugUIMessages.getString(ERROR)  
 e.getMessage()
If getBytesFromAddress fails, the following message appears in the Memory view:
Error creating tab:
org.eclipse.debug.core.DebugException: <message>
This happens because the following code is used to generate the output:
DebugUIMessages.getString(ERROR) + e.
Probably ""e"" should be replaced by ""e.getMessage()"".","org.eclipse.debug.internal.ui.views.memory.MemoryViewTab
org.eclipse.jface.resource.FontRegistry"
FILE,eclipse-3.1,82712,2005-01-12T15:54:00.000-06:00,[1.5] Code assist does not show method parameters from static imports,"import static java.lang.Math.*; 
 public class Test {

    void t() {
        abs(<CTRL+SPACE>);
    }
}
import static java.lang.Math.
*;,
public class Test {
void t() { abs(<CTRL+SPACE>);
}
}",org.eclipse.jdt.internal.codeassist.CompletionEngine
FILE,eclipse-3.1,83005,2005-01-17T14:08:00.000-06:00,[1.5][assist] Content Assist in annotation offers to override methods,"@interface A {
    // Content Assist here
}
I20050112-1200
Content Assist in annotations offers to override methods from the (implicit)
superinterface java.lang.Annotation, although the methods cannot be overridden.
The offered default constructor is also not valid.
@interface A {
    // Content Assist here
}",org.eclipse.jdt.internal.codeassist.CompletionEngine
FILE,eclipse-3.1,83205,2005-01-19T11:25:00.000-06:00,[osgi] shutdown did not complete,"System.exit()  
  
    
  
  
    
   
  
 
  
   Object.wait()  
   
  
  
  
  
  
  
  
 
 it()  
    
 
 
 
 
  
 Object.wait()  
   
  Object.wait()
The console window stayed open, and responsive (could use console).
No further activity seemed to be happening.
Noticed that the plug-in export failed due to classloaders being closed for business (see below), which is expected.
Took a snapshot of the VM state (see below).
It seems System.exit() was not called.
The console and an event dispatching threads were left behind.
Typing ""exit"" on the console caused the VM to exit.
Unable to reproduce.
!
SESSION 2005-01-19 11:11:22.132 -----------------------------------------------
eclipse.buildId=I20050118-1015 java.version=1.5.0 java.vendor=Sun Microsystems Inc.
BootLoader constants: OS=win32, ARCH=x86, WS=win32, NL=en_CA
Framework arguments:  -keyring d:\temp\.
keyring -showlocation
Command-line arguments:  -os win32 -ws win32 -arch x86 -keyring d:\temp\.
keyring
-consolelog -console -debug -showlocation
!
ENTRY org.eclipse.pde.build 0 1 2005-01-19 11:11:22.132
!
MESSAGE Some inter-plug-in dependencies have not been satisfied.java.lang.NoClassDefFoundError: org/eclipse/pde/internal/core/ifeature/IFeatureM odel at org.eclipse.pde.internal.ui.wizards.exports.FeatureExportJob.deleteBu ildFiles(FeatureExportJob.java:298)
at org.eclipse.pde.internal.ui.wizards.exports.PluginExportJob.doExports
(PluginExportJob.java:50)
at org.eclipse.pde.internal.ui.wizards.exports.FeatureExportJob.run(Feat ureExportJob.java:95)
at org.eclipse.core.internal.jobs.Worker.run(Worker.java:66)
osgi>
osgi>
osgi> osgi>
osgi> Full thread dump Java HotSpot(TM) Client VM (1.5.0-b64 mixed mode):
""DestroyJavaVM"" prio=5 tid=0x000361e8 nid=0xc84 waiting on condition [0x00000000
.
.0x0007fae8]
""OSGi Console"" prio=5 tid=0x19bd0e28 nid=0xa28 in Object.wait() [0x19fcf000.
.0x1
9fcfb68]
at java.lang.Object.wait(Native Method)
- waiting on <0x042db588> (a java.lang.Object)
at org.eclipse.osgi.framework.internal.core.FrameworkConsole.console(Fra meworkConsole.java:265)
- locked <0x042db588> (a java.lang.Object)
at org.eclipse.osgi.framework.internal.core.FrameworkConsole.console(Fra meworkConsole.java:236)
at org.eclipse.osgi.framework.internal.core.FrameworkConsole.run(Framewo rkConsole.java:207)
at java.lang.Thread.run(Thread.java:595)
""Framework Event Dispatcher"" daemon prio=5 tid=0x199d55a0 nid=0x878 in Object.wa it() [0x19f8f000.
.0x19f8fbe8]
at java.lang.Object.wait(Native Method)
at java.lang.Object.wait(Object.java:474)
at org.eclipse.osgi.framework.eventmgr.EventThread.getNextEvent(EventThr ead.java:162)
- locked <0x042db620> (a org.eclipse.osgi.framework.eventmgr.EventThread
)
at org.eclipse.osgi.framework.eventmgr.EventThread.run(EventThread.java:
100)
""Low Memory Detector"" daemon prio=5 tid=0x00a912f8 nid=0xe60 runnable [0x0000000
0. .0x00000000]
""CompilerThread0"" daemon prio=10 tid=0x00a8fec8 nid=0x2b8 waiting on condition [
0x00000000.
.0x198cf6c0]
""Signal Dispatcher"" daemon prio=10 tid=0x00a8f250 nid=0xd4c waiting on condition
[0x00000000.
.0x00000000]
""Finalizer"" daemon prio=9 tid=0x00a86670 nid=0xd9c in Object.wait() [0x1984f000.
.0x1984fa68]
at java.lang.Object.wait(Native Method)
at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:116)
- locked <0x042db808> (a java.lang.ref.ReferenceQueue$Lock)
at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:132)
at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)
""Reference Handler"" daemon prio=10 tid=0x00a851e0 nid=0x478 in Object.wait() [0x
1980f000.
.0x1980fae8]
at java.lang.Object.wait(Native Method)
at java.lang.Object.wait(Object.java:474)
at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:116)
- locked <0x042db888> (a java.lang.ref.Reference$Lock)
""VM Thread"" prio=10 tid=0x00a82810 nid=0x750 runnable
""VM Periodic Task Thread"" prio=10 tid=0x00a924d0 nid=0xd04 waiting on condition",org.eclipse.core.launcher.Main
FILE,eclipse-3.1,83206,2005-01-19T11:34:00.000-06:00,ICodeAssist#codeSelect(..) on implicit methods should not return a java element,"class User {
    enum Color {RED, GREEN, BLUE}
    void x() {
        Color.valueOf(""RED"");
        Color.values();
    }
}

     valueOf(String)  values()
I20050118-1015
class User { enum Color {RED, GREEN, BLUE} void x() {
Color.valueOf(""RED"");
Color.values();
}
}
Currently, the declaring enum is returned.",org.eclipse.jdt.internal.codeassist.SelectionEngine
FILE,eclipse-3.1,83321,2005-01-20T12:13:00.000-06:00,[1.5][assist][enum] no override completion proposals in type when followed by a package visible enum,"package test1;

public class Completion {
	| // does not work here
}

enum Natural {
	ONE;
     // works here
}

class After {
    // works here
}
I20050118 + 0120 ZRH plug-in export
I don't get any completion proposals in the following cu, with the caret at |.
Note that completion proposals *are* reported after the enum declaration, and even within the enum declaration after the semicolon-terminated list of enums, but never before.
--------- Completion.java ---------
package test1;
public class Completion {
| // does not work here
}
enum Natural {
ONE;
// works here
}
class After {
// works here
}",org.eclipse.jdt.internal.compiler.parser.Parser
FILE,eclipse-3.1,83383,2005-01-21T06:39:00.000-06:00,IllegalArgumentException in Signature.getParameterCount,"String signature= ""foo(+Ljava.lang.Comparable;)"";
Signature.getParameterCount(signature);
I20050118 + unreleased code (not showing in any build)
String signature= ""foo(+Ljava.lang.Comparable;)"";
Signature.getParameterCount(signature);
Background:
I copied code from CompletionRequestorWrapper to work with the new
CompletionRequestor API.
When completing a METHOD_REF proposal for a method that has a parameter with an open type bound, getParameterPackages I get an IAE:
The reason is the Util.scanTypeSignature does not handle bounded types.
-----------
I get this:
!
ENTRY org.eclipse.ui 4 0 2005-01-21 12:11:32.109
!
MESSAGE The command for the key you pressed failed
!
STACK 0 java.lang.IllegalArgumentException
at org.eclipse.jdt.internal.core.util.Util.scanTypeSignature(Util.java:2115)
at org.eclipse.jdt.core.Signature.getParameterCount(Signature.java:944)
at org.eclipse.jdt.core.Signature.getParameterTypes(Signature.java:1060)
at
org.eclipse.jdt.internal.ui.text.java.ResultCollector.getParameterPackages(ResultCollector.java:732)
at
org.eclipse.jdt.internal.ui.text.java.ResultCollector.internalAcceptMethod(ResultCollector.java:254)
at
org.eclipse.jdt.internal.ui.text.java.ResultCollector.accept(ResultCollector.java:654)
at
org.eclipse.jdt.internal.codeassist.CompletionEngine.findLocalMethods(CompletionEngine.java:2816)
at
org.eclipse.jdt.internal.codeassist.CompletionEngine.findIntefacesMethods(CompletionEngine.java:2551)
at
org.eclipse.jdt.internal.codeassist.CompletionEngine.findMethods(CompletionEngine.java:3270)
at
org.eclipse.jdt.internal.codeassist.CompletionEngine.findFieldsAndMethods(CompletionEngine.java:1903)
at
org.eclipse.jdt.internal.codeassist.CompletionEngine.complete(CompletionEngine.java:627)
at
org.eclipse.jdt.internal.codeassist.CompletionEngine.complete(CompletionEngine.java:1205)
at org.eclipse.jdt.internal.core.Openable.codeComplete(Openable.java:119)
at
org.eclipse.jdt.internal.core.CompilationUnit.codeComplete(CompilationUnit.java:286)
at
org.eclipse.jdt.internal.core.CompilationUnit.codeComplete(CompilationUnit.java:279)
at
org.eclipse.jdt.internal.ui.text.java.JavaCompletionProcessor.internalComputeCompletionProposals(JavaCompletionProcessor.java:363)
at
org.eclipse.jdt.internal.ui.text.java.JavaCompletionProcessor.computeCompletionProposals(JavaCompletionProcessor.java:334)
at
org.eclipse.jface.text.contentassist.ContentAssistant.computeCompletionProposals(ContentAssistant.java:1470)
at
org.eclipse.jface.text.contentassist.CompletionProposalPopup.computeProposals(CompletionProposalPopup.java:250)
at
org.eclipse.jface.text.contentassist.CompletionProposalPopup.access$7(CompletionProposalPopup.java:247)
at
org.eclipse.jface.text.contentassist.CompletionProposalPopup$9.run(CompletionProposalPopup.java:961)
at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:69)
at
org.eclipse.jface.text.contentassist.CompletionProposalPopup.incrementalComplete(CompletionProposalPopup.java:956)
at
org.eclipse.jface.text.contentassist.ContentAssistant.showPossibleCompletions(ContentAssistant.java:1318)
at
org.eclipse.jdt.internal.ui.javaeditor.CompilationUnitEditor$AdaptedSourceViewer.doOperation(CompilationUnitEditor.java:180)
at org.eclipse.ui.texteditor.ContentAssistAction$1.run(ContentAssistAction.java:82)
at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:69)
at org.eclipse.ui.texteditor.ContentAssistAction.run(ContentAssistAction.java:80)
at org.eclipse.jface.action.Action.runWithEvent(Action.java:989)
at org.eclipse.ui.commands.ActionHandler.execute(ActionHandler.java:188)
at org.eclipse.ui.internal.commands.Command.execute(Command.java:130)
at
org.eclipse.ui.internal.keys.WorkbenchKeyboard.executeCommand(WorkbenchKeyboard.java:445)
at org.eclipse.ui.internal.keys.WorkbenchKeyboard.press(WorkbenchKeyboard.java:724)
at
org.eclipse.ui.internal.keys.WorkbenchKeyboard.processKeyEvent(WorkbenchKeyboard.java:767)
at
org.eclipse.ui.internal.keys.WorkbenchKeyboard.filterKeySequenceBindings(WorkbenchKeyboard.java:536)
at
org.eclipse.ui.internal.keys.WorkbenchKeyboard.access$2(WorkbenchKeyboard.java:479)
at
org.eclipse.ui.internal.keys.WorkbenchKeyboard$1.handleEvent(WorkbenchKeyboard.java:221)
at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:82)
at org.eclipse.swt.widgets.Display.filterEvent(Display.java:1086)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1001)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1026)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1011)
at org.eclipse.swt.widgets.Widget.sendKeyEvent(Widget.java:1038)
at org.eclipse.swt.widgets.Widget.gtk_key_press_event(Widget.java:602)
at org.eclipse.swt.widgets.Control.gtk_key_press_event(Control.java:1889)
at org.eclipse.swt.widgets.Composite.gtk_key_press_event(Composite.java:527)
at org.eclipse.swt.widgets.Widget.windowProc(Widget.java:1338)
at org.eclipse.swt.widgets.Display.windowProc(Display.java:3261)
at org.eclipse.swt.internal.gtk.OS.
_gtk_main_do_event(Native Method)
at org.eclipse.swt.internal.gtk.OS.gtk_main_do_event(OS.java:4642)
at org.eclipse.swt.widgets.Display.eventProc(Display.java:926)
at org.eclipse.swt.internal.gtk.OS.
_g_main_context_iteration(Native Method)
at org.eclipse.swt.internal.gtk.OS.g_main_context_iteration(OS.java:1104)
at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2415)
at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:1575)
at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1541)
at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:287)
at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:144)
at org.eclipse.ui.internal.ide.IDEApplication.run(IDEApplication.java:102)
at
org.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:220)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:274)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:129)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:585)
at org.eclipse.core.launcher.Main.basicRun(Main.java:255)
at org.eclipse.core.launcher.Main.run(Main.java:811)
at org.eclipse.core.launcher.Main.main(Main.java:795)
The command for the key you pressed failed",org.eclipse.jdt.internal.core.util.Util
FILE,eclipse-3.1,83489,2005-01-22T17:33:00.000-06:00,[select] Code select returns IType instead of ITypeParameter on method parameters types,"class Test<T> {
  void foo(T t) {}
}
Using HEAD.
class Test<T> { void foo(T t) {}
}
When I select ""T"" in method declaration, selection engine returns an IType
""Test"" instead of expected ITypeParameter ""T"".",org.eclipse.jdt.internal.codeassist.SelectionEngine
FILE,eclipse-3.1,83536,2005-01-24T10:02:00.000-06:00,"""Incompatible argument to function"" at vararg function","package t1;
public class Test {
    public static void main (String[] args) {
        new Test ().test (new byte[5]);
    }
    private void test (Object... params) {
    }
}

 
  
 new Test ()  new Object[] {new byte[5]}
package t1;
public class Test {
    public static void main (String[] args) {
        new Test ().
test (new byte[5]);
    }
    private void test (Object... params) {
    }
}
The code generates the following error at runtime when started from Eclipse (and
only when started from Eclipse): 
java.lang.VerifyError: (class: t1/Test, method: main signature:
([Ljava/lang/String;)V) Incompatible argument to function
The error is eliminated if the call to method test is expressed as:
new Test ().
test (new Object[] {new byte[5]});
Could it be an autoboxing issue?","org.eclipse.jdt.internal.compiler.ast.Statement
org.eclipse.ui.internal.WorkbenchWindow
org.eclipse.ui.internal.Workbench"
FILE,eclipse-3.1,83699,2005-01-26T06:03:00.000-06:00,Font reset to default after screen saver,"StyledText.setFont(Font)  
   updateFont(Font, Font)  
   updateFont(Font, Font)  
 updateFont(Font, Font)  
 Composite.updateFont(Font, Font)  
 Composite.updateFont(Font, Font)  
 Composite.updateFont(Font, Font)  
 Composite.updateFont(Font, Font)  
 Composite.updateFont(Font, Font)  
 Composite.updateFont(Font, Font)  
 Composite.updateFont(Font, Font)  
 updateFont(Font, Font)  
 Display.updateFont()  
  
  
 Display.readAndDispatch()  
 Workbench.runEventLoop(Window$IExceptionHandler, Display)  
 Workbench.runUI()  
 Workbench.createAndRunWorkbench(Display, WorkbenchAdvisor)  
 PlatformUI.createAndRunWorkbench(Display, WorkbenchAdvisor)  
 IDEApplication.run(Object)  
 EclipseStarter.run(Object)
I20050125-0800
All editors and views using a StyledText widget have the font reset to default after coming back from my screen saver.
Makes build I20050125-0800 unusable for me.
Works if I replace org.eclipse.swt.win32_3.1.0 with the one from last I-build.
This breakpoint gets hit when I return from the screen saver
Thread [main] (Suspended (breakpoint at line 6820 in StyledText))
StyledText.setFont(Font) line: 6820
StyledText(Control).
updateFont(Font, Font) line: 2913
StyledText(Composite).
updateFont(Font, Font) line: 810
Canvas(Composite).
updateFont(Font, Font) line: 807
Composite.updateFont(Font, Font) line: 807
Composite.updateFont(Font, Font) line: 807
Composite.updateFont(Font, Font) line: 807
Composite.updateFont(Font, Font) line: 807
Composite.updateFont(Font, Font) line: 807
Composite.updateFont(Font, Font) line: 807
Composite.updateFont(Font, Font) line: 807
Shell(Composite).
updateFont(Font, Font) line: 807
Display.updateFont() line: 3379
Display.messageProc(int, int, int, int) line: 2276
OS.PeekMessageW(MSG, int, int, int, int) line: not available [native method]
OS.PeekMessage(MSG, int, int, int, int) line: 2016
Display.readAndDispatch() line: 2510
Workbench.runEventLoop(Window$IExceptionHandler, Display) line: 1584
Workbench.runUI() line: 1550
Workbench.createAndRunWorkbench(Display, WorkbenchAdvisor) line: 288
PlatformUI.createAndRunWorkbench(Display, WorkbenchAdvisor) line: 144
IDEApplication.run(Object) line: 102
1. run(Object) line: 225
EclipseStarter.run(Object) line: 274
EclipseStarter.run(String[], Runnable) line: 129
NativeMethodAccessorImpl.invoke0(Method, Object, Object[]) line: not available
[native method]
NativeMethodAccessorImpl.invoke(Object, Object[]) line: 39
DelegatingMethodAccessorImpl.invoke(Object, Object[]) line: 25
Method.invoke(Object, Object[]) line: 324
Main.basicRun(String[]) line: 255
Main.run(String[]) line: 811
Main.main(String[]) line: 795",org.eclipse.swt.widgets.Control
FILE,eclipse-3.1,84194,2005-02-01T18:05:00.000-06:00,[content assist] Code assist in import statements insert at the end,"import org.eclipse.core.runtime.*;
Build: I-20050201
import org.eclipse.core.runtime.
*;
You will see that upon pressing Enter to select, the text gets inserted several lines down under all the import statements.
the cursor is now in a random position also.","org.eclipse.jdt.internal.ui.text.java.JavaTypeCompletionProposal
org.eclipse.jdt.internal.ui.text.java.ExperimentalResultCollector"
FILE,eclipse-3.1,84724,2005-02-08T13:41:00.000-06:00,[1.5][search] fails to find call sites for varargs constructor_s,"public class Test {
    public void foo() {
        Cell c= new Cell("""", """"); // calls Cell.Cell(String...)
    }
}
 class Cell {
    public Cell(String... args) { }
}
The search engine fails to find the call to the varargs constructor_ in the example below.
> ""Workspace"" from the Java editor context menu; no occurrences will be found.
Bug manifests with integration build I2005-0202.
public class Test { public void foo() {
Cell c= new Cell("""", """"); // calls Cell.Cell(String...)
}
} class Cell { public Cell(String... args) { }
}",org.eclipse.jdt.internal.core.search.matching.ConstructorLocator
FILE,eclipse-3.1,84770,2005-02-09T06:46:00.000-06:00,Formatter fails in specific case (.class in code),"public class FormatterTest {
  void doTest(
      ) {
     System.out.println(""("" + 
         Object.class + "")"");
  }
}
 
 toString()
Steps to reproduce:
-----BEGIN-----
public class FormatterTest {
void doTest(
) {
System.out.println(""("" +
Object.class + "")"");
}
}
-----END-----
2 Try to format it by Ctrl+Shift+F  - nothing happens
It seems that formatter crashes, when it has some string operatation (like + ) 
after the keyword class",org.eclipse.jdt.internal.formatter.BinaryExpressionFragmentBuilder
FILE,eclipse-3.1,84944,2005-02-10T16:49:00.000-06:00,[1.5][builder] Parameterized return type is sometimes not visible.,"package parser;

public interface ValueParser<T> {
	T parse(final String string);
}
This is a very strange error because it is not always reproduceable.
--------------------------
package parser;
public interface ValueParser<T> {
	T parse(final String string);
}
--------------------------
However the return type seems to be not visible for some of the implementations.
The strange thing about this behavior is that a ""clean project"" may clean the
error until next compile, sometimes the error did not occur in the different
implementation.
I tried to create a minimal persion project which could be attached in bugzilla
but it doesn't seem to show the bug.
The error was shown in line 21 of ""test/BooleanParserTest.
java"".","org.eclipse.jdt.internal.compiler.lookup.BinaryTypeBinding
org.eclipse.jdt.internal.compiler.lookup.ParameterizedTypeBinding
org.eclipse.jdt.internal.compiler.lookup.WildcardBinding"
FILE,eclipse-3.1,85344,2005-02-15T17:36:00.000-06:00,Error evaluating logical structure value for Map in Java 5.0,"public class Test {
  public static void main(String[] args) {
    Map<String, Integer> map= new HashMap<String, Integer>();
    System.out.println();     // <-- breakpoint here
  }
}

  entrySet()
public class Test { public static void main(String[] args) {
Map<String, Integer> map= new HashMap<String, Integer>();
}
}
I get ""Error: The method entrySet() is undefined for the type Map__"" when I expand map in the variables view.",org.eclipse.jdt.internal.debug.eval.ast.engine.BinaryBasedSourceGenerator
FILE,eclipse-3.1,85397,2005-02-16T08:20:00.000-06:00,[1.5][enum] erroneous strictfp keyword on enum type produces error on constructor_,"strictfp enum Natural {
	ONE, TWO;
}

 
 strictfp enum Natural {
	ONE, TWO;
	
	private Natural() {
	}
}
I20050215-2300 (M5 test pass)
strictfp enum Natural {
ONE, TWO;
}
expected: strictfp is not allowed on the enum type actual: no error is reported
strictfp enum Natural {
ONE, TWO;
private Natural() {
}
}
expected: the wrong modifier is reported with the type name 'Natural' actual: the error is shown for the constructor_","org.eclipse.jdt.internal.compiler.lookup.SyntheticMethodBinding
org.eclipse.jdt.internal.ui.typehierarchy.TypeHierarchyViewPart
org.eclipse.jdt.internal.compiler.lookup.MethodScope"
FILE,eclipse-3.1,85402,2005-02-16T08:50:00.000-06:00,[1.5][assist] NPE while trying to complete on empty annotation,"import e.Team;
   @Author(name={Team.DAVID, Team.JEROME})
    
  public class Test {
	@Author(name=Team.PHILIPPE) void foo() {}
	@Author int t;
  }
  
  import e.Team;
  public @interface Author {
	Team[] name() default Team.FREDERIC;
  }
  
  package e;
  public enum Team {
	PHILIPPE, DAVID, JEROME, FREDERIC;
  }

 
 ResultCollector.accept(CompletionProposal)
Using build 3.1 M5 candidate (I20040215-2300).
Test.java:
import e.Team;
@Author(name={Team.DAVID, Team.JEROME})
@| // <-- Try to complete here: NPE
public class Test {
@Author(name=Team.PHILIPPE) void foo() {}
@Author int t;
}
Author.java:
import e.Team;
public @interface Author {
Team[] name() default Team.FREDERIC;
}
Team.java:
package e;
public enum Team {
PHILIPPE, DAVID, JEROME, FREDERIC;
}
If you try to complete at caret position, then you get an Error Excuting Command
dialog.
Debug shows that there's a NPE in ResultCollector.accept(CompletionProposal)
method due to name==null for CompletionProposal","org.eclipse.jdt.internal.codeassist.complete.CompletionOnAnnotationOfType
org.eclipse.jdt.internal.codeassist.CompletionEngine
org.eclipse.jdt.internal.codeassist.complete.CompletionParser"
FILE,eclipse-3.1,85672,2005-02-17T05:53:00.000-06:00,[projection] Unfolding a folded region with no line delimiter on the last line selects too much,"package folding;

class Test {
    
}
I20050215-2300 (m5 test pass)
""package folding;
class Test {
}""  <-- no delimiter on last line
Note that there is a phantom line in the editor since we cannot fold that one away.
expected: caret is right after the closing brace actual: everything from after the *opening* brace is selected
Not a regression - it is like this in 3.0",org.eclipse.jface.text.source.projection.ProjectionViewer
FILE,eclipse-3.1,85734,2005-02-17T12:28:00.000-06:00,Debug view flickers excessively,"Runtime.exec(...)
I20050217-0800, KDE 3.3.2, GTK+ 2.4.14, X.Org 6.8.0, Linux 2.6.10
The debug view flickers excessively when debugging.
I
wish I could show you the effect; it is most disturbing.
:)","org.eclipse.debug.internal.ui.views.RemoteTreeViewer
org.eclipse.debug.internal.ui.views.launch.LaunchViewer
org.eclipse.debug.internal.ui.views.launch.LaunchViewEventHandler
org.eclipse.debug.internal.ui.views.RemoteTreeContentManager"
FILE,eclipse-3.1,86000,2005-02-21T14:47:00.000-06:00,ImageLoader Save - produces invalid JPEG images,"package com.ibm.test.image;

import org.eclipse.swt.*;
import org.eclipse.swt.graphics.*;

public class ImageLoaderTest {
		
	public static void main(String[] args) {
		ImageLoader loader;
		String dir=""c:\\image-problems\\"";
		String files[]={
				""s34i3p04"",
				""s34n3p04"",
				""s35i3p04"",
				""s35n3p04"",
				""s36i3p04"",
				""s36n3p04"",
				""s37i3p04"",
				""s37n3p04"",
				""s38i3p04"",
				""s38n3p04"",
				""s39i3p04"",
				""s39n3p04""
		};
		
		try {
			for (int i=0; i<files.length; i++) {
			String filein  = dir+files[i]+"".png"";
			String fileout = dir+files[i]+"".jpg"";
			
			loader = new ImageLoader();
			loader.load(filein);
			loader.save(fileout,SWT.IMAGE_JPEG);
			}
		} catch (SWTException e) {
		  e.printStackTrace();
		}
	}
}
The ImageLoader Save function appears to be producing bad JPG images.
I have only verified this with JPEG output.
Many files were tested and the majority 
 did produced the proper JPG images as expected.
The attached Zip file contains
 only those files that did not save correctly to JPEG.
package com.ibm.test.image;
import org.eclipse.swt.
*;
import org.eclipse.swt.graphics.
*;
public class ImageLoaderTest {
		
	public static void main(String[] args) {
		ImageLoader loader;
		String dir=""c:\\image-problems\\"";
		String files[]={
				""s34i3p04"",
				""s34n3p04"",
				""s35i3p04"",
				""s35n3p04"",
				""s36i3p04"",
				""s36n3p04"",
				""s37i3p04"",
				""s37n3p04"",
				""s38i3p04"",
				""s38n3p04"",
				""s39i3p04"",
				""s39n3p04""
		};
		
		try {
			for (int i=0; i<files.length; i++) {
			String filein  = dir+files[i]+"".
png"";
			String fileout = dir+files[i]+"".
jpg"";
			
			loader = new ImageLoader();
			loader.load(filein);
			loader.save(fileout,SWT.IMAGE_JPEG);
			}
		} catch (SWTException e) {
		  e.printStackTrace();
		}
	}
}","org.eclipse.ui.internal.WorkbenchIntroManager
org.eclipse.swt.internal.image.JPEGFileFormat"
FILE,eclipse-3.1,86610,2005-02-25T06:25:00.000-06:00,Lots of Worker threads (around 100),"class AllZRZHTests
3.1 M5a
When running all our tests together (see attached class AllZRZHTests.java) on our buildmachine (Linux Fedora Core using Sun VM 1.4.2_06) we see that more and more Worker threads get created but not terminated.
When the last test cases are reached, tons of ""java.lang.StackOverflowError"" are written to the console but no stack trace.
The .log is empty.
Note:
- this worked with 3.1 M4 i.e. no errors written to the Console.
- this still works when using another VM but the amount of Workers is huge too
When running in the Debugger the VM often ""dies"" (or freezes) and the tests never finish.
I put a breakpoint into the Worker constructor_ and it looked as if the
DecorationScheduler is causing the creation of the Worker in the UI/main thread.
I would expect that there's an upper bound for the Workers and unused Workers get removed again.",org.eclipse.ui.internal.decorators.DecorationScheduler
FILE,eclipse-3.1,86614,2005-02-25T07:10:00.000-06:00,Deadlock on startup,"Target Workspace=c 
    
 
 
  
  
 Object.wait()
 
 
  
 
  
  Object.wait()
 
   
   
  Object.wait()
 
   
   
 
   
 
  
 
 Object.wait()  
 
  
   
 
   
   
 
 Object.wait()
 
   
   
  Object.wait()
3.1 M5a
Starting Eclipse  3.1_M5a
***************************
VM Options=-showversion -Xms50M -Xmx350M -Dosgi.clean=true
Target Workspace=c:\eclipse\workspaces\Development_2_2\plugins
C:\eclipse\drops\3.1_M5a>C:\JavaSDKs\jdk1.4.2_06\bin\java -showversion -Xms50M
-Xmx350M -Dosgi.clean=true -cp startup.jar org.eclipse.core.launcher.Main
-update -keyring c:\eclipse\.
keyring -applicati on org.eclipse.ui.ide.workbench -showlocation -data c:\eclipse\workspaces\Development_2_2\plugins java version ""1.4.2_06""
Java(TM) 2 Runtime Environment, Standard Edition (build 1.4.2_06-b02)
Java HotSpot(TM) Client VM (build 1.4.2_06-b02, mixed mode)
Full thread dump Java HotSpot(TM) Client VM (1.4.2_06-b02 mixed mode):
""Java indexing"" daemon prio=4 tid=0x0374a450 nid=0xb20 in Object.wait()
[3ccf000.
.3ccfd8c]
at java.lang.Object.wait(Native Method)
- waiting on <0x12daaf80> (a org.eclipse.jdt.internal.core.search.indexing.IndexManager)
at java.lang.Object.wait(Object.java:429)
at
org.eclipse.jdt.internal.core.search.processing.JobManager.run(JobManager.java:345)
- locked <0x12daaf80> (a org.eclipse.jdt.internal.core.search.indexing.IndexManager)
at java.lang.Thread.run(Thread.java:534)
""Reference Cleaner: 1"" prio=7 tid=0x02f08d00 nid=0xf08 in Object.wait()
[3c8f000.
.3c8fd8c]
at java.lang.Object.wait(Native Method)
- waiting on <0x12f58438> (a java.lang.ref.ReferenceQueue$Lock)
at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:111)
- locked <0x12f58438> (a java.lang.ref.ReferenceQueue$Lock)
at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:127)
at
org.eclipse.jface.resource.ImageCache$ReferenceCleanerThread.run(ImageCache.java:424)
""Worker-1"" daemon prio=5 tid=0x00a24c18 nid=0x610 in Object.wait()
[30ef000.
.30efd8c]
at java.lang.Object.wait(Native Method)
- waiting on <0x11c4a670> (a org.eclipse.core.internal.jobs.WorkerPool)
at org.eclipse.core.internal.jobs.WorkerPool.sleep(WorkerPool.java:167)
- locked <0x11c4a670> (a org.eclipse.core.internal.jobs.WorkerPool)
at org.eclipse.core.internal.jobs.WorkerPool.startJob(WorkerPool.java:199)
at org.eclipse.core.internal.jobs.Worker.run(Worker.java:60)
""Worker-0"" daemon prio=5 tid=0x00a1fcf8 nid=0x2f0 waiting for monitor entry
[30ae000.
.30afd8c] at
org.eclipse.ui.internal.WorkbenchPlugin.getWorkingSetManager(WorkbenchPlugin.java:430)
- waiting to lock <0x11ea79c0> (a org.eclipse.ui.internal.WorkbenchPlugin)
at
org.eclipse.ui.internal.Workbench.getWorkingSetManager(Workbench.java:804)
at
org.eclipse.debug.internal.ui.views.breakpoints.WorkingSetBreakpointOrganizer.<init>(WorkingSetBreakpointOrganizer.java:39)
at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
at
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
at
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
at java.lang.reflect.Constructor.newInstance(Constructor.java:274)
at java.lang.Class.newInstance0(Class.java:308)
at java.lang.Class.newInstance(Class.java:261)
at
org.eclipse.core.internal.registry.ConfigurationElement.createExecutableExtension(ConfigurationElement.java:175)
at
org.eclipse.core.internal.registry.ConfigurationElement.createExecutableExtension(ConfigurationElement.java:152)
at
org.eclipse.core.internal.registry.ConfigurationElement.createExecutableExtension(ConfigurationElement.java:139)
at
org.eclipse.core.internal.registry.ConfigurationElementHandle.createExecutableExtension(ConfigurationElementHandle.java:48)
at
org.eclipse.debug.internal.ui.views.breakpoints.BreakpointOrganizerExtension.getOrganizer(BreakpointOrganizerExtension.java:97)
at
org.eclipse.debug.internal.ui.views.breakpoints.BreakpointOrganizerExtension.addPropertyChangeListener(BreakpointOrganizerExtension.java:116)
at
org.eclipse.debug.internal.ui.views.breakpoints.BreakpointOrganizerManager.start(BreakpointOrganizerManager.java:80)
at
org.eclipse.debug.internal.ui.views.breakpoints.BreakpointOrganizerManager.<init>(BreakpointOrganizerManager.java:65)
at
org.eclipse.debug.internal.ui.views.breakpoints.BreakpointOrganizerManager.getDefault(BreakpointOrganizerManager.java:54)
at org.eclipse.debug.internal.ui.DebugUIPlugin.start(DebugUIPlugin.java:403)
at
org.eclipse.osgi.framework.internal.core.BundleContextImpl$2.run(BundleContextImpl.java:995)
at java.security.AccessController.doPrivileged(Native Method)
at
org.eclipse.osgi.framework.internal.core.BundleContextImpl.startActivator(BundleContextImpl.java:989)
at
org.eclipse.osgi.framework.internal.core.BundleContextImpl.start(BundleContextImpl.java:970)
at
org.eclipse.osgi.framework.internal.core.BundleHost.startWorker(BundleHost.java:327)
at
org.eclipse.osgi.framework.internal.core.AbstractBundle.start(AbstractBundle.java:276)
at
org.eclipse.core.runtime.adaptor.EclipseClassLoader.findLocalClass(EclipseClassLoader.java:110)
at
org.eclipse.osgi.framework.internal.core.BundleLoader.findLocalClass(BundleLoader.java:331)
at
org.eclipse.osgi.framework.internal.core.SingleSourcePackage.loadClass(SingleSourcePackage.java:34)
at
org.eclipse.osgi.framework.internal.core.BundleLoader.findRequiredClass(BundleLoader.java:726)
at
org.eclipse.osgi.framework.internal.core.BundleLoader.findClass(BundleLoader.java:355)
at
org.eclipse.osgi.framework.adaptor.core.AbstractClassLoader.loadClass(AbstractClassLoader.java:94)
at java.lang.ClassLoader.loadClass(ClassLoader.java:235)
at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:302)
- locked <0x130110c0> (a org.eclipse.core.runtime.adaptor.EclipseClassLoader)
at
org.eclipse.ui.externaltools.internal.launchConfigurations.ExternalToolsUtil.getResourcesForBuildScope(ExternalToolsUtil.java:180)
at
org.eclipse.ui.externaltools.internal.model.ExternalToolBuilder.doBuildBasedOnScope(ExternalToolBuilder.java:164)
at
org.eclipse.ui.externaltools.internal.model.ExternalToolBuilder.build(ExternalToolBuilder.java:81)
at
org.eclipse.core.internal.events.BuildManager$2.run(BuildManager.java:581)
at
org.eclipse.core.internal.runtime.InternalPlatform.run(InternalPlatform.java:1015)
at org.eclipse.core.runtime.Platform.run(Platform.java:757)
at
org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:160)
at
org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:198)
at
org.eclipse.core.internal.events.BuildManager$1.run(BuildManager.java:227)
at
org.eclipse.core.internal.runtime.InternalPlatform.run(InternalPlatform.java:1015)
at org.eclipse.core.runtime.Platform.run(Platform.java:757)
at
org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:230)
at
org.eclipse.core.internal.events.BuildManager.basicBuildLoop(BuildManager.java:249)
at
org.eclipse.core.internal.events.BuildManager.build(BuildManager.java:278)
at
org.eclipse.core.internal.events.AutoBuildJob.doBuild(AutoBuildJob.java:138)
at org.eclipse.core.internal.events.AutoBuildJob.run(AutoBuildJob.java:199)
at org.eclipse.core.internal.jobs.Worker.run(Worker.java:67)
""Start Level Event Dispatcher"" daemon prio=5 tid=0x00a37e70 nid=0xe70 in
Object.wait() [302f000.
.302fd8c]
at java.lang.Object.wait(Native Method)
- waiting on <0x11af0060> (a org.eclipse.osgi.framework.eventmgr.EventThread)
at java.lang.Object.wait(Object.java:429)
at
org.eclipse.osgi.framework.eventmgr.EventThread.getNextEvent(EventThread.java:162)
- locked <0x11af0060> (a org.eclipse.osgi.framework.eventmgr.EventThread)
at org.eclipse.osgi.framework.eventmgr.EventThread.run(EventThread.java:100)
""Framework Event Dispatcher"" daemon prio=5 tid=0x00a32d10 nid=0xd64 waiting for monitor entry [2fef000.
.2fefd8c] at
org.eclipse.ui.internal.WorkbenchPlugin.getWorkingSetRegistry(WorkbenchPlugin.java:444)
- waiting to lock <0x11ea79c0> (a org.eclipse.ui.internal.WorkbenchPlugin)
at
org.eclipse.ui.internal.AbstractWorkingSetManager.bundleChanged(AbstractWorkingSetManager.java:485)
- locked <0x13010d00> (a org.eclipse.ui.internal.WorkingSetManager)
at
org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:1206)
at
org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:186)
at org.eclipse.osgi.framework.eventmgr.EventThread.run(EventThread.java:104)
""Signal Dispatcher"" daemon prio=10 tid=0x009c2188 nid=0xb94 waiting on condition
[0.
.0]
""Finalizer"" daemon prio=9 tid=0x009bfb50 nid=0x974 in Object.wait()
[2caf000.
.2cafd8c]
at java.lang.Object.wait(Native Method)
- waiting on <0x11af0310> (a java.lang.ref.ReferenceQueue$Lock)
at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:111)
- locked <0x11af0310> (a java.lang.ref.ReferenceQueue$Lock)
at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:127)
at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)
""Reference Handler"" daemon prio=10 tid=0x009be7d0 nid=0x898 in Object.wait()
[2c6f000.
.2c6fd8c]
at java.lang.Object.wait(Native Method)
- waiting on <0x11af00b0> (a java.lang.ref.Reference$Lock)
at java.lang.Object.wait(Object.java:429)
at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:115)
- locked <0x11af00b0> (a java.lang.ref.Reference$Lock)
""main"" prio=7 tid=0x00036090 nid=0xce4 waiting for monitor entry [7e000.
.7fc3c] at
org.eclipse.ui.internal.AbstractWorkingSetManager.addToUpdater(AbstractWorkingSetManager.java:511)
- waiting to lock <0x13010d00> (a org.eclipse.ui.internal.WorkingSetManager)
at
org.eclipse.ui.internal.AbstractWorkingSetManager.internalAddWorkingSet(AbstractWorkingSetManager.java:153)
at
org.eclipse.ui.internal.AbstractWorkingSetManager.restoreWorkingSetState(AbstractWorkingSetManager.java:338)
at
org.eclipse.ui.internal.WorkingSetManager.restoreState(WorkingSetManager.java:107)
at
org.eclipse.ui.internal.WorkbenchPlugin.getWorkingSetManager(WorkbenchPlugin.java:432)
- locked <0x11ea79c0> (a org.eclipse.ui.internal.WorkbenchPlugin)
at
org.eclipse.ui.internal.Workbench.getWorkingSetManager(Workbench.java:804)
at
org.eclipse.ui.internal.ide.actions.BuildSetMenu.fillMenu(BuildSetMenu.java:100)
at
org.eclipse.ui.internal.ide.actions.BuildSetMenu.fill(BuildSetMenu.java:87)
at org.eclipse.jface.action.MenuManager.update(MenuManager.java:625)
at org.eclipse.jface.action.MenuManager.update(MenuManager.java:547)
at org.eclipse.jface.action.MenuManager.fill(MenuManager.java:232)
at org.eclipse.jface.action.MenuManager.update(MenuManager.java:625)
at org.eclipse.jface.action.MenuManager.update(MenuManager.java:547)
at org.eclipse.jface.action.MenuManager.fill(MenuManager.java:232)
at org.eclipse.jface.action.MenuManager.update(MenuManager.java:625)
at org.eclipse.jface.action.MenuManager.update(MenuManager.java:547)
at org.eclipse.jface.action.MenuManager.createMenuBar(MenuManager.java:158)
at org.eclipse.jface.action.MenuManager.createMenuBar(MenuManager.java:174)
at
org.eclipse.ui.internal.WorkbenchWindow.createDefaultContents(WorkbenchWindow.java:810)
at
org.eclipse.ui.internal.WorkbenchWindowConfigurer.createDefaultContents(WorkbenchWindowConfigurer.java:573)
at
org.eclipse.ui.application.WorkbenchWindowAdvisor.createWindowContents(WorkbenchWindowAdvisor.java:352)
at
org.eclipse.ui.internal.WorkbenchWindow.createContents(WorkbenchWindow.java:778)
at org.eclipse.jface.window.Window.create(Window.java:375)
at org.eclipse.ui.internal.Workbench.restoreState(Workbench.java:1434)
at org.eclipse.ui.internal.Workbench.access$9(Workbench.java:1409)
at org.eclipse.ui.internal.Workbench$14.run(Workbench.java:1312)
at
org.eclipse.core.internal.runtime.InternalPlatform.run(InternalPlatform.java:1015)
at org.eclipse.core.runtime.Platform.run(Platform.java:757)
at org.eclipse.ui.internal.Workbench.restoreState(Workbench.java:1246)
at
org.eclipse.ui.internal.WorkbenchConfigurer.restoreState(WorkbenchConfigurer.java:171)
at
org.eclipse.ui.application.WorkbenchAdvisor.openWindows(WorkbenchAdvisor.java:711)
at org.eclipse.ui.internal.Workbench.init(Workbench.java:918)
at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1554)
at
org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:293)
at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:144)
at org.eclipse.ui.internal.ide.IDEApplication.run(IDEApplication.java:102)
at
org.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:228)
at
org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:333)
at
org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:150)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:324)
at org.eclipse.core.launcher.Main.invokeFramework(Main.java:268)
at org.eclipse.core.launcher.Main.basicRun(Main.java:260)
at org.eclipse.core.launcher.Main.run(Main.java:887)
at org.eclipse.core.launcher.Main.main(Main.java:871)
""VM Thread"" prio=5 tid=0x009fb720 nid=0xc50 runnable
""VM Periodic Task Thread"" prio=10 tid=0x009fc968 nid=0x318 waiting on condition
""Suspend Checker Thread"" prio=10 tid=0x009c1c40 nid=0xc40 runnable
Found one Java-level deadlock:
=============================
""main"":
waiting to lock monitor 0x009bf394 (object 0x13010d00, a org.eclipse.ui.internal.WorkingSetManager), which is held by ""Framework Event Dispatcher""
""Framework Event Dispatcher"":
waiting to lock monitor 0x009bf334 (object 0x11ea79c0, a org.eclipse.ui.internal.WorkbenchPlugin), which is held by ""main""
Java stack information for the threads listed above:
===================================================
""main"":
at
org.eclipse.ui.internal.AbstractWorkingSetManager.addToUpdater(AbstractWorkingSetManager.java:511)
- waiting to lock <0x13010d00> (a org.eclipse.ui.internal.WorkingSetManager)
at
org.eclipse.ui.internal.AbstractWorkingSetManager.internalAddWorkingSet(AbstractWorkingSetManager.java:153)
at
org.eclipse.ui.internal.AbstractWorkingSetManager.restoreWorkingSetState(AbstractWorkingSetManager.java:338)
at
org.eclipse.ui.internal.WorkingSetManager.restoreState(WorkingSetManager.java:107)
at
org.eclipse.ui.internal.WorkbenchPlugin.getWorkingSetManager(WorkbenchPlugin.java:432)
- locked <0x11ea79c0> (a org.eclipse.ui.internal.WorkbenchPlugin)
at
org.eclipse.ui.internal.Workbench.getWorkingSetManager(Workbench.java:804)
at
org.eclipse.ui.internal.ide.actions.BuildSetMenu.fillMenu(BuildSetMenu.java:100)
at
org.eclipse.ui.internal.ide.actions.BuildSetMenu.fill(BuildSetMenu.java:87)
at org.eclipse.jface.action.MenuManager.update(MenuManager.java:625)
at org.eclipse.jface.action.MenuManager.update(MenuManager.java:547)
at org.eclipse.jface.action.MenuManager.fill(MenuManager.java:232)
at org.eclipse.jface.action.MenuManager.update(MenuManager.java:625)
at org.eclipse.jface.action.MenuManager.update(MenuManager.java:547)
at org.eclipse.jface.action.MenuManager.fill(MenuManager.java:232)
at org.eclipse.jface.action.MenuManager.update(MenuManager.java:625)
at org.eclipse.jface.action.MenuManager.update(MenuManager.java:547)
at org.eclipse.jface.action.MenuManager.createMenuBar(MenuManager.java:158)
at org.eclipse.jface.action.MenuManager.createMenuBar(MenuManager.java:174)
at
org.eclipse.ui.internal.WorkbenchWindow.createDefaultContents(WorkbenchWindow.java:810)
at
org.eclipse.ui.internal.WorkbenchWindowConfigurer.createDefaultContents(WorkbenchWindowConfigurer.java:573)
at
org.eclipse.ui.application.WorkbenchWindowAdvisor.createWindowContents(WorkbenchWindowAdvisor.java:352)
at
org.eclipse.ui.internal.WorkbenchWindow.createContents(WorkbenchWindow.java:778)
at org.eclipse.jface.window.Window.create(Window.java:375)
at org.eclipse.ui.internal.Workbench.restoreState(Workbench.java:1434)
at org.eclipse.ui.internal.Workbench.access$9(Workbench.java:1409)
at org.eclipse.ui.internal.Workbench$14.run(Workbench.java:1312)
at
org.eclipse.core.internal.runtime.InternalPlatform.run(InternalPlatform.java:1015)
at org.eclipse.core.runtime.Platform.run(Platform.java:757)
at org.eclipse.ui.internal.Workbench.restoreState(Workbench.java:1246)
at
org.eclipse.ui.internal.WorkbenchConfigurer.restoreState(WorkbenchConfigurer.java:171)
at
org.eclipse.ui.application.WorkbenchAdvisor.openWindows(WorkbenchAdvisor.java:711)
at org.eclipse.ui.internal.Workbench.init(Workbench.java:918)
at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1554)
at
org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:293)
at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:144)
at org.eclipse.ui.internal.ide.IDEApplication.run(IDEApplication.java:102)
at
org.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:228)
at
org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:333)
at
org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:150)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:324)
at org.eclipse.core.launcher.Main.invokeFramework(Main.java:268)
at org.eclipse.core.launcher.Main.basicRun(Main.java:260)
at org.eclipse.core.launcher.Main.run(Main.java:887)
at org.eclipse.core.launcher.Main.main(Main.java:871)
""Framework Event Dispatcher"":
at
org.eclipse.ui.internal.WorkbenchPlugin.getWorkingSetRegistry(WorkbenchPlugin.java:444)
- waiting to lock <0x11ea79c0> (a org.eclipse.ui.internal.WorkbenchPlugin)
at
org.eclipse.ui.internal.AbstractWorkingSetManager.bundleChanged(AbstractWorkingSetManager.java:485)
- locked <0x13010d00> (a org.eclipse.ui.internal.WorkingSetManager)
at
org.eclipse.osgi.framework.internal.core.BundleContextImpl.dispatchEvent(BundleContextImpl.java:1206)
at
org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:186)
at org.eclipse.osgi.framework.eventmgr.EventThread.run(EventThread.java:104)
Found 1 deadlock.","org.eclipse.ui.internal.AbstractWorkingSetManager
org.eclipse.ui.IWorkingSetUpdater"
FILE,eclipse-3.1,87171,2005-03-04T14:19:00.000-06:00,Find declaring node doesn't work for methods/fields using type parameters,"public class Inline<T> {
	void foo(T t) {
		System.out.println(t);
	}
}

 class Use {
	public static void main(String[] args) {
		Inline<String> i= null;
		i.foo(""Eclipse"");
	}
}

  i.foo(""Eclipse"");
 
 root.findDeclaringNode(methodBinding);
public class Inline<T> {
	void foo(T t) {
		System.out.println(t);
	}
}
class Use {
	public static void main(String[] args) {
		Inline<String> i= null;
		i.foo(""Eclipse"");
	}
}
observe: null is returned although the CU contains the corresponding declaration.
Please note that the same happens for fields using type parameters.","org.eclipse.jdt.core.dom.CompilationUnit
org.eclipse.jdt.core.dom.DefaultBindingResolver"
FILE,eclipse-3.1,87211,2005-03-05T13:36:00.000-06:00,[PresentationAPI] standalone + movable stacks should remain standalone when dragged,"The dragOver()  
   
   
 PartStack.getDropTarget()
The dragOver() method for a custom presentation is not called when an entire 
stack (i.e. ViewStack) is being dragged.
Thus, you cannot prevent a ViewStack 
from being dropped onto another ViewStack.
The offending code seems to be in PartStack.getDropTarget().
I'm trying to code my presentation such that views can be dragged around and 
repositioned, but views cannot be combined with other views.","org.eclipse.ui.internal.ide.dialogs.ResourceTreeAndListGroup
org.eclipse.ui.internal.PartSashContainer"
FILE,eclipse-3.1,87569,2005-03-09T16:41:00.000-06:00,Infinte loop obtaining image when switching to Debug Perspective,"class which implements java.io.Serializable
I20050308-1510
3XMTHREADINFO      ""main"" (TID:0x02A08A00, sys_thread_t:0x000356F4, state:CW,
native ID:0x000009F4) prio=6
4XESTACKTRACE          at java/lang/Throwable.printStackTrace(Throwable.java:241)
4XESTACKTRACE          at
org/eclipse/core/runtime/CoreException.printStackTrace(CoreException.java:94)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseLog.getStackTrace(EclipseLog.java:316)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseLog.writeStack(EclipseLog.java:372)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseLog.writeLog(EclipseLog.java:337)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseLog.log(EclipseLog.java:208)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/PlatformLogWriter.logging(PlatformLogWriter.java:35)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform$1.run(InternalPlatform.java:831)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform.run(InternalPlatform.java:1015)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform.log(InternalPlatform.java:834)
4XESTACKTRACE          at org/eclipse/core/internal/runtime/Log.log(Log.java:56)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DebugUIPlugin.log(DebugUIPlugin.java:497)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DebugUIPlugin.log(DebugUIPlugin.java:506)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImageKey(DefaultLabelProvider.java:133)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:57)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
...
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/DebugViewInterimLabelProvider.getImage(DebugViewInterimLabelProvider.java:62)
4XESTACKTRACE          at
org/eclipse/jface/viewers/DecoratingLabelProvider.getImage(DecoratingLabelProvider.java:82)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/RemoteTreeViewer.doUpdateItem(RemoteTreeViewer.java:448)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer$UpdateItemSafeRunnable.run(AbstractTreeViewer.java:86)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform.run(InternalPlatform.java:1015)
4XESTACKTRACE          at org/eclipse/core/runtime/Platform.run(Platform.java:757)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.doUpdateItem(AbstractTreeViewer.java:490)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer$UpdateItemSafeRunnable.run(StructuredViewer.java:352)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform.run(InternalPlatform.java:1015)
4XESTACKTRACE          at org/eclipse/core/runtime/Platform.run(Platform.java:757)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer.updateItem(StructuredViewer.java:1655)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.updateChildren(AbstractTreeViewer.java:1621)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.internalRefreshStruct(AbstractTreeViewer.java:1109)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.internalRefresh(AbstractTreeViewer.java:1086)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.internalRefresh(AbstractTreeViewer.java:1047)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.internalRefresh(AbstractTreeViewer.java:1034)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer$7.run(StructuredViewer.java:1172)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer.preservingSelection(StructuredViewer.java:1109)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer.refresh(StructuredViewer.java:1170)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/LaunchViewer.refresh(LaunchViewer.java:80)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer.refresh(StructuredViewer.java:1129)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/AbstractDebugEventHandler.refresh(AbstractDebugEventHandler.java:255)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/AbstractDebugEventHandler.viewBecomesVisible(AbstractDebugEventHandler.java:348)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/AbstractDebugEventHandlerView.becomesVisible(AbstractDebugEventHandlerView.java:69)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/LaunchView.becomesVisible(LaunchView.java:1061)
4XESTACKTRACE          at
org/eclipse/debug/ui/AbstractDebugView$DebugViewPartListener.partVisible(AbstractDebugView.java:162)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartListenerList2$7.run(PartListenerList2.java:168)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform.run(InternalPlatform.java:1015)
4XESTACKTRACE          at org/eclipse/core/runtime/Platform.run(Platform.java:757)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartListenerList2.fireEvent(PartListenerList2.java:54)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartListenerList2.firePartVisible(PartListenerList2.java:166)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage$1.propertyChange(WorkbenchPage.java:179)
4XESTACKTRACE          at
org/eclipse/ui/internal/LayoutPart.setVisible(LayoutPart.java:305)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartPane.setVisible(PartPane.java:331)
4XESTACKTRACE          at
org/eclipse/ui/internal/ViewPane.setVisible(ViewPane.java:614)
4XESTACKTRACE          at
org/eclipse/ui/internal/presentations/PresentablePart.setVisible(PresentablePart.java:126)
4XESTACKTRACE          at
org/eclipse/ui/internal/presentations/newapi/PresentablePartFolder.select(PresentablePartFolder.java:266)
4XESTACKTRACE          at
org/eclipse/ui/internal/presentations/newapi/LeftToRightTabOrder.select(LeftToRightTabOrder.java:65)
4XESTACKTRACE          at
org/eclipse/ui/internal/presentations/newapi/TabbedStackPresentation.selectPart(TabbedStackPresentation.java:391)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartStack.refreshPresentationSelection(PartStack.java:1051)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartStack.createControl(PartStack.java:536)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartStack.createControl(PartStack.java:473)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartSashContainer.createControl(PartSashContainer.java:485)
4XESTACKTRACE          at
org/eclipse/ui/internal/PerspectiveHelper.activate(PerspectiveHelper.java:230)
4XESTACKTRACE          at
org/eclipse/ui/internal/Perspective.onActivate(Perspective.java:773)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage.setPerspective(WorkbenchPage.java:2829)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage.busySetPerspective(WorkbenchPage.java:845)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage.access$10(WorkbenchPage.java:830)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage$13.run(WorkbenchPage.java:2980)
4XESTACKTRACE          at
org/eclipse/swt/custom/BusyIndicator.showWhile(BusyIndicator.java:69)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage.setPerspective(WorkbenchPage.java:2978)
4XESTACKTRACE          at
org/eclipse/ui/internal/PerspectiveBarContributionItem.select(PerspectiveBarContributionItem.java:109)
4XESTACKTRACE          at
org/eclipse/ui/internal/PerspectiveBarManager$1.widgetSelected(PerspectiveBarManager.java:145)
4XESTACKTRACE          at
org/eclipse/swt/widgets/TypedListener.handleEvent(TypedListener.java:89)
4XESTACKTRACE          at
org/eclipse/swt/widgets/EventTable.sendEvent(EventTable.java:82)
4XESTACKTRACE          at org/eclipse/swt/widgets/Widget.sendEvent(Widget.java:842)
4XESTACKTRACE          at
org/eclipse/swt/widgets/Display.runDeferredEvents(Display.java:2894)
4XESTACKTRACE          at
org/eclipse/swt/widgets/Display.readAndDispatch(Display.java:2527)
4XESTACKTRACE          at
org/eclipse/ui/internal/PerspectiveBarManager.handleChevron(PerspectiveBarManager.java:161)
4XESTACKTRACE          at
org/eclipse/ui/internal/PerspectiveSwitcher$9.widgetSelected(PerspectiveSwitcher.java:766)
4XESTACKTRACE          at
org/eclipse/swt/widgets/TypedListener.handleEvent(TypedListener.java:89)
4XESTACKTRACE          at
org/eclipse/swt/widgets/EventTable.sendEvent(EventTable.java:82)
4XESTACKTRACE          at org/eclipse/swt/widgets/Widget.sendEvent(Widget.java:842)
4XESTACKTRACE          at
org/eclipse/swt/widgets/Display.runDeferredEvents(Display.java:2894)
4XESTACKTRACE          at
org/eclipse/swt/widgets/Display.readAndDispatch(Display.java:2527)
4XESTACKTRACE          at
org/eclipse/ui/internal/Workbench.runEventLoop(Workbench.java:1514)
4XESTACKTRACE          at
org/eclipse/ui/internal/Workbench.runUI(Workbench.java:1478)
4XESTACKTRACE          at
org/eclipse/ui/internal/Workbench.createAndRunWorkbench(Workbench.java:297)
4XESTACKTRACE          at
org/eclipse/ui/PlatformUI.createAndRunWorkbench(PlatformUI.java:143)
4XESTACKTRACE          at
org/eclipse/ui/internal/ide/IDEApplication.run(IDEApplication.java:103)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/PlatformActivator$1.run(PlatformActivator.java:228)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseStarter.run(EclipseStarter.java:338)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseStarter.run(EclipseStarter.java:151)
4XESTACKTRACE          at sun/reflect/NativeMethodAccessorImpl.invoke0(Native
Method)
4XESTACKTRACE          at
sun/reflect/NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:85)
4XESTACKTRACE          at
sun/reflect/NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:58)
4XESTACKTRACE          at
sun/reflect/DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:60)
4XESTACKTRACE          at java/lang/reflect/Method.invoke(Method.java:391)
4XESTACKTRACE          at
org/eclipse/core/launcher/Main.invokeFramework(Main.java:268)
4XESTACKTRACE          at org/eclipse/core/launcher/Main.basicRun(Main.java:260)
4XESTACKTRACE          at org/eclipse/core/launcher/Main.run(Main.java:887)
4XESTACKTRACE          at org/eclipse/core/launcher/Main.main(Main.java:871)",org.eclipse.debug.internal.ui.DefaultLabelProvider
FILE,eclipse-3.1,87665,2005-03-10T11:38:00.000-06:00,Clicking on x on performance page opens details with no errors,"testOpenJavaEditor1()
http://fullmoon.rtp.raleigh.ibm.com/downloads/drops/M-3.0.2RC2-200502161722/performance/org.eclipse.jdt.text.php?
Observe: red x for RHEL 3.0 Sun 1.4.2_06.
Looks like a bug regarding the handling of negative numbers.","org.eclipse.swt.printing.PrintDialog
org.eclipse.swt.widgets.MessageBox"
FILE,eclipse-3.1,87796,2005-03-11T12:18:00.000-06:00,[WorkbenchParts] IWorkbenchSite.getShell() returns null / every text-based editor is leaked,"AbstractTextEditor.dispose() 
 Shell shell= getSite().getShell();
	if (shell != null && !shell.isDisposed())
		shell.removeShellListener(fActivationListener);

  getSite()  getShell()
I20050311-1510
When the editor gets closed (AbstractTextEditor.dispose()) we do the following:
Shell shell= getSite().
getShell();
	if (shell !
= null && !
shell.isDisposed())
		shell.removeShellListener(fActivationListener);
The bad thing is that getSite().
getShell() returns null (which it did not in
previous released like 3.0.2).
This now causes every single editor to be kept in
memory until the workbench window gets closed.
This is most likely also the cause for bug 76077.","org.eclipse.jface.bindings.BindingManager
org.eclipse.ui.keys.IBindingService
org.eclipse.ui.internal.PartSite
org.eclipse.ui.internal.keys.BindingService"
FILE,eclipse-3.1,88295,2005-03-17T03:34:00.000-06:00,[1.5][assist] too many completion on enum case label,"public class Class3 {

	enum Color {
		BLUE, WHITE, RED;
	}
	
	void select(Color c) {
		
		switch(c){
			case BLUE :
			case WHITE:
			case R<|>
		}
	}
}
20050315
public class Class3 {
enum Color {
BLUE, WHITE, RED;
} void select(Color c) { switch(c){ case BLUE :
case WHITE:
case R<|>
}
}
}",org.eclipse.jdt.internal.codeassist.CompletionEngine
FILE,eclipse-3.1,88339,2005-03-17T10:49:00.000-06:00,configuration area tests failing if bundles are JAR'd,"Platform.asLocalURL(IPluginDescriptor.getInstallURL())
n20050317
The configuration area tests failed because org.eclipse.osgi and org.eclipse.core.runtime were in JAR'd form.
This has the following effects:
Platform.asLocalURL(IPluginDescriptor.getInstallURL())
returns a URL in the form jar:file:/path/file.jar!
/ but such URLs are not supported by the framework/Main.
Changing them to be file:/path/file.jar works.
See also bug 86195.","org.eclipse.jdt.internal.debug.ui.JDIModelPresentation
org.eclipse.debug.internal.ui.DefaultLabelProvider
org.eclipse.debug.internal.ui.DebugUIMessages
org.eclipse.jdt.internal.debug.ui.snippeteditor.JavaSnippetEditor"
FILE,eclipse-3.1,89014,2005-03-24T13:10:00.000-06:00,IMethodBinding#isEqualTo(..) returns true for methods in different anonymous classes,"run()  
 public class Try {
	Runnable one= new Runnable(){
		public void run() {
		}
	};
	Runnable two= new Runnable(){
		public void run() {
		}
	};
}
I20050323-1615
IMethodBinding#isEqualTo(.
.)
returns true for methods in different anonymous classes.
Here, the two run() methods are said to be equal:
public class Try {
Runnable one= new Runnable(){ public void run() {
}
};
Runnable two= new Runnable(){ public void run() {
}
};
}",org.eclipse.jdt.core.dom.BindingComparator
FILE,eclipse-3.1,89621,2005-03-30T12:41:00.000-06:00,[code assist] the caret position is wrong after code assist,"import java.awt.Frame;
import java.awt.event.WindowAdapter;

public class Foo extends Frame {

    public void bar() {
        addWindow<CODE ASSIST HERE>Listener(new WindowAdapter());
    }
}
Using 20030330-0500, I got this weird behavior.
import java.awt.Frame;
import java.awt.event.WindowAdapter;
public class Foo extends Frame {
public void bar() { addWindow<CODE ASSIST HERE>Listener(new WindowAdapter());
}
}
The result is:
addWindowListene<POSITION OF THE CARET>rListener
addWindowListener<POSITION OF THE CARET>Listener
This is pretty annoying and seems to occur only for method name proposal.","org.eclipse.jdt.ui.text.java.CompletionProposalCollector
org.eclipse.jdt.internal.ui.text.java.ExperimentalResultCollector
org.eclipse.jdt.internal.ui.text.java.GenericJavaTypeProposal"
FILE,eclipse-3.1,89632,2005-03-30T13:10:00.000-06:00,Exception when trying to evaluate in Snippet Editor,"Collection<String> c = new ArrayList<String>();
        c.add(""a"");
        c.add(""b"");
        c.add(""c"");

        for (Iterator<String> i = c.iterator(); i.hasNext(); )
            if (i.next().length() == 4)
            {
                String x = i.next();
                System.out.println(x);
            }
        
        return c;

 
   
  run()
Collection<String> c = new ArrayList<String>();
c.add(""a"");
c.add(""b"");
c.add(""c"");
for (Iterator<String> i = c.iterator(); i.hasNext(); )
if (i.next().
length() == 4)
{
String x = i.next();
System.out.println(x);
} return c;
Trying a ""Display"" or ""Inspect"" resulted in the following error in the console:
java.lang.VerifyError: arguments are not type compatible (class: CodeSnippet_2 method: run()V) at pc: 57
at java.lang.Class.verifyImpl(Native Method)
at java.lang.Class.verify(Class.java:254)
at java.lang.Class.initialize(Class.java:317)
at java.lang.Class.forNameImpl(Native Method)
at java.lang.Class.forName(Class.java:128)
at org.eclipse.jdt.internal.debug.ui.snippeteditor.ScrapbookMain1.eval
(ScrapbookMain1.java:20)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke
(NativeMethodAccessorImpl.java:46)
at sun.reflect.DelegatingMethodAccessorImpl.invoke
(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:611)
at org.eclipse.jdt.internal.debug.ui.snippeteditor.ScrapbookMain.evalLoop
(ScrapbookMain.java:54)
at org.eclipse.jdt.internal.debug.ui.snippeteditor.ScrapbookMain.main
(ScrapbookMain.java:35)",org.eclipse.jdt.internal.eval.CodeSnippetMessageSend
FILE,eclipse-3.1,90283,2005-04-05T08:56:00.000-05:00,[WorkbenchParts]IPartListener2#partInputChanged is not being sent,"partActivated(IWorkbenchPartReference ref)  
 ref.getId()  
 ref.getPart(true)  getSite()  
 ASTProvider.ActivationListener.isJavaEditor()
3.1 M6
We (ASTProvider) receive partActivated(IWorkbenchPartReference ref) where:
ref.getId() -> null ref.getPart(true).
getSite() -> correct id.
Test Case:
==> occurrence marking not working
To see the null value you can put a breakpoint in
ASTProvider.ActivationListener.isJavaEditor().
Might be related to bug 89374.",org.eclipse.ui.texteditor.AbstractTextEditor
FILE,eclipse-3.1,90289,2005-04-05T09:17:00.000-05:00,>1 debug worker thread calling IStackFrame.getVariables(),"IStackFrame.getVariables()
M6 driver
If I add a Suspsend VM breakpoint on the call to IStackFrame.getVariables() in 
my StackFrame object, I am seeing it hit 2 or more times.
As a result the Variables view shows duplicates of my local variables.","org.eclipse.debug.internal.ui.views.variables.VariablesViewEventHandler
org.eclipse.debug.internal.ui.views.registers.RegistersView
org.eclipse.debug.internal.ui.views.registers.RegistersViewEventHandler
org.eclipse.debug.internal.ui.views.expression.ExpressionViewEventHandler"
FILE,eclipse-3.1,91098,2005-04-12T06:07:00.000-05:00,The Mark Occurrences feature does not mark all occurrences,"String a;
String[] b;
String[][] c;
String a;
String[] b;
String[][] c;
All occurrences of String get highlighted.
No occurrence of String is highlighted.
It
looks like there is a missing loop when removing square brackets ;o)
I use 3.1M6.
Best regards,
Cyril",org.eclipse.jdt.core.dom.ASTConverter
FILE,eclipse-3.1,91346,2005-04-13T16:43:00.000-05:00,available property reference not found for marking occurrences,"{buildDirectory}
<project name=""project"" default=""default"">
	<property name=""buildDirectory"" location=""C:\buildDirectory"" />
	<target name=""default"">
		<available property=""${buildDirectory}"" file=""available2.xml"" />
		<echo message=""${C:\buildDirectory2}""></echo>
	</target>
</project>
Cursor in property=""${buildDirectory}"" does not mark the property declaration 
occurrence",org.eclipse.ant.internal.ui.model.AntPropertyNode
FILE,eclipse-3.1,92236,2005-04-21T11:12:00.000-05:00,ConcurrentModificationException on shutdown,"org.eclipse.team.internal.core.TeamPlugin.stop()
Build: I20050419
I found the following exception in my log.
org.osgi.framework.BundleException: Exception in org.eclipse.team.internal.core.TeamPlugin.stop() of bundle org.eclipse.team.core.
at
org.eclipse.osgi.framework.internal.core.BundleContextImpl.stop(BundleContextImpl.java:1061)
at
org.eclipse.osgi.framework.internal.core.BundleHost.stopWorker(BundleHost.java:402)
at
org.eclipse.osgi.framework.internal.core.AbstractBundle.stop(AbstractBundle.java:410)
at
org.eclipse.core.runtime.adaptor.BundleStopper.basicStopBundles(BundleStopper.java:73)
at
org.eclipse.core.runtime.adaptor.BundleStopper.stopBundles(BundleStopper.java:62)
at
org.eclipse.core.runtime.adaptor.EclipseAdaptor.frameworkStopping(EclipseAdaptor.java:695)
at org.eclipse.osgi.framework.internal.core.Framework.shutdown(Framework.java:502)
at
org.eclipse.osgi.framework.internal.core.SystemBundle$1.run(SystemBundle.java:171)
at java.lang.Thread.run(Thread.java:813)
Caused by: java.util.ConcurrentModificationException
at java.util.HashMap$HashIterator.nextEntry(HashMap.java:930)
at java.util.HashMap$KeyIterator.next(HashMap.java:966)
at
org.eclipse.team.internal.core.ResourceVariantCache.shutdown(ResourceVariantCache.java:102)
at org.eclipse.team.internal.core.TeamPlugin.stop(TeamPlugin.java:81)
at
org.eclipse.osgi.framework.internal.core.BundleContextImpl$3.run(BundleContextImpl.java:1045)
at java.security.AccessController.doPrivileged(AccessController.java:202)
at
org.eclipse.osgi.framework.internal.core.BundleContextImpl.stop(BundleContextImpl.java:1041)
at
org.eclipse.osgi.framework.internal.core.BundleHost.stopWorker(BundleHost.java:402)
at
org.eclipse.osgi.framework.internal.core.AbstractBundle.stop(AbstractBundle.java:410)
at
org.eclipse.core.runtime.adaptor.BundleStopper.basicStopBundles(BundleStopper.java:73)
at
org.eclipse.core.runtime.adaptor.BundleStopper.stopBundles(BundleStopper.java:62)
at
org.eclipse.core.runtime.adaptor.EclipseAdaptor.frameworkStopping(EclipseAdaptor.java:695)
at org.eclipse.osgi.framework.internal.core.Framework.shutdown(Framework.java:502)
at
org.eclipse.osgi.framework.internal.core.SystemBundle$1.run(SystemBundle.java:171)
at java.lang.Thread.run(Thread.java:813)",org.eclipse.team.internal.core.ResourceVariantCache
FILE,eclipse-3.1,92291,2005-04-21T16:48:00.000-05:00,[Commands] Util.compare uses toString(),"Util.compare(Object, Object)   toString() 
 org.eclipse.ui.commands.HandlerSubmission.compareTo(Object)  
 org.eclipse.ui.contexts.EnabledSubmission.compareTo(Object)
build I20050420-1200
Noticed that Util.compare(Object, Object) compares the toString()s of the args.
This could be very inefficient (not to mention inaccurate).
The only callers are:
org.eclipse.ui.commands.HandlerSubmission.compareTo(Object) (3 matches)
org.eclipse.ui.contexts.EnabledSubmission.compareTo(Object) (2 matches)
where they compare site objects.
Not sure why it's necessary to do this.
There's no well-defined order between
site objects.",org.eclipse.ui.internal.util.Util
FILE,eclipse-3.1,92451,2005-04-22T16:36:00.000-05:00,code assist failure: new+cast+arrays,"public class Test {
	public static void main(String[] args) {
		java.util.List elements = null;
		// code assist works on this line
		new Test(Test.toStrings((Test[])elements.toArray(new Test
[0])));
		//code assist fails on this line
	}
	public Test(Object object) {
	}
	public static Object toStrings(Test[] objects) {
		return null;
	}
}
I20050419
J2SE 5 (but also fails in JDK 1.4)
Code assist fails in the following (self-contained) class (see comments for line of error)
public class Test { public static void main(String[] args) { java.util.List elements = null;
// code assist works on this line new Test(Test.toStrings((Test[])elements.toArray(new Test
[0])));
//code assist fails on this line
} public Test(Object object) {
} public static Object toStrings(Test[] objects) { return null;
}
}",org.eclipse.jdt.internal.codeassist.complete.CompletionParser
FILE,eclipse-3.1,92602,2005-04-25T12:07:00.000-05:00,Deadlock in reentrant lock acquire during waitEnd,"ThreadJob.joinRun(IProgressMonitor)  
      
 JobManager.beginRule(ISchedulingRule, IProgressMonitor)  
 WorkManager.checkIn(ISchedulingRule, IProgressMonitor)  
 Workspace.prepareOperation(ISchedulingRule, IProgressMonitor)  
    
    
 SynchronizationManager$ActivationListener.handleActivated(ResourceInfo)  
 SynchronizationManager$ActivationListener.handleActivated()  
 SynchronizationManager$ActivationListener.windowActivated(IWorkbenchWindow)
 
 Workbench$6.run()  
 InternalPlatform.run(ISafeRunnable)  
 Platform.run(ISafeRunnable)  
 Workbench.fireWindowActivated(IWorkbenchWindow)  
 WorkbenchWindow$5.shellActivated(ShellEvent)  
 TypedListener.handleEvent(Event)  
 EventTable.sendEvent(Event)  
 sendEvent(Event)  
  
  
  
  
  
  
 destroyWidget()  
 dispose()  
 dispose()  
 Shell.dispose()  
   close()  
   close()  
 BlockedJobsDialog.close()  
 BlockedJobsDialog.close(IProgressMonitor)  
 BlockedJobsDialog.clear(IProgressMonitor)  
 WorkbenchDialogBlockedHandler.clearBlocked()  
 EventLoopProgressMonitor.clearBlocked()  
 JobManager.reportUnblocked(IProgressMonitor)  
 ThreadJob.waitEnd(IProgressMonitor)  
 ThreadJob.joinRun(IProgressMonitor)  
      
 JobManager.beginRule(ISchedulingRule, IProgressMonitor)  
 WorkManager.checkIn(ISchedulingRule, IProgressMonitor)  
 Workspace.prepareOperation(ISchedulingRule, IProgressMonitor)  
    
    
 URIConverterImpl$WorkbenchHelper.createPlatformResourceInputStream(String)
 
 URIConverterImpl.createPlatformResourceInputStream(String)  
 URIConverterImpl.createInputStream(URI)  
    
 MonUtils.loadResource(ResourceSet, String)  
 MonUtils.getMonitorResource(ResourceSet, String)  
 MonUtils.getMonitorResource(Resource)  
     initializeMonAdapters()  
     
   
 Class.newInstanceImpl()  
 Class.newInstance()  
 ConfigurationElement.createExecutableExtension(Bundle, String, Object,
IConfigurationElement, String)  
 ConfigurationElement.createExecutableExtension(Bundle, String, String, Object,
IConfigurationElement, String)  
 ConfigurationElement.createExecutableExtension(String)  
 SectionDescriptor.getSectionClass()  
 TabDescriptor.createTab()  
        
     setInput(IWorkbenchPart,
ISelection)  
     selectionChanged(IWorkbenchPart,
ISelection)  
 BPELTabbedPropertySheetPage.selectionChanged(IWorkbenchPart, ISelection)  
 PropertySheet.selectionChanged(IWorkbenchPart, ISelection)  
 AbstractSelectionService$3.run()  
 InternalPlatform.run(ISafeRunnable)  
 Platform.run(ISafeRunnable)  
     fireSelection(IWorkbenchPart,
ISelection)  
     partActivated(IWorkbenchPart)
 
 WorkbenchPage.firePartActivated(IWorkbenchPart)  
 WorkbenchPage.setActivePart(IWorkbenchPart)  
 WorkbenchPage.activate(IWorkbenchPart)  
    
    
      
 WorkbenchPage$9.run()  
 BusyIndicator.showWhile(Display, Runnable)  
    
      
 SCDLUIUtils.openEditor(IWorkbenchPart, IFileEditorInput)  
 SCDLUIUtils.openEditor(IWorkbenchPart, IFile)  
 ComponentEditPart.performOpen()  
     performRequest(Request)  
 CreateImplementationAction.run()  
   runWithEvent(Event)  
  
    
 ActionContributionItem$7.handleEvent(Event)  
 EventTable.sendEvent(Event)  
   sendEvent(Event)  
 Display.runDeferredEvents()  
 Display.readAndDispatch()  
 Workbench.runEventLoop(Window$IExceptionHandler, Display)  
 Workbench.runUI()  
 Workbench.createAndRunWorkbench(Display, WorkbenchAdvisor)  
 PlatformUI.createAndRunWorkbench(Display, WorkbenchAdvisor)  
 IDEApplication.run(Object)  
 PlatformActivator$1.run(Object)  
 EclipseStarter.run(Object)
Build: Release 3.0.0
1 Thread is waiting for scheduling rule
2 Thread gets rule, thread job starts running
3 After the thread job starts, we call waitEnd, which calls the UI to close the
blocked job dialog.
4 If this call to the UI results in a recursive attempt to acquire the same
lock, the thread deadlocks with itself.
We need to be adding the thread job to the list of running jobs before calling
waitEnd, or the loop in joinRun should handle the case where the blocking job is
itself.
Here is an example stack:
Thread [main] (Suspended (breakpoint at line 149 in ThreadJob))
ThreadJob.joinRun(IProgressMonitor) line: 149
ImplicitJobs.begin(ISchedulingRule, IProgressMonitor, boolean) line: 87
JobManager.beginRule(ISchedulingRule, IProgressMonitor) line: 170
WorkManager.checkIn(ISchedulingRule, IProgressMonitor) line: 95
Workspace.prepareOperation(ISchedulingRule, IProgressMonitor) line: 1628
File(Resource).refreshLocal(int, IProgressMonitor) line: 1224
File.refreshLocal(int, IProgressMonitor) line: 311
SynchronizationManager$ActivationListener.handleActivated(ResourceInfo) line: 231
SynchronizationManager$ActivationListener.handleActivated() line: 164
SynchronizationManager$ActivationListener.windowActivated(IWorkbenchWindow)
line: 126
Workbench$6.run() line: 369
InternalPlatform.run(ISafeRunnable) line: 616
Platform.run(ISafeRunnable) line: 747
Workbench.fireWindowActivated(IWorkbenchWindow) line: 367
WorkbenchWindow$5.shellActivated(ShellEvent) line: 1917
TypedListener.handleEvent(Event) line: 163
EventTable.sendEvent(Event) line: 82
Shell(Widget).sendEvent(Event) line: 796
Shell(Widget).sendEvent(int, Event, boolean) line: 820
Shell(Widget).sendEvent(int) line: 801
Shell(Decorations).WM_ACTIVATE(int, int) line: 1435
Shell.WM_ACTIVATE(int, int) line: 1336
Shell(Control).windowProc(int, int, int, int) line: 2969
Shell(Decorations).windowProc(int, int, int, int) line: 1391
Display.windowProc(int, int, int, int) line: 3339
OS.DestroyWindow(int) line: not available [native method]
Shell(Control).destroyWidget() line: 505
Shell(Widget).dispose() line: 369
Shell(Decorations).dispose() line: 347
Shell.dispose() line: 487
BlockedJobsDialog(Window).close() line: 253
BlockedJobsDialog(Dialog).close() line: 826
BlockedJobsDialog.close() line: 416
BlockedJobsDialog.close(IProgressMonitor) line: 404
BlockedJobsDialog.clear(IProgressMonitor) line: 228
WorkbenchDialogBlockedHandler.clearBlocked() line: 42
EventLoopProgressMonitor.clearBlocked() line: 69
JobManager.reportUnblocked(IProgressMonitor) line: 743
ThreadJob.waitEnd(IProgressMonitor) line: 264
ThreadJob.joinRun(IProgressMonitor) line: 166
ImplicitJobs.begin(ISchedulingRule, IProgressMonitor, boolean) line: 87
JobManager.beginRule(ISchedulingRule, IProgressMonitor) line: 170
WorkManager.checkIn(ISchedulingRule, IProgressMonitor) line: 95
Workspace.prepareOperation(ISchedulingRule, IProgressMonitor) line: 1628
File(Resource).refreshLocal(int, IProgressMonitor) line: 1224
File.refreshLocal(int, IProgressMonitor) line: 311
URIConverterImpl$WorkbenchHelper.createPlatformResourceInputStream(String)
line: 193
URIConverterImpl.createPlatformResourceInputStream(String) line: 446
URIConverterImpl.createInputStream(URI) line: 404
XmlResource(ResourceImpl).load(Map) line: 738
MonUtils.loadResource(ResourceSet, String) line: 307
MonUtils.getMonitorResource(ResourceSet, String) line: 196
MonUtils.getMonitorResource(Resource) line: 144
BpelCEISection(CEISection).initializeMonAdapters() line: 3173
BpelCEISection(CEISection).<init>() line: 850
BpelCEISection.<init>() line: 77
Class.newInstanceImpl() line: not available [native method]
Class.newInstance() line: 1437
ConfigurationElement.createExecutableExtension(Bundle, String, Object,
IConfigurationElement, String) line: 141
ConfigurationElement.createExecutableExtension(Bundle, String, String, Object,
IConfigurationElement, String) line: 124
ConfigurationElement.createExecutableExtension(String) line: 113
SectionDescriptor.getSectionClass() line: 174
TabDescriptor.createTab() line: 203
BPELTabbedPropertySheetPage(TabbedPropertySheetPage).updateTabs(TabDescriptor[],
Object) line: 498
BPELTabbedPropertySheetPage(TabbedPropertySheetPage).setInput(IWorkbenchPart,
ISelection) line: 548
BPELTabbedPropertySheetPage(TabbedPropertySheetPage).selectionChanged(IWorkbenchPart,
ISelection) line: 415
BPELTabbedPropertySheetPage.selectionChanged(IWorkbenchPart, ISelection) line: 77
PropertySheet.selectionChanged(IWorkbenchPart, ISelection) line: 185
AbstractSelectionService$3.run() line: 153
InternalPlatform.run(ISafeRunnable) line: 616
Platform.run(ISafeRunnable) line: 747
PageSelectionService(AbstractSelectionService).fireSelection(IWorkbenchPart,
ISelection) line: 151
PageSelectionService(AbstractSelectionService).partActivated(IWorkbenchPart)
line: 242
WorkbenchPage.firePartActivated(IWorkbenchPart) line: 1372
WorkbenchPage.setActivePart(IWorkbenchPart) line: 2738
WorkbenchPage.activate(IWorkbenchPart) line: 457
WorkbenchPage.busyOpenEditorBatched(IEditorInput, String, boolean) line: 2258
WorkbenchPage.busyOpenEditor(IEditorInput, String, boolean) line: 2177
WorkbenchPage.access$6(WorkbenchPage, IEditorInput, String, boolean) line: 2169
WorkbenchPage$9.run() line: 2156
BusyIndicator.showWhile(Display, Runnable) line: 69
WorkbenchPage.openEditor(IEditorInput, String, boolean) line: 2151
IDE.openEditor(IWorkbenchPage, IEditorInput, String, boolean) line: 268
SCDLUIUtils.openEditor(IWorkbenchPart, IFileEditorInput) line: 194
SCDLUIUtils.openEditor(IWorkbenchPart, IFile) line: 185
ComponentEditPart.performOpen() line: 171
ComponentEditPart(SCDLNodeEditPart).performRequest(Request) line: 93
CreateImplementationAction.run() line: 145
CreateImplementationAction(Action).runWithEvent(Event) line: 881
ActionContributionItem.handleWidgetSelection(Event, boolean) line: 915
ActionContributionItem.access$2(ActionContributionItem, Event, boolean) line: 866
ActionContributionItem$7.handleEvent(Event) line: 785
EventTable.sendEvent(Event) line: 82
MenuItem(Widget).sendEvent(Event) line: 796
Display.runDeferredEvents() line: 2773
Display.readAndDispatch() line: 2432
Workbench.runEventLoop(Window$IExceptionHandler, Display) line: 1377
Workbench.runUI() line: 1348
Workbench.createAndRunWorkbench(Display, WorkbenchAdvisor) line: 254
PlatformUI.createAndRunWorkbench(Display, WorkbenchAdvisor) line: 141
IDEApplication.run(Object) line: 96
PlatformActivator$1.run(Object) line: 335
EclipseStarter.run(Object) line: 273
EclipseStarter.run(String[], Runnable) line: 129
NativeMethodAccessorImpl.invoke0(Method, Object, Object[]) line: not available
[native method]
NativeMethodAccessorImpl.invoke(Object, Object[]) line: 85
NativeMethodAccessorImpl.invoke(Method, Object, Object[]) line: 58
DelegatingMethodAccessorImpl.invoke(Method, Object, Object[]) line: 60
Method.invoke(Object, Object[]) line: 391
Main.basicRun(String[]) line: 185
Main.run(String[]) line: 684
Main.main(String[]) line: 668","org.eclipse.core.internal.jobs.ImplicitJobs
org.eclipse.core.internal.jobs.ThreadJob
org.eclipse.core.internal.jobs.JobManager"
FILE,eclipse-3.1,93069,2005-04-28T03:38:00.000-05:00,Eclipse can't start,"org.eclipse.core.internal.compatibility.PluginActivator.start()
!
SESSION 2005-04-28 11:25:42.906 ----------------------------------------------
- eclipse.buildId=I20041216-2000 java.version=1.5.0_02 java.vendor=Sun Microsystems Inc.
BootLoader constants: OS=win32, ARCH=x86, WS=win32, NL=ru_RU
Command-line arguments:  -os win32 -ws win32 -arch x86 -data
\\darksite\mike\eclipse
!
ENTRY org.eclipse.osgi 2005-04-28 11:25:42.906
!
MESSAGE An error occured while automatically activating bundle org.eclipse.core.resources (15).
!
STACK 0 org.osgi.framework.BundleException: Exception in org.eclipse.core.internal.compatibility.PluginActivator.start() of bundle org.eclipse.core.resources.
at org.eclipse.osgi.framework.internal.core.BundleContextImpl.startActivator
(BundleContextImpl.java:975)
at org.eclipse.osgi.framework.internal.core.BundleContextImpl.start
(BundleContextImpl.java:937)
at org.eclipse.osgi.framework.internal.core.BundleHost.startWorker
(BundleHost.java:417)
at org.eclipse.osgi.framework.internal.core.AbstractBundle.start
(AbstractBundle.java:293)
at org.eclipse.core.runtime.adaptor.EclipseClassLoader.findLocalClass
(EclipseClassLoader.java:110)
at org.eclipse.osgi.framework.internal.core.BundleLoader.findLocalClass
(BundleLoader.java:371)
at org.eclipse.osgi.framework.internal.core.BundleLoader.requireClass
(BundleLoader.java:336)
at org.eclipse.osgi.framework.internal.core.BundleLoader.findRequiredClass
(BundleLoader.java:914)
at org.eclipse.osgi.framework.internal.core.BundleLoader.findClass
(BundleLoader.java:399)
at org.eclipse.osgi.framework.adaptor.core.AbstractClassLoader.loadClass
(AbstractClassLoader.java:93)
at java.lang.ClassLoader.loadClass(Unknown Source)
at java.lang.ClassLoader.loadClassInternal(Unknown Source)
at org.eclipse.ui.internal.ide.model.WorkbenchAdapterFactory.
<init>
(WorkbenchAdapterFactory.java:33)
at org.eclipse.ui.internal.ide.model.WorkbenchAdapterBuilder.registerAdapters
(WorkbenchAdapterBuilder.java:33)
at org.eclipse.ui.internal.ide.IDEWorkbenchAdvisor.initialize
(IDEWorkbenchAdvisor.java:173)
at org.eclipse.ui.application.WorkbenchAdvisor.internalBasicInitialize
(WorkbenchAdvisor.java:167)
at org.eclipse.ui.internal.Workbench.init(Workbench.java:852)
at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1516)
at org.eclipse.ui.internal.Workbench.createAndRunWorkbench
(Workbench.java:285)
at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:144)
at org.eclipse.ui.internal.ide.IDEApplication.run
(IDEApplication.java:102)
at org.eclipse.core.internal.runtime.PlatformActivator$1.
run
(PlatformActivator.java:220)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run
(EclipseStarter.java:273)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run
(EclipseStarter.java:129)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
at java.lang.reflect.Method.invoke(Unknown Source)
at org.eclipse.core.launcher.Main.basicRun(Main.java:185)
at org.eclipse.core.launcher.Main.run(Main.java:710)
at org.eclipse.core.launcher.Main.main(Main.java:694)
Caused by: java.lang.IndexOutOfBoundsException: Index: 458761, Size: 5
at java.util.ArrayList.RangeCheck(Unknown Source)
at java.util.ArrayList.get(Unknown Source)
at org.eclipse.core.internal.resources.MarkerReader_3.
readMarkerInfo
(MarkerReader_3.java:134)
at org.eclipse.core.internal.resources.MarkerReader_3.
read
(MarkerReader_3.java:69)
at org.eclipse.core.internal.resources.MarkerReader.read
(MarkerReader.java:49)
at org.eclipse.core.internal.resources.MarkerManager.restoreFromSave
(MarkerManager.java:449)
at org.eclipse.core.internal.resources.MarkerManager.restore
(MarkerManager.java:434)
at org.eclipse.core.internal.resources.SaveManager.restoreMarkers
(SaveManager.java:633)
at org.eclipse.core.internal.resources.SaveManager.restore
(SaveManager.java:558)
at org.eclipse.core.internal.resources.SaveManager.startup
(SaveManager.java:1241)
at org.eclipse.core.internal.resources.Workspace.startup
(Workspace.java:1822)
at org.eclipse.core.internal.resources.Workspace.open
(Workspace.java:1601)
at org.eclipse.core.resources.ResourcesPlugin.startup
(ResourcesPlugin.java:357)
at org.eclipse.core.internal.compatibility.PluginActivator.start
(PluginActivator.java:56)
at org.eclipse.osgi.framework.internal.core.BundleContextImpl$1.
run
(BundleContextImpl.java:958)
at java.security.AccessController.doPrivileged(Native Method)
at org.eclipse.osgi.framework.internal.core.BundleContextImpl.startActivator
(BundleContextImpl.java:954)
... 30 more
Root exception:
java.lang.IndexOutOfBoundsException: Index: 458761, Size: 5
at java.util.ArrayList.RangeCheck(Unknown Source)
at java.util.ArrayList.get(Unknown Source)
at org.eclipse.core.internal.resources.MarkerReader_3.
readMarkerInfo
(MarkerReader_3.java:134)
at org.eclipse.core.internal.resources.MarkerReader_3.
read
(MarkerReader_3.java:69)
at org.eclipse.core.internal.resources.MarkerReader.read
(MarkerReader.java:49)
at org.eclipse.core.internal.resources.MarkerManager.restoreFromSave
(MarkerManager.java:449)
at org.eclipse.core.internal.resources.MarkerManager.restore
(MarkerManager.java:434)
at org.eclipse.core.internal.resources.SaveManager.restoreMarkers
(SaveManager.java:633)
at org.eclipse.core.internal.resources.SaveManager.restore
(SaveManager.java:558)
at org.eclipse.core.internal.resources.SaveManager.startup
(SaveManager.java:1241)
at org.eclipse.core.internal.resources.Workspace.startup
(Workspace.java:1822)
at org.eclipse.core.internal.resources.Workspace.open
(Workspace.java:1601)
at org.eclipse.core.resources.ResourcesPlugin.startup
(ResourcesPlugin.java:357)
at org.eclipse.core.internal.compatibility.PluginActivator.start
(PluginActivator.java:56)
at org.eclipse.osgi.framework.internal.core.BundleContextImpl$1.
run
(BundleContextImpl.java:958)
at java.security.AccessController.doPrivileged(Native Method)
at org.eclipse.osgi.framework.internal.core.BundleContextImpl.startActivator
(BundleContextImpl.java:954)
at org.eclipse.osgi.framework.internal.core.BundleContextImpl.start
(BundleContextImpl.java:937)
at org.eclipse.osgi.framework.internal.core.BundleHost.startWorker
(BundleHost.java:417)
at org.eclipse.osgi.framework.internal.core.AbstractBundle.start
(AbstractBundle.java:293)
at org.eclipse.core.runtime.adaptor.EclipseClassLoader.findLocalClass
(EclipseClassLoader.java:110)
at org.eclipse.osgi.framework.internal.core.BundleLoader.findLocalClass
(BundleLoader.java:371)
at org.eclipse.osgi.framework.internal.core.BundleLoader.requireClass
(BundleLoader.java:336)
at org.eclipse.osgi.framework.internal.core.BundleLoader.findRequiredClass
(BundleLoader.java:914)
at org.eclipse.osgi.framework.internal.core.BundleLoader.findClass
(BundleLoader.java:399)
at org.eclipse.osgi.framework.adaptor.core.AbstractClassLoader.loadClass
(AbstractClassLoader.java:93)
at java.lang.ClassLoader.loadClass(Unknown Source)
at java.lang.ClassLoader.loadClassInternal(Unknown Source)
at org.eclipse.ui.internal.ide.model.WorkbenchAdapterFactory.
<init>
(WorkbenchAdapterFactory.java:33)
at org.eclipse.ui.internal.ide.model.WorkbenchAdapterBuilder.registerAdapters
(WorkbenchAdapterBuilder.java:33)
at org.eclipse.ui.internal.ide.IDEWorkbenchAdvisor.initialize
(IDEWorkbenchAdvisor.java:173)
at org.eclipse.ui.application.WorkbenchAdvisor.internalBasicInitialize
(WorkbenchAdvisor.java:167)
at org.eclipse.ui.internal.Workbench.init(Workbench.java:852)
at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1516)
at org.eclipse.ui.internal.Workbench.createAndRunWorkbench
(Workbench.java:285)
at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:144)
at org.eclipse.ui.internal.ide.IDEApplication.run
(IDEApplication.java:102)
at org.eclipse.core.internal.runtime.PlatformActivator$1.
run
(PlatformActivator.java:220)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run
(EclipseStarter.java:273)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run
(EclipseStarter.java:129)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
at java.lang.reflect.Method.invoke(Unknown Source)
at org.eclipse.core.launcher.Main.basicRun(Main.java:185)
at org.eclipse.core.launcher.Main.run(Main.java:710)
at org.eclipse.core.launcher.Main.main(Main.java:694)
!
ENTRY org.eclipse.osgi 2005-04-28 11:25:42.984
!
MESSAGE Application error
!
STACK 1 java.lang.NoClassDefFoundError: org/eclipse/core/resources/IProject at org.eclipse.ui.internal.ide.model.WorkbenchAdapterFactory.
<init>
(WorkbenchAdapterFactory.java:33)
at org.eclipse.ui.internal.ide.model.WorkbenchAdapterBuilder.registerAdapters
(WorkbenchAdapterBuilder.java:33)
at org.eclipse.ui.internal.ide.IDEWorkbenchAdvisor.initialize
(IDEWorkbenchAdvisor.java:173)
at org.eclipse.ui.application.WorkbenchAdvisor.internalBasicInitialize
(WorkbenchAdvisor.java:167)
at org.eclipse.ui.internal.Workbench.init(Workbench.java:852)
at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1516)
at org.eclipse.ui.internal.Workbench.createAndRunWorkbench
(Workbench.java:285)
at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:144)
at org.eclipse.ui.internal.ide.IDEApplication.run
(IDEApplication.java:102)
at org.eclipse.core.internal.runtime.PlatformActivator$1.
run
(PlatformActivator.java:220)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run
(EclipseStarter.java:273)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run
(EclipseStarter.java:129)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
at java.lang.reflect.Method.invoke(Unknown Source)
at org.eclipse.core.launcher.Main.basicRun(Main.java:185)
at org.eclipse.core.launcher.Main.run(Main.java:710)
at org.eclipse.core.launcher.Main.main(Main.java:694)","org.eclipse.core.internal.resources.Synchronizer
org.eclipse.core.internal.resources.MarkerManager"
FILE,eclipse-3.1,93119,2005-04-28T10:10:00.000-05:00,code assist: proposals for wildcard types,"package codeAssist;

import java.util.List ;

public class Extends {
	void m() {
		List <? |>
	}
}
I20050426-1700
package codeAssist;
import java.util.List ;
public class Extends {
	void m() {
		List <?
|>
	}
}
> actual: the only proposed item is the CU's type (Extends)
> actual: dozens of type proposals are proposed (and two template proposals, but
that is not a jdt-core problem)
< expected: only 'extends' is proposed.",org.eclipse.jdt.internal.codeassist.complete.CompletionParser
FILE,eclipse-3.1,93249,2005-04-29T05:49:00.000-05:00,Code assist doesn't propose full method stub,"IRunnableWithProgress runnable= new IRunnableWithProgress() {
};

  
  
 public void run(org.eclipse.core.runtime.IProgressMonitor monitor) throws
InvocationTargetException, InterruptedException
IRunnableWithProgress runnable= new IRunnableWithProgress() {
};
observe: only the following method signature gets inserted.
No method body.
Additionally IProgressMonitor is fully qualified.
public void run(org.eclipse.core.runtime.IProgressMonitor monitor) throws
InvocationTargetException, InterruptedException","org.eclipse.jdt.internal.codeassist.CompletionEngine
org.eclipse.jdt.internal.ui.text.java.OverrideCompletionProposal"
FILE,eclipse-3.1,93727,2005-05-04T17:43:00.000-05:00,Code Formatter fails with Method Parameter Annotations,"import org.drools.semantics.annotation.DroolsParameter;

public class Test
{
  public Object passthrough( @DroolsParameter(""parameter"") Object parameter ) {
    return parameter;
  }
}
The eclipse code formatter doesn't seem to work when you have methods with
parameter annotations.
It fails silently, and I don't see an error in
<Workspace>/.
metadata/.
log.
public class Test
{
  public Object passthrough( @DroolsParameter(""parameter"") Object parameter ) {
    return parameter;
  }
}",org.eclipse.jdt.internal.formatter.CodeFormatterVisitor
FILE,eclipse-3.1,93854,2005-05-05T17:23:00.000-05:00,IAE in  Util.scanTypeSignature when scanning a signature retrieved from a binding key,"Signature.getTypeParameters(String)  
    
      
    
  
     getText(Object)  
 HierarchyLabelProvider.getText(Object)  
     getText(Object)  
     updateLabel(ViewerLabel,
Object)  
     buildLabel(ViewerLabel, Object,
IViewerLabelProvider)  
     doUpdateItem(Item, Object)  
 AbstractTreeViewer$UpdateItemSafeRunnable.run()  
 InternalPlatform.run(ISafeRunnable)  
 Platform.run(ISafeRunnable)  
 JFaceUtil$1.run(ISafeRunnable)  
 SafeRunnable.run(ISafeRunnable)  
      
 StructuredViewer$UpdateItemSafeRunnable.run()  
 InternalPlatform.run(ISafeRunnable)  
 Platform.run(ISafeRunnable)  
 JFaceUtil$1.run(ISafeRunnable)  
 SafeRunnable.run(ISafeRunnable)  
     updateItem(Widget, Object)  
      
 AbstractTreeViewer$1.run()  
 BusyIndicator.showWhile(Display, Runnable)  
     createChildren(Widget)  
      
      
      
      
  
 TypeHierarchyViewPart$11.run()  
 BusyIndicator.showWhile(Display, Runnable)  
  
 TypeHierarchyViewPart.updateInput(IJavaElement)  
 TypeHierarchyViewPart.setInputElement(IJavaElement)  
 OpenTypeHierarchyUtil.openInViewPart(IWorkbenchWindow, IJavaElement)  
      
    
 OpenTypeHierarchyAction.run(ITextSelection)  
     dispatchRun(ISelection)  
     run()  
   runWithEvent(Event)  
 ActionHandler.execute(Map)  
 LegacyHandlerWrapper.execute(ExecutionEvent)  
 Command.execute(ExecutionEvent)  
 ParameterizedCommand.execute(Object, Object)  
 WorkbenchKeyboard.executeCommand(Binding, Object)  
 WorkbenchKeyboard.press(List, Event)  
 WorkbenchKeyboard.processKeyEvent(List, Event)  
 WorkbenchKeyboard.filterKeySequenceBindings(Event)  
 WorkbenchKeyboard.access$3(WorkbenchKeyboard, Event)  
 WorkbenchKeyboard$KeyDownFilter.handleEvent(Event)  
 EventTable.sendEvent(Event)  
 Display.filterEvent(Event)  
   sendEvent(Event)  
    
    
    
    
    
  
    
  
  
 Display.readAndDispatch()  
 Workbench.runEventLoop(Window$IExceptionHandler, Display)  
 Workbench.runUI()  
 Workbench.createAndRunWorkbench(Display, WorkbenchAdvisor)  
 PlatformUI.createAndRunWorkbench(Display, WorkbenchAdvisor)  
 IDEApplication.run(Object)  
 PlatformActivator$1.run(Object)  
 EclipseStarter.run(Object)
Thread [main] (Suspended (breakpoint at line 2319 in Util))
Util.scanTypeSignature(char[], int) line: 2319
Signature.getTypeParameters(char[]) line: 1382
Signature.getTypeParameters(String) line: 1407
JavaElementLabels.getTypeLabel(IType, long, StringBuffer) line: 821
JavaElementLabels.getElementLabel(IJavaElement, long, StringBuffer) line: 398
JavaElementLabels.getElementLabel(IJavaElement, long) line: 363
JavaElementLabels.getTextLabel(Object, long) line: 345
HierarchyLabelProvider(JavaUILabelProvider).
getText(Object) line: 161
HierarchyLabelProvider.getText(Object) line: 126
DecoratingJavaLabelProvider(DecoratingLabelProvider).
getText(Object) line: 118
DecoratingJavaLabelProvider(DecoratingLabelProvider).
updateLabel(ViewerLabel,
Object) line: 208
TraditionalHierarchyViewer(StructuredViewer).
buildLabel(ViewerLabel, Object,
IViewerLabelProvider) line: 1846
TraditionalHierarchyViewer(TreeViewer).
doUpdateItem(Item, Object) line: 228
AbstractTreeViewer$UpdateItemSafeRunnable.run() line: 85
InternalPlatform.run(ISafeRunnable) line: 1031
Platform.run(ISafeRunnable) line: 757
JFaceUtil$1.
run(ISafeRunnable) line: 44
SafeRunnable.run(ISafeRunnable) line: 148
TraditionalHierarchyViewer(AbstractTreeViewer).
doUpdateItem(Widget, Object, boolean) line: 621
StructuredViewer$UpdateItemSafeRunnable.run() line: 434
InternalPlatform.run(ISafeRunnable) line: 1031
Platform.run(ISafeRunnable) line: 757
JFaceUtil$1.
run(ISafeRunnable) line: 44
SafeRunnable.run(ISafeRunnable) line: 148
TraditionalHierarchyViewer(StructuredViewer).
updateItem(Widget, Object) line: 1754
TraditionalHierarchyViewer(AbstractTreeViewer).
createTreeItem(Widget, Object, int) line: 535
AbstractTreeViewer$1.
run() line: 514
BusyIndicator.showWhile(Display, Runnable) line: 69
TraditionalHierarchyViewer(AbstractTreeViewer).
createChildren(Widget) line: 494
TraditionalHierarchyViewer(AbstractTreeViewer).
internalExpandToLevel(Widget, int) line: 1120
TraditionalHierarchyViewer(AbstractTreeViewer).
internalExpandToLevel(Widget, int) line: 1129
TraditionalHierarchyViewer(AbstractTreeViewer).
expandToLevel(Object, int) line: 658
TraditionalHierarchyViewer(AbstractTreeViewer).
expandToLevel(int) line: 641
TraditionalHierarchyViewer.updateContent(boolean) line: 61
TypeHierarchyViewPart$11.
run() line: 1090
BusyIndicator.showWhile(Display, Runnable) line: 69
TypeHierarchyViewPart.updateHierarchyViewer(boolean) line: 1093
TypeHierarchyViewPart.updateInput(IJavaElement) line: 541
TypeHierarchyViewPart.setInputElement(IJavaElement) line: 486
OpenTypeHierarchyUtil.openInViewPart(IWorkbenchWindow, IJavaElement) line: 98
OpenTypeHierarchyUtil.open(IJavaElement[], IWorkbenchWindow) line: 75
OpenTypeHierarchyAction.run(IJavaElement[]) line: 181
OpenTypeHierarchyAction.run(ITextSelection) line: 143
OpenTypeHierarchyAction(SelectionDispatchAction).
dispatchRun(ISelection) line: 226
OpenTypeHierarchyAction(SelectionDispatchAction).
run() line: 198
OpenTypeHierarchyAction(Action).
runWithEvent(Event) line: 996
ActionHandler.execute(Map) line: 182
LegacyHandlerWrapper.execute(ExecutionEvent) line: 108
Command.execute(ExecutionEvent) line: 312
ParameterizedCommand.execute(Object, Object) line: 396
WorkbenchKeyboard.executeCommand(Binding, Object) line: 452
WorkbenchKeyboard.press(List, Event) line: 722
WorkbenchKeyboard.processKeyEvent(List, Event) line: 766
WorkbenchKeyboard.filterKeySequenceBindings(Event) line: 543
WorkbenchKeyboard.access$3(WorkbenchKeyboard, Event) line: 486
WorkbenchKeyboard$KeyDownFilter.handleEvent(Event) line: 110
EventTable.sendEvent(Event) line: 82
Display.filterEvent(Event) line: 781
StyledText(Widget).
sendEvent(Event) line: 841
StyledText(Widget).
sendEvent(int, Event, boolean) line: 866
StyledText(Widget).
sendEvent(int, Event) line: 851
StyledText(Widget).
sendKeyEvent(int, int, int, int, Event) line: 879
StyledText(Widget).
sendKeyEvent(int, int, int, int) line: 875
StyledText(Widget).
wmKeyDown(int, int, int) line: 1467
StyledText(Control).
WM_KEYDOWN(int, int) line: 3342
StyledText(Control).
windowProc(int, int, int, int) line: 3062
Display.windowProc(int, int, int, int) line: 3493
OS.DispatchMessageW(MSG) line: not available [native method]
OS.DispatchMessage(MSG) line: 1650
Display.readAndDispatch() line: 2532
Workbench.runEventLoop(Window$IExceptionHandler, Display) line: 1592
Workbench.runUI() line: 1556
Workbench.createAndRunWorkbench(Display, WorkbenchAdvisor) line: 314
PlatformUI.createAndRunWorkbench(Display, WorkbenchAdvisor) line: 143
IDEApplication.run(Object) line: 103
PlatformActivator$1.
run(Object) line: 230
EclipseStarter.run(Object) line: 345
EclipseStarter.run(String[], Runnable) line: 158
NativeMethodAccessorImpl.invoke0(Method, Object, Object[]) line: not available
[native method]
NativeMethodAccessorImpl.invoke(Object, Object[]) line: 85
NativeMethodAccessorImpl.invoke(Method, Object, Object[]) line: 58
DelegatingMethodAccessorImpl.invoke(Method, Object, Object[]) line: 60
Method.invoke(Object, Object[]) line: 391
Main.invokeFramework(String[], URL[]) line: 328
Main.basicRun(String[]) line: 272
Main.run(String[]) line: 974
Main.main(String[]) line: 950
Binding key retrieved from Java element:
Ljava/util/Collections$CheckedMap<TK;T,V;>;
Signature retrieved from binding key for which we ask type parameters:
<K:,V:>Ljava.util.Collections$CheckedMap;
char[] in scanTypeSignature
[<, K, :, ,, V, :, >, L, j, a, v, a, .
, u, t, i, l, .
, C, o, l, l, e, c, t, i, o, n, s, $, C, h, e, c, k, e, d, M, a, p, ;]
start in scanTypeSignature: 3
Setting to major since this blocks type hierarchies on generic types.","org.eclipse.jdt.internal.core.hierarchy.HierarchyBinaryType
org.eclipse.jdt.internal.ui.typehierarchy.HierarchyLabelProvider"
FILE,eclipse-3.1,94201,2005-05-09T17:08:00.000-05:00,Applet Contextual Launch Action broken,"public class MyApplet extends Applet {
	private static final long serialVersionUID = 1L;

	public void paint(Graphics graphics) {
		graphics.drawString(""Hello World"", 50, 100);
	}
}
public void paint(Graphics graphics) {
		graphics.drawString(""Hello World"", 50, 100);
	}
}
When run from the context Menu an error message is display ""No Applet Found""
Manually creating a launch config via the lcd works fine.",org.eclipse.jdt.internal.debug.ui.launcher.AppletLaunchConfigurationUtils
FILE,eclipse-3.1,94216,2005-05-09T20:04:00.000-05:00,Open type does not work for generic types,"interface IGeneric<T> {
}
 public class Generic<T> implements IGeneric<T> {
    public static void main(String[] args) {
        IGeneric<String> gen= new Generic<String>();
        System.out.println();  // <-- breakpoint here
    }
}
interface IGeneric<T> {
} public class Generic<T> implements IGeneric<T> { public static void main(String[] args) {
IGeneric<String> gen= new Generic<String>();
System.out.println();  // <-- breakpoint here
}
}
Try to do 'open declaring type' or 'open concrete type' for 'gen' at the breakpoint, nothing happens.","org.eclipse.jdt.internal.debug.ui.actions.OpenVariableDeclaredTypeAction
org.eclipse.jdt.internal.debug.ui.actions.OpenVariableConcreteTypeAction"
FILE,eclipse-3.1,94465,2005-05-10T14:33:00.000-05:00,Java Core Dump where modifying value in the Variables View.,"String [] elms= { ""abc"", ""cde"", ""xyz"" };
String [] elms= { ""abc"", ""cde"", ""xyz"" };
I have a string array.
4. Click ok and it will result in a java dump.
Got the following error in the console:
JVMDG217: Dump Handler is Processing Signal 11 - Please Wait.
JVMDG303: JVM Requesting Java core file
JVMDG304: Java core file written to D:\eclipse3.1\I20050509
\eclipse\workspace\YetAnotherProj\javacore.20050510.142923.2576.txt
JVMDG215: Dump Handler has Processed Exception Signal 11.
Runnign IBM JVM 1.4.2","org.eclipse.jdt.internal.debug.ui.JDIModelPresentation
org.eclipse.jdt.internal.debug.ui.actions.JavaObjectValueEditor
org.eclipse.jdt.internal.debug.ui.actions.ActionMessages"
FILE,eclipse-3.1,94540,2005-05-10T17:28:00.000-05:00,[Undo] ClassNotFoundException disposing undoable operations on shutdown,"Workbench.shutdown()  
  
  
  
  
                           
  
  
 org.eclipse.ui.internal.WorkbenchPlugin.stop()
build N20050509
Noticed the following in the console output for this build.
The undo support is being shutdown during WorkbenchPlugin.stop, and is disposing
operations that come from higher level plug-ins.
By this time, however, higher level plug-ins have already been stopped.
Recommend shutting down the undo support during Workbench.shutdown() instead of
WorkbenchPlugin.stop.
[java] !ENTRY org.eclipse.osgi 2005-05-09 05:28:03.250
[java] !MESSAGE The class
""org.eclipse.ltk.core.refactoring.CompositeChange$2"" cannot be loaded because
the system is shutting down and the plug-in ""org.eclipse.ltk.core.refactoring""
has already been stopped.
[java] !STACK 0
[java] java.lang.ClassNotFoundException: The class
""org.eclipse.ltk.core.refactoring.CompositeChange$2"" cannot be loaded because
the system is shutting down and the plug-in ""org.eclipse.ltk.core.refactoring""
has already been stopped.
[java] 	at
org.eclipse.core.runtime.adaptor.EclipseClassLoader.shouldActivateFor(EclipseClassLoader.java:148)
[java] 	at
org.eclipse.core.runtime.adaptor.EclipseClassLoader.findLocalClass(EclipseClassLoader.java:66)
[java] 	at
org.eclipse.osgi.framework.internal.core.BundleLoader.findLocalClass(BundleLoader.java:321)
[java] 	at
org.eclipse.osgi.framework.internal.core.BundleLoader.findClass(BundleLoader.java:369)
[java] 	at
org.eclipse.osgi.framework.internal.core.BundleLoader.findClass(BundleLoader.java:334)
[java] 	at
org.eclipse.osgi.framework.adaptor.core.AbstractClassLoader.loadClass(AbstractClassLoader.java:74)
[java] 	at java.lang.ClassLoader.loadClass(ClassLoader.java:235)
[java] 	at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:302)
[java] 	at
org.eclipse.ltk.core.refactoring.CompositeChange.dispose(CompositeChange.java:411)
[java] 	at
org.eclipse.ltk.internal.core.refactoring.UndoableOperation2ChangeAdapter.dispose(UndoableOperation2ChangeAdapter.java:252)
[java] 	at
org.eclipse.core.commands.operations.TriggeredOperations.dispose(TriggeredOperations.java:263)
[java] 	at
org.eclipse.core.commands.operations.DefaultOperationHistory.internalRemove(DefaultOperationHistory.java:801)
[java] 	at
org.eclipse.core.commands.operations.DefaultOperationHistory.flushUndo(DefaultOperationHistory.java:587)
[java] 	at
org.eclipse.core.commands.operations.DefaultOperationHistory.dispose(DefaultOperationHistory.java:299)
[java] 	at
org.eclipse.ui.internal.operations.WorkbenchOperationSupport.dispose(WorkbenchOperationSupport.java:58)
[java] 	at
org.eclipse.ui.internal.WorkbenchPlugin.stop(WorkbenchPlugin.java:893)
[java] 	at
org.eclipse.osgi.framework.internal.core.BundleContextImpl$3.run(BundleContextImpl.java:1035)
[java] 	at java.security.AccessController.doPrivileged(Native Method)
[java] 	at
org.eclipse.osgi.framework.internal.core.BundleContextImpl.stop(BundleContextImpl.java:1031)
[java] 	at
org.eclipse.osgi.framework.internal.core.BundleHost.stopWorker(BundleHost.java:402)
[java] 	at
org.eclipse.osgi.framework.internal.core.AbstractBundle.stop(AbstractBundle.java:410)
[java] 	at
org.eclipse.core.runtime.adaptor.BundleStopper.basicStopBundles(BundleStopper.java:73)
[java] 	at
org.eclipse.core.runtime.adaptor.BundleStopper.stopBundles(BundleStopper.java:62)
[java] 	at
org.eclipse.core.runtime.adaptor.EclipseAdaptor.frameworkStopping(EclipseAdaptor.java:696)
[java] 	at
org.eclipse.osgi.framework.internal.core.Framework.shutdown(Framework.java:515)
[java] 	at
org.eclipse.osgi.framework.internal.core.SystemBundle$1.run(SystemBundle.java:171)
[java] 	at java.lang.Thread.run(Thread.java:534)
[java] !ENTRY org.eclipse.osgi 2005-05-09 05:28:03.265
[java] !MESSAGE Error while stopping ""org.eclipse.ui.workbench_3.1.0"".
[java] !STACK 0
[java] org.osgi.framework.BundleException: Exception in
org.eclipse.ui.internal.WorkbenchPlugin.stop() of bundle org.eclipse.ui.workbench.
[java] 	at
org.eclipse.osgi.framework.internal.core.BundleContextImpl.stop(BundleContextImpl.java:1051)
[java] 	at
org.eclipse.osgi.framework.internal.core.BundleHost.stopWorker(BundleHost.java:402)
[java] 	at
org.eclipse.osgi.framework.internal.core.AbstractBundle.stop(AbstractBundle.java:410)
[java] 	at
org.eclipse.core.runtime.adaptor.BundleStopper.basicStopBundles(BundleStopper.java:73)
[java] 	at
org.eclipse.core.runtime.adaptor.BundleStopper.stopBundles(BundleStopper.java:62)
[java] 	at
org.eclipse.core.runtime.adaptor.EclipseAdaptor.frameworkStopping(EclipseAdaptor.java:696)
[java] 	at
org.eclipse.osgi.framework.internal.core.Framework.shutdown(Framework.java:515)
[java] 	at
org.eclipse.osgi.framework.internal.core.SystemBundle$1.run(SystemBundle.java:171)
[java] 	at java.lang.Thread.run(Thread.java:534)
[java] Caused by: java.lang.NoClassDefFoundError:
org/eclipse/ltk/core/refactoring/CompositeChange$2
[java] 	at
org.eclipse.ltk.core.refactoring.CompositeChange.dispose(CompositeChange.java:411)
[java] 	at
org.eclipse.ltk.internal.core.refactoring.UndoableOperation2ChangeAdapter.dispose(UndoableOperation2ChangeAdapter.java:252)
[java] 	at
org.eclipse.core.commands.operations.TriggeredOperations.dispose(TriggeredOperations.java:263)
[java] 	at
org.eclipse.core.commands.operations.DefaultOperationHistory.internalRemove(DefaultOperationHistory.java:801)
[java] 	at
org.eclipse.core.commands.operations.DefaultOperationHistory.flushUndo(DefaultOperationHistory.java:587)
[java] 	at
org.eclipse.core.commands.operations.DefaultOperationHistory.dispose(DefaultOperationHistory.java:299)
[java] 	at
org.eclipse.ui.internal.operations.WorkbenchOperationSupport.dispose(WorkbenchOperationSupport.java:58)
[java] 	at
org.eclipse.ui.internal.WorkbenchPlugin.stop(WorkbenchPlugin.java:893)
[java] 	at
org.eclipse.osgi.framework.internal.core.BundleContextImpl$3.run(BundleContextImpl.java:1035)
[java] 	at java.security.AccessController.doPrivileged(Native Method)
[java] 	at
org.eclipse.osgi.framework.internal.core.BundleContextImpl.stop(BundleContextImpl.java:1031)
[java] 	... 8 more
[java] Root exception:
[java] java.lang.NoClassDefFoundError:
org/eclipse/ltk/core/refactoring/CompositeChange$2
[java] 	at
org.eclipse.ltk.core.refactoring.CompositeChange.dispose(CompositeChange.java:411)
[java] 	at
org.eclipse.ltk.internal.core.refactoring.UndoableOperation2ChangeAdapter.dispose(UndoableOperation2ChangeAdapter.java:252)
[java] 	at
org.eclipse.core.commands.operations.TriggeredOperations.dispose(TriggeredOperations.java:263)
[java] 	at
org.eclipse.core.commands.operations.DefaultOperationHistory.internalRemove(DefaultOperationHistory.java:801)
[java] 	at
org.eclipse.core.commands.operations.DefaultOperationHistory.flushUndo(DefaultOperationHistory.java:587)
[java] 	at
org.eclipse.core.commands.operations.DefaultOperationHistory.dispose(DefaultOperationHistory.java:299)
[java] 	at
org.eclipse.ui.internal.operations.WorkbenchOperationSupport.dispose(WorkbenchOperationSupport.java:58)
[java] 	at
org.eclipse.ui.internal.WorkbenchPlugin.stop(WorkbenchPlugin.java:893)
[java] 	at
org.eclipse.osgi.framework.internal.core.BundleContextImpl$3.run(BundleContextImpl.java:1035)
[java] 	at java.security.AccessController.doPrivileged(Native Method)
[java] 	at
org.eclipse.osgi.framework.internal.core.BundleContextImpl.stop(BundleContextImpl.java:1031)
[java] 	at
org.eclipse.osgi.framework.internal.core.BundleHost.stopWorker(BundleHost.java:402)
[java] 	at
org.eclipse.osgi.framework.internal.core.AbstractBundle.stop(AbstractBundle.java:410)
[java] 	at
org.eclipse.core.runtime.adaptor.BundleStopper.basicStopBundles(BundleStopper.java:73)
[java] 	at
org.eclipse.core.runtime.adaptor.BundleStopper.stopBundles(BundleStopper.java:62)
[java] 	at
org.eclipse.core.runtime.adaptor.EclipseAdaptor.frameworkStopping(EclipseAdaptor.java:696)
[java] 	at
org.eclipse.osgi.framework.internal.core.Framework.shutdown(Framework.java:515)
[java] 	at
org.eclipse.osgi.framework.internal.core.SystemBundle$1.run(SystemBundle.java:171)
[java] 	at java.lang.Thread.run(Thread.java:534)",org.eclipse.ui.internal.WorkbenchPlugin
FILE,eclipse-3.1,95096,2005-05-13T06:16:00.000-05:00,[5.0][content assist] Content assist popup disappears while completing the statically imported method name,"import static java.lang.Math
I20050513-0010
Steps to reproduce:
-> Instead of constraining the proposals to all members with prefix a, the popup closes","org.eclipse.jdt.internal.ui.text.java.JavaMethodCompletionProposal
org.eclipse.jdt.internal.ui.text.java.LazyJavaCompletionProposal"
FILE,eclipse-3.1,95152,2005-05-13T12:14:00.000-05:00,[search] F3 can't find synthetic constructor_,"InputReadJob readJob = new InputReadJob(streamsProxy);
Build: I20050513-0010
InputReadJob readJob = new InputReadJob(streamsProxy);
-> It opens a new class file editor, positioned at the top of the file.
5) The outline view in this editor has the constructor_
InputReadJob(ProcessConsole, IStreamsProxy).
Clicking this entry in the outline view does not jump to the constructor_ in the editor.
The mapping of class file to source is not handling the synthetic addition of the enclosing class by the compiler.
This breaks any kind of navigation to the corresponding constructor_ in the source attachment.","org.eclipse.ant.internal.ui.views.AntViewDropAdapter
org.eclipse.ant.internal.ui.launchConfigurations.AntLaunchShortcut
org.eclipse.ant.internal.ui.AntUtil
org.eclipse.jdt.internal.core.search.matching.ConstructorLocator
org.eclipse.jdt.internal.core.search.indexing.BinaryIndexer
org.eclipse.jdt.internal.core.index.DiskIndex
org.eclipse.jdt.internal.core.search.matching.ConstructorPattern"
FILE,eclipse-3.1,95505,2005-05-17T02:56:00.000-05:00,Can not use code completion,"{cursor}
Eclipse 3.1 M7
It was very convinient in Eclipse that when it already knows type and I write
""new "" and press Ctrl+Space, it shows this type.
button.addActionListener(new {cursor})
But in M7 I have now look, what type should be used and write several first
letters?
Why?
Please return old behaviour, at least make this optional.",org.eclipse.jdt.internal.codeassist.CompletionEngine
FILE,eclipse-3.1,95731,2005-05-18T07:29:00.000-05:00,[Progress] NPE in JobErrorDialog.refresh(...) line 92,"JobErrorDialog.refresh(...)
N20050517-0010
JDT Text Performance tests which used to run now fail with an NPE in
JobErrorDialog.refresh(...) line 92, for details see:
http://relengbuildserv.ottawa.ibm.com/downloads/master/downloads/drops/N20050517-0010/performance/html/org.eclipse.jdt.text.tests_win32perf2.html#PerformanceTestSuite
It only happened on one test machine.
Failed to execute runnable (java.lang.NullPointerException)
org.eclipse.swt.SWTException: Failed to execute runnable
(java.lang.NullPointerException)
at org.eclipse.swt.SWT.error(SWT.java:2940)
at org.eclipse.swt.SWT.error(SWT.java:2863)
at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:121)
at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:2898)
at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2557)
at
org.eclipse.jdt.text.tests.performance.DisplayHelper.driveEventQueue(DisplayHelper.java:158)
at
org.eclipse.jdt.text.tests.performance.DisplayHelper.waitForCondition(DisplayHelper.java:60)
at
org.eclipse.jdt.text.tests.performance.DisplayHelper.sleep(DisplayHelper.java:101)
at
org.eclipse.jdt.text.tests.performance.EditorTestHelper.runEventQueue(EditorTestHelper.java:212)
at
org.eclipse.jdt.text.tests.performance.EditorTestHelper.runEventQueue(EditorTestHelper.java:199)
at
org.eclipse.jdt.text.tests.performance.EditorTestHelper.joinJobs(EditorTestHelper.java:287)
at
org.eclipse.jdt.text.tests.performance.EditorTestHelper.joinBackgroundActivities(EditorTestHelper.java:281)
at
org.eclipse.jdt.text.tests.performance.ContentTypeTest.setUp(ContentTypeTest.java:81)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.eclipse.test.EclipseTestRunner.run(EclipseTestRunner.java:313)
at org.eclipse.test.EclipseTestRunner.run(EclipseTestRunner.java:199)
at org.eclipse.test.UITestApplication$3.run(UITestApplication.java:188)
at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:118)
at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:2898)
at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2557)
at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:1601)
at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1565)
at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:315)
at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:143)
at org.eclipse.ui.internal.ide.IDEApplication.run(IDEApplication.java:103)
at org.eclipse.test.UITestApplication.runApplication(UITestApplication.java:131)
at org.eclipse.test.UITestApplication.run(UITestApplication.java:58)
at
org.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:230)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:371)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:160)
at org.eclipse.core.launcher.Main.invokeFramework(Main.java:330)
at org.eclipse.core.launcher.Main.basicRun(Main.java:274)
at org.eclipse.core.launcher.Main.run(Main.java:977)
at org.eclipse.core.launcher.Main.main(Main.java:952)
Caused by: java.lang.NullPointerException
at org.eclipse.ui.internal.progress.JobErrorDialog.refresh(JobErrorDialog.java:92)
at
org.eclipse.ui.internal.progress.ErrorNotificationManager$2.runInUIThread(ErrorNotificationManager.java:113)
at org.eclipse.ui.progress.UIJob$1.run(UIJob.java:93)
at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)
at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:118)
... 52 more",org.eclipse.ui.internal.progress.JobErrorDialog
FILE,eclipse-3.1,96440,2005-05-24T11:11:00.000-05:00,Tables laying out 3 times when trying to determine sizes,"table.getClientArea()
20050522
See Bug 93611
When we attempt to layout a table we are scaling columns with
table.getClientArea().
width.
In M6 this returned the width of the table - post
M6 it is returning a much smaller value and making all of our columns very small
in the Table Layout.
4 You will see a client area size of about 81
5 Do the same in M6 - it will be about 320 or so.",org.eclipse.jface.preference.PreferencePage
FILE,eclipse-3.1,96489,2005-05-24T14:40:00.000-05:00,[Presentations] (regression) Standalone view without title has no border,"layout.addStandaloneView(BrowserApp.BROWSER_VIEW_ID, false,
IPageLayout.RIGHT, .25f, IPageLayout.ID_EDITOR_AREA);
build N20050523
IPageLayout.RIGHT, .25f, IPageLayout.ID_EDITOR_AREA);
- the history view (a regular view) has a border, but the standalone view does not
This is a regression from 3.0.2.","org.eclipse.ui.presentations.WorkbenchPresentationFactory
org.eclipse.ui.internal.presentations.defaultpresentation.EmptyTabFolder"
FILE,eclipse-3.1,96604,2005-05-25T09:31:00.000-05:00,[1.5][codeassist] missing proposals for wildcard capture,"import java.util.List;
 public class X<U, V extends List<U>>  
 void foo(X<String, ?> x1, X<Object, ?> x2)  
 get(...)
Build N20050525
import java.util.List;
public class X<U, V extends List<U>> {
V v;
void foo(X<String, ?> x1, X<Object, ?> x2) {
x1.v.
|<-----CODEASSIST HERE: should offer List#get(...)",org.eclipse.jdt.internal.compiler.lookup.BlockScope
FILE,eclipse-3.1,96766,2005-05-26T07:47:00.000-05:00,Console hyperlinks broken by 3.1M7,"public class Tst {
    
    public static void main(String[] args) throws Exception {
        
        System.out.println(""Log: Tst.main(Tst.java:5) Some message"");
        System.out.println(""Log: Tst.main(Tst.java:6)"");
    }
}
In releases prior to 3.1M7, you could print log messages which acted as
hyperlinks in the console.
A useful feature for speedy development.
In 3.1M7 the
parsing of the line number has been changed to require a new line following the
final "")"".
public class Tst {
    
    public static void main(String[] args) throws Exception {
        
        System.out.println(""Log: Tst.main(Tst.java:5) Some message"");
        System.out.println(""Log: Tst.main(Tst.java:6)"");
    }
}
In the console the 'Tst.java:6' hyperlink will work,
but the 'Tst.java:5' hyperlink will give 'Hyperlink Error' with reason 'Unable
to parse line number from hyperlink'.
Fix would be to return the parsing to just need a terminating "")"", rather than
"")\n"".
This was the functionality in 3.1M6 and before.",org.eclipse.jdt.internal.debug.ui.console.JavaStackTraceHyperlink
FILE,eclipse-3.1,96820,2005-05-26T12:27:00.000-05:00,JME during Source lookup,"enable()
N20050526-0010
After opening the Find/Replace dialog and enabling ""Regular Expressions"", I got a ""Source not found."" editor and the JME below.
Since I imported all projects as source, a do have a project org.eclipse.core.boot, but it is not a Java project.
Error 2005-05-26 17:50:36.347 Error logged from Debug Core:
Java Model Exception: Java Model Status [org.eclipse.core.boot does not exist] at
org.eclipse.jdt.internal.core.JavaElement.newNotPresentException(JavaElement.java:468)
at
org.eclipse.jdt.internal.core.JavaModelManager.getPerProjectInfoCheckExistence(JavaModelManager.java:1200)
at
org.eclipse.jdt.internal.core.JavaProject.getPerProjectInfo(JavaProject.java:1794)
at org.eclipse.jdt.internal.core.JavaProject.getRawClasspath(JavaProject.java:1851)
at org.eclipse.jdt.internal.core.JavaProject.getRawClasspath(JavaProject.java:1837)
at
org.eclipse.jdt.launching.sourcelookup.containers.JavaProjectSourceContainer.createSourceContainers(JavaProjectSourceContainer.java:92)
at
org.eclipse.debug.core.sourcelookup.containers.CompositeSourceContainer.getSourceContainers(CompositeSourceContainer.java:126)
at
org.eclipse.jdt.launching.sourcelookup.containers.JavaProjectSourceContainer.findSourceElements(JavaProjectSourceContainer.java:133)
at
org.eclipse.debug.core.sourcelookup.AbstractSourceLookupParticipant.findSourceElements(AbstractSourceLookupParticipant.java:60)
at
org.eclipse.debug.core.sourcelookup.AbstractSourceLookupDirector$SourceLookupQuery.run(AbstractSourceLookupDirector.java:126)
at
org.eclipse.core.internal.runtime.InternalPlatform.run(InternalPlatform.java:1038)
at org.eclipse.core.runtime.Platform.run(Platform.java:775)
at
org.eclipse.debug.core.sourcelookup.AbstractSourceLookupDirector.doSourceLookup(AbstractSourceLookupDirector.java:465)
at
org.eclipse.debug.core.sourcelookup.AbstractSourceLookupDirector.getSourceElement(AbstractSourceLookupDirector.java:715)
at
org.eclipse.debug.internal.ui.sourcelookup.SourceLookupFacility.lookup(SourceLookupFacility.java:138)
at org.eclipse.debug.ui.DebugUITools.lookupSource(DebugUITools.java:658)
at
org.eclipse.debug.internal.ui.views.launch.LaunchView$SourceLookupJob.run(LaunchView.java:176)
at org.eclipse.core.internal.jobs.Worker.run(Worker.java:67)",org.eclipse.jdt.internal.launching.JavaSourceLookupUtil
FILE,eclipse-3.1,97190,2005-05-30T05:16:00.000-05:00,Incorrect handling of large long values,"System.out.println(Long.MAX_VALUE);
System.out.println(23092395825689123986L);
It seems like the compiler doesn't handle invalid long values correctly.
When a long value is longer than Long.MAX_VALUE it doesn't complain about it and compiles it.
When you run the code you get invalid results of course.
System.out.println(Long.MAX_VALUE);
System.out.println(23092395825689123986L);
is compiled and produces this output
9223372036854775807
4645651751979572370",org.eclipse.jdt.internal.compiler.ast.LongLiteral
FILE,eclipse-3.1,97655,2005-05-31T14:51:00.000-05:00,Problem with new Bundle Activation semantics in 3.1M7 (vs. 3.0),"Bundle.getState()  
  
 Bundle.getState()
In version 3.0 of the platform, a plug-in that
- does not define bundle manifests and
- does not define a custom plug-in lifecycle class is activated whenever any class in the plug-in was loaded.
That is, the apparent default setting of the implied Eclipse-AutoStart header is ""true"".
Upon updating my Eclipse platform to 3.0 M7, I find that this plug-in's underlying bundle no longer auto-starts when its extensions are loaded and executed.
In consequence, the evaluation of XML enablement expressions that depend on PropertyTesters defined by my plug-in do not work because the property test always results in EvaluationResult.NOT_LOADED.
I can fix the problem in M7 by either:
- providing a plug-in lifecycle class, or
- converting to a bundle manifest and explicitly setting
Eclipse-AutoStart: true
My concerns are:
1) Why the change in bundle activation?
It appears from bug 89261 that this was a deliberate change.
Plug-ins built for Eclipse 3.0 will not work correctly in 3.1 without being migrated, which may not be under the control of the user/developer/integrator.
2) Core APIs such as expression property testers that check bundles for active-ness using Bundle.getState() will cause unexpected results for people migrating from 3.0 to 3.1.
My own product does a lot of this checking for active state.
People need to know that they have to explicitly make their bundles auto-start in order for these APIs to work.
3) What is the real meaning of ""bundle activation""?
Why doesn't the bundle state always change to Bundle.ACTIVE whenever *any* of its code is run?
It doesn't matter whether the bundle requires activator hooks or not;
whenever it runs code, it is logically ""active"".
Currently, the
Bundle.getState() method is not a useful API for determining whether a bundle is engaged in doing stuff in the platform.
4) The Eclipse-AutoStart header does not appear to be documented in the on-line help, and the bundle manifest editor in PDE doesn't provide any
UI support for it.
So, it's not easy to find the work-around.
Thanks in advance for your response!","org.eclipse.core.runtime.internal.adaptor.IPluginInfo
org.eclipse.core.runtime.internal.adaptor.PluginParser
org.eclipse.core.runtime.internal.adaptor.PluginConverterImpl"
FILE,eclipse-3.1,97722,2005-05-31T16:41:00.000-05:00,Pref Page Ant/Runtime/Tasks/Add Task dialog problems,"@

Dialog
The dialog's error message is cropped at the bottom.
The space between Name and Location seems unneccessary.
The background color of the error message is different from the dialog
background -- is this intended?
@@
Dialog font used: Trebuchet MS, size 11",org.eclipse.ant.internal.ui.preferences.AddCustomDialog
FILE,eclipse-3.1,98147,2005-06-02T13:09:00.000-05:00,Variables View does not show all children if same instance is expanded twice,"package xy;
public class Try {
	String fName;
	int fID;
	
	public Try(String name, int id) {
		fName= name;
		fID= id;
	}
	
	public static void main(String[] args) {
		Try t= new Try(""Hello"", 5);
		callee(t, t);
	}
	
	static void callee(Try t1, Try t2) {
		boolean same= t1.equals(t2); //breakpoint here
	}
	
}
N20050602-0010
- Expand t2 -> only child fID is shown
package xy;
public class Try {
String fName;
int fID;
public Try(String name, int id) { fName= name;
fID= id;
} public static void main(String[] args) {
Try t= new Try(""Hello"", 5);
callee(t, t);
} static void callee(Try t1, Try t2) { boolean same= t1.equals(t2); //breakpoint here
}
}",org.eclipse.debug.internal.ui.views.RemoteTreeViewer
FILE,eclipse-3.1,98202,2005-06-02T18:28:00.000-05:00,NPE placing breakpoint on task outside of target,"lStack(java.lang.StringBuffer)  
 
 r.getStackFrames()  
  
 org.eclipse.ant.internal.ui.debug.model.AntThread.getStackFrames0() 
 
 org.eclipse.ant.internal.ui.debug.model.AntThread.getTopStackFrame() 
 
  
    
 
     
  
 org.eclipse.debug.core.DebugPlugin$EventNotifier.run()  
  
  
  
  
  
  
  
 org.eclipse.core.internal.jobs.Worker.run()
Thread [Worker-20] (Suspended (exception java.lang.NullPointerException))
owns: org.eclipse.ant.internal.ui.debug.model.AntThread  (id=1198)
owns: java.lang.Object  (id=1199)
org.eclipse.ant.internal.ui.antsupport.logger.util.AntDebugState.marsha
lStack(java.lang.StringBuffer) line: 345
org.eclipse.ant.internal.ui.antsupport.logger.AntProcessDebugBuildLogge
r.getStackFrames() line: 193
org.eclipse.ant.internal.ui.debug.model.AntDebugTarget.getStackFrames
() line: 419
org.eclipse.ant.internal.ui.debug.model.AntThread.getStackFrames0()
line: 94
org.eclipse.ant.internal.ui.debug.model.AntThread.getTopStackFrame()
line: 132
org.eclipse.debug.internal.ui.views.launch.LaunchViewEventHandler.doPre
processEvents(org.eclipse.debug.core.DebugEvent[]) line: 616
org.eclipse.debug.internal.ui.views.launch.LaunchViewEventHandler
(org.eclipse.debug.internal.ui.views.AbstractDebugEventHandler).handleDebugEven
ts(org.eclipse.debug.core.DebugEvent[]) line: 149
org.eclipse.debug.core.DebugPlugin$EventNotifier.run() line: 1081
org.eclipse.core.internal.runtime.InternalPlatform.run
(org.eclipse.core.runtime.ISafeRunnable) line: 1038
org.eclipse.core.runtime.Platform.run
(org.eclipse.core.runtime.ISafeRunnable) line: 775
org.eclipse.debug.core.DebugPlugin$EventNotifier.dispatch
(org.eclipse.debug.core.DebugEvent[]) line: 1113
org.eclipse.debug.core.DebugPlugin$EventDispatchJob.run
(org.eclipse.core.runtime.IProgressMonitor) line: 343
org.eclipse.core.internal.jobs.Worker.run() line: 67",org.eclipse.ant.internal.ui.antsupport.logger.util.AntDebugState
FILE,eclipse-3.1,98621,2005-06-06T22:04:00.000-05:00,[refactoring] [rename] Rename Type hangs,"class I18L  
 public class I18N {

	protected static void loadMessages(Class clazz, String name) {
		...
	}
}

 
 public class Messages extends I18L {
  public static String unexpectedException;
  ...
  static {
    loadMessages(Messages.class, ""messages.properties"");
  }
}
public class I18N {
protected static void loadMessages(Class clazz, String name) {
		...
	}
}
public class Messages extends I18L {
  public static String unexpectedException;
  ...
  static {
    loadMessages(Messages.class, ""messages.properties"");
  }
}
The only
noticeable effect was the Cancel button was disabled.
Clicking the window exit
box had no effect.
I didn't have a Java console window so couldn't get a thread
dump.
I finally killed Eclipse with the Task Manager (WinXP SP2).
When I restarted Eclipse, 7 of the references had been changed to I18N and 3 had
not.
Open Type (after re-indexing its database) still shows the non-existant
I18L type, though if you try to open it, the path cannot be found.","org.eclipse.core.internal.jobs.ImplicitJobs
org.eclipse.core.internal.jobs.ThreadJob"
FILE,eclipse-3.1,98740,2005-06-07T13:25:00.000-05:00,Container attempts to refresh children on project that is not open,"String folder = ""/temp"";//$NON-NLS-1$
String projName = ""project"";//$NON-NLS-1$ 
IProjectDescription description = ResourcesPlugin.getWorkspace
().loadProjectDescription(projPath);
IProject project = ResourcesPlugin.getWorkspace().getRoot().getProject
(description.getName());
project.create(description, new NullProgressMonitor());

  project.open()  
 The members()  
 if (info.isSet(ICoreConstants.M_CHILDREN_UNKNOWN))
			workspace.refreshManager.refresh(this);
String folder = ""/temp"";//$NON-NLS-1$
String projName = ""project"";//$NON-NLS-1$
IProjectDescription description = ResourcesPlugin.getWorkspace
().
loadProjectDescription(projPath);
IProject project = ResourcesPlugin.getWorkspace().
getRoot().
getProject
(description.getName());
project.create(description, new NullProgressMonitor());
This is the key to the issue.
A background refresh job has now been started for the closed project, but it never finishes and is stuck in an infinite loop.
I believe the offending code is in the class org.eclipse.core.internal.resources.Container.
The members() method is excuting if (info.isSet(ICoreConstants.M_CHILDREN_UNKNOWN))
workspace.refreshManager.refresh(this);
because the projects members are not known.
Both the AliasManager and the Java
Perspective are calling members on the IProject.
If you override this method in Project and do not refresh for closed projects, the problem goes away.
On the next UI gesture, we get refresh infinite loops, one for each closed project.
We want the projects in the workspace, so we create them but do not open them, as open is very expensive.
This worked fine in Eclipse 3.0.","org.eclipse.core.internal.resources.Container
org.eclipse.core.internal.resources.Resource"
FILE,eclipse-3.1,99282,2005-06-09T19:46:00.000-05:00,[1.5][compiler] Enum / Switch method is not initialized in a thread safe way,"package com.bea;

public class TestEnumSwitch {
	
	public static synchronized void foo() {} 

	public static final void main(String args[]) {
		
		final TestEnum e = TestEnum.A1999;
		
		Thread[] runners = new Thread[40];
		for (int i = 0; i < runners.length; i++) {
			runners[i] = new Thread(new Runnable() {
				public void run() {
					switch (e) {
					case A1:
						System.err.println(""1"");
						break;
					case A2:
						System.err.println(""2"");
						break;
					case A8:
						System.err.println(""8"");
						break;
					case A13:
						System.err.println(""13"");
						break;
					case A1999:
						System.err.println(""1999"");
						break;
					default:
						System.err.println(""default"");
						break;
					}
					
				}
			});
		}
		
		for (int i = 0; i < runners.length; i++) {
			runners[i].start();
		}
		
	}
	
	public enum TestEnum {
		A0, A1, A2, A3, A4, A5, A6, A7, A8, A9,
		A10, A11, A12, A13, A14, A15, A16, A17, A18, A19,
		A20, A21, A22, A23, A24, A25, A26, A27, A28, A29,
		A30, A31, A32, A33, A34, A35, A36, A37, A38, A39,
		A40, A41, A42, A43, A44, A45, A46, A47, A48, A49,
		A50, A51, A52, A53, A54, A55, A56, A57, A58, A59,
		A60, A61, A62, A63, A64, A65, A66, A67, A68, A69,
		A70, A71, A72, A73, A74, A75, A76, A77, A78, A79,
		A80, A81, A82, A83, A84, A85, A86, A87, A88, A89,
		A90, A91, A92, A93, A94, A95, A96, A97, A98, A99,
		A100, A101, A102, A103, A104, A105, A106, A107, A108, A109,
		A110, A111, A112, A113, A114, A115, A116, A117, A118, A119,
		A120, A121, A122, A123, A124, A125, A126, A127, A128, A129,
		A130, A131, A132, A133, A134, A135, A136, A137, A138, A139,
		A140, A141, A142, A143, A144, A145, A146, A147, A148, A149,
		A150, A151, A152, A153, A154, A155, A156, A157, A158, A159,
		A160, A161, A162, A163, A164, A165, A166, A167, A168, A169,
		A170, A171, A172, A173, A174, A175, A176, A177, A178, A179,
		A180, A181, A182, A183, A184, A185, A186, A187, A188, A189,
		A190, A191, A192, A193, A194, A195, A196, A197, A198, A199,
		A200, A201, A202, A203, A204, A205, A206, A207, A208, A209,
		A210, A211, A212, A213, A214, A215, A216, A217, A218, A219,
		A220, A221, A222, A223, A224, A225, A226, A227, A228, A229,
		A230, A231, A232, A233, A234, A235, A236, A237, A238, A239,
		A240, A241, A242, A243, A244, A245, A246, A247, A248, A249,
		A250, A251, A252, A253, A254, A255, A256, A257, A258, A259,
		A260, A261, A262, A263, A264, A265, A266, A267, A268, A269,
		A270, A271, A272, A273, A274, A275, A276, A277, A278, A279,
		A280, A281, A282, A283, A284, A285, A286, A287, A288, A289,
		A290, A291, A292, A293, A294, A295, A296, A297, A298, A299,
		A300, A301, A302, A303, A304, A305, A306, A307, A308, A309,
		A310, A311, A312, A313, A314, A315, A316, A317, A318, A319,
		A320, A321, A322, A323, A324, A325, A326, A327, A328, A329,
		A330, A331, A332, A333, A334, A335, A336, A337, A338, A339,
		A340, A341, A342, A343, A344, A345, A346, A347, A348, A349,
		A350, A351, A352, A353, A354, A355, A356, A357, A358, A359,
		A360, A361, A362, A363, A364, A365, A366, A367, A368, A369,
		A370, A371, A372, A373, A374, A375, A376, A377, A378, A379,
		A380, A381, A382, A383, A384, A385, A386, A387, A388, A389,
		A390, A391, A392, A393, A394, A395, A396, A397, A398, A399,
		A400, A401, A402, A403, A404, A405, A406, A407, A408, A409,
		A410, A411, A412, A413, A414, A415, A416, A417, A418, A419,
		A420, A421, A422, A423, A424, A425, A426, A427, A428, A429,
		A430, A431, A432, A433, A434, A435, A436, A437, A438, A439,
		A440, A441, A442, A443, A444, A445, A446, A447, A448, A449,
		A450, A451, A452, A453, A454, A455, A456, A457, A458, A459,
		A460, A461, A462, A463, A464, A465, A466, A467, A468, A469,
		A470, A471, A472, A473, A474, A475, A476, A477, A478, A479,
		A480, A481, A482, A483, A484, A485, A486, A487, A488, A489,
		A490, A491, A492, A493, A494, A495, A496, A497, A498, A499,
		A500, A501, A502, A503, A504, A505, A506, A507, A508, A509,
		A510, A511, A512, A513, A514, A515, A516, A517, A518, A519,
		A520, A521, A522, A523, A524, A525, A526, A527, A528, A529,
		A530, A531, A532, A533, A534, A535, A536, A537, A538, A539,
		A540, A541, A542, A543, A544, A545, A546, A547, A548, A549,
		A550, A551, A552, A553, A554, A555, A556, A557, A558, A559,
		A560, A561, A562, A563, A564, A565, A566, A567, A568, A569,
		A570, A571, A572, A573, A574, A575, A576, A577, A578, A579,
		A580, A581, A582, A583, A584, A585, A586, A587, A588, A589,
		A590, A591, A592, A593, A594, A595, A596, A597, A598, A599,
		A600, A601, A602, A603, A604, A605, A606, A607, A608, A609,
		A610, A611, A612, A613, A614, A615, A616, A617, A618, A619,
		A620, A621, A622, A623, A624, A625, A626, A627, A628, A629,
		A630, A631, A632, A633, A634, A635, A636, A637, A638, A639,
		A640, A641, A642, A643, A644, A645, A646, A647, A648, A649,
		A650, A651, A652, A653, A654, A655, A656, A657, A658, A659,
		A660, A661, A662, A663, A664, A665, A666, A667, A668, A669,
		A670, A671, A672, A673, A674, A675, A676, A677, A678, A679,
		A680, A681, A682, A683, A684, A685, A686, A687, A688, A689,
		A690, A691, A692, A693, A694, A695, A696, A697, A698, A699,
		A700, A701, A702, A703, A704, A705, A706, A707, A708, A709,
		A710, A711, A712, A713, A714, A715, A716, A717, A718, A719,
		A720, A721, A722, A723, A724, A725, A726, A727, A728, A729,
		A730, A731, A732, A733, A734, A735, A736, A737, A738, A739,
		A740, A741, A742, A743, A744, A745, A746, A747, A748, A749,
		A750, A751, A752, A753, A754, A755, A756, A757, A758, A759,
		A760, A761, A762, A763, A764, A765, A766, A767, A768, A769,
		A770, A771, A772, A773, A774, A775, A776, A777, A778, A779,
		A780, A781, A782, A783, A784, A785, A786, A787, A788, A789,
		A790, A791, A792, A793, A794, A795, A796, A797, A798, A799,
		A800, A801, A802, A803, A804, A805, A806, A807, A808, A809,
		A810, A811, A812, A813, A814, A815, A816, A817, A818, A819,
		A820, A821, A822, A823, A824, A825, A826, A827, A828, A829,
		A830, A831, A832, A833, A834, A835, A836, A837, A838, A839,
		A840, A841, A842, A843, A844, A845, A846, A847, A848, A849,
		A850, A851, A852, A853, A854, A855, A856, A857, A858, A859,
		A860, A861, A862, A863, A864, A865, A866, A867, A868, A869,
		A870, A871, A872, A873, A874, A875, A876, A877, A878, A879,
		A880, A881, A882, A883, A884, A885, A886, A887, A888, A889,
		A890, A891, A892, A893, A894, A895, A896, A897, A898, A899,
		A900, A901, A902, A903, A904, A905, A906, A907, A908, A909,
		A910, A911, A912, A913, A914, A915, A916, A917, A918, A919,
		A920, A921, A922, A923, A924, A925, A926, A927, A928, A929,
		A930, A931, A932, A933, A934, A935, A936, A937, A938, A939,
		A940, A941, A942, A943, A944, A945, A946, A947, A948, A949,
		A950, A951, A952, A953, A954, A955, A956, A957, A958, A959,
		A960, A961, A962, A963, A964, A965, A966, A967, A968, A969,
		A970, A971, A972, A973, A974, A975, A976, A977, A978, A979,
		A980, A981, A982, A983, A984, A985, A986, A987, A988, A989,
		A990, A991, A992, A993, A994, A995, A996, A997, A998, A999,
		A1000, A1001, A1002, A1003, A1004, A1005, A1006, A1007, A1008, A1009,
		A1010, A1011, A1012, A1013, A1014, A1015, A1016, A1017, A1018, A1019,
		A1020, A1021, A1022, A1023, A1024, A1025, A1026, A1027, A1028, A1029,
		A1030, A1031, A1032, A1033, A1034, A1035, A1036, A1037, A1038, A1039,
		A1040, A1041, A1042, A1043, A1044, A1045, A1046, A1047, A1048, A1049,
		A1050, A1051, A1052, A1053, A1054, A1055, A1056, A1057, A1058, A1059,
		A1060, A1061, A1062, A1063, A1064, A1065, A1066, A1067, A1068, A1069,
		A1070, A1071, A1072, A1073, A1074, A1075, A1076, A1077, A1078, A1079,
		A1080, A1081, A1082, A1083, A1084, A1085, A1086, A1087, A1088, A1089,
		A1090, A1091, A1092, A1093, A1094, A1095, A1096, A1097, A1098, A1099,
		A1100, A1101, A1102, A1103, A1104, A1105, A1106, A1107, A1108, A1109,
		A1110, A1111, A1112, A1113, A1114, A1115, A1116, A1117, A1118, A1119,
		A1120, A1121, A1122, A1123, A1124, A1125, A1126, A1127, A1128, A1129,
	    A1999,
		}
}
The synthetic method that initializes the enum/switch table is not thread safe,
that is why javac places the initialization in the static initializer of an
anonymous class.
But on my machine, it prints ""default"" 22 times & 1999
18 times.
package com.bea;
public class TestEnumSwitch {
	
	public static synchronized void foo() {}
public static final void main(String args[]) {
final TestEnum e = TestEnum.A1999;
Thread[] runners = new Thread[40];
for (int i = 0; i < runners.length; i++) {
runners[i] = new Thread(new Runnable() {
public void run() {
switch (e) {
case A1:
System.err.println(""1"");
break;
case A2:
System.err.println(""2"");
break;
case A8:
System.err.println(""8"");
break;
case A13:
System.err.println(""13"");
break;
case A1999:
System.err.println(""1999"");
break;
default:
System.err.println(""default"");
break;
}
}
});
}
for (int i = 0; i < runners.length; i++) {
runners[i].start();
}
}
public enum TestEnum {
A0, A1, A2, A3, A4, A5, A6, A7, A8, A9,
A10, A11, A12, A13, A14, A15, A16, A17, A18, A19,
A20, A21, A22, A23, A24, A25, A26, A27, A28, A29,
A30, A31, A32, A33, A34, A35, A36, A37, A38, A39,
A40, A41, A42, A43, A44, A45, A46, A47, A48, A49,
A50, A51, A52, A53, A54, A55, A56, A57, A58, A59,
A60, A61, A62, A63, A64, A65, A66, A67, A68, A69,
A70, A71, A72, A73, A74, A75, A76, A77, A78, A79,
A80, A81, A82, A83, A84, A85, A86, A87, A88, A89,
A90, A91, A92, A93, A94, A95, A96, A97, A98, A99,
A100, A101, A102, A103, A104, A105, A106, A107, A108, A109,
A110, A111, A112, A113, A114, A115, A116, A117, A118, A119,
A120, A121, A122, A123, A124, A125, A126, A127, A128, A129,
A130, A131, A132, A133, A134, A135, A136, A137, A138, A139,
A140, A141, A142, A143, A144, A145, A146, A147, A148, A149,
A150, A151, A152, A153, A154, A155, A156, A157, A158, A159,
A160, A161, A162, A163, A164, A165, A166, A167, A168, A169,
A170, A171, A172, A173, A174, A175, A176, A177, A178, A179,
A180, A181, A182, A183, A184, A185, A186, A187, A188, A189,
A190, A191, A192, A193, A194, A195, A196, A197, A198, A199,
A200, A201, A202, A203, A204, A205, A206, A207, A208, A209,
A210, A211, A212, A213, A214, A215, A216, A217, A218, A219,
A220, A221, A222, A223, A224, A225, A226, A227, A228, A229,
A230, A231, A232, A233, A234, A235, A236, A237, A238, A239,
A240, A241, A242, A243, A244, A245, A246, A247, A248, A249,
A250, A251, A252, A253, A254, A255, A256, A257, A258, A259,
A260, A261, A262, A263, A264, A265, A266, A267, A268, A269,
A270, A271, A272, A273, A274, A275, A276, A277, A278, A279,
A280, A281, A282, A283, A284, A285, A286, A287, A288, A289,
A290, A291, A292, A293, A294, A295, A296, A297, A298, A299,
A300, A301, A302, A303, A304, A305, A306, A307, A308, A309,
A310, A311, A312, A313, A314, A315, A316, A317, A318, A319,
A320, A321, A322, A323, A324, A325, A326, A327, A328, A329,
A330, A331, A332, A333, A334, A335, A336, A337, A338, A339,
A340, A341, A342, A343, A344, A345, A346, A347, A348, A349,
A350, A351, A352, A353, A354, A355, A356, A357, A358, A359,
A360, A361, A362, A363, A364, A365, A366, A367, A368, A369,
A370, A371, A372, A373, A374, A375, A376, A377, A378, A379,
A380, A381, A382, A383, A384, A385, A386, A387, A388, A389,
A390, A391, A392, A393, A394, A395, A396, A397, A398, A399,
A400, A401, A402, A403, A404, A405, A406, A407, A408, A409,
A410, A411, A412, A413, A414, A415, A416, A417, A418, A419,
A420, A421, A422, A423, A424, A425, A426, A427, A428, A429,
A430, A431, A432, A433, A434, A435, A436, A437, A438, A439,
A440, A441, A442, A443, A444, A445, A446, A447, A448, A449,
A450, A451, A452, A453, A454, A455, A456, A457, A458, A459,
A460, A461, A462, A463, A464, A465, A466, A467, A468, A469,
A470, A471, A472, A473, A474, A475, A476, A477, A478, A479,
A480, A481, A482, A483, A484, A485, A486, A487, A488, A489,
A490, A491, A492, A493, A494, A495, A496, A497, A498, A499,
A500, A501, A502, A503, A504, A505, A506, A507, A508, A509,
A510, A511, A512, A513, A514, A515, A516, A517, A518, A519,
A520, A521, A522, A523, A524, A525, A526, A527, A528, A529,
A530, A531, A532, A533, A534, A535, A536, A537, A538, A539,
A540, A541, A542, A543, A544, A545, A546, A547, A548, A549,
A550, A551, A552, A553, A554, A555, A556, A557, A558, A559,
A560, A561, A562, A563, A564, A565, A566, A567, A568, A569,
A570, A571, A572, A573, A574, A575, A576, A577, A578, A579,
A580, A581, A582, A583, A584, A585, A586, A587, A588, A589,
A590, A591, A592, A593, A594, A595, A596, A597, A598, A599,
A600, A601, A602, A603, A604, A605, A606, A607, A608, A609,
A610, A611, A612, A613, A614, A615, A616, A617, A618, A619,
A620, A621, A622, A623, A624, A625, A626, A627, A628, A629,
A630, A631, A632, A633, A634, A635, A636, A637, A638, A639,
A640, A641, A642, A643, A644, A645, A646, A647, A648, A649,
A650, A651, A652, A653, A654, A655, A656, A657, A658, A659,
A660, A661, A662, A663, A664, A665, A666, A667, A668, A669,
A670, A671, A672, A673, A674, A675, A676, A677, A678, A679,
A680, A681, A682, A683, A684, A685, A686, A687, A688, A689,
A690, A691, A692, A693, A694, A695, A696, A697, A698, A699,
A700, A701, A702, A703, A704, A705, A706, A707, A708, A709,
A710, A711, A712, A713, A714, A715, A716, A717, A718, A719,
A720, A721, A722, A723, A724, A725, A726, A727, A728, A729,
A730, A731, A732, A733, A734, A735, A736, A737, A738, A739,
A740, A741, A742, A743, A744, A745, A746, A747, A748, A749,
A750, A751, A752, A753, A754, A755, A756, A757, A758, A759,
A760, A761, A762, A763, A764, A765, A766, A767, A768, A769,
A770, A771, A772, A773, A774, A775, A776, A777, A778, A779,
A780, A781, A782, A783, A784, A785, A786, A787, A788, A789,
A790, A791, A792, A793, A794, A795, A796, A797, A798, A799,
A800, A801, A802, A803, A804, A805, A806, A807, A808, A809,
A810, A811, A812, A813, A814, A815, A816, A817, A818, A819,
A820, A821, A822, A823, A824, A825, A826, A827, A828, A829,
A830, A831, A832, A833, A834, A835, A836, A837, A838, A839,
A840, A841, A842, A843, A844, A845, A846, A847, A848, A849,
A850, A851, A852, A853, A854, A855, A856, A857, A858, A859,
A860, A861, A862, A863, A864, A865, A866, A867, A868, A869,
A870, A871, A872, A873, A874, A875, A876, A877, A878, A879,
A880, A881, A882, A883, A884, A885, A886, A887, A888, A889,
A890, A891, A892, A893, A894, A895, A896, A897, A898, A899,
A900, A901, A902, A903, A904, A905, A906, A907, A908, A909,
A910, A911, A912, A913, A914, A915, A916, A917, A918, A919,
A920, A921, A922, A923, A924, A925, A926, A927, A928, A929,
A930, A931, A932, A933, A934, A935, A936, A937, A938, A939,
A940, A941, A942, A943, A944, A945, A946, A947, A948, A949,
A950, A951, A952, A953, A954, A955, A956, A957, A958, A959,
A960, A961, A962, A963, A964, A965, A966, A967, A968, A969,
A970, A971, A972, A973, A974, A975, A976, A977, A978, A979,
A980, A981, A982, A983, A984, A985, A986, A987, A988, A989,
A990, A991, A992, A993, A994, A995, A996, A997, A998, A999,
A1000, A1001, A1002, A1003, A1004, A1005, A1006, A1007, A1008, A1009,
A1010, A1011, A1012, A1013, A1014, A1015, A1016, A1017, A1018, A1019,
A1020, A1021, A1022, A1023, A1024, A1025, A1026, A1027, A1028, A1029,
A1030, A1031, A1032, A1033, A1034, A1035, A1036, A1037, A1038, A1039,
A1040, A1041, A1042, A1043, A1044, A1045, A1046, A1047, A1048, A1049,
A1050, A1051, A1052, A1053, A1054, A1055, A1056, A1057, A1058, A1059,
A1060, A1061, A1062, A1063, A1064, A1065, A1066, A1067, A1068, A1069,
A1070, A1071, A1072, A1073, A1074, A1075, A1076, A1077, A1078, A1079,
A1080, A1081, A1082, A1083, A1084, A1085, A1086, A1087, A1088, A1089,
A1090, A1091, A1092, A1093, A1094, A1095, A1096, A1097, A1098, A1099,
A1100, A1101, A1102, A1103, A1104, A1105, A1106, A1107, A1108, A1109,
A1110, A1111, A1112, A1113, A1114, A1115, A1116, A1117, A1118, A1119,
A1120, A1121, A1122, A1123, A1124, A1125, A1126, A1127, A1128, A1129,
A1999,
}
}","org.eclipse.jdt.internal.compiler.lookup.SourceTypeBinding
org.eclipse.jdt.internal.compiler.codegen.CodeStream"
FILE,eclipse-3.1,99355,2005-06-10T09:48:00.000-05:00,extract method trips up with generics and final variables,"package p;

class Container<T>
{
   private final T m_t;

   public Container(T t)
   {
      m_t = t;
   }

   T get()
   {
      return m_t;
   }
}

class GenericContainer
{
   private final Container<?> m_c;

   public GenericContainer(Container<?> c) 
   {
      m_c = c;
   }

   public Container<?> getC()
   {
      return m_c;
   }
}

public class A
{
   GenericContainer createContainer()
   {
      final Container<String> innerContainer = new Container<String>(""hello"");
      final Container<Container<String>> outerContainer = new
Container<Container<String>>(innerContainer);
      return new GenericContainer(outerContainer);
   }
   
   void method()
   {
      final GenericContainer createContainer = createContainer();
      @SuppressWarnings(""unchecked"")
      final Container<Container<String>> c = (Container<Container<String>>)
createContainer.getC();
      //extract method from here
      final Container<String> container = c.get();
      final String string = container.get();
      //to here
   }
}
 
 

package p;

class Container<T>
{
   private final T m_t;

   public Container(T t)
   {
      m_t = t;
   }

   T get()
   {
      return m_t;
   }
}

class GenericContainer
{
   private final Container<?> m_c;

   public GenericContainer(Container<?> c) 
   {
      m_c = c;
   }

   public Container<?> getC()
   {
      return m_c;
   }
}

public class A
{
   GenericContainer createContainer()
   {
      final Container<String> innerContainer = new Container<String>(""hello"");
      final Container<Container<String>> outerContainer = new
Container<Container<String>>(innerContainer);
      return new GenericContainer(outerContainer);
   }
   
   void method()
   {
      final GenericContainer createContainer = createContainer();
      @SuppressWarnings(""unchecked"")
      final Container<Container<String>> c = (Container<Container<String>>)
createContainer.getC();
      //extract method from here
      extractedMethod(c);
      //to here
   }

   private void extractedMethod(final final final Container<Container<String>> c)
   {
      final Container<String> container = c.get();
      final String string = container.get();
   }
}
you will see that the extracted method declares its paramater with too many final modifiers:
-------------------------------------
package p;
class Container<T>
{ private final T m_t;
public Container(T t)
{ m_t = t;
}
T get()
{ return m_t;
}
}
class GenericContainer
{ private final Container<?> m_c;
public GenericContainer(Container<?> c)
{ m_c = c;
}
public Container<?> getC()
{ return m_c;
}
}
public class A
{
GenericContainer createContainer()
{ final Container<String> innerContainer = new Container<String>(""hello"");
final Container<Container<String>> outerContainer = new
Container<Container<String>>(innerContainer);
return new GenericContainer(outerContainer);
} void method()
{ final GenericContainer createContainer = createContainer();
@SuppressWarnings(""unchecked"")
final Container<Container<String>> c = (Container<Container<String>>)
createContainer.getC();
//extract method from here final Container<String> container = c.get();
final String string = container.get();
//to here
}
}
----------------------------------------------- results in
-----------------------------------------------
package p;
class Container<T>
{ private final T m_t;
public Container(T t)
{ m_t = t;
}
T get()
{ return m_t;
}
}
class GenericContainer
{ private final Container<?> m_c;
public GenericContainer(Container<?> c)
{ m_c = c;
}
public Container<?> getC()
{ return m_c;
}
}
public class A
{
GenericContainer createContainer()
{ final Container<String> innerContainer = new Container<String>(""hello"");
final Container<Container<String>> outerContainer = new
Container<Container<String>>(innerContainer);
return new GenericContainer(outerContainer);
} void method()
{ final GenericContainer createContainer = createContainer();
@SuppressWarnings(""unchecked"")
final Container<Container<String>> c = (Container<Container<String>>)
createContainer.getC();
//extract method from here extractedMethod(c);
//to here
}
private void extractedMethod(final final final Container<Container<String>> c)
{ final Container<String> container = c.get();
final String string = container.get();
}
}
-----------------------------------------------------------
notice the 3 final modifiers in the extractedMethod signature.",org.eclipse.jdt.core.dom.ASTConverter
FILE,eclipse-3.1,99631,2005-06-13T09:21:00.000-05:00,[assist][5.0] Unnecessary proposals on annotation completion,"@B 
 public class Test {}
3 1 RC2
Steps to reproduce:
-> The keyword proposals byte and boolean show up","org.eclipse.jdt.internal.corext.refactoring.reorg.JavaMoveProcessor
org.eclipse.jdt.internal.codeassist.CompletionEngine"
FILE,eclipse-3.1,99693,2005-06-13T11:29:00.000-05:00,Invalid stack frames during display,"private static void doGenerics() {
		List<Integer> list = new ArrayList<Integer>();
		for (int i = 0; i < 1000; i++) {
			int num = rand.nextInt(10000) + 1;
			list.add(num);
		}
		
		int max = 0;
//start eval
		for (Integer integer : list) { // BREAKPOINT HERE
			max = Math.max(max, integer);
		}
		System.out.println(max);
//end eval
	}
private static void doGenerics() {
List<Integer> list = new ArrayList<Integer>();
for (int i = 0; i < 1000; i++) { int num = rand.nextInt(10000) + 1;
list.add(num);
} int max = 0;
//start eval for (Integer integer : list) { // BREAKPOINT HERE max = Math.max(max, integer);
}
System.out.println(max);
//end eval
}
Watching the Variables View I see a lot of invalid stack frames.
They are not destructive (and nothing is logged).
Can we be smarter about not requesting and/or cancelling requests when the current stack frame is not valid?","org.eclipse.debug.internal.ui.views.variables.VariablesViewEventHandler
org.eclipse.debug.internal.ui.views.expression.ExpressionViewEventHandler"
CLASS,openjpa-2.2.0,OPENJPA-2149,2012-03-05T01:50:18.000-06:00,Criteria.function adds wrong casts to parameters making it unsuable,"Expression<String> stPointFunc = cb.function(
				""db2gse.st_point"", 
				String.class,
				cb.literal(0.0),
				cb.literal(0.0),
				cb.literal(1003));
		
		Expression<Double> distanceFunc = cb.function(
				""db2gse.st_distance"", 
				Double.class, 
				stPointFunc, 
				usersLocations.get(""location""));
		
		criteriaQuery.select(usersLocations).where(cb.lessThan(distanceFunc, cb.literal(50.0)));

 
    
    
 args.appendTo(sel, ctx, state, sql, 0);
     
 for (int i = 1; i < vals.length; i++) {
                sql.addCastForParam(getOperator(), vals[i]);
            }
     
  
  
 Expression<String> stPointFunc = cb.function(
				""db2gse.st_point"", 
				String.class,
				cb.coalesce(cb.literal(0.0), cb.literal(0.0)),
				cb.coalesce(cb.literal(1.0), cb.literal(1.0)),
				cb.coalesce(cb.literal(1003), cb.literal(1003)));
Criteria.function will generate an SQL with only the last parameter casted and to the wrong type.
Expression<String> stPointFunc = cb.function(
				""db2gse.st_point"", 
				String.class,
				cb.literal(0.0),
				cb.literal(0.0),
				cb.literal(1003));
		
		Expression<Double> distanceFunc = cb.function(
				""db2gse.st_distance"", 
				Double.class, 
				stPointFunc, 
				usersLocations.get(""location""));
		
		criteriaQuery.select(usersLocations).
where(cb.lessThan(distanceFunc, cb.literal(50.0)));
Will generate the following SQL:
(db2gse.st_distance(db2gse.st_point(?
, ?
, CAST(?
AS DOUBLE)), t0.LOCATION) < ?)
Notice the 3rd parameter is an Integer and its being cast as Double.
The problem is in org.apache.openjpa.jdbc.kernel.exps.DatastoreFunction#appendTo
Line 54:  args.appendTo(sel, ctx, state, sql, 0);
Will append 3 ?
to the sql buffer: ""(db2gse.st_distance(db2gse.st_point(?
, ?
, ?""
Then the loop in line 56-58
            for (int i = 1; i < vals.length; i++) {
                sql.addCastForParam(getOperator(), vals[i]);
            }
It becomes: ""(db2gse.st_distance(db2gse.st_point(?
, ?
, CAST(?
AS DOUBLE)""
Starts with 1 (second parameter and not the first one), whil sql.addCastForParam only works for the last ?
in the sql buffer, meaning the cast for the param at index 1 is added to the last ?
and the method will not do anything else.
This issue leaves Criteria.function useless to me, I tried extending my DBDictionary to remove all the cast as a work around but the function became ambiguous.
Thanks in advance.
Found a temporary (working but ugly) workaround:
		Expression<String> stPointFunc = cb.function(
				""db2gse.st_point"", 
				String.class,
				cb.coalesce(cb.literal(0.0), cb.literal(0.0)),
				cb.coalesce(cb.literal(1.0), cb.literal(1.0)),
				cb.coalesce(cb.literal(1003), cb.literal(1003)));
coalesce uses raw value instead of parameters and makes it work (the same value twice becuase if I put cb.nullLiteral I get a NullPointerException, might be another bug)","openjpa-jdbc.src.main.java.org.apache.openjpa.jdbc.kernel.exps.DatastoreFunction
openjpa-jdbc.src.main.java.org.apache.openjpa.jdbc.kernel.exps.Args
openjpa-jdbc.src.main.java.org.apache.openjpa.jdbc.kernel.exps.UnaryOp"
CLASS,openjpa-2.2.0,OPENJPA-2163,2012-03-27T15:56:55.000-05:00,Lifecycle event callback occurs more often than expect,"final EntityManager em = factory.createEntityManager();
final EntityManager em2 = factory.createEntityManager();
 
 MyLifecycleListener l1 = new MyLifecycleListener();
MyLifecycleListener l2 = new MyLifecycleListener();
 
 ((OpenJPAEntityManagerSPI)em).addLifecycleListener(l1, null);
((OpenJPAEntityManagerSPI)em2).addLifecycleListener(l2, null);
final EntityManager em = factory.createEntityManager();
final EntityManager em2 = factory.createEntityManager();
...
MyLifecycleListener l1 = new MyLifecycleListener();
MyLifecycleListener l2 = new MyLifecycleListener();
...
((OpenJPAEntityManagerSPI)em).
addLifecycleListener(l1, null);
((OpenJPAEntityManagerSPI)em2).
addLifecycleListener(l2, null);
When life cycle event occurs for a specific entity manager, all the listeners created under the emf are being invoked.","openjpa-kernel.src.main.java.org.apache.openjpa.conf.OpenJPAConfigurationImpl
openjpa-persistence-jdbc.src.test.java.org.apache.openjpa.persistence.validation.TestValidationMode"
CLASS,openjpa-2.2.0,OPENJPA-2197,2012-05-16T17:10:22.000-05:00,MethodComparator in AnnotationPersistenceMetaDataParser should also compare parameters,"@PreUpdate
    public void updateChangeLog(Object entity)  
 private void updateChangeLog(BaseEntity he, ChangeLogEntry cle)

 
   @PreUpdate
AnnotationPersistenceMetaDataParser contains a MethodComparator which only compares the class + the method name.
Too bad I have (had...) 2 methods with the same name in my EntityListener:
@PreUpdate
    public void updateChangeLog(Object entity) { .
.
and also
private void updateChangeLog(BaseEntity he, ChangeLogEntry cle)
which is a private helper method.
Due to the bug in MethodComparator, my @PreUpdate sometimes didn't get detected.",openjpa-persistence-jdbc.src.test.java.org.apache.openjpa.persistence.callbacks.ListenerImpl
CLASS,openjpa-2.2.0,OPENJPA-2227,2012-07-09T14:24:05.000-05:00,OpenJPA doesn't find custom SequenceGenerators,"{code}
 @Entity
@SequenceGenerator(name=""MySequence"", sequenceName=""org.apache.openjpa.generator.UIDGenerator()"")
public class Customer implements Serializable  
 @Id
    @GeneratedValue(strategy=GenerationType.SEQUENCE, generator=""MySequence"")
    private long id;
 {code}

 
     JavaTypes.classForName()     Class.forName()
I'm trying to use a custom SequenceGenerator within an enterprise application using openJPA (providing by WebSphere).
When defining a custom Sequence a ClassNotFoundException (for the Sequence class) will be thrown when trying to insert data into the database.
The example will produce the stacktrace attached.
It seems that the wrong class loader is used to instantiate the custom sequence class.
A very similar issue seems to be: OPENJPA-758.
With JavaSE (JUnit) all is working fine, but after deploying into WAS the Exception will occur.
I think within the method SequenceMetaData.instantiate(Classloader envLoader) the JavaTypes.classForName() -method with parameter mustExist=false should be used instead of the pure Class.forName() call.
But I'm not sure about the Metadata-parameter needed for this method call.",openjpa-kernel.src.main.java.org.apache.openjpa.meta.SequenceMetaData
CLASS,openjpa-2.2.0,OPENJPA-2247,2012-08-03T10:29:58.000-05:00,JoinColumn annotation is ignored when mapping a unidirectional owned OneToOne that is in a SecondaryTable,"@Entity
@SecondaryTable(name = ""ParentSecondaryTable"", pkJoinColumns = 
    { @PrimaryKeyJoinColumn(name = ""idParent"", referencedColumnName = ""idParent"") })
public class Parent {

    @Id
    @GeneratedValue
    int idParent;

    String child_ref;

    @OneToOne
    @JoinColumn(name = ""CHILD_REF"", table = ""ParentSecondaryTable"", referencedColumnName = ""idChild"")
    PChild child;

}
The runtime incorrectly ignores @JoinColumn.
name when mapping a unidirectional owned OneToOne that is in a SecondaryTable.
This problem only exists when running with a persistence.xml that is set to 2.0 (version=""2.0"">).
@Entity
@SecondaryTable(name = ""ParentSecondaryTable"", pkJoinColumns = 
    { @PrimaryKeyJoinColumn(name = ""idParent"", referencedColumnName = ""idParent"") })
public class Parent {
@Id
    @GeneratedValue
    int idParent;
String child_ref;
@OneToOne
    @JoinColumn(name = ""CHILD_REF"", table = ""ParentSecondaryTable"", referencedColumnName = ""idChild"")
    PChild child;
}
The column ""CHILD_REF"" will be ignored and the runtime will look for the fk in non-existent column ParentSecondaryTable.CHILD_IDCHILD.",openjpa-jdbc.src.main.java.org.apache.openjpa.jdbc.meta.MappingRepository
CLASS,openjpa-2.2.0,OPENJPA-2255,2012-08-30T20:15:52.000-05:00,Couldn't load the referencedColumn definition when create the JoinTable,"@Entity 
public class Student  
 @Id @Column(name=""id"", length=128, nullable=false) private String id; 
   @Column(name=""sName"", length=255) private String sName; 
   @ManyToMany 
  @JoinTable( 
    name=""student_course_map"", 
    joinColumns={@JoinColumn(name=""student_id"", referencedColumnName=""id"", nullable=false)}, 
    inverseJoinColumns={@JoinColumn(name=""course_id"", referencedColumnName=""id"", nullable=false)} 
  ) 
  public Collection getCourses() 

   
 @Entity 
public class Courses{ 
  @Id @Column(name=""id"", length=128, nullable=false) private String id; 
  @Column(name=""cName"", length=255) private String cName; 

  ... 
}
The JoinColumn couldn't have the referencedColumn's definition which includes the length definition.
@Entity 
public class Student { 
  @Id @Column(name=""id"", length=128, nullable=false) private String id; 
  @Column(name=""sName"", length=255) private String sName; 
  @ManyToMany 
  @JoinTable( 
    name=""student_course_map"", 
    joinColumns={@JoinColumn(name=""student_id"", referencedColumnName=""id"", nullable=false)}, 
    inverseJoinColumns={@JoinColumn(name=""course_id"", referencedColumnName=""id"", nullable=false)} 
  ) 
  public Collection getCourses()
... 
}
@Entity 
public class Courses{ 
  @Id @Column(name=""id"", length=128, nullable=false) private String id; 
  @Column(name=""cName"", length=255) private String cName;
... 
}
We can see the student id length has been defined to 128.
And there is no definition length in the JoinColumn student_id.
The warning message will occur like this
WARN  [Schema] Existing column ""student_id"" on table ""test.student_course_map"" is incompatible with the same column in the given schema definition.
Existing column: 
Full Name: student_course_map.
student_id 
Type: varchar 
Size: 128 
Default: null 
Not Null: true 
Given column: 
Full Name: student_course_map.
student_id 
Type: varchar 
Size: 255 
Default: null 
Not Null: true",openjpa-jdbc.src.main.java.org.apache.openjpa.jdbc.meta.MappingInfo
CLASS,openjpa-2.2.0,OPENJPA-428,2007-11-01T12:39:40.000-05:00,"Bad error message regarding ""openjpa.Id""","@Id 
 @Id  @Id 
 @Id 
 @Entity
@Table(name=""TAX"", schema=""JPA_SC"")
public class Tax  {
	
	// Class variables  
	protected double taxamount;
 
	public Tax(){
		
	}
	
	public Tax(double taxamount){
		this.taxamount = taxamount;
	}
//plus getter and setter for taxamount

}
Hi all, this bug is to report a confusing and misplaced error message.
Problem is described below.
Feel free to request more info from me.
When running my project with OpenJPA, I get the following error message:
140  INFO   [http-0.0.0.0-8080-Processor23] openjpa.Runtime - Starting OpenJPA 1.0.0
380  INFO   [http-0.0.0.0-8080-Processor23] openjpa.jdbc.JDBC - Using dictionary class ""org.apache.openjpa.jdbc.sql.DB2Dictionary"".
20  WARN   [http-0.0.0.0-8080-Processor25] openjpa.Runtime - The property named ""openjpa.Id"" was not recognized and will be ignored, although the name closely matches a valid property called ""openjpa.Id"".
100  INFO   [http-0.0.0.0-8080-Processor25] openjpa.Runtime - Starting OpenJPA 1.0.0
300  INFO   [http-0.0.0.0-8080-Processor25] openjpa.jdbc.JDBC - Using dictionary class ""org.apache.openjpa.jdbc.sql.DB2Dictionary"".
As you can see, the two property names printed are the same, not different or similar.
I retyped all my @Id annotations to make sure there was no special character in one of them coming from copy&paste.
Furthermore, I was able to identify that the error message was being printed only when I removed the @Id annotation from one of my classes (all the other classes still have @Id).
}
Regards,
Vitor Rodrigues","openjpa-lib.src.main.java.org.apache.openjpa.lib.conf.Configurations
openjpa-lib.src.main.java.org.apache.openjpa.lib.conf.ConfigurationImpl"
METHOD,atunes-1.10.0,231,2008-10-04T18:31:26.000-05:00,Can't add image if repository was read by older app version,"public boolean isSupportsInternalImage()
How to reproduce:
Result:
Adding image not possible.
Problem:
public boolean isSupportsInternalImage() returns false as was never set to true (as not supported in old versions).",net.sourceforge.atunes.kernel.modules.repository.audio.AudioFile:supportsInternalPicture()
METHOD,atunes-1.10.0,281,2008-12-25T02:58:34.000-06:00,Mute button in 1.11.1,"Debug mode = false
  Execution path = C   
  
  
 {MPlayer}
I tried to use the tray icon mute but it doesn't have effect unless I use the main UI's mute.
I mute the OS but the GUI doesn't display oin the main UI Wondow or the tray icon.
Log file
=====
INFO    [START       ] Starting aTunes 1.11.1 Bora  (Build 459 [29/11/2008])
INFO    [START       ] Running in Java Virtual Machine 1.6.0_11
INFO    [START       ] Arguments = [-jar, C:\Program Files\aTunes\aTunes.jar]
INFO    [START       ] Debug mode = false
INFO    [START       ] Execution path = C:\Program Files\aTunes
INFO    [START       ] Setting language: en
INFO    [HANDLER     ] Reading serialized favorites cache
INFO    [HANDLER     ] Reading serialized repository cache
INFO    [HANDLER     ] Reading repository cache done (0.156 seconds)
INFO    [HANDLER     ] Play lists loaded (13 playlists)
INFO    [START       ] Application started (2.437 seconds)
INFO    isJIntellitypeSupported checking for Windows and DLL in path
INFO    Loading JIntellitype DLL
INFO    Initializing JIntellitype library
INFO    isJIntellitypeSupported = true
INFO    [PLAYER      ] List of availables engines : {MPlayer}
INFO    [PLAYER      ] Selected engine : MPlayer
INFO    [HANDLER     ] Updating index for class net.sourceforge.atunes.kernel.modules.search.searchableobjects.FavoritesSearchableObject
INFO    [HANDLER     ] update search index
INFO    [HANDLER     ] Update index for class net.sourceforge.atunes.kernel.modules.search.searchableobjects.FavoritesSearchableObject finished
INFO    [HANDLER     ] Updating index for class net.sourceforge.atunes.kernel.modules.search.searchableobjects.RepositorySearchableObject
INFO    [HANDLER     ] update search index
INFO    [HANDLER     ] Update index for class net.sourceforge.atunes.kernel.modules.search.searchableobjects.RepositorySearchableObject finished
INFO    [PODCAST     ] Podcast feed entries retrieval done
INFO    [HANDLER     ] 4 songs added to play list
INFO    [PLAYER      ] Started play of file 01 - Musuhi no Toki.mp3
INFO    [PODCAST     ] Podcast feed entries retrieval done
INFO    [PODCAST     ] Podcast feed entries retrieval done
INFO    [PLAYER      ] Stop
INFO    [PLAYER      ] Started play of file 04 - Kioku no Keshiki Instrumental.mp3
INFO    [PODCAST     ] Podcast feed entries retrieval done",net.sourceforge.atunes.kernel.handlers.SystemTrayHandler:fillMenu(JTrayIconPopupMenu)
CLASS,solr-4.4.0,SOLR-5107,2013-08-01T09:48:12.000-05:00,LukeRequestHandler throws NullPointerException when numTerms=0,"{code}
    {code}
Defaults example http://localhost:8983/solr/collection1/admin/luke?fl=cat&numTerms=0 yields
{code}
ERROR org.apache.solr.core.SolrCore  – java.lang.NullPointerException
at org.apache.solr.handler.admin.LukeRequestHandler.getDetailedFieldInfo(LukeRequestHandler.java:610)
at org.apache.solr.handler.admin.LukeRequestHandler.getIndexedFieldsInfo(LukeRequestHandler.java:378)
at org.apache.solr.handler.admin.LukeRequestHandler.handleRequestBody(LukeRequestHandler.java:160)
at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)
at org.apache.solr.core.SolrCore.execute(SolrCore.java:1845)
at org.apache.solr.servlet.SolrDispatchFilter.execute(SolrDispatchFilter.java:666)
at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:369)
at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:158)
at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1419)
at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:455)
at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)
at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)
at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)
at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1075)
at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:384)
at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)
at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1009)
at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)
at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:255)
at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:154)
at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)
at org.eclipse.jetty.server.Server.handle(Server.java:368)
at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:489)
at org.eclipse.jetty.server.BlockingHttpConnection.handleRequest(BlockingHttpConnection.java:53)
at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:942)
at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1004)
at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:640)
at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)
at org.eclipse.jetty.server.BlockingHttpConnection.handle(BlockingHttpConnection.java:72)
at org.eclipse.jetty.server.bio.SocketConnector$ConnectorEndPoint.run(SocketConnector.java:264)
at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)
at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)
at java.lang.Thread.run(Thread.java:722)
{code}","solr.core.src.java.org.apache.solr.handler.admin.LukeRequestHandler
solr.core.src.test.org.apache.solr.handler.admin.LukeRequestHandlerTest"
CLASS,solr-4.4.0,SOLR-5295,2013-10-02T00:09:02.000-05:00,The createshard collection API creates maxShardsPerNode number of replicas if replicationFactor is not specified,"{quote}
 
  
  
  
 {quote}
As reported by Brett Hoerner on solr-user:
http://www.mail-archive.com/solr-user@lucene.apache.org/msg89545.html
{quote}
It seems that changes in 4.5 collection configuration now require users to set a maxShardsPerNode (or it defaults to 1).
Maybe this was the case before, but with the new CREATESHARD API it seems a very restrictive.
Everything is good.
Now I want a 4th shard, it seems impossible to create because the cluster
""knows"" I should only have 1 shard per node.
Yet my problem doesn't require more hardware, I just my new shard to exist on one of the existing servers.
Everything is good.
Now I add shard4 and it immediately tries to add 1000 replicas of shard4...
{quote}",solr.core.src.java.org.apache.solr.cloud.OverseerCollectionProcessor
CLASS,solr-4.4.0,SOLR-5296,2013-10-02T00:20:01.000-05:00,Creating a collection with implicit router adds shard ranges to each shard,"{quote}
 {quote}
Creating a collection with implicit router adds shard ranges to each shard.
http://localhost:8983/solr/admin/collections?action=CREATE&name=myimplicitcollection3&numShards=2&maxShardsPerNode=5&router.name=implicit&shards=s1,s2&replicationFactor=2
The following clusterstate is created:
{quote}
""myimplicitcollection3"":{
""shards"":{
""s1"":{
""range"":""80000000-ffffffff"",
""state"":""active"",
""replicas"":{
""core_node1"":{
""state"":""active"",
""base_url"":""http://192.168.1.5:8983/solr"",
""core"":""myimplicitcollection3_s1_replica2"",
""node_name"":""192.168.1.5:8983_solr""},
""core_node3"":{
""state"":""active"",
""base_url"":""http://192.168.1.5:7574/solr"",
""core"":""myimplicitcollection3_s1_replica1"",
""node_name"":""192.168.1.5:7574_solr"",
""leader"":""true""}}},
""s2"":{
""range"":""0-7fffffff"",
""state"":""active"",
""replicas"":{
""core_node2"":{
""state"":""active"",
""base_url"":""http://192.168.1.5:8983/solr"",
""core"":""myimplicitcollection3_s2_replica2"",
""node_name"":""192.168.1.5:8983_solr""},
""core_node4"":{
""state"":""active"",
""base_url"":""http://192.168.1.5:7574/solr"",
""core"":""myimplicitcollection3_s2_replica1"",
""node_name"":""192.168.1.5:7574_solr"",
""leader"":""true""}}}},
""maxShardsPerNode"":""5"",
""router"":{""name"":""implicit""},
""replicationFactor"":""2""}
{quote}
Note that the createshard API does the right thing.",solr.core.src.java.org.apache.solr.cloud.Overseer
FILE,AMQP,AMQP-164,2011-04-27T02:00:51.000-05:00,Exchange parsers do not handle anonymous queues correctly,"testContext(org.springframework.amqp.rabbit.stocks.web.ServletConfigurationTests)
The problem manifests itself as a test failure in the stocks sample because there is no integration test for the binding parsers in spring-rabbit.
Test set: org.springframework.amqp.rabbit.stocks.web.ServletConfigurationTests
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 3.521 sec <<< FAILURE!
testContext(org.springframework.amqp.rabbit.stocks.web.ServletConfigurationTests)  Time elapsed: 3.449 sec  <<< ERROR!
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.amqp.rabbit.core.RabbitAdmin#0': Invocation of init method failed; nested exception is org.springframework.amqp.AmqpIOException: java.io.IOException
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1420)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:519)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:456)
at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:291)
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:288)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:190)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:580)
at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:895)
at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:425)
at org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:139)
at org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:105)
at org.springframework.amqp.rabbit.stocks.web.ServletConfigurationTests.testContext(ServletConfigurationTests.java:32)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:76)
at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
at org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:35)
at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:115)
at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:97)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.maven.surefire.booter.ProviderFactory$ClassLoaderProxy.invoke(ProviderFactory.java:103)
at $Proxy0.invoke(Unknown Source)
at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:150)
at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcess(SurefireStarter.java:91)
at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:69)
Caused by: org.springframework.amqp.AmqpIOException: java.io.IOException
at org.springframework.amqp.rabbit.connection.RabbitUtils.convertRabbitAccessException(RabbitUtils.java:117)
at org.springframework.amqp.rabbit.connection.RabbitAccessor.convertRabbitAccessException(RabbitAccessor.java:106)
at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:314)
at org.springframework.amqp.rabbit.core.RabbitAdmin.initialize(RabbitAdmin.java:298)
at org.springframework.amqp.rabbit.core.RabbitAdmin$10.onCreate(RabbitAdmin.java:232)
at org.springframework.amqp.rabbit.connection.SingleConnectionFactory.addConnectionListener(SingleConnectionFactory.java:143)
at org.springframework.amqp.rabbit.core.RabbitAdmin.afterPropertiesSet(RabbitAdmin.java:215)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1477)
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1417)
... 40 more
Caused by: java.io.IOException
at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:107)
at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:131)
at com.rabbitmq.client.impl.ChannelN.exchangeBind(ChannelN.java:577)
at com.rabbitmq.client.impl.ChannelN.exchangeBind(ChannelN.java:59)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:239)
at $Proxy12.exchangeBind(Unknown Source)
at org.springframework.amqp.rabbit.core.RabbitAdmin.declareBindings(RabbitAdmin.java:347)
at org.springframework.amqp.rabbit.core.RabbitAdmin.access$200(RabbitAdmin.java:45)
at org.springframework.amqp.rabbit.core.RabbitAdmin$11.doInRabbit(RabbitAdmin.java:302)
at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:309)
... 46 more
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; reason: {#method<channel.close>(reply-code=404,reply-text=NOT_FOUND - no exchange 'tradeQueue' in vhost '/',class-id=40,method-id=30),null,""""}
at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:67)
at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:33)
at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:328)
at com.rabbitmq.client.impl.AMQChannel.rpc(AMQChannel.java:201)
at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:125)
... 58 more
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; reason: {#method<channel.close>(reply-code=404,reply-text=NOT_FOUND - no exchange 'tradeQueue' in vhost '/',class-id=40,method-id=30),null,""""}
at com.rabbitmq.client.impl.ChannelN.asyncShutdown(ChannelN.java:365)
at com.rabbitmq.client.impl.ChannelN.processAsync(ChannelN.java:235)
at com.rabbitmq.client.impl.AMQChannel.handleCompleteInboundCommand(AMQChannel.java:151)
at com.rabbitmq.client.impl.AMQChannel.handleFrame(AMQChannel.java:96)
at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:446)","org.springframework.amqp.rabbit.config.HeadersExchangeParser
org.springframework.amqp.rabbit.config.TopicExchangeParser
org.springframework.amqp.core.Binding
org.springframework.amqp.rabbit.config.FanoutExchangeParser
org.springframework.amqp.rabbit.config.DirectExchangeParser"
FILE,AMQP,AMQP-190,2011-09-10T20:24:17.000-05:00,CachingConnectionFactory leaks channels when synchronized with a TransactionManager,"convertAndSend()
It seems that when I use RabbitTemplate, channelTransacted=true, to convertAndSend() a message to an exchange within the context of a synchronized TransactionManager (e.g. an active transaction on the current thread), the channel is never closed, hence new publishes will always get their ""own"", shiny, new channel (that is never closed or released to the channel pool) until Rabbit can't handle any more channels.
See Forum Reference for more info.
The problem is not observed on the consumer side (e.g. MessageListenerContainer).
Its observed on the publishing side, (e.g. RabbitTemplate).
It is observed both if I use the RabbitTemplate, natively... or if I use spring-integration and the <int-amqp:outbound-channel-adapter...> tag.
BTW, the observed ""channel leak"" goes away when I choose channelTransacted=false.
I will look to supply a simple recreate, if I can scrounge the time.","org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer
org.springframework.amqp.rabbit.core.RabbitTemplatePerformanceIntegrationTests
org.springframework.amqp.rabbit.connection.ConnectionFactoryUtils
org.springframework.amqp.rabbit.connection.RabbitResourceHolder"
FILE,AMQP,AMQP-481,2015-03-02T05:28:36.000-06:00,@RabbitListener cannot be a scoped proxy,"@Scope(proxyMode=TARGET_CLASS)  @Lazy    RabbitListenerEndpointRegistrar.afterPropertiesSet()   RabbitListenerAnnotationBeanPostProcessor.afterSingletonsInstantiated()
Because of the way the endpoints are detected in a BeanPostProcessor and the message listener container is started in a SmartInitializingBean, the listener is never registered if it is a scoped proxy (e.g. @Scope(proxyMode=TARGET_CLASS) @Lazy).
The BeanPostProcessor is not presented with the actual listener until it is instantiated, and the instantiation happens lazily, the container is never created or started (I believe it's because the call to RabbitListenerEndpointRegistrar.afterPropertiesSet() in RabbitListenerAnnotationBeanPostProcessor.afterSingletonsInstantiated() is never made).
See https://github.com/spring-cloud/spring-cloud-config/issues/96 for original user's issue.","org.springframework.amqp.rabbit.listener.RabbitListenerEndpointRegistry
org.springframework.amqp.rabbit.annotation.EnableRabbitTests
org.springframework.amqp.rabbit.listener.RabbitListenerEndpointRegistrar"
FILE,AMQP,AMQP-502,2015-06-19T03:02:33.000-05:00,Fanout binding is not created due to missing routing key,"@RabbitListener(




      bindings = @QueueBinding(




          value = @Queue(




              autoDelete = ""true""




          ),




          exchange = @Exchange(




              type = ""fanout"",




              value = ""mytest.broadcast"",




              autoDelete = ""true""




          ),




          key = ""#""




      )




  )




  public void processBroadcast(String data) {




    int i = 0;




  }






 
  
  
  
     
 
     
 
  
  
  
  
  
   {}   
     
 
     
 
     
 
  
     
 
     
 
     
 
     
 
     
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   {}   
  
     
 
      
   {}
@RabbitListener(
bindings = @QueueBinding(
value = @Queue(
autoDelete = ""true""
),
exchange = @Exchange(
type = ""fanout"",
value = ""mytest.broadcast"",
autoDelete = ""true""
),
key = ""#""
)
)
public void processBroadcast(String data) {
int i = 0;
}
I will get an error, that the binding can not be created.
If i try another exchange type, the binding works.
Edit: It also does not work if omit the key.
The following is the debug logout and the stacktrace:
11:53:20.977 DEBUG   org.springframework.amqp.rabbit.core.RabbitAdmin - Initializing declarations
11:53:20.980  INFO   org.springframework.amqp.rabbit.core.RabbitAdmin - Auto-declaring a non-durable or auto-delete Exchange (mytest.broadcast) durable:false, auto-delete:true.
It will be deleted by the broker if it shuts down, and can be redeclared by closing and reopening the connection.
11:53:20.980  INFO   org.springframework.amqp.rabbit.core.RabbitAdmin - Auto-declaring a non-durable, auto-delete, or exclusive Queue (5df237ec-13d4-4aab-a0ff-772707bd7d03) durable:false, auto-delete:false, exclusive:true.
It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost.
11:53:20.982 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Creating cached Rabbit Channel from AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:20.982 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Executing callback on RabbitMQ Channel: Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:20.982 DEBUG   org.springframework.amqp.rabbit.core.RabbitAdmin - declaring Exchange 'mytest.broadcast'
11:53:20.984 DEBUG   org.springframework.amqp.rabbit.core.RabbitAdmin - declaring Queue '5df237ec-13d4-4aab-a0ff-772707bd7d03'
11:53:20.989 DEBUG   org.springframework.amqp.rabbit.core.RabbitAdmin - Binding destination [5df237ec-13d4-4aab-a0ff-772707bd7d03 (QUEUE)] to exchange [mytest.broadcast] with routing key [null]
11:53:20.991 DEBUG    o.s.a.r.listener.SimpleMessageListenerContainer - Recovering consumer in 5000 ms.
11:53:20.991 DEBUG    o.s.a.r.listener.SimpleMessageListenerContainer - Starting Rabbit listener container.
11:53:20.992 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Starting consumer Consumer: tags=[{}], channel=null, acknowledgeMode=AUTO local queue size=0
11:53:20.998 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Started on queue '5df237ec-13d4-4aab-a0ff-772707bd7d03' with tag amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA: Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:20.998 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - ConsumeOK : Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:20.999 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:21.093  INFO             mytest.server.Server - Started Server in 16.957 seconds (JVM running for 18.151)
11:53:22.003 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:23.004 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:24.009 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:25.013 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:26.017 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:26.071  WARN    o.s.a.r.listener.SimpleMessageListenerContainer - Consumer raised exception, processing can restart if the connection factory supports it
org.springframework.amqp.UncategorizedAmqpException: java.lang.IllegalStateException: Invalid configuration: 'routingKey' must be non-null.
at org.springframework.amqp.rabbit.support.RabbitExceptionTranslator.convertRabbitAccessException(RabbitExceptionTranslator.java:66) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.RabbitAccessor.convertRabbitAccessException(RabbitAccessor.java:110) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitTemplate.doExecute(RabbitTemplate.java:1124) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:1101) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:1077) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitAdmin.initialize(RabbitAdmin.java:381) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitAdmin$11.onCreate(RabbitAdmin.java:323) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.CompositeConnectionListener.onCreate(CompositeConnectionListener.java:32) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.createConnection(CachingConnectionFactory.java:446) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.ConnectionFactoryUtils$1.createConnection(ConnectionFactoryUtils.java:80) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.ConnectionFactoryUtils.doGetTransactionalResourceHolder(ConnectionFactoryUtils.java:130) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.ConnectionFactoryUtils.getTransactionalResourceHolder(ConnectionFactoryUtils.java:67) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.start(BlockingQueueConsumer.java:451) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1107) ~[spring-rabbit-1.5.0.M1.jar:na]
at java.lang.Thread.run(Thread.java:745) [na:1.8.0_20-ea]
Caused by: java.lang.IllegalStateException: Invalid configuration: 'routingKey' must be non-null.
at com.rabbitmq.client.impl.AMQImpl$Queue$Bind.<init>(AMQImpl.java:1577) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.AMQP$Queue$Bind$Builder.build(AMQP.java:870) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueBind(ChannelN.java:918) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueBind(ChannelN.java:61) ~[amqp-client-3.5.1.jar:na]
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_20-ea]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_20-ea]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_20-ea]
at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_20-ea]
at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:633) ~[spring-rabbit-1.5.0.M1.jar:na]
at com.sun.proxy.$Proxy0.queueBind(Unknown Source) ~[na:na]
at org.springframework.amqp.rabbit.core.RabbitAdmin.declareBindings(RabbitAdmin.java:480) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitAdmin.access$300(RabbitAdmin.java:54) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitAdmin$12.doInRabbit(RabbitAdmin.java:386) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitTemplate.doExecute(RabbitTemplate.java:1118) ~[spring-rabbit-1.5.0.M1.jar:na]
... 12 common frames omitted
11:53:26.071  INFO    o.s.a.r.listener.SimpleMessageListenerContainer - Restarting Consumer: tags=[{}], channel=null, acknowledgeMode=AUTO local queue size=0
11:53:26.071 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Closing Rabbit Channel: null
11:53:26.072 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Executing callback on RabbitMQ Channel: Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:26.072 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Publishing message on exchange [errors], routingKey = [org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.WARN]
11:53:26.072 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Starting consumer Consumer: tags=[{}], channel=null, acknowledgeMode=AUTO local queue size=0
11:53:26.075 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Creating cached Rabbit Channel from AMQChannel(amqp://stinger@10.0.10.34:5672/,2)
11:53:26.077 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
11:53:26.079 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Detected closed channel on exception.
Re-initializing: null
11:53:26.080  WARN     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Failed to declare queue:493eb6d6-8340-44a8-b73f-ab93446407dc
11:53:26.081 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Executing callback on RabbitMQ Channel: Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:26.081 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Publishing message on exchange [errors], routingKey = [org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.WARN]
11:53:26.081  WARN     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Queue declaration failed; retries left=3
org.springframework.amqp.rabbit.listener.BlockingQueueConsumer$DeclarationException: Failed to declare queue(s):[493eb6d6-8340-44a8-b73f-ab93446407dc]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:554) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.start(BlockingQueueConsumer.java:465) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1107) [spring-rabbit-1.5.0.M1.jar:na]
at java.lang.Thread.run(Thread.java:745) [na:1.8.0_20-ea]
Caused by: java.io.IOException: null
at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:106) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:102) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:124) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:873) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:61) ~[amqp-client-3.5.1.jar:na]
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_20-ea]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_20-ea]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_20-ea]
at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_20-ea]
at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:633) ~[spring-rabbit-1.5.0.M1.jar:na]
at com.sun.proxy.$Proxy0.queueDeclarePassive(Unknown Source) ~[na:na]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:544) ~[spring-rabbit-1.5.0.M1.jar:na]
... 3 common frames omitted
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:67) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:33) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:348) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.privateRpc(AMQChannel.java:221) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:118) ~[amqp-client-3.5.1.jar:na]
... 12 common frames omitted
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
at com.rabbitmq.client.impl.ChannelN.asyncShutdown(ChannelN.java:478) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.processAsync(ChannelN.java:315) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.handleCompleteInboundCommand(AMQChannel.java:144) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.handleFrame(AMQChannel.java:91) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:552) ~[amqp-client-3.5.1.jar:na]
... 1 common frames omitted
11:53:26.081 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Executing callback on RabbitMQ Channel: Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:26.081 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Publishing message on exchange [errors], routingKey = [org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.WARN]
11:53:27.018 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:28.022 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:29.025 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:30.030 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:31.034 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:31.086 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
11:53:31.086 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Detected closed channel on exception.
Re-initializing: null
11:53:31.088  WARN     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Failed to declare queue:493eb6d6-8340-44a8-b73f-ab93446407dc
11:53:31.089 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Executing callback on RabbitMQ Channel: Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:31.089 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Publishing message on exchange [errors], routingKey = [org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.WARN]
11:53:31.089  WARN     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Queue declaration failed; retries left=2
org.springframework.amqp.rabbit.listener.BlockingQueueConsumer$DeclarationException: Failed to declare queue(s):[493eb6d6-8340-44a8-b73f-ab93446407dc]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:554) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.start(BlockingQueueConsumer.java:465) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1107) [spring-rabbit-1.5.0.M1.jar:na]
at java.lang.Thread.run(Thread.java:745) [na:1.8.0_20-ea]
Caused by: java.io.IOException: null
at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:106) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:102) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:124) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:873) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:61) ~[amqp-client-3.5.1.jar:na]
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_20-ea]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_20-ea]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_20-ea]
at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_20-ea]
at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:633) ~[spring-rabbit-1.5.0.M1.jar:na]
at com.sun.proxy.$Proxy0.queueDeclarePassive(Unknown Source) ~[na:na]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:544) ~[spring-rabbit-1.5.0.M1.jar:na]
... 3 common frames omitted
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:67) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:33) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:348) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.privateRpc(AMQChannel.java:221) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:118) ~[amqp-client-3.5.1.jar:na]
... 12 common frames omitted
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
at com.rabbitmq.client.impl.ChannelN.asyncShutdown(ChannelN.java:478) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.processAsync(ChannelN.java:315) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.handleCompleteInboundCommand(AMQChannel.java:144) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.handleFrame(AMQChannel.java:91) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:552) ~[amqp-client-3.5.1.jar:na]
... 1 common frames omitted","org.springframework.amqp.rabbit.annotation.EnableRabbitIntegrationTests
org.springframework.amqp.rabbit.annotation.RabbitListenerAnnotationBeanPostProcessor"
FILE,AMQP,AMQP-516,2015-08-06T01:25:34.000-05:00,"Setting autoDelete or exclusive to anything, including ""true"" in @Queue without a queue name results in them being disabled","@RabbitListener(bindings = @QueueBinding(




    value = @Queue(autoDelete = ""true"", exclusive = ""true""),




    exchange = @Exchange(value = ""myFanout"", type = ExchangeTypes.FANOUT, durable = ""true"")




))






   
 if (!StringUtils.hasText(queueName)) {




    queueName = UUID.randomUUID().toString();




    if (!StringUtils.hasText(bindingQueue.exclusive())) {




        exclusive = true;




    }




    if (!StringUtils.hasText(bindingQueue.autoDelete())) {




        autoDelete = true;




    }




}




else {




    exclusive = resolveExpressionAsBoolean(bindingQueue.exclusive());




    autoDelete = resolveExpressionAsBoolean(bindingQueue.autoDelete());




}






 
 String e = bindingQueue.exclusive();




if (!StringUtils.hasText(e) || resolveExpressionAsBoolean(e)) {




    exclusive = true




}
The following queue declaration will result in a queue being declared with auto delete and exclusive set to false:
@RabbitListener(bindings = @QueueBinding(
value = @Queue(autoDelete = ""true"", exclusive = ""true""),
exchange = @Exchange(value = ""myFanout"", type = ExchangeTypes.FANOUT, durable = ""true"")
))
due to the following code in RabbitListenerAnnotationBeanProcessor:
if (!
StringUtils.hasText(queueName)) {
queueName = UUID.randomUUID().
toString();
if (!
StringUtils.hasText(bindingQueue.exclusive())) {
exclusive = true;
}
if (!
StringUtils.hasText(bindingQueue.autoDelete())) {
autoDelete = true;
}
}
else {
exclusive = resolveExpressionAsBoolean(bindingQueue.exclusive());
autoDelete = resolveExpressionAsBoolean(bindingQueue.autoDelete());
}
Making them exclusive and auto delete by default when using a random name seems like a good idea, but it should probably be changed to something like:
String e = bindingQueue.exclusive();
if (!
StringUtils.hasText(e) || resolveExpressionAsBoolean(e)) {
exclusive = true
}","org.springframework.amqp.rabbit.annotation.EnableRabbitIntegrationTests
org.springframework.amqp.rabbit.annotation.RabbitListenerAnnotationBeanPostProcessor"
FILE,AMQP,AMQP-633,2016-08-18T15:48:45.000-05:00,Non Transactional RabbitTemplate Uses Container Transactional Channel,"RabbitResourceHolder resourceHolder = (RabbitResourceHolder) TransactionSynchronizationManager




		.getResource(connectionFactory);




if (resourceHolder != null) {




	Channel channel = resourceFactory.getChannel(resourceHolder);




	if (channel != null) {




		return resourceHolder;




	}




}






    resourceFactory.isSynchedLocalTransactionAllowed()
When running a RabbitTemplate on a transactional container thread, the container channel is used, even if the RabbitTemplate is not marked transactional.
Consider the case where you wish to publish a message when there's an error, while rejecting the inbound message.
If the container is transactional, the published message is rolled back.
If you publish with a template that is not transactional, the publish should occur on a new channel.
RabbitResourceHolder resourceHolder = (RabbitResourceHolder) TransactionSynchronizationManager
.
getResource(connectionFactory);
if (resourceHolder !
= null) {
Channel channel = resourceFactory.getChannel(resourceHolder);
if (channel !
= null) {
return resourceHolder;
}
}","org.springframework.amqp.rabbit.listener.LocallyTransactedTests
org.springframework.amqp.rabbit.core.RabbitTemplate"
FILE,AMQP,AMQP-653,2016-10-08T02:53:08.000-05:00,RabbitMessagingTemplate doesn't take advantage of RabbitTemplate's registered converters,"@Bean




Jackson2JsonMessageConverter jackson2JsonMessageConverter() {




	return new Jackson2JsonMessageConverter();




}
@Bean
Jackson2JsonMessageConverter jackson2JsonMessageConverter() {
return new Jackson2JsonMessageConverter();
}
However, if you switch to RabbitMessagingTemplate, that bean no longer works, because RabbitMessagingTemplate doesn't offer to look up RabbitTemplate's converters, and instead relies on its own.
Looking inside Spring Boot, there doesn't appear to be any wiring that offers to hook up message converters either.","org.springframework.amqp.rabbit.core.RabbitMessagingTemplateTests
org.springframework.amqp.rabbit.core.RabbitMessagingTemplate"
FILE,AMQP,AMQP-196,2011-09-23T11:23:51.000-05:00,RabbitTemplate/RabbitGatewaySupport incompatible with JDK proxy,"class RabbitTemplate
RabbitGatewaySupport uses class RabbitTemplate rather than interface RabbitOperations for its rabbitTemplate property.
If AOP advice creates a proxy for a RabbitTemplate a JDK proxy will be created since RabbitTemplate implements the RabbitOperations interface.
If the advised bean is injected into RabbitGatewaySupport, an error will occur because the bean is not an instance of RabbitTemplate.
While a CGLIB proxy could be used, this would require making all proxies in the application CGLIB proxies which could have negative consequences.
Suggestion is to change RabbitGatewaySupport to make the type of rabbitTemplate RabbitOperations.
Since RabbitGatewaySupport invokes the getConnection method on rabbitTemplate, there would probably be a need to add this method to the RabbitOperations interface as well.
Also, there may be other places within Spring AMQP where RabbitTemplate could be injected; if so then these should be changed as well.
Workaround for this issue is to avoid use of RabbitGatewaySupport or create a local copy and modify it accordingly.",org.springframework.amqp.rabbit.core.RabbitOperations
FILE,AMQP,AMQP-656,2016-10-15T00:25:46.000-05:00,Unable to refer to the default exchange using @Argument within a @RabbitListener,"@Argument 
 @RabbitListener(bindings =




        @QueueBinding(




            value = @Queue(




                value = ""app.events.myEvent"",




                durable = ""true"",




                exclusive = ""false"",




                autoDelete = ""false"",




                arguments = {




                        @Argument(name=""x-dead-letter-exchange"", value = """"),




                        @Argument(name=""x-dead-letter-routing-key"", value=""app.dlq"")




                }),




            exchange = @Exchange(value=""amq.topic"", durable = ""true"", type = ""topic""),




            key=""event.app.myEvent.v1""




        ))






 
 @Bean




    public Queue appMyEventQueue() {




        return QueueBuilder.durable(""app.events.myEvent"")




            .withArgument(""x-dead-letter-exchange"", """")




            .withArgument(""x-dead-letter-routing-key"", deadLetterQueue().getName())




            .build();




    }
It seems you are unable to use @Argument annotations that use empty strings to refer to the default exchange.
@RabbitListener(bindings =
@QueueBinding(
value = @Queue(
value = ""app.events.myEvent"",
durable = ""true"",
exclusive = ""false"",
autoDelete = ""false"",
arguments = {
@Argument(name=""x-dead-letter-exchange"", value = """"),
@Argument(name=""x-dead-letter-routing-key"", value=""app.dlq"")
}),
exchange = @Exchange(value=""amq.topic"", durable = ""true"", type = ""topic""),
key=""event.app.myEvent.v1""
))
This fails though as spring seems to not send the empty string.
I tried being creative with using things like SPEL that would evaluate to an empty string, but same result.
If I use bean configs I am able to get the configuration I want using something like the following, the issue is just with the annotation based config.
@Bean
public Queue appMyEventQueue() {
return QueueBuilder.durable(""app.events.myEvent"")
.
withArgument(""x-dead-letter-exchange"", """")
.
withArgument(""x-dead-letter-routing-key"", deadLetterQueue().
getName())
.
build();
}","org.springframework.amqp.rabbit.annotation.EnableRabbitIntegrationTests
org.springframework.amqp.rabbit.annotation.RabbitListenerAnnotationBeanPostProcessor"
METHOD,commons-math-3-3.0,MATH-718,2011-12-03T18:40:44.000-06:00,inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials.,"{{System.out.println(new BinomialDistributionImpl(1000000, 0.5).inverseCumulativeProbability(0.5));}}
The inverseCumulativeProbability method of the BinomialDistributionImpl class returns wrong value for large trials.
{{System.out.println(new BinomialDistributionImpl(1000000, 0.5).
inverseCumulativeProbability(0.5));}}
This returns 499525, though it should be 499999.
I'm not sure how it should be fixed, but the cause is that the cumulativeProbability method returns Infinity, not NaN.
As the result the checkedCumulativeProbability method doesn't work as expected.","org.apache.commons.math3.util.ContinuedFraction:evaluate(double, double, int)"
METHOD,commons-math-3-3.0,MATH-841,2012-08-05T04:27:07.000-05:00,gcd speed up,"public void testApache(){
        Random rng=new Random(0);
        long checksum=0;
        long start=System.nanoTime();
        checksum+=gcd(0,Integer.MAX_VALUE);
        checksum+=gcd(Integer.MAX_VALUE,0);
        checksum+=gcd(Integer.MAX_VALUE,rng.nextInt());
        for(int i=0;i<10000;i++) checksum+=gcd(rng.nextInt(),Integer.MAX_VALUE);
        checksum+=gcd(Integer.MAX_VALUE,Integer.MAX_VALUE);
        checksum+=gcd(Integer.MIN_VALUE,1<<30);
        checksum+=gcd(1<<30,1<<30);
        checksum+=gcd(3 * (1<<20),9 * (1<<15));
        for(int i=0;i<30000000;i++) checksum+=gcd(rng.nextInt(),rng.nextInt());
        long end=System.nanoTime();
        long tns=end-start;
        long tms=(tns+500000)/1000000;
        long ts=(tms+500)/1000;
        System.out.println(""exec time=""+ts+""s, (""+tms+""ms), checksum=""+checksum);
        assertEquals(9023314441L,checksum);
    }
The gcd(int,int) method of ArithmeticUtils seems 2 times slower than the naive approach using modulo operator.
The following test code runs in 11s with current version and in 6s with the patch.
public void testApache(){
Random rng=new Random(0);
long checksum=0;
long start=System.nanoTime();
checksum+=gcd(0,Integer.MAX_VALUE);
checksum+=gcd(Integer.MAX_VALUE,0);
checksum+=gcd(Integer.MAX_VALUE,rng.nextInt());
for(int i=0;i<10000;i++) checksum+=gcd(rng.nextInt(),Integer.MAX_VALUE);
checksum+=gcd(Integer.MAX_VALUE,Integer.MAX_VALUE);
checksum+=gcd(Integer.MIN_VALUE,1<<30);
checksum+=gcd(1<<30,1<<30);
checksum+=gcd(3 * (1<<20),9 * (1<<15));
for(int i=0;i<30000000;i++) checksum+=gcd(rng.nextInt(),rng.nextInt());
long end=System.nanoTime();
long tns=end-start;
long tms=(tns+500000)/1000000;
long ts=(tms+500)/1000;
System.out.println(""exec time=""+ts+""s, (""+tms+""ms), checksum=""+checksum);
assertEquals(9023314441L,checksum);
}","org.apache.commons.math3.util.ArithmeticUtils:gcd(int, int)"
METHOD,commons-math-3-3.0,MATH-905,2012-11-20T14:54:39.000-06:00,"FastMath.[cosh, sinh] do not support the same range of values as the Math counterparts","Math.cosh(709.783)  
 FastMath.cosh(709.783)  
 Math.sinh(709.783)  
 FastMath.sinh(709.783)  
 StrictMath.log(Double.MAX_VALUE) 
 double t = exp(x*0.5);
return (0.5*t)*t;
 
 double t = exp(-x*0.5);
return (-0.5*t)*t;
As reported by Jeff Hain:
cosh(double) and sinh(double):
Math.cosh(709.783) = 8.991046692770538E307
FastMath.cosh(709.783) = Infinity
Math.sinh(709.783) = 8.991046692770538E307
FastMath.sinh(709.783) = Infinity
===> This is due to using exp( x )/2 for values of |x|
above 20: the result sometimes should not overflow,
but exp( x ) does, so we end up with some infinity.
===> for values of |x| >= StrictMath.log(Double.MAX_VALUE),
exp will overflow, so you need to use that instead:
for x positive:
double t = exp(x*0.5);
return (0.5*t)*t;
for x negative:
double t = exp(-x*0.5);
return (-0.5*t)*t;",org.apache.commons.math3.util.FastMathTest:testHyperbolicInverses()
METHOD,commons-math-3-3.0,MATH-915,2012-12-13T09:45:23.000-06:00,"Backward compatibility broken in ""EmpiricalDistribution""","{{o.a.c.m.random.EmpiricalDistribution}}
There is a binary-compatibility problem in {{o.a.c.m.random.EmpiricalDistribution}} (cf. ""Clirr"" report).
Usage of ""RandomDataImpl"" has been replaced by ""RandomDataGenerator"".
However, unless I'm mistaken, none of those is actually necessary.
Moreover, the ""randomData"" field in this class ""shadows"" the (deprecated) protected field in the super class.
Also, it duplicates functionality (RNG) already present in the super class (through the the ""random"" protected field).","org.apache.commons.math3.random.EmpiricalDistribution:EmpiricalDistribution()
org.apache.commons.math3.random.EmpiricalDistribution:reSeed(long)
org.apache.commons.math3.random.EmpiricalDistribution:EmpiricalDistribution(RandomGenerator)
org.apache.commons.math3.random.EmpiricalDistributionTest:setUp()
org.apache.commons.math3.random.EmpiricalDistribution:EmpiricalDistribution(int)
org.apache.commons.math3.random.EmpiricalDistribution:EmpiricalDistribution(int, RandomGenerator)"
FILE,DATACMNS,DATACMNS-57,2011-07-26T08:39:54.000-05:00,Use of parameterized type in constructor_ arguments is not supported,"Constructor.getParameterTypes()     getGenericParameterTypes()
When an object contains a List of another object (no simple types), the MongoMappingConverter finds correct generic type for the field, but when this field is used in the PersistenceConstructor, the type is considered to be the raw type and then no information is available to convert batck the DBObject instances for this list.
In the TypeDiscover class, the method getParameterTypes(Constructor<?>)
use the reflection method Class<?>
[] Constructor.getParameterTypes() that give no hint on the generic parameter types.
I replaced this call with Type[] Constructor::getGenericParameterTypes(), that has solved my problem.","org.springframework.data.util.TypeDiscovererUnitTests
org.springframework.data.util.TypeDiscoverer"
FILE,DATACMNS,DATACMNS-68,2011-08-26T08:05:09.000-05:00,NullPointerException in AbstractPersistentProperty::getComponentType(),"class TestClassSet extends TreeSet<Object> { }









 class TestClassComplex {




    private String id;




    private TestClassSet testClassSet;









    public String getId() {




        return id;




    }









    public TestClassSet getTestClassSet() {




        return testClassSet;




    }









    public void setTestClassSet(TestClassSet testClassSet) {




        this.testClassSet = testClassSet;




    }




}






 
 List<TestClassSet> o = mongoTemplate.findAll(TestClassSet.class);






 
 List<TestClassComplex> o = mongoTemplate.findAll(TestClassComplex.class);
class TestClassSet extends TreeSet<Object> { }
class TestClassComplex {
private String id;
private TestClassSet testClassSet;
public String getId() {
return id;
}
public TestClassSet getTestClassSet() {
return testClassSet;
}
public void setTestClassSet(TestClassSet testClassSet) {
this.testClassSet = testClassSet;
}
}
List<TestClassSet> o = mongoTemplate.findAll(TestClassSet.class);
But this fails with the NPE below:
List<TestClassComplex> o = mongoTemplate.findAll(TestClassComplex.class);
java.lang.NullPointerException: null
at org.springframework.data.mapping.model.AbstractPersistentProperty.getComponentType(AbstractPersistentProperty.java:147) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.model.AbstractPersistentProperty.isComplexType(AbstractPersistentProperty.java:136) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.model.AbstractPersistentProperty.isEntity(AbstractPersistentProperty.java:143) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.context.AbstractMappingContext.getNestedTypeToAdd(AbstractMappingContext.java:316) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.context.AbstractMappingContext.access$100(AbstractMappingContext.java:65) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.context.AbstractMappingContext$1.doWith(AbstractMappingContext.java:267) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.util.ReflectionUtils.doWithFields(ReflectionUtils.java:513) ~[spring-core-3.0.5.RELEASE.jar:3.0.5.RELEASE]
at org.springframework.data.mapping.context.AbstractMappingContext.addPersistentEntity(AbstractMappingContext.java:244) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.context.AbstractMappingContext.getPersistentEntity(AbstractMappingContext.java:165) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.context.AbstractMappingContext.getPersistentEntity(AbstractMappingContext.java:140) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.context.AbstractMappingContext.getPersistentEntity(AbstractMappingContext.java:65) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mongodb.core.MongoTemplate.determineCollectionName(MongoTemplate.java:1105) ~[spring-data-mongodb-1.0.0.BUILD-20110826.114729-388.jar:na]
at org.springframework.data.mongodb.core.MongoTemplate.findAll(MongoTemplate.java:786) ~[spring-data-mongodb-1.0.0.BUILD-20110826.114729-388.jar:na]
...",org.springframework.data.util.ClassTypeInformation
FILE,DATACMNS,DATACMNS-114,2011-12-19T03:21:41.000-06:00,Wrong custom implementation automatically detected,"AbstractRepositoryConfigDefinitionParser.detectCustomImplementation(...)  getImplementationClassName()
When automatically scanning the repositories, and their custom implementation, the wrong custom implementation is wired to our repository bean.
Resulting in the following exception:
Caused by: java.lang.IllegalArgumentException: No property find found for type class com.myproject.Contract
at org.springframework.data.repository.query.parser.Property.<init>(Property.java:76)
at org.springframework.data.repository.query.parser.Property.<init>(Property.java:97)
at org.springframework.data.repository.query.parser.Property.create(Property.java:312)
at org.springframework.data.repository.query.parser.Property.create(Property.java:326)
at org.springframework.data.repository.query.parser.Property.create(Property.java:326)
at org.springframework.data.repository.query.parser.Property.create(Property.java:326)
at org.springframework.data.repository.query.parser.Property.create(Property.java:292)
at org.springframework.data.repository.query.parser.Property.from(Property.java:251)
at org.springframework.data.repository.query.parser.Property.from(Property.java:232)
at org.springframework.data.repository.query.parser.Part.<init>(Part.java:48)
at org.springframework.data.repository.query.parser.PartTree$OrPart.<init>(PartTree.java:242)
at org.springframework.data.repository.query.parser.PartTree.buildTree(PartTree.java:101)
at org.springframework.data.repository.query.parser.PartTree.<init>(PartTree.java:77)
at org.springframework.data.jpa.repository.query.PartTreeJpaQuery.<init>(PartTreeJpaQuery.java:56)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:92)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateIfNotFoundQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:159)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$AbstractQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:71)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.<init>(RepositoryFactorySupport.java:303)
at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:157)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:120)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:39)
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:142)
... 67 more
When starting the application context, the contractRepository bean is linked to our anotherContractRepositoryImpl rather than the contractRepositoryImpl.
This behavior seems to be operating system dependent, as it only occurs on our Linux CI server.
The cause of our problem can be found at AbstractRepositoryConfigDefinitionParser.detectCustomImplementation(...).",org.springframework.data.repository.config.AbstractRepositoryConfigDefinitionParser
FILE,DATACMNS,DATACMNS-154,2012-04-17T06:02:43.000-05:00,Overwriting of delete(T entity) saveAndFlush(T entity); does not work anymore,"public interface UserRepository extends JpaRepository<User, Long>,




		PagingAndSortingRepository<User, Long> {









	public User saveAndFlush(User entity);









	public void delete(User entity);




}
During initialization of the following repository an exception occurs for these two methods.
public interface UserRepository extends JpaRepository<User, Long>,
PagingAndSortingRepository<User, Long> {
public User saveAndFlush(User entity);
public void delete(User entity);
}
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userRepository': FactoryBean threw exception on object creation; nested exception is java.lang.IllegalArgumentException: Could not create query metamodel for method public abstract entities.User repositories.UserRepository.saveAndFlush(entities.User)!
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:149)
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:102)
at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1442)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:248)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:848)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:790)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:707)
at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:478)
... 41 more
Caused by: java.lang.IllegalArgumentException: Could not create query metamodel for method public abstract entities.User repositories.UserRepository.saveAndFlush(entities.User)!
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:95)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateIfNotFoundQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:164)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$AbstractQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:71)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.<init>(RepositoryFactorySupport.java:269)
at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:142)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:114)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:38)
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:142)
... 49 more
Caused by: java.lang.IllegalArgumentException: No property save found for type class entities.User
at org.springframework.data.mapping.PropertyPath.<init>(PropertyPath.java:73)
at org.springframework.data.mapping.PropertyPath.<init>(PropertyPath.java:92)
at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:319)
at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:301)
at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:265)
at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:239)
at org.springframework.data.repository.query.parser.Part.<init>(Part.java:70)
at org.springframework.data.repository.query.parser.PartTree$OrPart.<init>(PartTree.java:180)
at org.springframework.data.repository.query.parser.PartTree$Predicate.buildTree(PartTree.java:260)
at org.springframework.data.repository.query.parser.PartTree$Predicate.<init>(PartTree.java:240)
at org.springframework.data.repository.query.parser.PartTree.<init>(PartTree.java:68)
at org.springframework.data.jpa.repository.query.PartTreeJpaQuery.<init>(PartTreeJpaQuery.java:57)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:93)
... 56 more
The same code works with snapshot before weekend (13.04.2012).
So","org.springframework.data.repository.core.support.DefaultRepositoryInformationUnitTests
org.springframework.data.repository.core.support.DefaultRepositoryInformation"
FILE,DATACMNS,DATACMNS-157,2012-04-20T01:24:38.000-05:00,@Query in extending interface is not picked up correctly,"@Query 
 @NoRepositoryBean




public interface EntityRepository<T> extends JpaRepository<T, Long> {









	T findByDealer(Dealer dealer);




}









 public interface CarRepository extends EntityRepository<PersonalSiteVehicle> {









	@Override




	@Query(""select p from PersonalSiteVehicle p join p.detail d join d.enrichable e where e.dealer = ?1"")




	PersonalSiteVehicle findByDealer(Dealer dealer);




}






 
  @Query
This does not work.
@NoRepositoryBean
public interface EntityRepository<T> extends JpaRepository<T, Long> {
T findByDealer(Dealer dealer);
}
public interface CarRepository extends EntityRepository<PersonalSiteVehicle> {
@Override
@Query(""select p from PersonalSiteVehicle p join p.detail d join d.enrichable e where e.dealer = ?
1"")
PersonalSiteVehicle findByDealer(Dealer dealer);
}
Results in
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'carRepository': FactoryBean threw exception on object creation; nested exception is java.lang.IllegalArgumentException: Could not create query metamodel for method public abstract java.lang.Object nl.inmotiv.indi.repository.EntityRepository.findByDealer(nl.inmotiv.indi.domain.Dealer)!
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:149)
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:102)
at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1442)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:248)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:848)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:790)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:707)
at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:478)
... 32 more
Caused by: java.lang.IllegalArgumentException: Could not create query metamodel for method public abstract java.lang.Object nl.inmotiv.indi.repository.EntityRepository.findByDealer(nl.inmotiv.indi.domain.Dealer)!
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:95)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateIfNotFoundQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:164)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$AbstractQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:71)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.<init>(RepositoryFactorySupport.java:269)
at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:142)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:114)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:38)
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:142)
... 40 more
Caused by: java.lang.IllegalArgumentException: No property dealer found for type class nl.inmotiv.indi.domain.PersonalSiteVehicle
at org.springframework.data.mapping.PropertyPath.<init>(PropertyPath.java:73)
at org.springframework.data.mapping.PropertyPath.<init>(PropertyPath.java:92)
at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:319)
at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:301)
at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:265)
at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:239)
at org.springframework.data.repository.query.parser.Part.<init>(Part.java:70)
at org.springframework.data.repository.query.parser.PartTree$OrPart.<init>(PartTree.java:180)
at org.springframework.data.repository.query.parser.PartTree$Predicate.buildTree(PartTree.java:260)
at org.springframework.data.repository.query.parser.PartTree$Predicate.<init>(PartTree.java:240)
at org.springframework.data.repository.query.parser.PartTree.<init>(PartTree.java:71)
at org.springframework.data.jpa.repository.query.PartTreeJpaQuery.<init>(PartTreeJpaQuery.java:57)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:93)
It looks like Spring Data does not use the @Query annotation in the sub interface.","org.springframework.data.repository.core.support.DefaultRepositoryInformationUnitTests
org.springframework.data.repository.core.support.DefaultRepositoryInformation"
FILE,DATACMNS,DATACMNS-160,2012-04-21T08:47:35.000-05:00,Regression of Repository instances with only delete* methods,"public interface DeleteOnlyRepository<T, ID extends Serializable> extends Repository<T, ID>{









    public void delete(ID paramID);









    public void delete(T paramT);









    public void delete(Iterable<? extends T> paramIterable);









    public void deleteAll();









}
A repository which only defines delete methods is not created by the Spring Data code with the exception:
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'treeEntityDeleteRepository': FactoryBean threw exception on object creation; nested exception is java.lang.IllegalArgumentException: Could not create query metamodel for method public abstract void example.data.DeleteOnlyRepository.delete(java.lang.Object)!
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:149)
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:102)
at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1441)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:305)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:585)
at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:913)
at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:464)
at org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:139)
at org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:83)
at example.data.RepositoryTest.testExample(RepositoryTest.java:10)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:601)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
at org.junit.runners.BlockJUnit4ClassRunner.runNotIgnored(BlockJUnit4ClassRunner.java:79)
at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:71)
at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)
at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
Caused by: java.lang.IllegalArgumentException: Could not create query metamodel for method public abstract void example.data.DeleteOnlyRepository.delete(java.lang.Object)!
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:95)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateIfNotFoundQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:164)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$AbstractQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:71)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.<init>(RepositoryFactorySupport.java:269)
at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:142)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:114)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:38)
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:142)
... 33 more
Caused by: java.lang.IllegalArgumentException: No property delete found for type class example.data.TreeEntity
at org.springframework.data.mapping.PropertyPath.<init>(PropertyPath.java:73)
at org.springframework.data.mapping.PropertyPath.<init>(PropertyPath.java:92)
at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:319)
at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:301)
at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:265)
at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:239)
at org.springframework.data.repository.query.parser.Part.<init>(Part.java:70)
at org.springframework.data.repository.query.parser.PartTree$OrPart.<init>(PartTree.java:180)
at org.springframework.data.repository.query.parser.PartTree$Predicate.buildTree(PartTree.java:260)
at org.springframework.data.repository.query.parser.PartTree$Predicate.<init>(PartTree.java:240)
at org.springframework.data.repository.query.parser.PartTree.<init>(PartTree.java:68)
at org.springframework.data.jpa.repository.query.PartTreeJpaQuery.<init>(PartTreeJpaQuery.java:57)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:93)
... 40 more
caused by a repository which extends:
public interface DeleteOnlyRepository<T, ID extends Serializable> extends Repository<T, ID>{
public void delete(ID paramID);
public void delete(T paramT);
public void delete(Iterable<? extends T> paramIterable);
public void deleteAll();
}
This appears to be a regression following the upgrade to Spring Data Commons 1.3.0 RC1, as it's not present when using Spring Data JPA 1.1.0.
RC1, only when using the build snapshots.
I realise that the bug is most likely in the data commons package, but I wasn't sure how to reproduce it without using the JPA component, so I'm reporting here for the mo - hope that's OK.
The reason for wanting such a repository is to prevent clients from performing CRU operations on a child object without the use of the parent, but I do need to offer the ability to delete it.","org.springframework.data.repository.core.support.DefaultRepositoryInformationUnitTests
org.springframework.data.repository.core.support.DefaultRepositoryInformation"
FILE,DATACMNS,DATACMNS-176,2012-05-21T11:47:05.000-05:00,StackOverflowError when inserted object is a CGLIB proxy,"@Scope(value=""session"", proxyMode = ScopedProxyMode.TARGET_CLASS)
M1)] that is in ""session"" scope and using a CGLIB proxy (ie: ""@Scope(value=""session"", proxyMode = ScopedProxyMode.TARGET_CLASS)"") I receive a StackOverflowError.
When removing the session scoping, it works correctly.java.lang.StackOverflowError
at java.util.HashMap$EntryIterator.<init>(HashMap.java:832)
at java.util.HashMap$EntryIterator.<init>(HashMap.java:832)
at java.util.HashMap.newEntryIterator(HashMap.java:846)
at java.util.HashMap$EntrySet.iterator(HashMap.java:950)
at java.util.AbstractMap.hashCode(AbstractMap.java:459)
at org.springframework.util.ObjectUtils.nullSafeHashCode(ObjectUtils.java:336)
at org.springframework.data.util.TypeDiscoverer.hashCode(TypeDiscoverer.java:365)
at org.springframework.data.util.ClassTypeInformation.hashCode(ClassTypeInformation.java:39)
at org.springframework.util.ObjectUtils.nullSafeHashCode(ObjectUtils.java:336)
at org.springframework.data.util.ParentTypeAwareTypeInformation.hashCode(ParentTypeAwareTypeInformation.java:79)
at org.springframework.util.ObjectUtils.nullSafeHashCode(ObjectUtils.java:336)
at org.springframework.data.util.ParentTypeAwareTypeInformation.hashCode(ParentTypeAwareTypeInformation.java:79)
at org.springframework.util.ObjectUtils.nullSafeHashCode(ObjectUtils.java:336)
at org.springframework.data.util.ParentTypeAwareTypeInformation.hashCode(ParentTypeAwareTypeInformation.java:79)
at org.springframework.util.ObjectUtils.nullSafeHashCode(ObjectUtils.java:336)
.... (Repeats)",org.springframework.data.util.ClassTypeInformation
FILE,DATACMNS,DATACMNS-233,2012-09-14T07:38:12.000-05:00,DomainClassConverter should gracefully return null for null sources or empty strings,"@javax.validation.constraints.NotNull  @javax.persistence.ManyToOne
I've noticed an important issue related to automatic web binding of String id to Domain class.
When posting a new Order where Order.customer == """" then a converter exception is thrown:
Failed to convert property value of type java.lang.String to required type org.mycomp.domain.Customer for property customer; nested exception is org.springframework.core.convert.ConversionFailedException: Failed to convert from type java.lang.String to type @javax.
validation.constraints.NotNull @javax.
persistence.ManyToOne org.mycomp.domain.Customer for value '; nested exception is org.springframework.dao.InvalidDataAccessApiUsageException: The given id must not be null!
; nested exception is java.lang.IllegalArgumentException: The given id must not be null!
And note that for optional references this even might even cause a complete blocker?
<form:select path=""customer"">
<form:option value="""" label=""Select"" />
<form:options items=""${customers}"" itemValue=""id""></form:options>
</form:select>","org.springframework.data.repository.support.DomainClassConverterUnitTests
org.springframework.data.repository.support.DomainClassConverter"
FILE,DATACMNS,DATACMNS-257,2012-11-29T02:29:27.000-06:00,PropertyPath cannot deal with all uppercase fields,"@Id 
 class Foo{




  




  @Id




  private String UID;









  //code omitted




}
Cannot execute MongoOperations.findOne method if my model entity contains @Id field which name is uppercase, like UID.
class Foo{
@Id
private String UID;
//code omitted
}
Steps to reproduce:
3) at this step you will get an exception
java.lang.IllegalArgumentException: No property uID found on com.xxxxxxxxxxxxx.TemplateDefinitionObject!
at org.springframework.data.mapping.context.AbstractMappingContext.getPersistentPropertyPath(AbstractMappingContext.java:225)
at org.springframework.data.mongodb.core.convert.QueryMapper.getPath(QueryMapper.java:202)
at org.springframework.data.mongodb.core.convert.QueryMapper.determineKey(QueryMapper.java:221)
at org.springframework.data.mongodb.core.convert.QueryMapper.getMappedObject(QueryMapper.java:87)
at org.springframework.data.mongodb.core.MongoTemplate.doFindOne(MongoTemplate.java:1307)
at org.springframework.data.mongodb.core.MongoTemplate.findById(MongoTemplate.java:516)
at org.springframework.data.mongodb.core.MongoTemplate.findById(MongoTemplate.java:509)
at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.findOne(SimpleMongoRepository.java:99)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:616)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.executeMethodOn(RepositoryFactorySupport.java:334)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.invoke(RepositoryFactorySupport.java:319)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)
at $Proxy37.findOne(Unknown Source)
at com.xxxxxxxx.ShortTest.testFoo(ShortTest.java:65)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:616)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:74)
at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:83)
at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:72)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:231)
at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:174)
at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)","org.springframework.data.mapping.PropertyPath
org.springframework.data.mapping.PropertyPathUnitTests"
FILE,DATACMNS,DATACMNS-390,2013-10-28T09:07:46.000-05:00,ConcurrentModificationException in MappingContextTypeInformationMapper.resolveTypeFrom,"getPersistentEntities()
	 public Collection<E> getPersistentEntities() {
		try 
{
			read.lock();
			return persistentEntities.values();
		}
 finally 
{
			read.unlock();
		}
	}
       
     values()
I am using Spring Data and found the following Stacktrace in the logs:
Caused by: java.util.ConcurrentModificationException
at java.util.HashMap$HashIterator.nextEntry(HashMap.java:894)
at java.util.HashMap$ValueIterator.next(HashMap.java:922)
at org.springframework.data.convert.MappingContextTypeInformationMapper.resolveTypeFrom(MappingContextTypeInformationMapper.java:117)
at org.springframework.data.convert.DefaultTypeMapper.getFromCacheOrCreate(DefaultTypeMapper.java:122)
at org.springframework.data.convert.DefaultTypeMapper.readType(DefaultTypeMapper.java:102)
at org.springframework.data.convert.DefaultTypeMapper.getDefaultedTypeToBeUsed(DefaultTypeMapper.java:164)
at org.springframework.data.convert.DefaultTypeMapper.readType(DefaultTypeMapper.java:141)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:186)
I think that there might be a data race in the implementation of  org.springframework.data.mapping.context.AbstractMappingContext#getPersistentEntities()
public Collection<E> getPersistentEntities() { try
{ read.lock();
return persistentEntities.values();
} finally
{ read.unlock();
}
}
Although the code acquires a read lock when returning the values of the HashMap ""persistentEntities"" it immediately releases the lock.
This opens up the possibility that a thread modifies the values of ""persistentEntities"" while another thread is iterating over the values.
The JavaDoc of java.util.HashMap#values() says ""If the map is modified while an iteration over the collection is in progress
(except through the iterator's own <tt>remove</tt> operation), the results of the iteration are undefined.""
In my case I get a ConcurrentModificationException.
It would be nice, if you could take a look at this issue.","org.springframework.data.mapping.context.AbstractMappingContext
org.springframework.data.mapping.context.AbstractMappingContextUnitTests"
FILE,DATACMNS,DATACMNS-509,2014-05-08T08:39:02.000-05:00,NullableWrapper Breaks JSON Conversion,"{




    final Set<Pos> allPos = posService.findAll();




    return ImmutableSortedSet.copyOf(allPos);




}






 
 {""name: ""pos1""}  {""name: ""pos2""} 
  
     {""name: ""pos1""}  {""name: ""pos2""}
Since an upgrade to JPA 1.6 RC1, Spring MVC fails to properly address a NullableWrapper and this is returned, with the contents contained with the NullableWrapper.
public Callable<Set<Pos>> get(.....) {
final Set<Pos> allPos = posService.findAll();
return ImmutableSortedSet.copyOf(allPos);
}
With Spring Data JPA 1.5.
, I get on the wire a set of Pos's in JSON format, i.e.,
[{""name: ""pos1""}, {""name: ""pos2""}]
With Spring Data JPA 1.6 RC1, I now get the NullableWrapper with Contents:
[valueType: ""java.util.ArrayList"", value: [{""name: ""pos1""}, {""name: ""pos2""}]]","org.springframework.data.repository.core.support.DummyRepositoryFactory
org.springframework.data.repository.core.support.RepositoryFactorySupport
org.springframework.data.repository.core.support.RepositoryFactorySupportUnitTests"
FILE,DATACMNS,DATACMNS-511,2014-05-22T00:04:43.000-05:00,AbstractMappingContext.addPersistentEntity causes infinite loop,"public class User extends AbstractTenantUser<User, Role, Permission, Tenant> {




    ...




}




 public abstract class AbstractTenantUser<USER extends AbstractTenantUser<USER, ROLE, PERMISSION, TENANT>, ROLE extends AbstractRole<USER, PERMISSION>, PERMISSION extends AbstractPermission<USER>, TENANT extends AbstractTenant<USER>> extends AbstractUser<USER, ROLE, PERMISSION> implements TenantEntity<TENANT> {




    ...




}




 public abstract class AbstractUser<USER extends AbstractUser<USER, ROLE, PERMISSION>, ROLE extends AbstractRole<USER, PERMISSION>, PERMISSION extends AbstractPermission<USER>> extends AuditingDateBaseEntity<USER> {




    ...




}




 public abstract class AbstractPermission<USER extends AbstractUser<USER, ?, ?>> extends AuditingDateBaseEntity<USER> {




    ...




}




 public abstract class AuditingDateBaseEntity<USER extends AbstractUser<USER, ?, ?>> extends AbstractDateBaseEntity implements AuditingEntity<USER> {




    ...




}




 public abstract class AbstractDateBaseEntity extends AbstractBaseEntity implements DateEntity {




    ...




}




 public abstract class AbstractBaseEntity implements BaseEntity {




    ...




}
After updating from Codd SR2 to Dijkstra I could not run my tests.
After debugging the issue I found that the problem lies in AbstractMappingContext.addPersistentEntity.
This method is never called in Codd SR2 due to initialize not being triggered.
public class User extends AbstractTenantUser<User, Role, Permission, Tenant> {
...
}
public abstract class AbstractTenantUser<USER extends AbstractTenantUser<USER, ROLE, PERMISSION, TENANT>, ROLE extends AbstractRole<USER, PERMISSION>, PERMISSION extends AbstractPermission<USER>, TENANT extends AbstractTenant<USER>> extends AbstractUser<USER, ROLE, PERMISSION> implements TenantEntity<TENANT> {
...
}
public abstract class AbstractUser<USER extends AbstractUser<USER, ROLE, PERMISSION>, ROLE extends AbstractRole<USER, PERMISSION>, PERMISSION extends AbstractPermission<USER>> extends AuditingDateBaseEntity<USER> {
...
}
public abstract class AbstractPermission<USER extends AbstractUser<USER, ?
, ?
>> extends AuditingDateBaseEntity<USER> {
...
}
public abstract class AuditingDateBaseEntity<USER extends AbstractUser<USER, ?
, ?
>> extends AbstractDateBaseEntity implements AuditingEntity<USER> {
...
}
public abstract class AbstractDateBaseEntity extends AbstractBaseEntity implements DateEntity {
...
}
public abstract class AbstractBaseEntity implements BaseEntity {
...
}
I hope this gives enough insight into the problem and hopefully you can fix this soon.",org.springframework.data.util.TypeVariableTypeInformation
FILE,DATACMNS,DATACMNS-562,2014-08-19T01:25:20.000-05:00,MappingContext fails to resolve TreeMap as Map value type,"public class ClassC extends ClassA {




	private ClassB b;









	public ClassB getB() {




		return b;




	}









	public void setB(ClassB b) {




		this.b = b;




	}




}









 class ClassA {









	private String name;









	private ClassD dObject;









	public String getName() {




		return name;




	}









	public void setName(String name) {




		this.name = name;




	}









	public ClassD getdObject() {




		return dObject;




	}









	public void setdObject(ClassD dObject) {




		this.dObject = dObject;




	}




}









 class ClassB extends ClassA {




}









 class ClassD {









	private TreeMap<String, TreeMap<String, String>> map = new TreeMap<>();









	public TreeMap<String, TreeMap<String, String>> getMap() {




		return map;




	}









	public void setMap(TreeMap<String, TreeMap<String, String>> map) {




		this.map = map;




	}









}






 
 
 
 
 
 
 
 ClassC cObject = new ClassC();




cObject.setName(""Jon"");




try {




	mongoTemplate.save(cObject, ""c"");




} catch (Exception e) {




	e.printStackTrace();




}






 
 
     private transient EntrySet entrySet = null;
ClassC.java
public class ClassC extends ClassA {
private ClassB b;
public ClassB getB() {
return b;
}
public void setB(ClassB b) {
this.b = b;
}
}
class ClassA {
private String name;
private ClassD dObject;
public String getName() {
return name;
}
public void setName(String name) {
this.name = name;
}
public ClassD getdObject() {
return dObject;
}
public void setdObject(ClassD dObject) {
this.dObject = dObject;
}
}
class ClassB extends ClassA {
}
class ClassD {
private TreeMap<String, TreeMap<String, String>> map = new TreeMap<>();
public TreeMap<String, TreeMap<String, String>> getMap() {
return map;
}
public void setMap(TreeMap<String, TreeMap<String, String>> map) {
this.map = map;
}
}
// handle this correctly somewhere
// @Autowired
// private MongoOperations	mongoTemplate;
ClassC cObject = new ClassC();
cObject.setName(""Jon"");
try {
mongoTemplate.save(cObject, ""c"");
} catch (Exception e) {
e.printStackTrace();
}
Exception caught as below:
java.lang.ArrayIndexOutOfBoundsException: 0
at org.springframework.data.util.ParameterizedTypeInformation.getComponentType(ParameterizedTypeInformation.java:147)
at org.springframework.data.util.TypeDiscoverer.getActualType(TypeDiscoverer.java:292)
at org.springframework.data.util.ParentTypeAwareTypeInformation.getActualType(ParentTypeAwareTypeInformation.java:29)
at org.springframework.data.mapping.model.AbstractPersistentProperty.getPersistentEntityType(AbstractPersistentProperty.java:125)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.createAndRegisterProperty(AbstractMappingContext.java:469)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.doWith(AbstractMappingContext.java:427)
at org.springframework.util.ReflectionUtils.doWithFields(ReflectionUtils.java:572)
at org.springframework.data.mapping.context.AbstractMappingContext.addPersistentEntity(AbstractMappingContext.java:295)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.createAndRegisterProperty(AbstractMappingContext.java:470)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.doWith(AbstractMappingContext.java:427)
at org.springframework.util.ReflectionUtils.doWithFields(ReflectionUtils.java:572)
at org.springframework.data.mapping.context.AbstractMappingContext.addPersistentEntity(AbstractMappingContext.java:295)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.createAndRegisterProperty(AbstractMappingContext.java:470)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.doWith(AbstractMappingContext.java:427)
at org.springframework.util.ReflectionUtils.doWithFields(ReflectionUtils.java:572)
at org.springframework.data.mapping.context.AbstractMappingContext.addPersistentEntity(AbstractMappingContext.java:295)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.createAndRegisterProperty(AbstractMappingContext.java:470)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.doWith(AbstractMappingContext.java:427)
at org.springframework.util.ReflectionUtils.doWithFields(ReflectionUtils.java:572)
at org.springframework.data.mapping.context.AbstractMappingContext.addPersistentEntity(AbstractMappingContext.java:295)
at org.springframework.data.mapping.context.AbstractMappingContext.getPersistentEntity(AbstractMappingContext.java:181)
at org.springframework.data.mapping.context.AbstractMappingContext.getPersistentEntity(AbstractMappingContext.java:141)
at org.springframework.data.mapping.context.AbstractMappingContext.getPersistentEntity(AbstractMappingContext.java:67)
at org.springframework.data.mongodb.core.MongoTemplate.getPersistentEntity(MongoTemplate.java:1831)
at org.springframework.data.mongodb.core.MongoTemplate.save(MongoTemplate.java:829)
I got the same issues on both spring-data-mongodb-1.5.0-RELEASE.jar and spring-data-mongodb-1.5.2-RELEASE.jar.
Below is some of my investigation, maybe helpful.
It seems something unsafe in spring-data-commons-1.8.0-RELEASE.jar and spring-data-commons-1.8.2-RELEASE.jar.
It seems that TreeMap has something different to HashMap, such as private transient EntrySet entrySet = null;, which causes returning empty Type array to emit ArrayIndexOutOfBoundsException.
May I know why the author treats Map as normal entity Type to traverse every field inside?
Normally Map and List only used as container.","org.springframework.data.mapping.model.AbstractPersistentPropertyUnitTests
org.springframework.data.mapping.model.AbstractPersistentProperty"
FILE,DATACMNS,DATACMNS-616,2014-12-17T02:25:54.000-06:00,AnnotationRevisionMetadata can't access private fields,"@Entity




@RevisionEntity(ExtendedRevisionListener.class)




@Table(name = ""revinfo"")




public class ExtendedRevision implements Serializable  
 @Id




	@GeneratedValue




	@Column(name = ""REV"")




	@RevisionNumber




	private Integer id;









	 @RevisionTimestamp




	@Temporal(TemporalType.TIMESTAMP)




	@Column(name = ""REVTSTMP"", nullable = false)




	private Date date;









	 @Column(nullable = false, length = 15)




	private String username;









	 public Integer getId() {




		return id;




	}









	 public Date getDate() {




		return date;




	}









	 public String getUsername() {




		return username;




	}









	 public void setUsername(String username) {




		this.username = username;




	}
@Entity
@RevisionEntity(ExtendedRevisionListener.class)
@Table(name = ""revinfo"")
public class ExtendedRevision implements Serializable {
@Id
@GeneratedValue
@Column(name = ""REV"")
@RevisionNumber
private Integer id;
@RevisionTimestamp
@Temporal(TemporalType.TIMESTAMP)
@Column(name = ""REVTSTMP"", nullable = false)
private Date date;
@Column(nullable = false, length = 15)
private String username;
public Integer getId() {
return id;
}
public Date getDate() {
return date;
}
public String getUsername() {
return username;
}
public void setUsername(String username) {
this.username = username;
}
triggers this error:
java.lang.IllegalStateException: Could not access method: Class org.springframework.util.ReflectionUtils can not access a member of class ExtendedRevision with modifiers ""private""
at org.springframework.util.ReflectionUtils.handleReflectionException(ReflectionUtils.java:262)
at org.springframework.util.ReflectionUtils.getField(ReflectionUtils.java:132)
at org.springframework.data.util.AnnotationDetectionFieldCallback.getValue(AnnotationDetectionFieldCallback.java:82)
at org.springframework.data.history.AnnotationRevisionMetadata.<init>(AnnotationRevisionMetadata.java:54)
I assume the fields have to be made accessible from the field callback.",org.springframework.data.util.AnnotationDetectionFieldCallback
FILE,DATACMNS,DATACMNS-683,2015-04-13T05:31:25.000-05:00,Enabling Spring Data web support breaks @ModelAttribute binding in Spring MVC,"package be.vdab.web;









import org.springframework.context.annotation.ComponentScan;




import org.springframework.context.annotation.Configuration;




import org.springframework.data.web.config.EnableSpringDataWebSupport;




import org.springframework.web.servlet.config.annotation.EnableWebMvc;




import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;









// enkele imports




@Configuration




@EnableWebMvc




@EnableSpringDataWebSupport




@ComponentScan




public class CreateControllerBeans extends WebMvcConfigurerAdapter {




}






  






package be.vdab.web;









import org.springframework.stereotype.Controller;




import org.springframework.web.bind.annotation.ModelAttribute;




import org.springframework.web.bind.annotation.RequestMapping;




import org.springframework.web.bind.annotation.RequestMethod;




import org.springframework.web.servlet.ModelAndView;









import be.vdab.entities.Person;









@Controller




@RequestMapping(value = ""/"")




public class PersonController {




	private static final String TOEVOEGEN_VIEW = ""/WEB-INF/JSP/index.jsp"";














	@RequestMapping(method=RequestMethod.GET)




	ModelAndView get() {




		return new ModelAndView(TOEVOEGEN_VIEW).addObject(new Person());




	}




	




	@RequestMapping(method = RequestMethod.POST)




	String post(@ModelAttribute Person person) {




	  if (person == null) {




		  throw new IllegalArgumentException(""person IS NULL"");




	  }




	  return ""redirect:/"";




	}



















}






 
    
 
 
 
    
 @EnableSpringDataWebSupport   
 @ModelAttribute
package be.vdab.web;
import org.springframework.context.annotation.ComponentScan;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.web.config.EnableSpringDataWebSupport;
import org.springframework.web.servlet.config.annotation.EnableWebMvc;
import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;
// enkele imports
@Configuration
@EnableWebMvc
@EnableSpringDataWebSupport
@ComponentScan
public class CreateControllerBeans extends WebMvcConfigurerAdapter {
}
package be.vdab.web;
import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.ModelAttribute;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestMethod;
import org.springframework.web.servlet.ModelAndView;
import be.vdab.entities.Person;
@Controller
@RequestMapping(value = ""/"")
public class PersonController {
private static final String TOEVOEGEN_VIEW = ""/WEB-INF/JSP/index.jsp"";
@RequestMapping(method=RequestMethod.GET)
ModelAndView get() {
return new ModelAndView(TOEVOEGEN_VIEW).
addObject(new Person());
}
@RequestMapping(method = RequestMethod.POST)
String post(@ModelAttribute Person person) {
if (person == null) {
throw new IllegalArgumentException(""person IS NULL"");
}
return ""redirect:/"";
}
}
<%@page contentType=""text/html"" pageEncoding=""UTF-8"" session=""false""%>
<%@taglib prefix=""form"" uri=""http://www.springframework.org/tags/form"" %>
<!doctype html>
<html lang=""nl"">
<head>
<title>Add person</title>
</head>
<body>
<form:form action="""" method=""post"" commandName=""person"">
<form:label path=""name"">Name:</form:label>
<form:input path=""name"" autofocus=""true""/>
<input type=""submit"">
</form:form>
</body>
</html>
the method post in PersonController throws the InvalidArgumentException because the person parameter is null.
Observation 1:
This worked up to and including spring-data-jpa 1.7.2.
RELEASE
Observation 2:
The bug disappears when @EnableSpringDataWebSupport is put in comment in CreateControllerBeans.java
Observation 3:
The bug disappears when @ModelAttribute is put in comment in PersonController.java
You can clone a project that shows the bug from https://github.com/desmethans/springDataJpaError.git","org.springframework.data.repository.support.DomainClassConverterUnitTests
org.springframework.data.repository.support.DomainClassConverter"
FILE,DATACMNS,DATACMNS-695,2015-05-13T09:08:15.000-05:00,Potential NullPointerException in AbstractMappingContext,"public class External{




 ..




 private Optional<Internal> field = new Optional<Internal>();




 ..




}
We found the reported issue upgrading Spring Data MongoDB library from 1.3.5.
RELEASE to 1.5.5.
RELEASE.
public class External{
.
.
private Optional<Internal> field = new Optional<Internal>();
.
.
}
The call to mongoOperations throws a NullPointerException originating from AbstractMappingContext.
It is a Spring Data Commons class and we noticed that the issue starts from version 1.7.2.
RELEASE of this library, just after commit 02046da.","org.springframework.data.mapping.context.AbstractMappingContext
org.springframework.data.mapping.context.AbstractMappingContextUnitTests"
FILE,DATACMNS,DATACMNS-748,2015-08-08T00:23:11.000-05:00,Spring version check in QueryExecutionConverters might fail,"org.springframework.core.SpringVersion.getVersion()  
 
 
  private static final Version SPRING_VERSION = Version.parse(SpringVersion.getVersion());   Version.parse()   Assert.hasText()  
 SpringVersion.getVersion()
With the latest Gosling RC I'm intermittently seeing the following Exceptions on deployment.
Usually a consecutive deployment will be successful.
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'entryDao': Invocation of init method failed; nested exception is java.lang.ExceptionInInitializerError
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1578) ~[spring-beans-4.2.0.RELEASE.jar:na]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:545) ~[spring-beans-4.2.0.RELEASE.jar:na]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482) ~[spring-beans-4.2.0.RELEASE.jar:na]
at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:305) ~[spring-beans-4.2.0.RELEASE.jar:na]
at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.2.0.RELEASE.jar:na]
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:301) ~[spring-beans-4.2.0.RELEASE.jar:na]
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:196) ~[spring-beans-4.2.0.RELEASE.jar:na]
at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1145) ~[spring-beans-4.2.0.RELEASE.jar:na]
at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1069) ~[spring-beans-4.2.0.RELEASE.jar:na]
at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:967) ~[spring-beans-4.2.0.RELEASE.jar:na]
at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:543) ~[spring-beans-4.2.0.RELEASE.jar:na]
... 37 common frames omitted
Caused by: java.lang.ExceptionInInitializerError: null
at org.springframework.data.repository.core.support.QueryExecutionResultHandler.<init>(QueryExecutionResultHandler.java:41) ~[spring-data-commons-1.11.0.RC1.jar:na]
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.<init>(RepositoryFactorySupport.java:383) ~[spring-data-commons-1.11.0.RC1.jar:na]
at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:203) ~[spring-data-commons-1.11.0.RC1.jar:na]
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.initAndReturn(RepositoryFactoryBeanSupport.java:251) ~[spring-data-commons-1.11.0.RC1.jar:na]
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:237) ~[spring-data-commons-1.11.0.RC1.jar:na]
at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:92) ~[spring-data-jpa-1.9.0.RC1.jar:na]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1637) ~[spring-beans-4.2.0.RELEASE.jar:na]
at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1574) ~[spring-beans-4.2.0.RELEASE.jar:na]
... 47 common frames omitted
Caused by: java.lang.IllegalArgumentException: [Assertion failed] - this String argument must have text; it must not be null, empty, or blank
at org.springframework.util.Assert.hasText(Assert.java:168) ~[spring-core-4.2.0.RELEASE.jar:4.2.0.RELEASE]
at org.springframework.util.Assert.hasText(Assert.java:181) ~[spring-core-4.2.0.RELEASE.jar:4.2.0.RELEASE]
at org.springframework.data.util.Version.parse(Version.java:67) ~[spring-data-commons-1.11.0.RC1.jar:na]
at org.springframework.data.repository.util.QueryExecutionConverters.<clinit>(QueryExecutionConverters.java:47) ~[spring-data-commons-1.11.0.RC1.jar:na]
... 55 common frames omitted
Own analysis:
Commit in question: https://github.com/spring-projects/spring-data-commons/commit/e0dafd29f4027bd2fe40215c8a916e61bff16740
The usage of org.springframework.core.SpringVersion.getVersion() is unreliable, as already stated in the comment section of said class:
/**
* Class that exposes the Spring version.
Fetches the
* ""Implementation-Version"" manifest attribute from the jar file.
*
* <p>Note that some ClassLoaders do not expose the package metadata,
* hence this class might not be able to determine the Spring version
* in all environments.
Consider using a reflection-based check instead:
* For example, checking for the presence of a specific Spring 2.0
* method that you intend to call.
*
* @author Juergen Hoeller
* @since 1.1
*/
The code in QueryExecutionConverters private static final Version SPRING_VERSION = Version.parse(SpringVersion.getVersion()); fails to handle null, because Version.parse() has an Assert.hasText() and can't handle null.
So there are at least two obvious things to consider here: One is the not handling the null case.
And the other is the reliance on SpringVersion.getVersion(), which is said to not work in all environments.
Or probably in my case has timing issues.",org.springframework.data.repository.util.QueryExecutionConverters
FILE,DATACMNS,DATACMNS-943,2016-10-04T21:54:22.000-05:00,Redeclared save(Iterable) results in wrong method overload to be invoked eventually,"myRepository.save(Arrays.asList(new MyEntity(1, ""foo""), new MyEntity(2, ""bar"")));
I have upgrade my project from spring boot 1.3.1 to 1.4.1.
After the update the code seems to behave fine in windows with java 1.8.0_45 64bit
But in jenkins server (on linux) with the same java version the code breaks with this exception
org.springframework.beans.NotReadablePropertyException: Invalid property 'id' of bean class [java.util.Arrays$ArrayList]: Could not find field for property during fallback access!
at org.springframework.data.util.DirectFieldAccessFallbackBeanWrapper.getPropertyValue(DirectFieldAccessFallbackBeanWrapper.java:56)
at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.getId(JpaMetamodelEntityInformation.java:149)
at org.springframework.data.repository.core.support.AbstractEntityInformation.isNew(AbstractEntityInformation.java:51)
at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.isNew(JpaMetamodelEntityInformation.java:225)
at org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:505)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:497)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.executeMethodOn(RepositoryFactorySupport.java:503)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.doInvoke(RepositoryFactorySupport.java:488)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.invoke(RepositoryFactorySupport.java:460)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:61)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99)
at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:281)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:136)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
at
myRepository.save(Arrays.asList(new MyEntity(1, ""foo""), new MyEntity(2, ""bar"")));
.
In linux and with the upgrade to spring boot 1.4.1 it seems the save(Iterable) method is not invoked, but the save(entity) method is invoked and causes this exception.","org.springframework.data.repository.core.support.DefaultRepositoryInformationUnitTests
org.springframework.data.repository.core.support.DefaultRepositoryInformation"
CLASS,derby-10.9.1.0,DERBY-3024,2007-08-23T05:24:31.000-05:00,Validation of shared plans hurts scalability,"GenericPreparedStatement.upToDate()   BaseActivation.checkStatementValidity()
To investigate whether there was anything in the SQL execution layer that prevented scaling on a multi-CPU machine, I wrote a multi-threaded test which continuously executed ""VALUES 1"" using a PreparedStatement. I ran the test on a machine with 8 CPUs and expected the throughput to be proportional to the number of concurrent clients up to 8 clients (the same as the number of CPUs). However, the throughput only had a small increase from 1 to 2 clients, and adding more clients did not increase the throughput. Looking at the test in a profiler, it seems like the threads are spending a lot of time waiting to enter synchronization blocks in GenericPreparedStatement.upToDate() and BaseActivation.checkStatementValidity() (both of which are synchronized on the a GenericPreparedStatement object).
That means the threads still did the same work, but each thread got its own plan (GenericPreparedStatement object) since the statement cache didn't regard the SQL text strings as identical.
When I made that change, the test scaled more or less perfectly up to 8 concurrent threads.","java.engine.org.apache.derby.impl.store.access.heap.HeapConglomerateFactory
java.engine.org.apache.derby.impl.store.raw.data.FileContainer
java.engine.org.apache.derby.impl.store.raw.data.RAFContainer
java.testing.org.apache.derbyTesting.functionTests.tests.lang.DBInJarTest
java.engine.org.apache.derby.impl.store.raw.data.TempRAFContainer
java.engine.org.apache.derby.impl.store.raw.data.InputStreamContainer
java.engine.org.apache.derby.impl.store.access.btree.index.B2IFactory"
CLASS,derby-10.9.1.0,DERBY-4269,2009-06-12T06:40:38.000-05:00,Failover did not succeed in 2 min.: testReplication_Local_3_p6_autocommit_OK,"testReplication_Local_3_p6_autocommit_OK(org.apache.derbyTesting.functionTests.tests.replicationTests.ReplicationRun_Local_3_p6)
Failover did not succeed.
2 testReplication_Local_3_p6_autocommit_OK(org.apache.derbyTesting.functionTests.tests.replicationTests.ReplicationRun_Local_3_p6)junit.framework.AssertionFailedError: Failover did not succeed.
at org.apache.derbyTesting.functionTests.tests.replicationTests.ReplicationRun.connectPing(ReplicationRun.java:270)
at org.apache.derbyTesting.functionTests.tests.replicationTests.ReplicationRun_Local_3_p6.derby_3896(ReplicationRun_Local_3_p6.java:200)
at org.apache.derbyTesting.functionTests.tests.replicationTests.ReplicationRun_Local_3_p6.testReplication_Local_3_p6_autocommit_OK(ReplicationRun_Local_3_p6.java:86)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:106)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
See http://dbtg.thresher.com/derby/test/Daily/jvm1.4/testing/testlog/vista-64/782274-suitesAll_diff.txt","java.engine.org.apache.derby.iapi.util.DoubleProperties
java.testing.org.apache.derbyTesting.functionTests.tests.replicationTests.ReplicationRun_Local_3_p6"
CLASS,derby-10.9.1.0,DERBY-4647,2010-05-07T13:34:26.000-05:00,BaseTestCase.execJavaCmd() does not work with weme 6.2,"BaseTestCase.execJavaCmd()
Spawning a java process with BaseTestCase.execJavaCmd() does not work with weme 6.2, I think because the boot classpath does not get passed.
This issue came up in DERBY-4179.
After this issue is fixed, BootLockTest should be enabled for weme.
The error is actually
.
JVMJ9VM011W Unable to load jclfoun10_24: The specified module could not be foun
d.
JVMEXEX013E Internal VM error: Failed to create Java VM
JVMEXEX014I Run C:\cygwin\ibmsvn\ntsoftware\weme6.2\bin\j9.exe -help for usage
execJavaProcess does pick up the j9 executable but does not pass on the other settings.
It probably has a lot of legacy system properties not needed, but I suppose execJavaCmd should just pass along all system properties, but I don't know how it would get the bootclasspath.
Perhaps -Dbootcp was a way to pass it on in the old harness.
c:/cygwin/ibmsvn/ntsoftware/weme6.2/bin/j9 -jcl:foun11 -DderbyTesting.serverho
st=localhost -DderbyTesting.clienthost=localhost -Demma.active= -Xbootclasspath/
a:c:/cygwin/ibmsvn/ntsoftware/weme6.2/lib/jdbc.
jar -Dbootcp=c:/cygwin/ibmsvn/nts
oftware/weme6.2/lib/jdbc.
jar junit.textui.TestRunner org.apache.derbyTesting.fun
ctionTests.tests.store.BootLockTest
Otherwise, currently I think the method is only used in replication and network server, but am not sure.","java.testing.org.apache.derbyTesting.functionTests.tests.store.BootLockMinion
java.testing.org.apache.derbyTesting.functionTests.tests.store.BootLockTest"
CLASS,derby-10.9.1.0,DERBY-4669,2010-05-20T05:08:54.000-05:00,ClassLoaderBootTest fails if derbyclient.jar comes before derby.jar on the classpath,"testBootingAnAlreadyBootedDatabase(org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest)  testBootingDatabaseShutdownByAnotherCLR(org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest)
If derbyclient.jar comes before derby.jar on the classpath, and the build is sane, the test fails.
java -cp derbyclient.jar:derby.jar:derbyTesting.jar:junit.jar junit.textui.TestRunner org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest
...
1 testBootingAnAlreadyBootedDatabase(org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest)java.lang.ExceptionInInitializerError
at org.apache.derby.jdbc.EmbeddedDataSource.findDriver(EmbeddedDataSource.java:500)
at org.apache.derby.jdbc.EmbeddedDataSource.getConnection(EmbeddedDataSource.java:479)
at org.apache.derby.jdbc.EmbeddedDataSource.getConnection(EmbeddedDataSource.java:423)
at org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest.testBootingAnAlreadyBootedDatabase(ClassLoaderBootTest.java:178)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:109)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
Caused by: java.lang.SecurityException: sealing violation: package org.apache.derby.iapi.services.sanity is sealed
at java.net.URLClassLoader.defineClass(URLClassLoader.java:234)
at java.net.URLClassLoader.access$000(URLClassLoader.java:58)
at java.net.URLClassLoader$1.
run(URLClassLoader.java:197)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
at org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest$DerbyURLClassLoader.loadClass(ClassLoaderBootTest.java:293)
at org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest$DerbyURLClassLoader.loadClass(ClassLoaderBootTest.java:303)
at org.apache.derby.iapi.services.monitor.Monitor.startSystemModule(Monitor.java:369)
at org.apache.derby.impl.services.monitor.BaseMonitor.runWithState(BaseMonitor.java:386)
at org.apache.derby.impl.services.monitor.FileMonitor.
<init>(FileMonitor.java:60)
at org.apache.derby.iapi.services.monitor.Monitor.startMonitor(Monitor.java:289)
at org.apache.derby.iapi.jdbc.JDBCBoot.boot(JDBCBoot.java:69)
at org.apache.derby.jdbc.EmbeddedDriver.boot(EmbeddedDriver.java:199)
at org.apache.derby.jdbc.EmbeddedDriver.
<clinit>(EmbeddedDriver.java:96)
... 33 more
2 testBootingDatabaseShutdownByAnotherCLR(org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest)java.lang.ExceptionInInitializerError
at org.apache.derby.jdbc.EmbeddedDataSource.findDriver(EmbeddedDataSource.java:500)
at org.apache.derby.jdbc.EmbeddedDataSource.getConnection(EmbeddedDataSource.java:479)
at org.apache.derby.jdbc.EmbeddedDataSource.getConnection(EmbeddedDataSource.java:423)
at org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest.testBootingDatabaseShutdownByAnotherCLR(ClassLoaderBootTest.java:208)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:109)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
Caused by: java.lang.SecurityException: sealing violation: package org.apache.derby.iapi.services.sanity is sealed
at java.net.URLClassLoader.defineClass(URLClassLoader.java:234)
at java.net.URLClassLoader.access$000(URLClassLoader.java:58)
at java.net.URLClassLoader$1.
run(URLClassLoader.java:197)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
at org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest$DerbyURLClassLoader.loadClass(ClassLoaderBootTest.java:293)
at org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest$DerbyURLClassLoader.loadClass(ClassLoaderBootTest.java:303)
at org.apache.derby.iapi.services.monitor.Monitor.startSystemModule(Monitor.java:369)
at org.apache.derby.impl.services.monitor.BaseMonitor.runWithState(BaseMonitor.java:386)
at org.apache.derby.impl.services.monitor.FileMonitor.
<init>(FileMonitor.java:60)
at org.apache.derby.iapi.services.monitor.Monitor.startMonitor(Monitor.java:289)
at org.apache.derby.iapi.jdbc.JDBCBoot.boot(JDBCBoot.java:69)
at org.apache.derby.jdbc.EmbeddedDriver.boot(EmbeddedDriver.java:199)
at org.apache.derby.jdbc.EmbeddedDriver.
<clinit>(EmbeddedDriver.java:96)
... 33 more","java.client.org.apache.derby.client.net.EncodedInputStream
java.engine.org.apache.derby.iapi.services.info.JVMInfo
java.client.org.apache.derby.client.am.ClobLocatorReader
java.client.org.apache.derby.client.am.ClobLocatorInputStream
java.client.org.apache.derby.client.am.PreparedStatement
java.client.org.apache.derby.client.net.Utf8CcsidManager"
CLASS,derby-10.9.1.0,DERBY-4873,2010-10-28T18:45:13.000-05:00,NullPointerException in testBoundaries with ibm jvm 1.6,"testBoundaries(org.apache.derbyTesting.functionTests.tests.jdbcapi.InternationalConnectTest)
With the line skipping the testBoundaries fixture of the InternationalConnectTest commented out, I get the following stack when I run the test with ibm 1.6:
1 testBoundaries(org.apache.derbyTesting.functionTests.tests.jdbcapi.InternationalConnectTest)java.sql.SQLException: DERBY SQL error: SQLCODE: -1, SQLSTATE: XJ001, SQLERRMC: java.lang.NullPointerExceptionXJ001.U
at org.apache.derby.client.am.SQLExceptionFactory40.getSQLException(SQLExceptionFactory40.java:96)
at org.apache.derby.client.am.SqlException.getSQLException(SqlException.java:358)
at org.apache.derby.jdbc.ClientDriver.connect(ClientDriver.java:149)
at java.sql.DriverManager.getConnection(DriverManager.java:322)
at java.sql.DriverManager.getConnection(DriverManager.java:273)
at org.apache.derbyTesting.functionTests.tests.jdbcapi.InternationalConnectTest.testBoundaries(InternationalConnectTest.java:111)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:48)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:109)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
Caused by: org.apache.derby.client.am.SqlException: DERBY SQL error: SQLCODE: -1, SQLSTATE: XJ001, SQLERRMC: java.lang.NullPointerExceptionXJ001.U
at org.apache.derby.client.am.Connection.completeSqlca(Connection.java:2117)
at org.apache.derby.client.net.NetConnectionReply.parseRdbAccessFailed(NetConnectionReply.java:541)
at org.apache.derby.client.net.NetConnectionReply.parseAccessRdbError(NetConnectionReply.java:434)
at org.apache.derby.client.net.NetConnectionReply.parseACCRDBreply(NetConnectionReply.java:297)
at org.apache.derby.client.net.NetConnectionReply.readAccessDatabase(NetConnectionReply.java:121)
at org.apache.derby.client.net.NetConnection.readSecurityCheckAndAccessRdb(NetConnection.java:846)
at org.apache.derby.client.net.NetConnection.flowSecurityCheckAndAccessRdb(NetConnection.java:769)
at org.apache.derby.client.net.NetConnection.flowUSRIDONLconnect(NetConnection.java:601)
at org.apache.derby.client.net.NetConnection.flowConnect(NetConnection.java:408)
at org.apache.derby.client.net.NetConnection.<init>(NetConnection.java:218)
at org.apache.derby.client.net.NetConnection40.<init>(NetConnection40.java:77)
at org.apache.derby.client.net.ClientJDBCObjectFactoryImpl40.newNetConnection(ClientJDBCObjectFactoryImpl40.java:269)
at org.apache.derby.jdbc.ClientDriver.connect(ClientDriver.java:140)
... 35 more
This is after the latest check in for DERBY-4836 (revision 1028035).
I'll attach derby.log.",java.engine.org.apache.derby.impl.store.raw.data.BaseDataFileFactory
CLASS,derby-10.9.1.0,DERBY-5251,2011-05-29T04:27:15.000-05:00,make ErrorCodeTest pass in non-English locale,"test_errorcode(org.apache.derbyTesting.functionTests.tests.lang.ErrorCodeTest
)
lang.ErrorCodeTest will fail in Chinese Locale:
D:\derby\test>java junit.textui.TestRunner org.apache.derbyTesting.functionTests
.
tests.lang.ErrorCodeTest
.
F
Time: 4.797
There was 1 failure:
1 test_errorcode(org.apache.derbyTesting.functionTests.tests.lang.ErrorCodeTest
)junit.framework.AssertionFailedError: Column value mismatch @ column 'MESSAGE',
row 1:
Expected: >At least one parameter to the current statement is uninitialized.
<
Found:    >当前语句中至少一个参数未初始化。<
at org.apache.derbyTesting.junit.JDBC.assertRowInResultSet(JDBC.java:121
3
at org.apache.derbyTesting.junit.JDBC.assertRowInResultSet(JDBC.java:112
5
at org.apache.derbyTesting.junit.JDBC.assertFullResultSetMinion(JDBC.jav
a:1012)
at org.apache.derbyTesting.junit.JDBC.assertFullResultSet(JDBC.java:935)
at org.apache.derbyTesting.junit.JDBC.assertFullResultSet(JDBC.java:892)
at org.apache.derbyTesting.junit.JDBC.assertFullResultSet(JDBC.java:850)
at org.apache.derbyTesting.functionTests.tests.lang.ErrorCodeTest.test_e
rrorcode(ErrorCodeTest.java:88)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.
java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAcces
sorImpl.java:25)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:
112)
FAILURES!!!
Tests run: 1,  Failures: 1,  Errors: 0
D:\derby\test>",java.testing.org.apache.derbyTesting.functionTests.tests.lang.ErrorCodeTest
CLASS,derby-10.9.1.0,DERBY-5377,2011-08-08T09:44:29.000-05:00,AssertionFailedError in testCaseCS4595B_NonUniqueIndex in AccessTest,"testCaseCS4595B_NonUniqueIndex(org.apache.derbyTesting.functionTests.tests.store.AccessTest)
There was 1 failure:
1 testCaseCS4595B_NonUniqueIndex(org.apache.derbyTesting.functionTests.tests.store.AccessTest)junit.framework.AssertionFailedError
at org.apache.derbyTesting.functionTests.tests.store.AccessTest.assertStatsOK(AccessTest.java:402)
at org.apache.derbyTesting.functionTests.tests.store.AccessTest.doTestCaseCS4595B(AccessTest.java:1720)
at org.apache.derbyTesting.functionTests.tests.store.AccessTest.testCaseCS4595B_NonUniqueIndex(AccessTest.java:1830)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:112)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
Cf. http://dbtg.foundry.sun.com/derby/test/Daily/jvm1.5/testing/Limited/testSummary-1154534.html",java.testing.org.apache.derbyTesting.functionTests.tests.store.AccessTest
CLASS,derby-10.9.1.0,DERBY-5407,2011-09-12T08:50:38.000-05:00,"When run across the network, dblook produces unusable DDL for VARCHAR FOR BIT DATA columns.","varchar( 20 )  
 
 
 VARCHAR ()
In private correspondence, Mani Afschar Yazdi reports that dblook omits the length specification for VARCHAR FOR BIT DATA columns when run across the network.
Embedded dblook runs fine.
connect 'jdbc:derby://localhost:8246/memory:db;create=true';
create table t( a varchar( 20 ) for bit data );
java -org.apache.derby.tools.dblook -d ""jdbc:derby://localhost:8246/memory:db""
This produces the following DDL for the table:
CREATE TABLE ""APP"".
""T"" (""A"" VARCHAR () FOR BIT DATA);
A similar experiment using an embedded database produces usable DDL which includes a length specification for the VARCHAR FOR BIT DATA column.","java.testing.org.apache.derbyTesting.functionTests.tests.lang.SystemCatalogTest
java.engine.org.apache.derby.catalog.types.BaseTypeIdImpl"
CLASS,derby-10.9.1.0,DERBY-5424,2011-09-20T14:24:29.000-05:00,On z/OS testConnectWrongSubprotocolWithSystemProperty(org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest)junit.framework.Asserti ailedError,"testConnectWrongSubprotocolWithSystemProperty(org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest) 
    
  
  testConnectWrongSubprotoctestolWithoutSystemProperty(org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest)   
  
 
 String ijResult = runIjScript(ijScript, useSystemProperties);       
                assertTrue(ijResult.indexOf(""08001"") > -1);
With the release candidate  10.8.2.1 - (1170221) I saw the following two failures on z/OS in testConnectWrongSubprotoctestolWithoutSystemProperty
There were 2 failures:
1) testConnectWrongSubprotocolWithSystemProperty(org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest)junit.framework.Asserti onFailedError at org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest.checkConnectWrongSubprotocol(ConnectWrongSubprotocolTest.java
:82)
at org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest.testConnectWrongSubprotocolWithSystemProperty(ConnectWrongSub protocolTest.java:68)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:60)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:37)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:113)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:16)
2) testConnectWrongSubprotoctestolWithoutSystemProperty(org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest)junit.framework.
AssertionFailedError at org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest.checkConnectWrongSubprotocol(ConnectWrongSubprotocolTest.java
:82)
at org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest.testConnectWrongSubprotoctestolWithoutSystemProperty(ConnectW rongSubprotocolTest.java:76)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:60)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:37)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:113)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:16)
FAILURES!!!
Tests run: 13984,  Failures: 2,  Errors: 0
The test is newly converted with DERBY-5084 so not likely a regression, but probably more likely an encoding issue related to this test:
String ijResult = runIjScript(ijScript, useSystemProperties);
assertTrue(ijResult.indexOf(""08001"") > -1);",java.testing.org.apache.derbyTesting.functionTests.tests.tools.ConnectWrongSubprotocolTest
CLASS,derby-10.9.1.0,DERBY-5531,2011-12-12T06:34:21.000-06:00,Assert failure when inserting NULL into indexed column with territory-based collation,"colldb;territory=en;collation=TERRITORY_BASED; 
 varchar(10)
ij> connect 'jdbc:derby:colldb;territory=en;collation=TERRITORY_BASED;create=true';
ij> create table t(x varchar(10) unique);
0 rows inserted/updated/deleted
ij> insert into t values null;
ERROR XJ001: Java exception: 'ASSERT FAILED type of inserted column[0] = org.apache.derby.iapi.types.SQLVarchartype of template column[0] = org.apache.derby.iapi.types.CollatorSQLVarchar: org.apache.derby.shared.common.sanity.AssertFailure'.
java.sql.SQLException: Java exception: 'ASSERT FAILED type of inserted column[0] = org.apache.derby.iapi.types.SQLVarchartype of template column[0] = org.apache.derby.iapi.types.CollatorSQLVarchar: org.apache.derby.shared.common.sanity.AssertFailure'.
at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(SQLExceptionFactory40.java:98)
at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Util.java:142)
at org.apache.derby.impl.jdbc.Util.javaException(Util.java:299)
at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(TransactionResourceImpl.java:436)
at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(TransactionResourceImpl.java:353)
at org.apache.derby.impl.jdbc.EmbedConnection.handleException(EmbedConnection.java:2288)
at org.apache.derby.impl.jdbc.ConnectionChild.handleException(ConnectionChild.java:82)
at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(EmbedStatement.java:1334)
at org.apache.derby.impl.jdbc.EmbedStatement.execute(EmbedStatement.java:630)
at org.apache.derby.impl.jdbc.EmbedStatement.execute(EmbedStatement.java:559)
at org.apache.derby.impl.tools.ij.ij.executeImmediate(ij.java:367)
at org.apache.derby.impl.tools.ij.utilMain.doCatch(utilMain.java:527)
at org.apache.derby.impl.tools.ij.utilMain.runScriptGuts(utilMain.java:369)
at org.apache.derby.impl.tools.ij.utilMain.go(utilMain.java:245)
at org.apache.derby.impl.tools.ij.Main.go(Main.java:229)
at org.apache.derby.impl.tools.ij.Main.mainCore(Main.java:184)
at org.apache.derby.impl.tools.ij.Main.main(Main.java:75)
at org.apache.derby.tools.ij.main(ij.java:59)
at org.apache.derby.iapi.tools.run.main(run.java:53)
Caused by: java.sql.SQLException: Java exception: 'ASSERT FAILED type of inserted column[0] = org.apache.derby.iapi.types.SQLVarchartype of template column[0] = org.apache.derby.iapi.types.CollatorSQLVarchar: org.apache.derby.shared.common.sanity.AssertFailure'.
at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(SQLExceptionFactory.java:42)
at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(SQLExceptionFactory40.java:122)
at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(SQLExceptionFactory40.java:71)
... 18 more
Caused by: org.apache.derby.shared.common.sanity.AssertFailure: ASSERT FAILED type of inserted column[0] = org.apache.derby.iapi.types.SQLVarchartype of template column[0] = org.apache.derby.iapi.types.CollatorSQLVarchar
at org.apache.derby.shared.common.sanity.SanityManager.THROWASSERT(SanityManager.java:162)
at org.apache.derby.shared.common.sanity.SanityManager.THROWASSERT(SanityManager.java:147)
at org.apache.derby.impl.store.access.btree.OpenBTree.isIndexableRowConsistent(OpenBTree.java:515)
at org.apache.derby.impl.store.access.btree.BTreeController.doIns(BTreeController.java:679)
at org.apache.derby.impl.store.access.btree.BTreeController.insert(BTreeController.java:1374)
at org.apache.derby.impl.store.access.btree.index.B2IController.insert(B2IController.java:210)
at org.apache.derby.impl.sql.execute.IndexChanger.insertAndCheckDups(IndexChanger.java:440)
at org.apache.derby.impl.sql.execute.IndexChanger.doInsert(IndexChanger.java:383)
at org.apache.derby.impl.sql.execute.IndexChanger.insert(IndexChanger.java:590)
at org.apache.derby.impl.sql.execute.IndexSetChanger.insert(IndexSetChanger.java:268)
at org.apache.derby.impl.sql.execute.RowChangerImpl.insertRow(RowChangerImpl.java:453)
at org.apache.derby.impl.sql.execute.InsertResultSet.normalInsertCore(InsertResultSet.java:999)
at org.apache.derby.impl.sql.execute.InsertResultSet.open(InsertResultSet.java:519)
at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(GenericPreparedStatement.java:443)
at org.apache.derby.impl.sql.GenericPreparedStatement.execute(GenericPreparedStatement.java:324)
at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(EmbedStatement.java:1242)
... 11 more","java.engine.org.apache.derby.impl.sql.compile.ResultColumnList
java.engine.org.apache.derby.impl.store.access.btree.OpenBTree
java.testing.org.apache.derbyTesting.functionTests.tests.lang.CollationTest"
CLASS,derby-10.9.1.0,DERBY-5567,2012-01-05T07:35:04.000-06:00,AlterTableTest#testDropColumn fails: drop view cannot be performed due to dependency,"testDropColumn(org.apache.derbyTesting.functionTests.tests.lang.AlterTableTest)
Saw this when running suitesAll on 10.8.2.2:
1 testDropColumn(org.apache.derbyTesting.functionTests.tests.lang.AlterTableTest)java.sql.SQLException: Operation 'DROP VIEW' cannot be performed on object 'ATDC_VW_5A_1' because VIEW 'ATDC_VW_5A_2' is dependent on that object.
at org.apache.derby.client.am.SQLExceptionFactory40.getSQLException(Unknown Source)
at org.apache.derby.client.am.SqlException.getSQLException(Unknown Source)
at org.apache.derby.client.am.Statement.executeUpdate(Unknown Source)
at org.apache.derbyTesting.functionTests.tests.lang.AlterTableTest.testDropColumn(AlterTableTest.java:2465)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:113)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
Caused by: org.apache.derby.client.am.SqlException: Operation 'DROP VIEW' cannot be performed on object 'ATDC_VW_5A_1' because VIEW 'ATDC_VW_5A_2' is dependent on that object.
at org.apache.derby.client.am.Statement.completeSqlca(Unknown Source)
at org.apache.derby.client.am.Statement.completeExecuteImmediate(Unknown Source)
at org.apache.derby.client.net.NetStatementReply.parseEXCSQLIMMreply(Unknown Source)
at org.apache.derby.client.net.NetStatementReply.readExecuteImmediate(Unknown Source)
at org.apache.derby.client.net.StatementReply.readExecuteImmediate(Unknown Source)
at org.apache.derby.client.net.NetStatement.readExecuteImmediate_(Unknown Source)
at org.apache.derby.client.am.Statement.readExecuteImmediate(Unknown Source)
at org.apache.derby.client.am.Statement.flowExecute(Unknown Source)
at org.apache.derby.client.am.Statement.executeUpdateX(Unknown Source)
... 55 more
Prior to this, though, I saw this on the console, but no error/failure.
Probably not related, I believe we have seen this before:
java.lang.Exception: DRDA_InvalidReplyTooShort.S:Invalid reply from network server: Insufficient data.
at org.apache.derby.impl.drda.NetworkServerControlImpl.consolePropertyMessageWork(Unknown Source)
at org.apache.derby.impl.drda.NetworkServerControlImpl.consolePropertyMessage(Unknown Source)
at org.apache.derby.impl.drda.NetworkServerControlImpl.fillReplyBuffer(Unknown Source)
at org.apache.derby.impl.drda.NetworkServerControlImpl.readResult(Unknown Source)
at org.apache.derby.impl.drda.NetworkServerControlImpl.pingWithNoOpen(Unknown Source)
at org.apache.derby.impl.drda.NetworkServerControlImpl.ping(Unknown Source)
at org.apache.derby.drda.NetworkServerControl.ping(Unknown Source)
at org.apache.derbyTesting.junit.NetworkServerTestSetup.pingForServerUp(NetworkServerTestSetup.java:567)
at org.apache.derbyTesting.functionTests.tests.derbynet.ServerPropertiesTest.canPingServer(ServerPropertiesTest.java:280)
at org.apache.derbyTesting.functionTests.tests.derbynet.ServerPropertiesTest.ttestSetPortPriority(ServerPropertiesTest.java:472)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:601)
at junit.framework.TestCase.runTest(TestCase.java:164)
at junit.framework.TestCase.runBare(TestCase.java:130)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:113)
at junit.framework.TestResult$1.protect(TestResult.java:106)
at junit.framework.TestResult.runProtected(TestResult.java:124)
at junit.framework.TestResult.run(TestResult.java:109)
at junit.framework.TestCase.run(TestCase.java:120)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.framework.TestResult.runProtected(TestResult.java:124)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.framework.TestResult.runProtected(TestResult.java:124)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.framework.TestResult.runProtected(TestResult.java:124)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.framework.TestResult.runProtected(TestResult.java:124)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.framework.TestSuite.runTest(TestSuite.java:230)
at junit.framework.TestSuite.run(TestSuite.java:225)
at junit.framework.TestSuite.runTest(TestSuite.java:230)
at junit.framework.TestSuite.run(TestSuite.java:225)
at junit.framework.TestSuite.runTest(TestSuite.java:230)
at junit.framework.TestSuite.run(TestSuite.java:225)
at junit.framework.TestSuite.runTest(TestSuite.java:230)
at junit.framework.TestSuite.run(TestSuite.java:225)
at junit.textui.TestRunner.doRun(TestRunner.java:121)
at junit.textui.TestRunner.start(TestRunner.java:185)
at junit.textui.TestRunner.main(TestRunner.java:143)",java.engine.org.apache.derby.iapi.sql.dictionary.ViewDescriptor
CLASS,derby-10.9.1.0,DERBY-5663,2012-03-17T23:45:11.000-05:00,Getting NPE when trying to set derby.language.logStatementText property to true inside a junit suite.,"patch(DERBY5663_patch1.txt)
Derby has a large data suite which runs LobLimitsTest with small data size, large data size and with embedded and network server configurations.
The large data suite is run as follows
time java  -Dderby.tests.trace=true -Dderby.infolog.append=true junit.textui.TestRunner org.apache.derbyTesting.functionTests.tests.largedata.
_Suite > runall.out 2>&1
I made a simple change to the suite to log statement text as shown in the attached patch(DERBY5663_patch1.
txt).
This causes the large data suite to run into NPE (NPE can be seen in runall.out) as shown below.
Not sure what I am doing wrong while trying to set the property, which results in NPE.
.
(emb)largedata.Derby5624Test.testDERBY_5624 used 411473 ms .
(emb)largedata.LobLimitsTest.test_01_Blob used 1555 ms .
(emb)largedata.LobLimitsTest.test_02_BlobNegative used 42 ms .
(emb)largedata.LobLimitsTest.test_03_Clob1 used 1436 ms .
(emb)largedata.LobLimitsTest.test_04_Clob2 used 1707 ms .
(emb)largedata.LobLimitsTest.test_05_ClobNegative used 967 ms E.
(emb)largedata.LobLimitsTest.test_01_Blob used 2929139 ms .
(emb)largedata.LobLimitsTest.test_02_BlobNegative used 154 ms .
(emb)largedata.LobLimitsTest.test_03_Clob1 used 2854121 ms .
(emb)largedata.LobLimitsTest.test_04_Clob2 used 656137 ms .
(emb)largedata.LobLimitsTest.test_05_ClobNegative used 331288 ms EF
Time: 7,589.168
There were 2 errors:
1 LobLimitsTestjava.lang.NullPointerException
at org.apache.derbyTesting.junit.SystemPropertyTestSetup.setProperties(SystemPropertyTestSetup.java:116)
at org.apache.derbyTesting.junit.SystemPropertyTestSetup.setUp(SystemPropertyTestSetup.java:87)
at junit.extensions.TestSetup$1.protect(TestSetup.java:18)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
2 LobLimitsTestjava.sql.SQLNonTransientConnectionException: DERBY SQL error: SQLCODE: -1, SQLSTATE: 08006, SQLERRMC: org.apache.derby.jdbc.EmbeddedDriver is not registered with the JDBC driver manager
at org.apache.derby.client.am.SQLExceptionFactory40.getSQLException(SQLExceptionFactory40.java:71)
at org.apache.derby.client.am.SqlException.getSQLException(SqlException.java:364)
at org.apache.derby.jdbc.ClientDriver.connect(ClientDriver.java:166)
at java.sql.DriverManager.getConnection(DriverManager.java:322)
at java.sql.DriverManager.getConnection(DriverManager.java:297)
at org.apache.derbyTesting.junit.DriverManagerConnector.openConnection(DriverManagerConnector.java:100)
at org.apache.derbyTesting.junit.DriverManagerConnector.openConnection(DriverManagerConnector.java:67)
at org.apache.derbyTesting.junit.DriverManagerConnector.openConnection(DriverManagerConnector.java:43)
at org.apache.derbyTesting.junit.TestConfiguration.openDefaultConnection(TestConfiguration.java:1633)
at org.apache.derbyTesting.junit.BaseJDBCTestSetup.getConnection(BaseJDBCTestSetup.java:72)
at org.apache.derbyTesting.junit.CleanDatabaseTestSetup.setUp(CleanDatabaseTestSetup.java:104)
at junit.extensions.TestSetup$1.protect(TestSetup.java:18)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
Caused by: org.apache.derby.client.am.SqlException: DERBY SQL error: SQLCODE: -1, SQLSTATE: 08006, SQLERRMC: org.apache.derby.jdbc.EmbeddedDriver is not registered with the JDBC driver manager
at org.apache.derby.client.am.Connection.completeSqlca(Connection.java:2125)
at org.apache.derby.client.net.NetConnectionReply.parseRdbAccessFailed(NetConnectionReply.java:538)
at org.apache.derby.client.net.NetConnectionReply.parseAccessRdbError(NetConnectionReply.java:431)
at org.apache.derby.client.net.NetConnectionReply.parseACCRDBreply(NetConnectionReply.java:294)
at org.apache.derby.client.net.NetConnectionReply.readAccessDatabase(NetConnectionReply.java:121)
at org.apache.derby.client.net.NetConnection.readSecurityCheckAndAccessRdb(NetConnection.java:826)
at org.apache.derby.client.net.NetConnection.flowSecurityCheckAndAccessRdb(NetConnection.java:762)
at org.apache.derby.client.net.NetConnection.flowUSRIDPWDconnect(NetConnection.java:591)
at org.apache.derby.client.net.NetConnection.flowConnect(NetConnection.java:406)
at org.apache.derby.client.net.NetConnection.<init>(NetConnection.java:220)
at org.apache.derby.client.net.NetConnection40.<init>(NetConnection40.java:74)
at org.apache.derby.client.net.ClientJDBCObjectFactoryImpl40.newNetConnection(ClientJDBCObjectFactoryImpl40.java:269)
at org.apache.derby.jdbc.ClientDriver.connect(ClientDriver.java:157)
... 43 more
There was 1 failure:
1 LobLimitsTestjunit.framework.ComparisonFailure: Engine shutdown expected:<XJ015> but was:<08001>
at org.apache.derbyTesting.junit.BaseJDBCTestCase.assertSQLState(BaseJDBCTestCase.java:790)
at org.apache.derbyTesting.junit.TestConfiguration.shutdownEngine(TestConfiguration.java:1751)
at org.apache.derbyTesting.junit.SystemPropertyTestSetup.tearDown(SystemPropertyTestSetup.java:108)
at junit.extensions.TestSetup$1.protect(TestSetup.java:20)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
Caused by: java.sql.SQLException: No suitable driver
at java.sql.DriverManager.getConnection(DriverManager.java:330)
at java.sql.DriverManager.getConnection(DriverManager.java:297)
at org.apache.derbyTesting.junit.DriverManagerConnector.getConnectionByAttributes(DriverManagerConnector.java:163)
at org.apache.derbyTesting.junit.DriverManagerConnector.shutEngine(DriverManagerConnector.java:140)
at org.apache.derbyTesting.junit.TestConfiguration.shutdownEngine(TestConfiguration.java:1748)
... 31 more
FAILURES!!!
Tests run: 11,  Failures: 1,  Errors: 2","java.testing.org.apache.derbyTesting.functionTests.tests.largedata.LobLimitsTest
java.testing.org.apache.derbyTesting.junit.SystemPropertyTestSetup"
CLASS,derby-10.9.1.0,DERBY-5740,2012-05-03T07:31:43.000-05:00,Remove unsued code in AlterTableConstantaction.columnDroppedAndTriggerDependencies,"CollectNodesVisitor visitor = new CollectNodesVisitor(ColumnReference.class);
			stmtnode.accept(visitor);
			Vector refs = visitor.getList();
The following code is executed, but the results are not used:
			CollectNodesVisitor visitor = new CollectNodesVisitor(ColumnReference.class);
			stmtnode.accept(visitor);
			Vector refs = visitor.getList();  <--- never used
I plan to remove the code, but just want to record it here in case there are side-effects by using the visitor.",java.engine.org.apache.derby.impl.sql.execute.AlterTableConstantAction
CLASS,derby-10.9.1.0,DERBY-5816,2012-06-13T15:12:35.000-05:00,store.ServicePropertiesFileTest fails on z/OS,"testSevicePropertiesFileWithBackup(org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest) 
 
   
  
  
  
  testSevicePropertiesFileCorruptedWithBackup(org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTe
st)   {```
@    @    k@   }
store.ServicePropertiesFileTest fails on z/OS with two failures below.
Looks like likely test encoding issue
1 testSevicePropertiesFileWithBackup(org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest)junit.
framework.AssertionFailedError
at org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest.assertEOFToken(ServicePropertiesF
ileTest.java:275)
at org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest.testSevicePropertiesFileWithBacku
p(ServicePropertiesFileTest.java:178)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:88)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:113)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBareOverridable(BaseJDBCTestCase.java:424)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBare(BaseJDBCTestCase.java:441)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
2 testSevicePropertiesFileCorruptedWithBackup(org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTe
st)junit.framework.ComparisonFailure: expected:<[#--- last line, don't put anything after this line ---]> but was:<[{```
@    @    k@   } @   @        @     @    @    @```§]>
at org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest.removeEOFToken(ServicePropertiesF
ileTest.java:301)
at org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest.testSevicePropertiesFileCorrupted
WithBackup(ServicePropertiesFileTest.java:199)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:88)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:113)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBareOverridable(BaseJDBCTestCase.java:424)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBare(BaseJDBCTestCase.java:441)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.
protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
FAILURES!!!
Tests run: 290,  Failures: 2,  Errors: 0","java.engine.org.apache.derby.impl.services.monitor.StorageFactoryService
java.testing.org.apache.derbyTesting.functionTests.tests.store.ServicePropertiesFileTest"
CLASS,derby-10.9.1.0,DERBY-5912,2012-08-28T19:43:59.000-05:00,testIsValidImplemented fails for NetworkServer in some slow running machines/configurations,"isValid()  
 testIsValidImplemented(org.apache.derbyTesting.functionTests.tests.jdbc4.ConnectionTest) 
 
  assertTrue(getConnection().isValid(1));
The following test has been seen to fail as below  in some runs where the machine is under heavy load  and slow running options are specified and the isValid() call takes more than a second to return.
1 testIsValidImplemented(org.apache.derbyTesting.functionTests.tests.jdbc4.ConnectionTest)junit.framework.AssertionFailedError
at org.apache.derbyTesting.functionTests.tests.jdbc4.ConnectionTest.testIsValidImplemented(ConnectionTest.java:168)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:60)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:37)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:113)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
The test does:
   // Test with a 1 second timeout
        assertTrue(getConnection().
isValid(1));
assuming it will return in one second.
For embedded the int parameter is not implemented so indeed this always passes.
For the Network implementation in NetConnection40.java we actually do timeout and perform a query as part of the implementation so might indeed return false.","java.testing.org.apache.derbyTesting.functionTests.tests.jdbc4.ConnectionMethodsTest
java.drda.org.apache.derby.impl.drda.DRDAConnThread
java.testing.org.apache.derbyTesting.functionTests.tests.jdbc4.ConnectionTest"
CLASS,derby-10.9.1.0,DERBY-6053,2013-01-25T09:02:53.000-06:00,Client should use a prepared statement rather than regular statement for Connection.setTransactionIsolation,"client.am.Connection setTransactionIsolation()   setTransactionIsolation()   
 private Statement setTransactionIsolationStmt = null;
 
  
 createStatementX(java.sql.ResultSet.TYPE_FORWARD_ONLY,
                            java.sql.ResultSet.CONCUR_READ_ONLY,
                            holdability());
 
 private void setTransactionIsolationX(int level)
 
 setTransactionIsolationStmt.executeUpdate(
                ""SET CURRENT ISOLATION = "" + levelString);


 
   

import java.sql.*;
import java.net.*;
import java.io.*;
import org.apache.derby.drda.NetworkServerControl;

/**
 * Client template starts its own NetworkServer and runs some SQL against it.
 * The SQL or JDBC API calls can be modified to reproduce issues
 * 
 */public class SetTransactionIsolation {
    public static Statement s;
    
    public static void main(String[] args) throws Exception {
        try {
            // Load the driver. Not needed for network server.
            
            Class.forName(""org.apache.derby.jdbc.ClientDriver"");
            // Start Network Server
            startNetworkServer();
            // If connecting to a customer database. Change the URL
            Connection conn = DriverManager
                    .getConnection(""jdbc:derby://localhost:1527/wombat;create=true"");
            // clean up from a previous run
            s = conn.createStatement();
            try {
                s.executeUpdate(""DROP TABLE T"");
            } catch (SQLException se) {
                if (!se.getSQLState().equals(""42Y55""))
                    throw se;
            }

            for (int i = 0; i < 50000; i++) {
		conn.setTransactionIsolation(Connection.TRANSACTION_REPEATABLE_READ);
		conn.setTransactionIsolation(Connection.TRANSACTION_SERIALIZABLE);

	    }
            
            // rs.close();
            // ps.close();
            runtimeInfo();
            conn.close();
            // Shutdown the server
            shutdownServer();
        } catch (SQLException se) {
            while (se != null) {
                System.out.println(""SQLState="" + se.getSQLState()
                        + se.getMessage());
                se.printStackTrace();
                se = se.getNextException();
            }
        }
    }
    
    /**
     * starts the Network server
     * 
     */
    public static void startNetworkServer() throws SQLException {
        Exception failException = null;
        try {
            
            NetworkServerControl networkServer = new NetworkServerControl(
                    InetAddress.getByName(""localhost""), 1527);
            
            networkServer.start(new PrintWriter(System.out));
            
            // Wait for the network server to start
            boolean started = false;
            int retries = 10; // Max retries = max seconds to wait
            
            while (!started && retries > 0) {
                try {
                    // Sleep 1 second and then ping the network server
                    Thread.sleep(1000);
                    networkServer.ping();
                    
                    // If ping does not throw an exception the server has
                    // started
                    started = true;
                } catch (Exception e) {
                    retries--;
                    failException = e;
                }
                
            }
            
            // Check if we got a reply on ping
            if (!started) {
                throw failException;
            }
        } catch (Exception e) {
            SQLException se = new SQLException(""Error starting network  server"");
            se.initCause(failException);
            throw se;
        }
    }
    
    public static void shutdownServer() throws Exception {
        NetworkServerControl networkServer = new NetworkServerControl(
                InetAddress.getByName(""localhost""), 1527);
        networkServer.shutdown();
    }
    
    public static void runtimeInfo() throws Exception {
        NetworkServerControl networkServer = new NetworkServerControl(
                InetAddress.getByName(""localhost""), 1527);
        System.out.println(networkServer.getRuntimeInfo());
    }
    
}
o.a.d.client.am.Connection setTransactionIsolation() uses a Statement which  it builds up each time for setTransactionIsolation()  is called.
private Statement setTransactionIsolationStmt = null;
...
setTransactionIsolationStmt =
                    createStatementX(java.sql.ResultSet.TYPE_FORWARD_ONLY,
                            java.sql.ResultSet.CONCUR_READ_ONLY,
                            holdability());
....
private void setTransactionIsolationX(int level)
...
            setTransactionIsolationStmt.executeUpdate(
                ""SET CURRENT ISOLATION = "" + levelString);
import java.sql.
*;
import java.net.
*;
import java.io.
*;
import org.apache.derby.drda.NetworkServerControl;
/**
* Client template starts its own NetworkServer and runs some SQL against it.
* The SQL or JDBC API calls can be modified to reproduce issues
*
*/public class SetTransactionIsolation {
public static Statement s;
public static void main(String[] args) throws Exception {
try {
// Load the driver.
Not needed for network server.
Class.forName(""org.apache.derby.jdbc.ClientDriver"");
// Start Network Server
startNetworkServer();
// If connecting to a customer database.
Change the URL
Connection conn = DriverManager
.
getConnection(""jdbc:derby://localhost:1527/wombat;create=true"");
// clean up from a previous run
s = conn.createStatement();
try {
s.executeUpdate(""DROP TABLE T"");
} catch (SQLException se) {
if (!
se.getSQLState().
equals(""42Y55""))
throw se;
}
for (int i = 0; i < 50000; i++) {
		conn.setTransactionIsolation(Connection.TRANSACTION_REPEATABLE_READ);
		conn.setTransactionIsolation(Connection.TRANSACTION_SERIALIZABLE);
}
// rs.close();
// ps.close();
runtimeInfo();
conn.close();
// Shutdown the server
shutdownServer();
} catch (SQLException se) {
while (se !
= null) {
System.out.println(""SQLState="" + se.getSQLState()
+ se.getMessage());
se.printStackTrace();
se = se.getNextException();
}
}
}
/**
* starts the Network server
*
*/
public static void startNetworkServer() throws SQLException {
Exception failException = null;
try {
NetworkServerControl networkServer = new NetworkServerControl(
InetAddress.getByName(""localhost""), 1527);
networkServer.start(new PrintWriter(System.out));
// Wait for the network server to start
boolean started = false;
int retries = 10; // Max retries = max seconds to wait
while (!
started && retries > 0) {
try {
// Sleep 1 second and then ping the network server
Thread.sleep(1000);
networkServer.ping();
// If ping does not throw an exception the server has
// started
started = true;
} catch (Exception e) {
retries--;
failException = e;
}
}
// Check if we got a reply on ping
if (!
started) {
throw failException;
}
} catch (Exception e) {
SQLException se = new SQLException(""Error starting network  server"");
se.initCause(failException);
throw se;
}
}
public static void shutdownServer() throws Exception {
NetworkServerControl networkServer = new NetworkServerControl(
InetAddress.getByName(""localhost""), 1527);
networkServer.shutdown();
}
public static void runtimeInfo() throws Exception {
NetworkServerControl networkServer = new NetworkServerControl(
InetAddress.getByName(""localhost""), 1527);
System.out.println(networkServer.getRuntimeInfo());
}
}",java.client.org.apache.derby.client.am.Connection
CLASS,derby-10.9.1.0,DERBY-6058,2013-01-28T16:57:49.000-06:00,2 ClassNotFoundException failures on trunk with ibm's weme6.2 since build 1433263,"noSpecialCollation(org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest)  specialCollation(org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest)
Since the build of 1433263 on trunk, we see the following test failures:
1 noSpecialCollation(org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest)java.sql.SQLException: The class 'org.apache.derbyTesting.functionTests.tests.lang.VarargsRoutines' does not exist or is inaccessible.
This can happen if the class is not public.
at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)
at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedPreparedStatement.<init>(Unknown Source)
at org.apache.derby.jdbc.Driver169.newEmbedPreparedStatement(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.prepareStatement(BaseJDBCTestCase.java:217)
at org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest.assertResults(TableFunctionTest.java:2579)
at org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest.assertResults(TableFunctionTest.java:2568)
at org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest.derby_6040(TableFunctionTest.java:2370)
at org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest.miscBugs(TableFunctionTest.java:1936)
at org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest.tableFunctionTest(TableFunctionTest.java:1005)
at org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest.noSpecialCollation(TableFunctionTest.java:971)
at java.lang.reflect.AccessibleObject.invokeV(AccessibleObject.java:195)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:117)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBareOverridable(BaseJDBCTestCase.java:424)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBare(BaseJDBCTestCase.java:441)
Caused by: java.sql.SQLException: Java exception: 'org.apache.derbyTesting.functionTests.tests.lang.VarargsRoutines : JVMCFRE003 bad major version; class=org/apache/derbyTesting/functionTests/tests/lang/VarargsRoutines, offset=6: java.lang.ClassNotFoundException'.
at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)
at org.apache.derby.impl.jdbc.Util.javaException(Unknown Source)
at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
... 37 more
Caused by: java.lang.ClassNotFoundException: org.apache.derbyTesting.functionTests.tests.lang.VarargsRoutines : JVMCFRE003 bad major version; class=org/apache/derbyTesting/functionTests/tests/lang/VarargsRoutines, offset=6
at org.apache.derby.impl.services.reflect.DatabaseClasses.loadApplicationClass(Unknown Source)
at org.apache.derby.iapi.services.loader.ClassInspector.getClass(Unknown Source)
at org.apache.derby.iapi.services.loader.ClassInspector.accessible(Unknown Source)
at org.apache.derby.impl.sql.compile.QueryTreeNode.verifyClassExist(Unknown Source)
at org.apache.derby.impl.sql.compile.StaticMethodCallNode.bindExpression(Unknown Source)
at org.apache.derby.impl.sql.compile.FromVTI.bindVTITables(Unknown Source)
at org.apache.derby.impl.sql.compile.FromList.bindTables(Unknown Source)
at org.apache.derby.impl.sql.compile.SelectNode.bindNonVTITables(Unknown Source)
at org.apache.derby.impl.sql.compile.DMLStatementNode.bindTables(Unknown Source)
at org.apache.derby.impl.sql.compile.DMLStatementNode.bind(Unknown Source)
at org.apache.derby.impl.sql.compile.CursorNode.bindStatement(Unknown Source)
at org.apache.derby.impl.sql.GenericStatement.prepMinion(Unknown Source)
at org.apache.derby.impl.sql.GenericStatement.prepare(Unknown Source)
at org.apache.derby.impl.sql.conn.GenericLanguageConnectionContext.prepareInternalStatement(Unknown Source)
... 33 more
2 specialCollation(org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest)java.sql.SQLException: The class 'org.apache.derbyTesting.functionTests.tests.lang.VarargsRoutines' does not exist or is inaccessible.
This can happen if the class is not public.
at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)
at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
at org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedPreparedStatement.<init>(Unknown Source)
at org.apache.derby.jdbc.Driver169.newEmbedPreparedStatement(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedConnection.prepareStatement(Unknown Source)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.prepareStatement(BaseJDBCTestCase.java:217)
at org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest.assertResults(TableFunctionTest.java:2579)
at org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest.assertResults(TableFunctionTest.java:2568)
at org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest.derby_6040(TableFunctionTest.java:2370)
at org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest.miscBugs(TableFunctionTest.java:1936)
at org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest.tableFunctionTest(TableFunctionTest.java:1005)
at org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest.specialCollation(TableFunctionTest.java:981)
at java.lang.reflect.AccessibleObject.invokeV(AccessibleObject.java:195)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:117)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBareOverridable(BaseJDBCTestCase.java:424)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBare(BaseJDBCTestCase.java:441)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
Caused by: java.sql.SQLException: Java exception: 'org.apache.derbyTesting.functionTests.tests.lang.VarargsRoutines : JVMCFRE003 bad major version; class=org/apache/derbyTesting/functionTests/tests/lang/VarargsRoutines, offset=6: java.lang.ClassNotFoundException'.
at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)
at org.apache.derby.impl.jdbc.Util.javaException(Unknown Source)
at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
... 52 more
Caused by: java.lang.ClassNotFoundException: org.apache.derbyTesting.functionTests.tests.lang.VarargsRoutines : JVMCFRE003 bad major version; class=org/apache/derbyTesting/functionTests/tests/lang/VarargsRoutines, offset=6
at org.apache.derby.impl.services.reflect.DatabaseClasses.loadApplicationClass(Unknown Source)
at org.apache.derby.iapi.services.loader.ClassInspector.getClass(Unknown Source)
at org.apache.derby.iapi.services.loader.ClassInspector.accessible(Unknown Source)
at org.apache.derby.impl.sql.compile.QueryTreeNode.verifyClassExist(Unknown Source)
at org.apache.derby.impl.sql.compile.StaticMethodCallNode.bindExpression(Unknown Source)
at org.apache.derby.impl.sql.compile.FromVTI.bindVTITables(Unknown Source)
at org.apache.derby.impl.sql.compile.FromList.bindTables(Unknown Source)
at org.apache.derby.impl.sql.compile.SelectNode.bindNonVTITables(Unknown Source)
at org.apache.derby.impl.sql.compile.DMLStatementNode.bindTables(Unknown Source)
at org.apache.derby.impl.sql.compile.DMLStatementNode.bind(Unknown Source)
at org.apache.derby.impl.sql.compile.CursorNode.bindStatement(Unknown Source)
at org.apache.derby.impl.sql.GenericStatement.prepMinion(Unknown Source)
at org.apache.derby.impl.sql.GenericStatement.prepare(Unknown Source)
at org.apache.derby.impl.sql.conn.GenericLanguageConnectionContext.prepareInternalStatement(Unknown Source)
... 48 more
Things were fine with build 1432788.
Things are also fine with ibm 1.5, 1.6, 1.7.
See also: http://people.apache.org/~myrnavl/derby_test_results/main/windows/testSummary-1433263.html",java.testing.org.apache.derbyTesting.functionTests.tests.lang.TableFunctionTest
CLASS,derby-10.9.1.0,DERBY-6079,2013-02-19T18:51:03.000-06:00,100's of errors in nightly test run on weme after jacoco property/priviledges checkin,"testAll(org.apache.derbyTesting.functionTests.tests.lang.NativeAuthenticationServiceTest)
100's of errors in nightly test, all seem to be a null pointer while processing policy files during setup.
problem is in jvm code, and it seems specific to the weme6.2 jvm.
The only change being tested in this run was
For instance:
330) testAll(org.apache.derbyTesting.functionTests.tests.lang.NativeAuthenticationServiceTest)java.lang.NullPointerException
at com.ibm.oti.util.DefaultPolicy.addGrant(DefaultPolicy.java:619)
at com.ibm.oti.util.DefaultPolicy.readPolicy(DefaultPolicy.java:608)
at com.ibm.oti.util.DefaultPolicy.getSystemPolicy(DefaultPolicy.java:922)
at com.ibm.oti.util.DefaultPolicy.getPermissionsImpl(DefaultPolicy.java:114)
at com.ibm.oti.util.DefaultPolicy$1.run(DefaultPolicy.java:67)
at java.security.AccessController.doPrivileged(AccessController.java:204)
at com.ibm.oti.util.DefaultPolicy.privateGetPermissions(DefaultPolicy.java:65)
at com.ibm.oti.util.DefaultPolicy.getPermissions(DefaultPolicy.java:53)
at java.security.Policy.getPermissions(Policy.java:131)
at java.security.ProtectionDomain.implies(ProtectionDomain.java:177)
at java.security.AccessController.checkPermission(AccessController.java:99)
at java.lang.SecurityManager.checkPermission(SecurityManager.java:534)
at java.lang.SecurityManager.checkPropertyAccess(SecurityManager.java:331)
at java.lang.System.getProperty(System.java:384)
at java.lang.System.getProperty(System.java:366)
at org.apache.derbyTesting.junit.BaseTestCase$3.run(BaseTestCase.java:292)
at java.security.AccessController.doPrivileged(AccessController.java:204)
at org.apache.derbyTesting.junit.BaseTestCase.getSystemProperty(BaseTestCase.java:288)
at org.apache.derbyTesting.junit.DropDatabaseSetup.removeDatabase(DropDatabaseSetup.java:86)
at org.apache.derbyTesting.junit.TestConfiguration$5.tearDown(TestConfiguration.java:868)
at junit.extensions.TestSetup$1.protect(TestSetup.java:22)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
Here is link to all errors:
http://people.apache.org/~myrnavl/derby_test_results/main/windows/testlog/weme6.2/1447575-suites.All_diff.txt http://people.apache.org/~myrnavl/derby_test_results/main/windows/testlog/weme6.2/1447575-derbyall_diff.txt","java.testing.org.apache.derbyTesting.junit.SecurityManagerSetup
java.testing.org.apache.derbyTesting.junit.BaseTestCase"
CLASS,derby-10.9.1.0,DERBY-6092,2013-02-25T18:48:14.000-06:00,testPositionAgressive(org.apache.derbyTesting.functionTests.tests.jdbcapi.BlobClob4BlobTest)j fails with : 'The handle is invalid.: java.io.IOException'.,"testPositionAgressive(org.apache.derbyTesting.functionTests.tests.jdbcapi.BlobClob4BlobTest)
There was 1 error:
http://people.apache.org/~myrnavl/derby_test_results/main/windows/testlog/ibm15/1449432-suites.All_diff.txt
1 testPositionAgressive(org.apache.derbyTesting.functionTests.tests.jdbcapi.BlobClob4BlobTest)java.sql.SQLException: Java exception: 'The handle is invalid.: java.io.IOException'.
at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Unknown Source)
at org.apache.derby.impl.jdbc.Util.javaException(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedConnection.clearLOBMapping(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedConnection.commit(Unknown Source)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.commit(BaseJDBCTestCase.java:393)
at org.apache.derbyTesting.functionTests.tests.jdbcapi.BlobClob4BlobTest.testPositionAgressive(BlobClob4BlobTest.java:1070)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:79)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:117)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBareOverridable(BaseJDBCTestCase.java:424)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBare(BaseJDBCTestCase.java:441)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
Caused by: java.io.IOException: The handle is invalid.
at java.io.RandomAccessFile.close0(Native Method)
at java.io.RandomAccessFile.close(RandomAccessFile.java:573)
at org.apache.derby.impl.jdbc.LOBFile.close(Unknown Source)
at org.apache.derby.impl.jdbc.EncryptedLOBFile.close(Unknown Source)
... 53 more",java.testing.org.apache.derbyTesting.functionTests.tests.jdbcapi.BlobClob4BlobTest
CLASS,derby-10.9.1.0,DERBY-6108,2013-03-13T12:14:01.000-05:00,suites.All no longer runs with weme 6.2,"suite()
Since revision 1454647 the suites.All no longer kicks off with weme 6.2.
The stack trace (which does not get copied to my apache location because the test doesn't finish) looks like this:
Failed to invoke class org.apache.derbyTesting.functionTests.tests.derbynet._Suite
java.lang.reflect.InvocationTargetException
at java.lang.reflect.AccessibleObject.invokeL(AccessibleObject.java:205)
at java.lang.reflect.Method.invoke(Method.java:252)
at org.apache.derbyTesting.functionTests.suites.AllPackages.invokeSuite(AllPackages.java:179)
at org.apache.derbyTesting.functionTests.suites.AllPackages.suite(AllPackages.java:63)
at org.apache.derbyTesting.functionTests.suites.All.suite(All.java:51)
at java.lang.reflect.AccessibleObject.invokeL(AccessibleObject.java:203)
at java.lang.reflect.Method.invoke(Method.java:252)
at junit.runner.BaseTestRunner.getTest(BaseTestRunner.java:126)
at junit.textui.TestRunner.start(TestRunner.java:184)
at junit.textui.TestRunner.main(TestRunner.java:143)
Caused by: junit.framework.AssertionFailedError: unexpected error
at org.apache.derbyTesting.junit.BaseTestCase.fail(BaseTestCase.java:1104)
at org.apache.derbyTesting.junit.JDBCDataSource.getDataSourceObject(JDBCDataSource.java:187)
at org.apache.derbyTesting.junit.JDBCDataSource.getDataSource(JDBCDataSource.java:108)
at org.apache.derbyTesting.junit.JDBCDataSource.getDataSource(JDBCDataSource.java:93)
at org.apache.derbyTesting.junit.DataSourceConnector.setConfiguration(DataSourceConnector.java:51)
at org.apache.derbyTesting.junit.TestConfiguration.initConnector(TestConfiguration.java:1484)
at org.apache.derbyTesting.junit.TestConfiguration.<init>(TestConfiguration.java:1393)
at org.apache.derbyTesting.junit.TestConfiguration.<clinit>(TestConfiguration.java:138)
at java.lang.J9VMInternals.initializeImpl(Native Method)
at java.lang.J9VMInternals.initialize(J9VMInternals.java:209)
at org.apache.derbyTesting.functionTests.tests.derbynet.ShutDownDBWhenNSShutsDownTest.suite(ShutDownDBWhenNSShutsDownTest.java:53)
at org.apache.derbyTesting.functionTests.tests.derbynet._Suite.suite(_Suite.java:50)
at java.lang.reflect.AccessibleObject.invokeL(AccessibleObject.java:203)
... 9 more
Caused by: java.lang.NullPointerException
at org.apache.derbyTesting.junit.TestConfiguration.getCurrent(TestConfiguration.java:220)
at org.apache.derbyTesting.junit.JDBCDataSource.getDataSourceObject(JDBCDataSource.java:183)
... 20 more
Failed to invoke suite():java.lang.reflect.InvocationTargetException
The changes between the previous successful run and this one were:
r1454600 | rhillegas | 2013-03-08 14:05:09 -0800 (Fri, 08 Mar 2013) | 1 line
DERBY-6094: Enforce login timeouts in the embedded driver and data sources.
------------------------------------------------------------------------
r1454537 | rhillegas | 2013-03-08 12:42:08 -0800 (Fri, 08 Mar 2013) | 1 line
DERBY-6022: Add an optional tool for turning on optimizer tracing and dumping the trace to the console.
------------------------------------------------------------------------
r1454358 | kahatlen | 2013-03-08 04:58:58 -0800 (Fri, 08 Mar 2013) | 1 line
Add the generated source folder to the NetBeans project.
------------------------------------------------------------------------
r1454296 | kahatlen | 2013-03-08 01:13:04 -0800 (Fri, 08 Mar 2013) | 3 lines
DERBY-6075: Use modern collections in impl/sql/compile
Replace Hashtable fields with HashSets.
I think we should not be running the derbynet suite with weme at all, but we should be able to get a datasource...",java.testing.org.apache.derbyTesting.junit.JDBCDataSource
CLASS,derby-10.9.1.0,DERBY-6138,2013-04-02T13:14:31.000-05:00,org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest fails with  sealing violation: package org.apache.derby.iapi.services.sanity is sealed depending on classpath order,"testBootingDatabaseShutdownByAnotherCLR(org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest)
Depending on classpath order, I believe if derbyclient.jar is before derby.jar in the classpath ClassLoaderBootTest fails with a sealing violation.,
There were 2 errors:
1 testBootingAnAlreadyBootedDatabase(org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest)java.lang.ExceptionInInitializerError
at java.lang.J9VMInternals.initialize(J9VMInternals.java:255)
at org.apache.derby.jdbc.EmbeddedBaseDataSource.findDriver(EmbeddedBaseDataSource.java:366)
at org.apache.derby.jdbc.EmbeddedBaseDataSource.getConnection(EmbeddedBaseDataSource.java:615)
at org.apache.derby.jdbc.EmbeddedBaseDataSource.getConnection(EmbeddedBaseDataSource.java:552)
at org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest.testBootingAnAlreadyBootedDatabase(ClassLoaderBootTest.java:178)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:88)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:117)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBareOverridable(BaseJDBCTestCase.java:424)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBare(BaseJDBCTestCase.java:441)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
Caused by: java.lang.SecurityException: sealing violation: package org.apache.derby.iapi.services.sanity is sealed
at java.net.URLClassLoader.getAndVerifyPackage(URLClassLoader.java:623)
at java.net.URLClassLoader.defineClass(URLClassLoader.java:655)
at java.net.URLClassLoader.access$400(URLClassLoader.java:92)
at java.net.URLClassLoader$ClassFinder.run(URLClassLoader.java:1159)
at java.security.AccessController.doPrivileged(AccessController.java:288)
at java.net.URLClassLoader.findClass(URLClassLoader.java:594)
at org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest$DerbyURLClassLoader.loadClass(ClassLoaderBootTest.java:293)
at org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest$DerbyURLClassLoader.loadClass(ClassLoaderBootTest.java:303)
at org.apache.derby.iapi.services.monitor.Monitor.startSystemModule(Monitor.java:365)
at org.apache.derby.impl.services.monitor.BaseMonitor.runWithState(BaseMonitor.java:342)
at org.apache.derby.impl.services.monitor.FileMonitor.<init>(FileMonitor.java:58)
at org.apache.derby.iapi.services.monitor.Monitor.startMonitor(Monitor.java:285)
at org.apache.derby.iapi.jdbc.JDBCBoot.boot(JDBCBoot.java:67)
at org.apache.derby.jdbc.EmbeddedDriver.boot(EmbeddedDriver.java:196)
at org.apache.derby.jdbc.EmbeddedDriver.<clinit>(EmbeddedDriver.java:92)
at java.lang.J9VMInternals.initializeImpl(Native Method)
at java.lang.J9VMInternals.initialize(J9VMInternals.java:233)
... 41 more
2 testBootingDatabaseShutdownByAnotherCLR(org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest)java.lang.ExceptionInInitializerError
at java.lang.J9VMInternals.initialize(J9VMInternals.java:255)
at org.apache.derby.jdbc.EmbeddedBaseDataSource.findDriver(EmbeddedBaseDataSource.java:366)
at org.apache.derby.jdbc.EmbeddedBaseDataSource.getConnection(EmbeddedBaseDataSource.java:615)
at org.apache.derby.jdbc.EmbeddedBaseDataSource.getConnection(EmbeddedBaseDataSource.java:552)
at org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest.testBootingDatabaseShutdownByAnotherCLR(ClassLoaderBootTest.java:208)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:88)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:117)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBareOverridable(BaseJDBCTestCase.java:424)
at org.apache.derbyTesting.junit.BaseJDBCTestCase.runBare(BaseJDBCTestCase.java:441)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
Caused by: java.lang.SecurityException: sealing violation: package org.apache.derby.iapi.services.sanity is sealed
at java.net.URLClassLoader.getAndVerifyPackage(URLClassLoader.java:623)
at java.net.URLClassLoader.defineClass(URLClassLoader.java:655)
at java.net.URLClassLoader.access$400(URLClassLoader.java:92)
at java.net.URLClassLoader$ClassFinder.run(URLClassLoader.java:1159)
at java.security.AccessController.doPrivileged(AccessController.java:288)
at java.net.URLClassLoader.findClass(URLClassLoader.java:594)
at org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest$DerbyURLClassLoader.loadClass(ClassLoaderBootTest.java:293)
at org.apache.derbyTesting.functionTests.tests.store.ClassLoaderBootTest$DerbyURLClassLoader.loadClass(ClassLoaderBootTest.java:303)
at org.apache.derby.iapi.services.monitor.Monitor.startSystemModule(Monitor.java:365)
at org.apache.derby.impl.services.monitor.BaseMonitor.runWithState(BaseMonitor.java:342)
at org.apache.derby.impl.services.monitor.FileMonitor.<init>(FileMonitor.java:58)
at org.apache.derby.iapi.services.monitor.Monitor.startMonitor(Monitor.java:285)
at org.apache.derby.iapi.jdbc.JDBCBoot.boot(JDBCBoot.java:67)
at org.apache.derby.jdbc.EmbeddedDriver.boot(EmbeddedDriver.java:196)
at org.apache.derby.jdbc.EmbeddedDriver.<clinit>(EmbeddedDriver.java:92)
at java.lang.J9VMInternals.initializeImpl(Native Method)
at java.lang.J9VMInternals.initialize(J9VMInternals.java:233)
... 41 more
My classpath when this occurred was:
.
;C:/cygwin/svn/trunk/jars/sane/derbyclient.
jar;C:/cygwin/svn/trunk/jars/sane/derby.
jar;C:/cygwin/svn/trunk/jars/sane/de
rbyrun.jar;C:/cygwin/svn/trunk/jars/sane/derby.
jar;C:/cygwin/svn/trunk/jars/sane/derbyTesting.
jar;C:/cygwin/svn/trunk/to
ols/java/junit.
jar;C:/cygwin/svn/trunk/tools/java/jakarta-oro-2.0.8.
jar
Taking out all but derbyrun.jar and derbyTesting.jar resolved the issue.",java.client.org.apache.derby.client.am.LogWriter
METHOD,time,18,2013-04-19T08:28:47.000-05:00,NPE in DateTimeZoneBuilder,"PrecalculatedZone.create()  ZoneInfoCompiler.verbose() 
    
 static {
 cVerbose.set(Boolean.FALSE);
 }
 
 public static boolean verbose() {
 return cVerbose.get();
 }
 
 public static boolean verbose(){
 Boolean verbose = cVerbose.get();
 return (verbose != null) ? verbose : false;
}
 
 @Test
 public void testDateTimeZoneBuilder() throws Exception {
 getTestDataTimeZoneBuilder().toDateTimeZone(""TestDTZ1"", true);
 Thread t = new Thread(new Runnable() {
 @Override
 public void run() {
 getTestDataTimeZoneBuilder().toDateTimeZone(""TestDTZ2"", true);
 }
 });
 t.start();
 t.join();
 }

  private DateTimeZoneBuilder getTestDataTimeZoneBuilder() {
 return new DateTimeZoneBuilder()
 .addCutover(1601, 'w', 1, 1, 1, false, 7200000)
 .setStandardOffset(3600000)
 .addRecurringSavings("""", 3600000, 1601, Integer.MAX_VALUE, 'w', 3, -1, 1, false, 7200000)
 .addRecurringSavings("""", 0, 1601, Integer.MAX_VALUE, 'w', 10, -1, 1, false, 10800000);
 }
When a DateTimeZone is build with duplicate-named 'recurring saving time' in a first thread, all goes Ok: a warning message is generated and an identifier is automatically generated in PrecalculatedZone.create().
When a second thread does the same, an NPE is generated in ZoneInfoCompiler.verbose().
The cause is that the cVerbose ThreadLocal is incorrectly initialized in ZoneInfoCompiler:
``` java
 static {
 cVerbose.set(Boolean.FALSE);
 }
```
...will initialize cVerbose only for the first thread and not for the subsequent ones.
The NPE is caused by the autoboxing in:
``` java
 public static boolean verbose() {
 return cVerbose.get();
 }
```
A better approach could be to remove the initialization and test for null:
``` java
public static boolean verbose(){
 Boolean verbose = cVerbose.get();
 return (verbose !
= null) ?
verbose : false;
}
```
---
``` java
 @Test
 public void testDateTimeZoneBuilder() throws Exception {
 getTestDataTimeZoneBuilder().
toDateTimeZone(""TestDTZ1"", true);
 Thread t = new Thread(new Runnable() {
 @Override
 public void run() {
 getTestDataTimeZoneBuilder().
toDateTimeZone(""TestDTZ2"", true);
 }
 });
 t.start();
 t.join();
 }
private DateTimeZoneBuilder getTestDataTimeZoneBuilder() {
 return new DateTimeZoneBuilder()
 .
addCutover(1601, 'w', 1, 1, 1, false, 7200000)
 .
setStandardOffset(3600000)
 .
addRecurringSavings("""", 3600000, 1601, Integer.MAX_VALUE, 'w', 3, -1, 1, false, 7200000)
 .
addRecurringSavings("""", 0, 1601, Integer.MAX_VALUE, 'w', 10, -1, 1, false, 10800000);
 }
```",org.joda.time.tz.ZoneInfoCompiler:<clinit0>
METHOD,time,21,2013-05-03T21:03:46.000-05:00,DateTimeFormat.parseInto sometimes miscalculates year (2.2),"public void testParseInto_monthDay_feb29_startOfYear() {
 DateTimeFormatter f = DateTimeFormat.forPattern(""M d"").withLocale(Locale.UK);
 MutableDateTime result = new MutableDateTime(2000, 1, 1, 0, 0, 0, 0, NEWYORK);
 assertEquals(4, f.parseInto(result, ""2 29"", 0));
 assertEquals(new MutableDateTime(2000, 2, 29, 0, 0, 0, 0, NEWYORK), result);
 }
There appears to be a bug in the fix to http://sourceforge.net/p/joda-time/bugs/148 (which I also reported).
The following code (which can be added to org.joda.time.format.TestDateTimeFormatter) breaks, because the input mutable date time's millis appear to be mishandled and the year for the parse is changed to 1999:
``` java
 public void testParseInto_monthDay_feb29_startOfYear() {
 DateTimeFormatter f = DateTimeFormat.forPattern(""M d"").
withLocale(Locale.UK);
 MutableDateTime result = new MutableDateTime(2000, 1, 1, 0, 0, 0, 0, NEWYORK);
 assertEquals(4, f.parseInto(result, ""2 29"", 0));
 assertEquals(new MutableDateTime(2000, 2, 29, 0, 0, 0, 0, NEWYORK), result);
 }
```","org.joda.time.format.DateTimeFormatter:parseInto(ReadWritableInstant, String, int)"
METHOD,time,22,2013-05-07T14:19:36.000-05:00,Days#daysBetween throw exception for MonthDay with 29 February,"final LocalDate january12012 = new LocalDate(2012, 1,1);
final LocalDate february292012 = new LocalDate(2012, 2, 29);
// OK
assertEquals(59, Days.daysBetween(january12012, february292012).getDays());

final MonthDay january1 = new MonthDay(1,1);
final MonthDay february29 = new MonthDay(2, 29);
// FAIL
assertEquals(59, Days.daysBetween(january1, february29).getDays());
final LocalDate january12012 = new LocalDate(2012, 1,1);
final LocalDate february292012 = new LocalDate(2012, 2, 29);
// OK
assertEquals(59, Days.daysBetween(january12012, february292012).
getDays());
final MonthDay january1 = new MonthDay(1,1);
final MonthDay february29 = new MonthDay(2, 29);
// FAIL
assertEquals(59, Days.daysBetween(january1, february29).
getDays());
org.joda.time.IllegalFieldValueException: Value 29 for dayOfMonth must be in the range [1,28]
at org.joda.time.field.FieldUtils.verifyValueBounds(FieldUtils.java:217)
at org.joda.time.field.PreciseDurationDateTimeField.set(PreciseDurationDateTimeField.java:78)
at org.joda.time.chrono.BaseChronology.set(BaseChronology.java:240)
at org.joda.time.base.BaseSingleFieldPeriod.between(BaseSingleFieldPeriod.java:103)
at org.joda.time.Days.daysBetween(Days.java:141)
Is there a way to avoid this happening?
I understand fiddling around with the leap year, you're bound to get issues.
Thanks!","org.joda.time.base.BaseSingleFieldPeriod:between(ReadablePartial, ReadablePartial, ReadablePeriod)"
METHOD,time,28,2013-05-31T00:52:24.000-05:00,Questionable behaviour of GJChronology when dates pass 1BC,"Chronology chronology = GJChronology.getInstance();

LocalDate start = new LocalDate(2013, 5, 31, chronology);
LocalDate expectedEnd = new LocalDate(-1, 5, 31, chronology); // 1 BC
assertThat(start.minusYears(2013), is(equalTo(expectedEnd)));
assertThat(start.plus(Period.years(-2013)), is(equalTo(expectedEnd)));
```
Chronology chronology = GJChronology.getInstance();
LocalDate start = new LocalDate(2013, 5, 31, chronology);
LocalDate expectedEnd = new LocalDate(-1, 5, 31, chronology); // 1 BC
assertThat(start.minusYears(2013), is(equalTo(expectedEnd)));
assertThat(start.plus(Period.years(-2013)), is(equalTo(expectedEnd)));
```
The error it gives is:
```
org.joda.time.IllegalFieldValueException: Value 0 for year is not supported
```
However, I never provided ""0"" for the year myself.","org.joda.time.chrono.GJChronology:getInstance(DateTimeZone, ReadableInstant, int)
org.joda.time.chrono.GJChronology:add(long, long)
org.joda.time.chrono.GJChronology:add(long, int)"
METHOD,time,77,2013-10-16T15:36:22.000-05:00,addDays(0) changes value of MutableDateTime,"final MutableDateTime mdt = new MutableDateTime(2011, 10, 30, 3, 0, 0, 0, DateTimeZone.forID(""Europe/Berlin""));
System.out.println(""Start date: "" + mdt + "" ("" + mdt.toInstant().getMillis() + "")"");
mdt.addHours(-1);
System.out.println(""addHours(-1): "" + mdt + "" ("" + mdt.toInstant().getMillis() + "")"");
mdt.addHours(0);
System.out.println(""addHours(0): "" + mdt + "" ("" + mdt.toInstant().getMillis() + "")"");
mdt.addDays(0);
System.out.println(""addDays(0): "" + mdt + "" ("" + mdt.toInstant().getMillis() + "")"");
 
 
 addHours(-1)  
 addHours(0)  
 addDays(0)  
 
          
 addDays(0)
Upon DST transition from summer to winter time zone, adding the amount of zero days to a mutable date time object changes the value of the object.
``` java final MutableDateTime mdt = new MutableDateTime(2011, 10, 30, 3, 0, 0, 0, DateTimeZone.forID(""Europe/Berlin""));
System.out.println(""Start date: "" + mdt + "" ("" + mdt.toInstant().
getMillis() + "")"");
mdt.addHours(-1);
System.out.println(""addHours(-1): "" + mdt + "" ("" + mdt.toInstant().
getMillis() + "")"");
mdt.addHours(0);
System.out.println(""addHours(0): "" + mdt + "" ("" + mdt.toInstant().
getMillis() + "")"");
mdt.addDays(0);
System.out.println(""addDays(0): "" + mdt + "" ("" + mdt.toInstant().
getMillis() + "")"");
```
prints
```
Start date: 2011-10-30T03:00:00.000+01:00 (1319940000000) //OK addHours(-1): 2011-10-30T02:00:00.000+01:00 (1319936400000) //OK addHours(0): 2011-10-30T02:00:00.000+01:00 (1319936400000) //OK, no change in time addDays(0): 2011-10-30T02:00:00.000+02:00 (1319932800000) //error, time has changed by 1 hour
```
The methods addMonths and addYears show the same problem; addSeconds, addMinutes and addHours are ok.
I have tested with version 2.3.
However, if I repeat the test with Joda 1.5.2, the invocation of addDays(0) does not change the date's value.","org.joda.time.MutableDateTime:add(DurationFieldType, int)
org.joda.time.MutableDateTime:addWeeks(int)
org.joda.time.MutableDateTime:addYears(int)
org.joda.time.MutableDateTime:addMonths(int)
org.joda.time.MutableDateTime:addMinutes(int)
org.joda.time.MutableDateTime:addHours(int)
org.joda.time.MutableDateTime:addWeekyears(int)
org.joda.time.MutableDateTime:addDays(int)
org.joda.time.MutableDateTime:addSeconds(int)
org.joda.time.MutableDateTime:addMillis(int)"
METHOD,time,79,2013-10-17T20:36:31.000-05:00,none standard PeriodType without year throws exception,"Period p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.forFields(new DurationFieldType[]{DurationFieldType.months(), DurationFieldType.weeks()})).normalizedStandard(PeriodType.forFields(new DurationFieldType[]{DurationFieldType.months(), DurationFieldType.weeks()}));
return p.getMonths();
 
    
      
   
 withYearsRemoved() throws the  
 Period p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.standard()).normalizedStandard(PeriodType.standard());
return p.getMonths();
 
 Period p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.standard().withYearsRemoved()).normalizedStandard(PeriodType.standard().withYearsRemoved());
return p.getMonths();
Hi.
``` Java
Period p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.forFields(new DurationFieldType[]{DurationFieldType.months(), DurationFieldType.weeks()})).
normalizedStandard(PeriodType.forFields(new DurationFieldType[]{DurationFieldType.months(), DurationFieldType.weeks()}));
return p.getMonths();
```
This throws following exception:
```
10-17 14:35:50.999: E/AndroidRuntime(1350): java.lang.UnsupportedOperationException: Field is not supported
10-17 14:35:50.999: E/AndroidRuntime(1350): at org.joda.time.PeriodType.setIndexedField(PeriodType.java:690)
10-17 14:35:50.999: E/AndroidRuntime(1350): at org.joda.time.Period.withYears(Period.java:896) 10-17
14:35:50.999: E/AndroidRuntime(1350): at org.joda.time.Period.normalizedStandard(Period.java:1630)
```
Even removing the year component with .
withYearsRemoved() throws the same exception:
this works:
``` Java
Period p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.standard()).
normalizedStandard(PeriodType.standard());
return p.getMonths();
```
this fails:
``` Java
Period p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.standard().
withYearsRemoved()).
normalizedStandard(PeriodType.standard().
withYearsRemoved());
return p.getMonths();
```",org.joda.time.Period:normalizedStandard(PeriodType)
METHOD,time,88,2013-11-25T19:15:46.000-06:00,Constructing invalid Partials,"Partial a = new Partial(new DateTimeFieldType[] { year(), hourOfDay() }, new int[] { 1, 1});
Partial b = new Partial(year(), 1).with(hourOfDay(), 1);
assert(a == b);
 
 new Partial(new DateTimeFieldType[] { clockhourOfDay(), hourOfDay() }, new int[] { 1, 1}); // throws Types array must not contain duplicate
new Partial(clockhourOfDay(), 1).with(hourOfDay(), 1); // #<Partial [clockhourOfDay=1, hourOfDay=1]>
 
 new Partial(clockhourOfDay(), 1)  with(hourOfDay(), 1)  isEqual(new Partial(hourOfDay() ,1).with(clockhourOfDay(), 1)) // throws objects must have matching field types
Partials can be constructed by invoking a constructor `Partial(DateTimeFieldType[], int[])` or by merging together a set of partials using `with`, each constructed by calling `Partial(DateTimeFieldType, int)`, e.g.:
``` java
Partial a = new Partial(new DateTimeFieldType[] { year(), hourOfDay() }, new int[] { 1, 1});
Partial b = new Partial(year(), 1).
with(hourOfDay(), 1);
assert(a == b);
```
``` java
new Partial(new DateTimeFieldType[] { clockhourOfDay(), hourOfDay() }, new int[] { 1, 1}); // throws Types array must not contain duplicate
new Partial(clockhourOfDay(), 1).
with(hourOfDay(), 1); // #<Partial [clockhourOfDay=1, hourOfDay=1]>
```
Is that right?
There's also a related issue (probably stems from the fact that the Partial is invalid):
``` java
new Partial(clockhourOfDay(), 1).
with(hourOfDay(), 1).
isEqual(new Partial(hourOfDay() ,1).
with(clockhourOfDay(), 1)) // throws objects must have matching field types
```","org.joda.time.Partial:with(DateTimeFieldType, int)"
METHOD,time,93,2013-12-01T09:33:58.000-06:00,Partial.with fails with NPE,"new Partial(yearOfCentury(), 1)  with(weekyear(), 1);
// NullPointerException
// org.joda.time.Partial.with (Partial.java:447)
``` java
new Partial(yearOfCentury(), 1).
with(weekyear(), 1);
// NullPointerException
// org.joda.time.Partial.with (Partial.java:447)
```
Fails with yearOfCentury, year and yearOfEra.
Probably because weekyear has a null range duration type.","org.joda.time.Partial:Partial(DateTimeFieldType[], int[], Chronology)
org.joda.time.field.UnsupportedDurationField:compareTo(DurationField)"
FILE,COMPRESS,COMPRESS-131,2011-06-03T16:25:45.000-05:00,ArrayOutOfBounds while decompressing bz2,"recvDecodingTables()
Decompressing a bz2 file generated by bzip2 utility throws an ArrayIndexOutOfBounds at method recvDecodingTables() line 469.
I believe it is related to encodings used to generate the original text file (the compressed file).",org.apache.commons.compress.compressors.BZip2TestCase
FILE,COMPRESS,COMPRESS-189,2012-06-26T21:30:39.000-05:00,ZipArchiveInputStream may read 0 bytes when reading from a nested Zip file,"ZipFile zipFile = new ZipFile(""C:/test.ZIP"");
    for (Enumeration<ZipArchiveEntry> iterator = zipFile.getEntries(); iterator.hasMoreElements(); ) {
      ZipArchiveEntry entry = iterator.nextElement();
      InputStream is = new BufferedInputStream(zipFile.getInputStream(entry));
      ZipArchiveInputStream zipInput = new ZipArchiveInputStream(is);
      ZipArchiveEntry innerEntry;
      while ((innerEntry = zipInput.getNextZipEntry()) != null){
        if (innerEntry.getName().endsWith(""XML""))
{

          //zipInput.read();

          System.out.println(IOUtils.toString(zipInput));

        }
      }
    }
When the following code is run an error ""Underlying input stream returned zero bytes"" is produced.
If the commented line is uncommented it can be seen that the ZipArchiveInputStream returned 0 bytes.
This only happens the first time read is called, subsequent calls work as expected i.e. the following code actually works correctly with that line uncommented!
If this is not the correct way of processing a zip file of zip files please let me know.
Also I believe whilst ZipFile can iterate over entries fast due to being able to look at the master table whilst ZipArchiveInputStream cannot.
Is there anyway of instantiating a ZipFile from a zip file inside another zip file without first extracting the nested zip file?
ZipFile zipFile = new ZipFile(""C:/test.ZIP"");
for (Enumeration<ZipArchiveEntry> iterator = zipFile.getEntries(); iterator.hasMoreElements(); ) {
ZipArchiveEntry entry = iterator.nextElement();
InputStream is = new BufferedInputStream(zipFile.getInputStream(entry));
ZipArchiveInputStream zipInput = new ZipArchiveInputStream(is);
ZipArchiveEntry innerEntry;
while ((innerEntry = zipInput.getNextZipEntry()) !
= null){ if (innerEntry.getName().
endsWith(""XML""))
{
//zipInput.read();
System.out.println(IOUtils.toString(zipInput));
}
}
}","org.apache.commons.compress.archivers.zip.ZipArchiveInputStreamTest
org.apache.commons.compress.archivers.zip.ZipArchiveInputStream"
FILE,COMPRESS,COMPRESS-245,2013-12-05T11:01:39.000-06:00,TarArchiveInputStream#getNextTarEntry returns null prematurely,"FileInputStream fin = new FileInputStream(""exampletar.tar.gz"");

GZIPInputStream gin = new GZIPInputStream(fin);

TarArchiveInputStream tin = new TarArchiveInputStream(gin);            TarArchiveEntry entry;

              tin.getNextTarEntry()
The attached archive decompressed with 1.6 only extracts part of the archive.
This does not happen with version 1.5
FileInputStream fin = new FileInputStream(""exampletar.tar.gz"");
GZIPInputStream gin = new GZIPInputStream(fin);
TarArchiveInputStream tin = new TarArchiveInputStream(gin);            TarArchiveEntry entry;
while ((entry = tin.getNextTarEntry()) !
= null) {
topdirectory/
topdirectory/about.html
topdirectory/.
eclipseproduct
topdirectory/plugins/
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/about.html
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/META-INF/
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/META-INF/eclipse.
inf
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/META-INF/ECLIPSEF.
SF
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/META-INF/MANIFEST.
MF
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/META-INF/ECLIPSEF.
RSA
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/launcher.
gtk.linux.x86_64.
properties
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/eclipse_1206.
so
topdirectory/plugins/org.
eclipse.core.runtime.compatibility.registry_3.2.200.v20090429-1800/
topdirectory/plugins/org.
eclipse.core.runtime.compatibility.registry_3.2.200.v20090429-1800/about.html
topdirectory/plugins/org.
eclipse.core.runtime.compatibility.registry_3.2.200.v20090429-1800/fragment.properties
topdirectory/plugins/org.
eclipse.core.runtime.compatibility.registry_3.2.200.v20090429-1800/.
api_description
topdirectory/plugins/org.
eclipse.core.runtime.compatibility.registry_3.2.200.v20090429-1800/META-INF/
topdirectory/plugins/org.
eclipse.core.runtime.compatibility.registry_3.2.200.v20090429-1800/META-INF/eclipse.
inf
topdirectory/plugins/org.
eclipse.core.runtime.compatibility.registry_3.2.200.v20090429-1800/META-INF/ECLIPSEF.
SF
topdirectory/plugins/org.
eclipse.core.runtime.compatibility.registry_3.2.200.v20090429-1800/META-INF/MANIFEST.
MF
topdirectory/plugins/org.
eclipse.core.runtime.compatibility.registry_3.2.200.v20090429-1800/META-INF/ECLIPSEF.
RSA
topdirectory/plugins/org.
eclipse.core.runtime.compatibility.registry_3.2.200.v20090429-1800/runtime_registry_compatibility.jar
topdirectory/configuration/
topdirectory/configuration/config.ini
topdirectory/icon.
xpm
topdirectory/about_files/
topdirectory/about_files/pixman-licenses.txt
topdirectory/about_files/mpl-v11.txt
topdirectory/about_files/about_cairo.html
topdirectory/libcairo-swt.
so
with commons-compress-1.6 it looks like this:
topdirectory/
topdirectory/about.html
topdirectory/.
eclipseproduct
topdirectory/plugins
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/about.html
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/META-INF
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/META-INF/eclipse.
inf
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/META-INF/ECLIPSEF.
SF
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/META-INF/MANIFEST.
MF
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/META-INF/ECLIPSEF.
RSA
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/launcher.
gtk.linux.x86_64.
properties
topdirectory/plugins/org.
eclipse.equinox.launcher.gtk.linux.x86_64_1.0.200.
v20090519/eclipse_1206.
so
topdirectory/plugins/org.
eclipse.core.runtime.compatibility.registry_3.2.200.v20090429-1800
topdirectory/plugins/org.
eclipse.core.runtime.compatibility.registry_3.2.200.v20090429-1800/about.html
topdirectory/plugins/org.
eclipse.core.runtime.compatibility.registry_3.2.200.v20090429-1800/fragment.properties
topdirectory/plugins/org.
eclipse.core.runtime.compatibility.registry_3.2.200.v20090429-1800/.
api_description
topdirectory/plugins/org.
eclipse.core.runtime.compatibility.registry_3.2.200.v20090429-1800/META-INF","org.apache.commons.compress.archivers.tar.TarArchiveInputStream
org.apache.commons.compress.archivers.tar.TarArchiveInputStreamTest"
FILE,COMPRESS,COMPRESS-276,2014-04-11T05:03:17.000-05:00,NullPointerException in ZipArchiveOutputStream with invalid entries,"java.io.ByteArrayOutputStream var0 = new java.io.ByteArrayOutputStream();
    org.apache.commons.compress.archivers.jar.JarArchiveOutputStream var1 = new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream((java.io.OutputStream)var0);
    var1.write(25843);
Writing raw data seems to cause problems in multiple ways, because an internal field is not set.
Is this a wrong API usage? java.io.ByteArrayOutputStream var0 = new java.io.ByteArrayOutputStream();
org.apache.commons.compress.archivers.jar.JarArchiveOutputStream var1 = new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream((java.io.OutputStream)var0);
var1.write(25843);
Other tests (see attachment) are very similar and cause the same problem.
They can probably be ignored because the first test is the shortest one.","org.apache.commons.compress.archivers.sevenz.SevenZFile
org.apache.commons.compress.archivers.tar.TarArchiveOutputStream
org.apache.commons.compress.archivers.sevenz.SevenZOutputFile
org.apache.commons.compress.archivers.tar.TarArchiveInputStream
org.apache.commons.compress.archivers.arj.ArjArchiveInputStream
org.apache.commons.compress.archivers.dump.DumpArchiveInputStream
org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream"
FILE,COMPRESS,COMPRESS-273,2014-04-11T04:13:32.000-05:00,NullPointerException when creation fields/entries from scratch,"org.apache.commons.compress.archivers.zip.UnicodeCommentExtraField var0 = new org.apache.commons.compress.archivers.zip.UnicodeCommentExtraField();
    org.apache.commons.compress.archivers.zip.ZipShort var1 = var0.getLocalFileDataLength();
The API has public default constructors for many data types.
However, when these 0-argument constructors are used, certain internal references are null, resulting in a NullPointerException soon after.
This also applies to some 1-argument constructors where two references should be set before get... is used later.
In the latter case, there must be public set methods for the missing data.
org.apache.commons.compress.archivers.zip.UnicodeCommentExtraField var0 = new org.apache.commons.compress.archivers.zip.UnicodeCommentExtraField();
org.apache.commons.compress.archivers.zip.ZipShort var1 = var0.getLocalFileDataLength();","org.apache.commons.compress.archivers.zip.AbstractUnicodeExtraField
org.apache.commons.compress.archivers.cpio.CpioArchiveEntry
org.apache.commons.compress.archivers.zip.ExtraFieldUtils
org.apache.commons.compress.archivers.zip.UnrecognizedExtraField"
FILE,COMPRESS,COMPRESS-278,2014-04-18T16:09:05.000-05:00,Incorrect handling of NUL username and group Tar.gz entries,"package TestBed;



import java.io.File;

import java.io.FileInputStream;

import java.io.FileNotFoundException;

import java.io.IOException;



import org.apache.commons.compress.archivers.tar.TarArchiveEntry;

import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;

import org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream;

import org.junit.Test;



/**

 * Unit test for simple App.

 */

public class AppTest

{



    @Test

    public void extractNoFileOwner()

    {

        TarArchiveInputStream tarInputStream = null;



        try

        {

            tarInputStream =

                new TarArchiveInputStream( new GzipCompressorInputStream( new FileInputStream( new File(

                    ""/home/pknobel/redis-dist-2.8.3_1-linux.tar.gz"" ) ) ) );

            TarArchiveEntry entry;

            while ( ( entry = tarInputStream.getNextTarEntry() ) != null )

            {

                System.out.println( entry.getName() );

                System.out.println(entry.getUserName()+""/""+entry.getGroupName());

            }



        }

        catch ( FileNotFoundException e )

        {

            e.printStackTrace();

        }

        catch ( IOException e )

        {

            e.printStackTrace();

        }

    }



}
With version 1.8 of commons-compress it's no longer possible to decompress  files from an archive if the archive contains entries having null (or being empty?)
set as username and/or usergroup.
With version 1.7 this still worked now I get this exception:
java.io.IOException: Error detected parsing the header
at org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:249)
at TestBed.AppTest.extractNoFileOwner(AppTest.java:30)
Caused by: java.lang.IllegalArgumentException: Invalid byte 32 at offset 7 in '       {NUL}' len=8
at org.apache.commons.compress.archivers.tar.TarUtils.parseOctal(TarUtils.java:134)
at org.apache.commons.compress.archivers.tar.TarUtils.parseOctalOrBinary(TarUtils.java:173)
at org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:953)
at org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:940)
at org.apache.commons.compress.archivers.tar.TarArchiveEntry.<init>(TarArchiveEntry.java:324)
at org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:247)
... 27 more
This exception leads to my suspision that the regression was introduced with the fix for this ticket COMPRESS-262, which has a nearly identical exception provided.
package TestBed;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import org.apache.commons.compress.archivers.tar.TarArchiveEntry;
import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;
import org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream;
import org.junit.Test;
/**
* Unit test for simple App.
*/
public class AppTest
{
@Test
public void extractNoFileOwner()
{
TarArchiveInputStream tarInputStream = null;
try
{
tarInputStream =
new TarArchiveInputStream( new GzipCompressorInputStream( new FileInputStream( new File(
""/home/pknobel/redis-dist-2.8.3_1-linux.tar.gz"" ) ) ) );
TarArchiveEntry entry;
while ( ( entry = tarInputStream.getNextTarEntry() ) !
= null )
{
System.out.println( entry.getName() );
System.out.println(entry.getUserName()+""/""+entry.getGroupName());
}
}
catch ( FileNotFoundException e )
{
e.printStackTrace();
}
catch ( IOException e )
{
e.printStackTrace();
}
}
}
With 1.7 the TestCase outputed this:
redis-dist-2.8.3_1/bin/
/
redis-dist-2.8.3_1/bin/redis-server
jenkins/jenkins
redis-dist-2.8.3_1/bin/redis-cli
jenkins/jenkins
With 1.8 it's failing once it reaches the null valued entry, which is the first.
The archive is created using maven assembly plugin, and I tried the same with maven ant task.
Both generating an archive with not set username and groups for at least some entries.
You can download the archive from http://heli0s.darktech.org/redis/2.8.3_1/redis-dist-2.8.3_1-linux.tar.gz
If you run a tar -tvzf on the file you see this report:
drwxr-xr-x 0/0               0 2014-04-18 09:43 redis-dist-2.8.3_1-SNAPSHOT/bin/
-rwxr-xr-x pknobel/pknobel 3824588 2014-01-02 14:58 redis-dist-2.8.3_1-SNAPSHOT/bin/redis-cli
-rwxr-xr-x pknobel/pknobel 5217234 2014-01-02 14:58 redis-dist-2.8.3_1-SNAPSHOT/bin/redis-server
The user 0/0 probably indicates that it's not set although it's the root user id.
A correctly root user file would show up as root/root","org.apache.commons.compress.archivers.tar.TarUtilsTest
org.apache.commons.compress.archivers.tar.TarUtils"
FILE,COMPRESS,COMPRESS-309,2015-02-18T17:22:16.000-06:00,BZip2CompressorInputStream return value wrong when told to read to a full buffer.,"BZip2CompressorInputStream.read(buffer, offset, length)  
 @Test

	public void testApacheCommonsBZipUncompression () throws Exception {

		// Create a big random piece of data

		byte[] rawData = new byte[1048576];

		for (int i=0; i<rawData.length; ++i) {

			rawData[i] = (byte) Math.floor(Math.random()*256);

		}



		// Compress it

		ByteArrayOutputStream baos = new ByteArrayOutputStream();

		BZip2CompressorOutputStream bzipOut = new BZip2CompressorOutputStream(baos);

		bzipOut.write(rawData);

		bzipOut.flush();

		bzipOut.close();

		baos.flush();

		baos.close();



		// Try to read it back in

		ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());

		BZip2CompressorInputStream bzipIn = new BZip2CompressorInputStream(bais);

		byte[] buffer = new byte[1024];

		// Works fine

		Assert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));

		// Fails, returns -1 (indicating the stream is complete rather than that the buffer 

		// was full)

		Assert.assertEquals(0, bzipIn.read(buffer, 1024, 0));

		// But if you change the above expected value to -1, the following line still works

		Assert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));

		bzipIn.close();

	}
BZip2CompressorInputStream.read(buffer, offset, length) returns -1 when given an offset equal to the length of the buffer.
This indicates, not that the buffer was full, but that the stream was finished.
@Test
public void testApacheCommonsBZipUncompression () throws Exception {
// Create a big random piece of data
byte[] rawData = new byte[1048576];
for (int i=0; i<rawData.length; ++i) {
rawData[i] = (byte) Math.floor(Math.random()*256);
}
// Compress it
ByteArrayOutputStream baos = new ByteArrayOutputStream();
BZip2CompressorOutputStream bzipOut = new BZip2CompressorOutputStream(baos);
bzipOut.write(rawData);
bzipOut.flush();
bzipOut.close();
baos.flush();
baos.close();
// Try to read it back in
ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());
BZip2CompressorInputStream bzipIn = new BZip2CompressorInputStream(bais);
byte[] buffer = new byte[1024];
// Works fine
Assert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));
// Fails, returns -1 (indicating the stream is complete rather than that the buffer
// was full)
Assert.assertEquals(0, bzipIn.read(buffer, 1024, 0));
// But if you change the above expected value to -1, the following line still works
Assert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));
bzipIn.close();
}",org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream
FILE,COMPRESS,COMPRESS-357,2016-05-25T17:50:50.000-05:00,BZip2CompressorOutputStream can affect output stream incorrectly,"finished()  
  
 s.close();
s = null;
  finalize()  finish()  finish()  
 finish()  
 finalize() 
 finalize()
BZip2CompressorOutputStream has an unsynchronized finished() method, and an unsynchronized finalize method.
Finish checks to see if the output stream is null, and if it is not it calls various methods, some of which write to the output stream.
Now, consider something like this sequence.
BZip2OutputStream s = ...
...
s.close();
s = null;
After the s = null, the stream is garbage.
At some point the garbage collector call finalize(), which calls finish().
But, since the GC may be on a different thread, there is no guarantee that the assignment this.out = null in finish() has actually been made visible to the GC thread, which results in bad data in the output stream.
This is not a theoretical problem; In a part of a large project I'm working on, this happens about 2% of the time.
The fixes are simple
A workaround is to derive a class and override the finalize() method.",org.apache.commons.compress.compressors.bzip2.BZip2CompressorOutputStream
METHOD,mahout-0.8,MAHOUT-1261,2013-06-13T10:09:15.000-05:00,TasteHadoopUtils.idToIndex can return an int that has size Integer.MAX_VALUE,"Longs.hashCode(id)
I'm running ItemSimilarityJob on a very large (~600M by 4B) matrix that's very sparse (total set of associations is 630MB).
The job fails because of an IndexException in ToUserVectorsReducer.
TasteHadoopUtils.idToIndex(long id) hashes a long with:
0x7fffffff & Longs.hashCode(id) (line o.a.m.cf.taste.hadoop.TasteHadoopUtils:57).
For some id (I don't know what value), the result returned is Integer.MAX_VALUE.
This cannot be set in the userVector because the cardinality of that is also Integer.MAX_VALUE and it throws an exception.
So, the issue is that values from 0 to INT_MAX are returned by idToIndex but the vector only has 0 to INT_MAX - 1 possible entries.
It's a nasty little off-by-one bug.
I'm thinking of just % size when setting.
[~ssc] & everyone else, thoughts?
:)","org.apache.mahout.cf.taste.hadoop.TasteHadoopUtils:idToIndex(long)
org.apache.mahout.cf.taste.hadoop.TasteHadoopUtils:readID(String, boolean)"
METHOD,mahout-0.8,MAHOUT-1301,2013-08-01T09:31:21.000-05:00,toString() method of SequentialAccessSparseVector has excess comma at the end,"SequentialAccessSparseVector toString()   toString()  
 {code:java}
 Vector v = new SequentialAccessSparseVector(capacity);
v.set(1, 0.1);
v.set(3, 0.3);
{code}
  v.toString()  
 {code:java}
 {1:0.1,3:0.3}
 {code}
 
 {code:java}
 {1:0.1,3:0.3,}
 {code}
Realization of SequentialAccessSparseVector toString() method had changed in MAHOUT-1259 patch.
Unfortunately, that patch introduced new bug: output of the toString() method had been changed - extra comma added at the end of the string
Example: 
Consider following sparse vector
{code:java}
Vector v = new SequentialAccessSparseVector(capacity);
v.set(1, 0.1);
v.set(3, 0.3);
{code}
In 0.7 v.toString() returns following string:
{code:java}
{1:0.1,3:0.3}
{code}
but in 0.8 it returns
{code:java}
{1:0.1,3:0.3,}
{code}
As you can see, there is extra comma at the end of the string.","org.apache.mahout.math.SequentialAccessSparseVector:toString()
org.apache.mahout.math.RandomAccessSparseVector:toString()"
METHOD,mahout-0.8,MAHOUT-1314,2013-08-18T09:07:48.000-05:00,StreamingKMeansReducer throws NullPointerException when REDUCE_STREAMING_KMEANS is set to true,"return input.getCentroid();  
 input.getCentroid()  clone();
when REDUCE_STREAMING_KMEANS option is set to true (-rskm) the reducer fails with NullPointerException.
the problem is in the reduce method itself: on line 60 ( return input.getCentroid(); )
it should be input.getCentroid().
clone();
similar to line 81.
full stack trace:
java.lang.NullPointerException
at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:191)
at org.apache.mahout.math.random.WeightedThing.<init>(WeightedThing.java:31)
at org.apache.mahout.math.neighborhood.BruteSearch.searchFirst(BruteSearch.java:133)
at org.apache.mahout.clustering.ClusteringUtils.estimateDistanceCutoff(ClusteringUtils.java:100)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansThread.call(StreamingKMeansThread.java:64)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:66)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:1)
at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:176)
at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:650)
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:418)
at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:260)","org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer:reduce(IntWritable, Iterable<CentroidWritable>, Context)
org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer:getBestCentroids(List<Centroid>, Configuration)"
METHOD,mahout-0.8,MAHOUT-1317,2013-08-23T13:05:58.000-05:00,Clarify some of the messages in Preconditions.checkArgument,"Preconditions.checkArgument(maxSimilaritiesPerRow > 0, ""Incorrect maximum number of similarities per row!"");
In experimenting with things, I was getting some errors from RowSimilarityJob, that in looking at the source I realized were a little incomplete as to what the true issue was.
In this case, they were of the form:
Preconditions.checkArgument(maxSimilaritiesPerRow > 0, ""Incorrect maximum number of similarities per row!"")
;
Here, it is known that the actual issue is that the parameter must be zero (or negative), not just that it's ""incorrect"", and a (trivial) change to the error message might save some folks some time... especially newbies like myself.
A quick grep of the code showed a few more cases like that across the code base that would be (apparently) easy to fix and maybe save folks time when they get the relevant error.","org.apache.mahout.math.als.AlternatingLeastSquaresSolver:addLambdaTimesNuiTimesE(Matrix, double, int)
org.apache.mahout.utils.SplitInput:validate()
org.apache.mahout.math.neighborhood.FastProjectionSearch:FastProjectionSearch(DistanceMeasure, int, int)
org.apache.mahout.classifier.naivebayes.training.WeightsMapper:setup(Context)
org.apache.mahout.cf.taste.example.kddcup.KDDCupDataModel:KDDCupDataModel(File, boolean, double)
org.apache.mahout.math.neighborhood.ProjectionSearch:ProjectionSearch(DistanceMeasure, int, int)
org.apache.mahout.classifier.df.mapreduce.partial.TreeID:TreeID(int, int)
org.apache.mahout.math.neighborhood.SearchQualityTest.StripWeight:apply(WeightedThing<Vector>)
org.apache.mahout.classifier.df.data.Dataset:valueOf(int, String)
org.apache.mahout.classifier.df.mapreduce.partial.TreeID:treeId()
org.apache.mahout.classifier.df.data.DataLoader:parseString(Attribute[], Set<String>[], CharSequence, boolean)
org.apache.mahout.cf.taste.impl.common.WeightedRunningAverage:changeDatum(double, double)
org.apache.mahout.math.als.AlternatingLeastSquaresSolver:solve(Iterable<Vector>, Vector, double, int)
org.apache.mahout.cf.taste.impl.model.cassandra.CassandraDataModel:CassandraDataModel(String, int, String)
org.apache.mahout.math.als.AlternatingLeastSquaresSolver:createRiIiMaybeTransposed(Vector)
org.apache.mahout.cf.taste.impl.common.SamplingLongPrimitiveIterator:SamplingLongPrimitiveIterator(RandomWrapper, LongPrimitiveIterator, double)
org.apache.mahout.math.neighborhood.BruteSearch:search(Vector, int)
org.apache.mahout.cf.taste.impl.similarity.GenericItemSimilarity.ItemItemSimilarity:ItemItemSimilarity(long, long, double)
org.apache.mahout.math.random.ChineseRestaurant:ChineseRestaurant(double, double)
org.apache.mahout.cf.taste.impl.similarity.GenericUserSimilarity.UserUserSimilarity:UserUserSimilarity(long, long, double)"
METHOD,mahout-0.8,MAHOUT-1320,2013-08-29T04:07:09.000-05:00,BallKMeansTest.testClustering is unstable,"{noformat}
  
 testClustering(org.apache.mahout.clustering.streaming.cluster.BallKMeansTest)   
 {noformat}



 
 {noformat}
 
      
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 testClustering(org.apache.mahout.clustering.streaming.cluster.BallKMeansTest)   
 {noformat}
From time to time this test fails with following in build log:
{noformat}
Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 48.134 sec <<< FAILURE! - in org.apache.mahout.clustering.streaming.cluster.BallKMeansTest
testClustering(org.apache.mahout.clustering.streaming.cluster.BallKMeansTest)  Time elapsed: 2.051 sec  <<< FAILURE!
java.lang.AssertionError: expected:<625.0> but was:<796.0>
at org.junit.Assert.fail(Assert.java:88)
at org.junit.Assert.failNotEquals(Assert.java:743)
at org.junit.Assert.assertEquals(Assert.java:494)
at org.junit.Assert.assertEquals(Assert.java:592)
at org.apache.mahout.clustering.streaming.cluster.BallKMeansTest.testClustering(BallKMeansTest.java:119)
{noformat}
Here is a bit more of build log output, which also shows other tests were running in parallel with this one:
{noformat}
[INFO] --- maven-surefire-plugin:2.15:test (default-test) @ mahout-core ---
[INFO] Surefire report directory: /home/jenkins/jenkins-slave/workspace/Mahout-Quality/trunk/core/target/surefire-reports
[INFO] parallel='classes', perCoreThreadCount=false, threadCount=1, useUnlimitedThreads=false
-------------------------------------------------------
T E S T S
-------------------------------------------------------
-------------------------------------------------------
T E S T S
-------------------------------------------------------
Running org.apache.mahout.common.distance.TestChebyshevMeasure
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.043 sec - in org.apache.mahout.common.distance.TestChebyshevMeasure
Running org.apache.mahout.common.distance.TestMinkowskiMeasure
Running org.apache.mahout.common.distance.TestMahalanobisDistanceMeasure
Running org.apache.mahout.common.distance.TestManhattanDistanceMeasure
Running org.apache.mahout.common.distance.CosineDistanceMeasureTest
Running org.apache.mahout.common.distance.TestTanimotoDistanceMeasure
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.143 sec - in org.apache.mahout.common.distance.TestMinkowskiMeasure
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.078 sec - in org.apache.mahout.common.distance.TestMahalanobisDistanceMeasure
Running org.apache.mahout.common.distance.TestWeightedManhattanDistanceMeasure
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.099 sec - in org.apache.mahout.common.distance.TestManhattanDistanceMeasure
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.075 sec - in org.apache.mahout.common.distance.CosineDistanceMeasureTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.094 sec - in org.apache.mahout.common.distance.TestTanimotoDistanceMeasure
Running org.apache.mahout.common.distance.TestWeightedEuclideanDistanceMeasureTest
Running org.apache.mahout.common.distance.TestEuclideanDistanceMeasure
Running org.apache.mahout.common.iterator.TestFixedSizeSampler
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.135 sec - in org.apache.mahout.common.distance.TestWeightedManhattanDistanceMeasure
Running org.apache.mahout.common.iterator.CountingIteratorTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.009 sec - in org.apache.mahout.common.iterator.CountingIteratorTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.073 sec - in org.apache.mahout.common.iterator.TestFixedSizeSampler
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.111 sec - in org.apache.mahout.common.distance.TestWeightedEuclideanDistanceMeasureTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.121 sec - in org.apache.mahout.common.distance.TestEuclideanDistanceMeasure
Running org.apache.mahout.common.iterator.TestSamplingIterator
Running org.apache.mahout.common.iterator.TestStableFixedSizeSampler
Running org.apache.mahout.common.DummyRecordWriterTest
Running org.apache.mahout.common.StringUtilsTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.093 sec - in org.apache.mahout.common.iterator.TestStableFixedSizeSampler
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.113 sec - in org.apache.mahout.common.DummyRecordWriterTest
Running org.apache.mahout.common.AbstractJobTest
Running org.apache.mahout.common.IntPairWritableTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.02 sec - in org.apache.mahout.common.IntPairWritableTest
Running org.apache.mahout.common.lucene.AnalyzerUtilsTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.07 sec - in org.apache.mahout.common.lucene.AnalyzerUtilsTest
Running org.apache.mahout.clustering.topdown.PathDirectoryTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.007 sec - in org.apache.mahout.clustering.topdown.PathDirectoryTest
Running org.apache.mahout.clustering.topdown.postprocessor.ClusterCountReaderTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.505 sec - in org.apache.mahout.common.StringUtilsTest
Running org.apache.mahout.clustering.classify.ClusterClassificationDriverTest
Running org.apache.mahout.clustering.topdown.postprocessor.ClusterOutputPostProcessorTest
Running org.apache.mahout.clustering.spectral.TestVectorCache
Running org.apache.mahout.clustering.spectral.TestVectorMatrixMultiplicationJob
Running org.apache.mahout.clustering.spectral.TestMatrixDiagonalizeJob
Running org.apache.mahout.clustering.lda.cvb.TestCVBModelTrainer
Running org.apache.mahout.clustering.spectral.TestAffinityMatrixInputJob
Running org.apache.mahout.clustering.spectral.TestUnitVectorizerJob
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.356 sec - in org.apache.mahout.common.AbstractJobTest
Running org.apache.mahout.clustering.canopy.TestCanopyCreation
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.046 sec - in org.apache.mahout.clustering.spectral.TestVectorMatrixMultiplicationJob
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.288 sec - in org.apache.mahout.clustering.spectral.TestMatrixDiagonalizeJob
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.624 sec - in org.apache.mahout.clustering.spectral.TestVectorCache
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.713 sec - in org.apache.mahout.common.iterator.TestSamplingIterator
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.054 sec - in org.apache.mahout.clustering.spectral.TestUnitVectorizerJob
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.518 sec - in org.apache.mahout.clustering.spectral.TestAffinityMatrixInputJob
Running org.apache.mahout.clustering.kmeans.TestRandomSeedGenerator
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.609 sec - in org.apache.mahout.clustering.topdown.postprocessor.ClusterCountReaderTest
Running org.apache.mahout.clustering.kmeans.TestEigenSeedGenerator
Running org.apache.mahout.clustering.kmeans.TestKmeansClustering
Running org.apache.mahout.clustering.TestGaussianAccumulators
Running org.apache.mahout.clustering.iterator.TestClusterClassifier
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.065 sec - in org.apache.mahout.clustering.topdown.postprocessor.ClusterOutputPostProcessorTest
Running org.apache.mahout.clustering.fuzzykmeans.TestFuzzyKmeansClustering
Running org.apache.mahout.clustering.TestClusterInterface
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.203 sec - in org.apache.mahout.clustering.TestClusterInterface
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.746 sec - in org.apache.mahout.clustering.kmeans.TestEigenSeedGenerator
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.897 sec - in org.apache.mahout.clustering.kmeans.TestRandomSeedGenerator
Running org.apache.mahout.clustering.streaming.cluster.StreamingKMeansTest
Running org.apache.mahout.clustering.streaming.cluster.BallKMeansTest
Running org.apache.mahout.math.stats.OnlineAucTest
Running org.apache.mahout.math.stats.SamplerTest
Running org.apache.mahout.math.VarintTest
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.031 sec - in org.apache.mahout.math.VarintTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.294 sec - in org.apache.mahout.math.stats.SamplerTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.821 sec - in org.apache.mahout.clustering.classify.ClusterClassificationDriverTest
Running org.apache.mahout.math.hadoop.stochasticsvd.SSVDCommonTest
Running org.apache.mahout.math.hadoop.stats.BasicStatsTest
Running org.apache.mahout.math.hadoop.TestDistributedRowMatrix
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.175 sec - in org.apache.mahout.math.hadoop.stochasticsvd.SSVDCommonTest
Running org.apache.mahout.math.hadoop.stochasticsvd.LocalSSVDPCASparseTest
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.366 sec - in org.apache.mahout.clustering.TestGaussianAccumulators
Running org.apache.mahout.math.hadoop.stochasticsvd.LocalSSVDSolverSparseSequentialTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.578 sec - in org.apache.mahout.math.stats.OnlineAucTest
Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.893 sec - in org.apache.mahout.clustering.iterator.TestClusterClassifier
Running org.apache.mahout.math.hadoop.stochasticsvd.LocalSSVDSolverDenseTest
Running org.apache.mahout.math.hadoop.solver.TestDistributedConjugateGradientSolverCLI
Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.419 sec - in org.apache.mahout.clustering.canopy.TestCanopyCreation
Running org.apache.mahout.math.hadoop.solver.TestDistributedConjugateGradientSolver
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.33 sec - in org.apache.mahout.math.hadoop.stats.BasicStatsTest
Running org.apache.mahout.math.hadoop.similarity.TestVectorDistanceSimilarityJob
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.475 sec - in org.apache.mahout.clustering.kmeans.TestKmeansClustering
Running org.apache.mahout.math.hadoop.similarity.cooccurrence.measures.VectorSimilarityMeasuresTest
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.076 sec - in org.apache.mahout.math.hadoop.similarity.cooccurrence.measures.VectorSimilarityMeasuresTest
Running org.apache.mahout.math.hadoop.similarity.cooccurrence.RowSimilarityJobTest
Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.855 sec - in org.apache.mahout.math.hadoop.TestDistributedRowMatrix
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.63 sec - in org.apache.mahout.math.hadoop.similarity.TestVectorDistanceSimilarityJob
Running org.apache.mahout.math.hadoop.decomposer.TestDistributedLanczosSolverCLI
Running org.apache.mahout.math.VectorWritableTest
Tests run: 100, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.046 sec - in org.apache.mahout.math.VectorWritableTest
Running org.apache.mahout.math.ssvd.SequentialOutOfCoreSvdTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.541 sec - in org.apache.mahout.math.hadoop.solver.TestDistributedConjugateGradientSolverCLI
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.658 sec - in org.apache.mahout.math.hadoop.solver.TestDistributedConjugateGradientSolver
Running org.apache.mahout.math.neighborhood.LocalitySensitiveHashSearchTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.045 sec - in org.apache.mahout.math.hadoop.stochasticsvd.LocalSSVDSolverSparseSequentialTest
Running org.apache.mahout.math.neighborhood.SearchSanityTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 33.918 sec - in org.apache.mahout.clustering.fuzzykmeans.TestFuzzyKmeansClustering
Running org.apache.mahout.math.MatrixWritableTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.944 sec - in org.apache.mahout.math.hadoop.similarity.cooccurrence.RowSimilarityJobTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.08 sec - in org.apache.mahout.math.MatrixWritableTest
Running org.apache.mahout.vectorizer.DocumentProcessorTest
Running org.apache.mahout.vectorizer.HighDFWordsPrunerTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.631 sec - in org.apache.mahout.vectorizer.HighDFWordsPrunerTest
Running org.apache.mahout.math.neighborhood.SearchQualityTest
Running org.apache.mahout.vectorizer.encoders.ContinuousValueEncoderTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.062 sec - in org.apache.mahout.vectorizer.encoders.ContinuousValueEncoderTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.581 sec - in org.apache.mahout.vectorizer.DocumentProcessorTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.304 sec - in org.apache.mahout.math.hadoop.stochasticsvd.LocalSSVDPCASparseTest
Running org.apache.mahout.vectorizer.encoders.ConstantValueEncoderTest
Running org.apache.mahout.vectorizer.encoders.InteractionValueEncoderTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.113 sec - in org.apache.mahout.vectorizer.encoders.ConstantValueEncoderTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.137 sec - in org.apache.mahout.vectorizer.encoders.InteractionValueEncoderTest
Running org.apache.mahout.vectorizer.encoders.WordLikeValueEncoderTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.174 sec - in org.apache.mahout.vectorizer.encoders.WordLikeValueEncoderTest
Running org.apache.mahout.vectorizer.encoders.TextValueEncoderTest
Running org.apache.mahout.vectorizer.SparseVectorsFromSequenceFilesTest
Running org.apache.mahout.vectorizer.collocations.llr.GramTest
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.082 sec - in org.apache.mahout.vectorizer.collocations.llr.GramTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.544 sec - in org.apache.mahout.vectorizer.encoders.TextValueEncoderTest
Running org.apache.mahout.vectorizer.collocations.llr.GramKeyGroupComparatorTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.069 sec - in org.apache.mahout.vectorizer.collocations.llr.GramKeyGroupComparatorTest
Running org.apache.mahout.vectorizer.collocations.llr.GramKeyPartitionerTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.061 sec - in org.apache.mahout.vectorizer.collocations.llr.GramKeyPartitionerTest
Running org.apache.mahout.vectorizer.collocations.llr.LLRReducerTest
Running org.apache.mahout.vectorizer.collocations.llr.CollocReducerTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.552 sec - in org.apache.mahout.vectorizer.collocations.llr.LLRReducerTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.369 sec - in org.apache.mahout.vectorizer.collocations.llr.CollocReducerTest
Running org.apache.mahout.vectorizer.collocations.llr.CollocMapperTest
Running org.apache.mahout.vectorizer.collocations.llr.GramKeyTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.081 sec - in org.apache.mahout.vectorizer.collocations.llr.GramKeyTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.693 sec - in org.apache.mahout.vectorizer.collocations.llr.CollocMapperTest
Running org.apache.mahout.vectorizer.DictionaryVectorizerTest
Running org.apache.mahout.vectorizer.EncodedVectorsFromSequenceFilesTest
Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 48.134 sec <<< FAILURE!
- in org.apache.mahout.clustering.streaming.cluster.BallKMeansTest
testClustering(org.apache.mahout.clustering.streaming.cluster.BallKMeansTest)  Time elapsed: 2.051 sec  <<< FAILURE!
java.lang.AssertionError: expected:<625.0> but was:<796.0>
at org.junit.Assert.fail(Assert.java:88)
at org.junit.Assert.failNotEquals(Assert.java:743)
at org.junit.Assert.assertEquals(Assert.java:494)
at org.junit.Assert.assertEquals(Assert.java:592)
at org.apache.mahout.clustering.streaming.cluster.BallKMeansTest.testClustering(BallKMeansTest.java:119)
{noformat}
Last time test failed it was on ubuntu-1 node, but it's also randomly successful on same node so it doesn't seem to be caused by something node specific.",org.apache.mahout.clustering.streaming.cluster.BallKMeansTest:testClusteringMultipleRuns()
METHOD,mahout-0.8,MAHOUT-1336,2013-09-16T23:35:54.000-05:00,HighDFWordsPrunerTest is failing silently,"{noformat}
 
        
        
      
         
      
 {noformat}
Apparently ToolRunner does not allow the --mapred option.
The validation is not very foolproof, so there is a resulting silent failure in HighDFWordsPrunerTest.
Error message:
{noformat}
org.apache.commons.cli2.OptionException: Unexpected --mapred while processing Options
at org.apache.commons.cli2.commandline.Parser.parse(Parser.java:99)
at org.apache.mahout.vectorizer.SparseVectorsFromSequenceFiles.run(SparseVectorsFromSequenceFiles.java:154)
at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
at org.apache.mahout.vectorizer.HighDFWordsPrunerTest.runTest(HighDFWordsPrunerTest.java:111)
at org.apache.mahout.vectorizer.HighDFWordsPrunerTest.testHighDFWordsPruning(HighDFWordsPrunerTest.java:85)
...
Usage:
[--minSupport <minSupport> --analyzerName <analyzerName> --chunkSize
<chunkSize> --output <output> --input <input> --minDF <minDF> --maxDFSigma
<maxDFSigma> --maxDFPercent <maxDFPercent> --weight <weight> --norm <norm>
--minLLR <minLLR> --numReducers <numReducers> --maxNGramSize <ngramSize>
--overwrite --help --sequentialAccessVector --namedVector --logNormalize]
O
{noformat}","org.apache.mahout.vectorizer.HighDFWordsPrunerTest:validateVectors(Path, int[], boolean)"
METHOD,mahout-0.8,MAHOUT-1349,2013-11-01T07:59:17.000-05:00,Clusterdumper/loadTermDictionary crashes when highest index in (sparse) dictionary vector is larger than dictionary vector size?,"OpenObjectIntHashMap dict = new OpenObjectIntHashMap();
//...
  String [] dictionary = new String[dict.size()];
I'm not sure if I'm doing something wrong here, or if ClusterDumper does not support my (fairly simple) use case
The kmeans ran fine and generate sensible looking results, but when I tried to run ClusterDumper I got the following error:
#bash> bin/mahout clusterdump -dt sequencefile -d completed/5159bba4e4b0718d03c8cf79_/EmailContentAnalytics_dict_5159bba4e4b0718d03c8cf79/part-*
-i test-kmeans/clusters-19 -b 10 -n 10 -sp 10 -o ~/test-kmeans-out
Running on hadoop, using /usr/bin/hadoop and HADOOP_CONF_DIR=
MAHOUT-JOB: /opt/mahout-distribution-0.7/mahout-examples-0.7-job.jar
13/05/17 08:26:41 INFO common.AbstractJob: Command line arguments:
{--dictionary=[completed/5159bba4e4b0718d03c8cf79_/EmailContentAnalytics_dict_5159bba4e4b0718d03c8cf79/part-*],
--dictionaryType=[sequencefile],
--distanceMeasure=[org.apache.mahout.common.distance.SquaredEuclideanDistanceMeasure],
--endPhase=[2147483647], --input=[test-kmeans/clusters-19],
--numWords=[10], --output=[/usr/share/tomcat6/test-kmeans-out],
--outputFormat=[TEXT], --samplePoints=[10], --startPhase=[0],
--substring=[10], --tempDir=[temp]}
Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 698948 at
org.apache.mahout.clustering.AbstractCluster.formatVector(AbstractCluster.java:350)
at
org.apache.mahout.clustering.AbstractCluster.asFormatString(AbstractCluster.java:306)
at
org.apache.mahout.utils.clustering.ClusterDumperWriter.write(ClusterDumperWriter.java:54)
at
org.apache.mahout.utils.clustering.AbstractClusterWriter.write(AbstractClusterWriter.java:169)
at
org.apache.mahout.utils.clustering.AbstractClusterWriter.write(AbstractClusterWriter.java:156)
at
org.apache.mahout.utils.clustering.ClusterDumper.printClusters(ClusterDumper.java:187)
at
org.apache.mahout.utils.clustering.ClusterDumper.run(ClusterDumper.java:153)
(...)
The error is when it tries to access the dictionary for the feature with index 698948
Looking at the dictionary loading code ( http://grepcode.com/file/repo1.maven.org/maven2/org.apache.mahout/mahout-integration/0.7/org/apache/mahout/utils/vectors/VectorHelper.java#VectorHelper.loadTermDictionary%28java.io.File%29
-  checked 0.8 and it hasn't changed)
It looks like the dictionary array is sized for the number of unique keywords, not the highest index:
OpenObjectIntHashMap dict = new OpenObjectIntHashMap();
//...
String [] dictionary = new String[dict.size()];
After I ran my custom dictionary/feature generation code I discovered I only had 517,327 unique features, therefore it is not surprising it would die on an index >= 517327 (though I don't understand why it didn't die when trying to load the dictionary file)
Is there any reason why the VectorHelper code should not create a dictionary array that has size the highest index read from the dictionary sequence file (which can be easily calculated during the preceding loop)?
Or am I misunderstanding something?
It worked fine when I reduced the hash size to be <= than the total number of features, but this is not desirable in general (for me) since I don't know the number of features before I run the job (and if I guess too high then ClusterDumper crashes)
Alex Piggott
IKANOW","org.apache.mahout.utils.vectors.VectorHelper:loadTermDictionary(Configuration, String)
org.apache.mahout.utils.vectors.VectorHelperTest:testJsonFormatting()"
METHOD,mahout-0.8,MAHOUT-1358,2013-11-18T01:58:22.000-06:00,StreamingKMeansThread throws IllegalArgumentException when REDUCE_STREAMING_KMEANS is set to true,"{Code}


 {Code}


  StreamingKMeansThread.call()


 {Code}
     Iterator<Centroid> datapointsIterator = datapoints.iterator();
    if (estimateDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
      List<Centroid> estimatePoints = Lists.newArrayListWithExpectedSize(NUM_ESTIMATE_POINTS);
      while (datapointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) {
        estimatePoints.add(datapointsIterator.next());
      }
      estimateDistanceCutoff = ClusteringUtils.estimateDistanceCutoff(estimatePoints, searcher.getDistanceMeasure());
    }


    StreamingKMeans clusterer = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);
    while (datapointsIterator.hasNext()) {
      clusterer.cluster(datapointsIterator.next());
    }
{Code}
Running StreamingKMeans Clustering with REDUCE_STREAMING_KMEANS = true and when no estimatedDistanceCutoff is specified, throws the following error
{Code}
java.lang.IllegalArgumentException: Must have nonzero number of training and test vectors. Asked for %.1f %% of %d vectors for test [10.000000149011612, 0]
at com.google.common.base.Preconditions.checkArgument(Preconditions.java:120)
at org.apache.mahout.clustering.streaming.cluster.BallKMeans.splitTrainTest(BallKMeans.java:176)
at org.apache.mahout.clustering.streaming.cluster.BallKMeans.cluster(BallKMeans.java:192)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.getBestCentroids(StreamingKMeansReducer.java:107)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:73)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:37)
at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:177)
at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:649)
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:418)
at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:398)
{Code}
The issue is caused by the following code in StreamingKMeansThread.call()
{Code}
    Iterator<Centroid> datapointsIterator = datapoints.iterator();
    if (estimateDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
      List<Centroid> estimatePoints = Lists.newArrayListWithExpectedSize(NUM_ESTIMATE_POINTS);
      while (datapointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) {
        estimatePoints.add(datapointsIterator.next());
      }
      estimateDistanceCutoff = ClusteringUtils.estimateDistanceCutoff(estimatePoints, searcher.getDistanceMeasure());
    }
StreamingKMeans clusterer = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);
    while (datapointsIterator.hasNext()) {
      clusterer.cluster(datapointsIterator.next());
    }
{Code}
The code is using the same iterator twice, and it fails on the second use for obvious reasons.","org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansThread:StreamingKMeansThread(Path, Configuration)
org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansThread:StreamingKMeansThread(Iterable<Centroid>, Configuration)"
CLASS,bookkeeper-4.1.0,BOOKKEEPER-294,2012-06-12T23:56:56.000-05:00,Not able to start the bookkeeper before the ZK session timeout.,"{noformat}
         
 {noformat}
Not able to start the bookkeeper before the ZK session timeout.
Here i killed the bookie and started again.
{noformat}
2012-06-12 20:00:25,220 - INFO  [main:LedgerCache@65] - openFileLimit is 900, pageSize is 8192, pageLimit is 456781
2012-06-12 20:00:25,238 - ERROR [main:Bookie@453] - ZK exception registering ephemeral Znode for Bookie!
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /ledgers/available/10.18.40.216:3181
at org.apache.zookeeper.KeeperException.create(KeeperException.java:119)
at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:778)
at org.apache.bookkeeper.bookie.Bookie.registerBookie(Bookie.java:450)
at org.apache.bookkeeper.bookie.Bookie.<init>(Bookie.java:348)
at org.apache.bookkeeper.proto.BookieServer.<init>(BookieServer.java:64)
at org.apache.bookkeeper.proto.BookieServer.main(BookieServer.java:249)
{noformat}","bookkeeper-server.src.test.java.org.apache.bookkeeper.bookie.BookieJournalTest
bookkeeper-server.src.main.java.org.apache.bookkeeper.bookie.Bookie
bookkeeper-server.src.main.java.org.apache.bookkeeper.proto.BookieServer"
CLASS,bookkeeper-4.1.0,BOOKKEEPER-318,2012-06-26T01:55:45.000-05:00,Spelling mistake in MultiCallback log message.,"{code}
 @Override
        public void processResult(int rc, String path, Object ctx) {
            if (rc != successRc) {
                LOG.error(""Error in multi callback : "" + rc);
                exceptions.add(rc);
            }
            tick();
        }
 {code}
{code}
@Override
        public void processResult(int rc, String path, Object ctx) {
            if (rc !
= successRc) {
                LOG.error(""Error in multi callback : "" + rc);
                exceptions.add(rc);
            }
            tick();
        }
{code}",bookkeeper-server.src.main.java.org.apache.bookkeeper.proto.BookkeeperInternalCallbacks
CLASS,bookkeeper-4.1.0,BOOKKEEPER-371,2012-08-17T05:42:02.000-05:00,NPE in hedwig hub client causes hedwig hub to shut down.,"Channel topicSubscriberChannel = client.getSubscriber().getChannelForTopic(topicSubscriber);
        HedwigClientImpl.getResponseHandlerFromChannel(topicSubscriberChannel).getSubscribeResponseHandler()
        .messageConsumed(messageConsumeData.msg);

  getPipeline()  getLast()   channel.close()   messageConsumed()
The hedwig client was connected to a remote region hub that restarted resulting in the channel getting disconnected.
2012-08-15 17:47:42,443 - ERROR - [pool-20-thread-1:TerminateJVMExceptionHandler@28] - Uncaught exception in thread pool-20-thread-1 java.lang.NullPointerException
at org.apache.hedwig.client.netty.HedwigClientImpl.getResponseHandlerFromChannel(HedwigClientImpl.java:323)
at org.apache.hedwig.client.handlers.MessageConsumeCallback.operationFinished(MessageConsumeCallback.java:75)
at org.apache.hedwig.client.handlers.MessageConsumeCallback.operationFinished(MessageConsumeCallback.java:41)
at org.apache.hedwig.server.regions.RegionManager$1$1$1.operationFinished(RegionManager.java:208)
at org.apache.hedwig.server.regions.RegionManager$1$1$1.operationFinished(RegionManager.java:202)
at org.apache.hedwig.server.persistence.ReadAheadCache$PersistCallback.operationFinished(ReadAheadCache.java:194)
at org.apache.hedwig.server.persistence.ReadAheadCache$PersistCallback.operationFinished(ReadAheadCache.java:171)
at org.apache.hedwig.server.persistence.BookkeeperPersistenceManager$PersistOp$1.safeAddComplete(BookkeeperPersistenceManager.java:548)
at org.apache.hedwig.zookeeper.SafeAsynBKCallback$AddCallback.addComplete(SafeAsynBKCallback.java:93)
at org.apache.bookkeeper.client.PendingAddOp.submitCallback(PendingAddOp.java:165)
at org.apache.bookkeeper.client.LedgerHandle.sendAddSuccessCallbacks(LedgerHandle.java:643)
at org.apache.bookkeeper.client.PendingAddOp.writeComplete(PendingAddOp.java:159)
at org.apache.bookkeeper.proto.PerChannelBookieClient.handleAddResponse(PerChannelBookieClient.java:577)
at org.apache.bookkeeper.proto.PerChannelBookieClient$7.safeRun(PerChannelBookieClient.java:525)
at org.apache.bookkeeper.util.SafeRunnable.run(SafeRunnable.java:31)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
at java.util.concurrent.FutureTask.run(FutureTask.java:166)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
at java.lang.Thread.run(Thread.java:722)
At 2012-08-15 17:47:42,443, the channel was disconnected as well.
I believe the following code in the MessageConsumeCallback is causing this problem.
Channel topicSubscriberChannel = client.getSubscriber().
getChannelForTopic(topicSubscriber);
HedwigClientImpl.getResponseHandlerFromChannel(topicSubscriberChannel).
getSubscribeResponseHandler()
.
messageConsumed(messageConsumeData.msg);
The channel was retrieved without checking if it was closed and then getPipeline().
getLast() was called which returned a null value resulting in a NPE.
I guess the same applies for other instances where we use this.
Does the above explanation seem right?","hedwig-client.src.main.java.org.apache.hedwig.client.netty.WriteCallback
hedwig-client.src.main.java.org.apache.hedwig.client.handlers.SubscribeResponseHandler
hedwig-client.src.main.java.org.apache.hedwig.client.netty.HedwigPublisher
hedwig-client.src.main.java.org.apache.hedwig.client.netty.HedwigSubscriber
hedwig-client.src.main.java.org.apache.hedwig.client.handlers.MessageConsumeCallback
hedwig-client.src.main.java.org.apache.hedwig.client.netty.HedwigClientImpl"
CLASS,bookkeeper-4.1.0,BOOKKEEPER-376,2012-08-22T13:32:57.000-05:00,LedgerManagers should consider 'underreplication' node as a special Znode,"{noformat}
     
 {noformat}
Saw this while running the RW tests:
{noformat}
2012-08-22 23:59:35,649 - WARN  - [GarbageCollectorThread:HierarchicalLedgerManager@354] - Exception during garbage collecting ledgers for underreplication of /ledgers
java.io.IOException: java.lang.NumberFormatException: For input string: ""underreplicationlocks0000""
at org.apache.bookkeeper.meta.HierarchicalLedgerManager.getLedgerId(HierarchicalLedgerManager.java:236)
at org.apache.bookkeeper.meta.HierarchicalLedgerManager.getStartLedgerIdByLevel(HierarchicalLedgerManager.java:254)
at org.apache.bookkeeper.meta.HierarchicalLedgerManager.doGcByLevel(HierarchicalLedgerManager.java:388)
at org.apache.bookkeeper.meta.HierarchicalLedgerManager.garbageCollectLedgers(HierarchicalLedgerManager.java:351)
at org.apache.bookkeeper.bookie.GarbageCollectorThread.doGcLedgers(GarbageCollectorThread.java:226)
at org.apache.bookkeeper.bookie.GarbageCollectorThread.run(GarbageCollectorThread.java:195)
Caused by: java.lang.NumberFormatException: For input string: ""underreplicationlocks0000""
at java.lang.NumberFormatException.forInputString(Unknown Source)
at java.lang.Long.parseLong(Unknown Source)
at java.lang.Long.parseLong(Unknown Source)
at org.apache.bookkeeper.meta.HierarchicalLedgerManager.getLedgerId(HierarchicalLedgerManager.java:234)
... 5 more
{noformat}","bookkeeper-server.src.main.java.org.apache.bookkeeper.meta.LedgerLayout
bookkeeper-server.src.main.java.org.apache.bookkeeper.meta.AbstractZkLedgerManager"
FILE,swt-3.1,102794,2005-07-05T17:56:00.000-05:00,GridLayout has change behaviour between 3.0.2 and 3.1,"public static void main(String[] args) {
        Display display = new Display();

        Shell shell = new Shell(display);

        shell.setLayout(new FillLayout());

        ScrolledComposite sc1 = new ScrolledComposite(shell, SWT.H_SCROLL
                | SWT.V_SCROLL);
        Composite editor = new Composite(sc1, SWT.SHADOW_NONE);
        sc1.setContent(editor);
        sc1.setLayout(new FillLayout());

        GridLayout layout = new GridLayout();

        layout.numColumns = 6;
        layout.makeColumnsEqualWidth = true;
        editor.setLayout(layout);

        Label boxLabel = new Label(editor, SWT.NONE);
        boxLabel.setText(""My label"");

        Text textBox = new Text(editor, SWT.H_SCROLL | SWT.V_SCROLL | SWT.MULTI
                | SWT.BORDER);
        textBox.setText(""Some text for the text box\nAlso with a new line"");

        // do layout bits
        GridData labelData = new GridData(SWT.RIGHT, SWT.TOP, false, false);
        boxLabel.setLayoutData(labelData);

        GridData textBoxData = new GridData(SWT.FILL, SWT.CENTER, true, false,
                5, 1);
        textBoxData.widthHint = 400;
        textBox.setLayoutData(textBoxData);

        sc1.setExpandHorizontal(true);
        sc1.setExpandVertical(true);
        sc1.setMinSize(editor.computeSize(SWT.DEFAULT, SWT.DEFAULT));

        shell.pack();
        shell.open();

        while (!shell.isDisposed()) {
            if (!display.readAndDispatch())
                display.sleep();
        }
        display.dispose();
    }
Running the following problem on 3.0.2 and 3.1 shows a difference in behaviour:
public static void main(String[] args) {
Display display = new Display();
Shell shell = new Shell(display);
shell.setLayout(new FillLayout());
ScrolledComposite sc1 = new ScrolledComposite(shell, SWT.H_SCROLL
| SWT.V_SCROLL);
Composite editor = new Composite(sc1, SWT.SHADOW_NONE);
sc1.setContent(editor);
sc1.setLayout(new FillLayout());
GridLayout layout = new GridLayout();
layout.numColumns = 6;
layout.makeColumnsEqualWidth = true;
editor.setLayout(layout);
Label boxLabel = new Label(editor, SWT.NONE);
boxLabel.setText(""My label"");
Text textBox = new Text(editor, SWT.H_SCROLL | SWT.V_SCROLL | SWT.MULTI
| SWT.BORDER);
textBox.setText(""Some text for the text box\nAlso with a new line"");
// do layout bits
GridData labelData = new GridData(SWT.RIGHT, SWT.TOP, false, false);
boxLabel.setLayoutData(labelData);
GridData textBoxData = new GridData(SWT.FILL, SWT.CENTER, true, false,
5, 1);
textBoxData.widthHint = 400;
textBox.setLayoutData(textBoxData);
sc1.setExpandHorizontal(true);
sc1.setExpandVertical(true);
sc1.setMinSize(editor.computeSize(SWT.DEFAULT, SWT.DEFAULT));
shell.pack();
shell.open();
while (! shell.isDisposed()) { if (! display.readAndDispatch())
display.sleep();
} display.dispose();
}
Basically on 3.0.2 the window that appears has a label of about 80 pixels wide and a textbox of 400 pixels wide.
With 3.1 the label is about 400 pixels wide, with the text box being about 2000 pixels wide.
This appears to be a combination of the text box spanning 5 columns and the use of layout.makeColumnsEqualWidth = true;
Turning off makeColumnsEqualWidth helps but it means that the real app this if from ends up looking untidy.
Using minimumWidth instead of widthHint doesn't help.
Commenting out the minimumWidth line helps, but the form ends up being wider than I'd like.",org.eclipse.swt.layout.GridLayout
FILE,swt-3.1,104150,2005-07-16T19:58:00.000-05:00,[Patch] Table cursor separated from table selection when clicking on grid lines or empty space,"table.getLinesVisible()  
 table.setLinesVisible(true)
SWT-win32, v3138 (3.1-final)
When using a table cursor, there are two kinds of table regions that have the potential to separate the table cursor from the table selection when clicked on:
1) grid lines (table.getLinesVisible() == true)
2) empty space to the left of the first cell of each row (SWT.FULL_SELECTION)
Expected behaviour:",org.eclipse.swt.custom.TableCursor
FILE,swt-3.1,104545,2005-07-20T14:21:00.000-05:00,Make default size of empty composites smaller,"static final int DEFAULT_WIDTH	= 64;
 static final int DEFAULT_HEIGHT	= 64;
/* Default widths for widgets */ static final int DEFAULT_WIDTH	= 64;
static final int DEFAULT_HEIGHT	= 64;
I have run our tests (JFace, UI, RCP) and they run fine when the constants are 0.
Background: When you write an RCP app and enable the cool bar, the cool bar will initially be empty, but 64x64 pixels in size.
On Windows, you cannot see the border of the empty coolbar so the user gets a big empty space at the top of their window and might be confused.
See also Bug 70049, where the same problem occurs in an RCP application that starts off with no open perspective and thus no cool bar items.",org.eclipse.swt.widgets.CoolBar
FILE,swt-3.1,117574,2005-11-22T15:22:00.000-06:00,RIGHT_TO_LEFT |  DOUBLE_BUFFERED don't get along,"public static void main(String[] args) {
	Display display = new Display();
	Shell shell = new Shell(display, SWT.SHELL_TRIM | SWT.RIGHT_TO_LEFT | SWT.DOUBLE_BUFFERED);
	shell.addListener(SWT.Paint, new Listener() {
		public void handleEvent(Event event) {
			System.out.println(event.gc.getClipping());
			event.gc.drawString(""This is broken "" + event.gc.getClipping(), 10, 10);
		}
	});
	shell.open();
	while (!shell.isDisposed()) {
		if (!display.readAndDispatch()) display.sleep();
	}
	display.dispose ();
}
build  I20051122-0800
When SWT.RIGHT_TO_LEFT | SWT.DOUBLE_BUFFERED are used the gc clipping is Rect(0,0,0,0) during paint.
public static void main(String[] args) {
	Display display = new Display();
	Shell shell = new Shell(display, SWT.SHELL_TRIM | SWT.RIGHT_TO_LEFT | SWT.DOUBLE_BUFFERED);
	shell.addListener(SWT.Paint, new Listener() {
		public void handleEvent(Event event) {
			System.out.println(event.gc.getClipping());
			event.gc.drawString(""This is broken "" + event.gc.getClipping(), 10, 10);
		}
	});
	shell.open();
	while (!
shell.isDisposed()) {
		if (!
display.readAndDispatch()) display.sleep();
	}
	display.dispose ();
}
Doesn't draw anything.
Note: my machine is a win xp bidi enabled.","org.eclipse.swt.widgets.Composite
org.eclipse.swt.graphics.GC"
FILE,swt-3.1,78634,2004-11-15T12:29:00.000-06:00,ImageData.getTransparencyMask - incorrect javadoc or implementation wrong,"public ImageData getTransparencyMask()
The implementation of getTransparencyMask appears to return a fully opaque mask when the image has no transparency.
/**
* Returns an <code>ImageData</code> which specifies the
* transparency mask information for the receiver, or null if the
* receiver has no transparency and is not an icon.
*
* @return the transparency mask or null if none exists
*/ public ImageData getTransparencyMask()
(see implementation of ImageData.colorMask)
On a different note, should we return a transparent mask based on the the alphaData values with the 127 threshold?",org.eclipse.swt.graphics.ImageData
FILE,swt-3.1,81264,2004-12-15T13:17:00.000-06:00,Table fails to setTopIndex after new items are added to the table,"public static void main(String[] args) {
		final Display display = new Display();
		Shell shell = new Shell(display);
		shell.setBounds(10,10,200,200);
		final Table table = new Table(shell, SWT.NONE);
		table.setBounds(10,10,100,100);
		for (int i = 0; i < 99; i++) {
			new TableItem(table, SWT.NONE).setText(""item "" + i);
		}
		
		table.setTopIndex(20);

		shell.open();

		System.out.println(""top visible index: "" + table.getTopIndex());
		
		for (int i = 0; i < 5; i++) {
			new TableItem(table, SWT.NONE).setText(""item "" + i);
		}

		table.setTopIndex(40);
		System.out.println(""top visible index: "" + table.getTopIndex());
		
		while (!shell.isDisposed()) {
			if (!display.readAndDispatch()) display.sleep();
		}
		display.dispose();
	}

  
  
 setTopTable(40)  
  
 setTopIndex(40)
I am working on a table viewer that keeps track of the scroll bar and loads content into the table dynamically as the user scrolls to the end of the table.
Items could be added/removed from the table as the user scrolls.
To maintain the position of the table, I call setTopIndex at the end of the update.
I have created a small testcase to simulate the process.
public static void main(String[] args) { final Display display = new Display();
Shell shell = new Shell(display);
shell.setBounds(10,10,200,200);
final Table table = new Table(shell, SWT.NONE);
table.setBounds(10,10,100,100);
for (int i = 0; i < 99; i++) { new TableItem(table, SWT.NONE).
setText(""item "" + i);
} table.setTopIndex(20);
shell.open();
System.out.println(""top visible index: "" + table.getTopIndex());
for (int i = 0; i < 5; i++) { new TableItem(table, SWT.NONE).
setText(""item "" + i);
}
table.setTopIndex(40);
System.out.println(""top visible index: "" + table.getTopIndex());
while (! shell.isDisposed()) { if (! display.readAndDispatch()) display.sleep();
} display.dispose();
}
Table.setTopIndex fails to position to the correct table item if new items are added to the table after the shell is opened.
The first call to setTopIndex succeeds.
The table is correctly positioned at item 20.
After adding new table items to the table, calling setTopTable(40) has no effect.
Calling getTopIndex continues to return 20.
Expected Result:
If the last 5 items are added before the shell is opened, setTopIndex to 40 will also succeed.
The testcase works as expected on Windows.","org.eclipse.swt.widgets.Tree
org.eclipse.swt.widgets.List
org.eclipse.swt.widgets.Table"
FILE,swt-3.1,83699,2005-01-26T06:03:00.000-06:00,Font reset to default after screen saver,"StyledText.setFont(Font)  
   updateFont(Font, Font)  
   updateFont(Font, Font)  
 updateFont(Font, Font)  
 Composite.updateFont(Font, Font)  
 Composite.updateFont(Font, Font)  
 Composite.updateFont(Font, Font)  
 Composite.updateFont(Font, Font)  
 Composite.updateFont(Font, Font)  
 Composite.updateFont(Font, Font)  
 Composite.updateFont(Font, Font)  
 updateFont(Font, Font)  
 Display.updateFont()  
  
  
 Display.readAndDispatch()  
 Workbench.runEventLoop(Window$IExceptionHandler, Display)  
 Workbench.runUI()  
 Workbench.createAndRunWorkbench(Display, WorkbenchAdvisor)  
 PlatformUI.createAndRunWorkbench(Display, WorkbenchAdvisor)  
 IDEApplication.run(Object)  
 EclipseStarter.run(Object)
I20050125-0800
All editors and views using a StyledText widget have the font reset to default
after coming back from my screen saver.
Makes build I20050125-0800 unusable for
me.
Works if I replace org.eclipse.swt.win32_3.1.0 with the one from last I-build.
This breakpoint gets hit when I return from the screen saver
Thread [main] (Suspended (breakpoint at line 6820 in StyledText))
StyledText.setFont(Font) line: 6820
StyledText(Control).
updateFont(Font, Font) line: 2913
StyledText(Composite).
updateFont(Font, Font) line: 810
Canvas(Composite).
updateFont(Font, Font) line: 807
Composite.updateFont(Font, Font) line: 807
Composite.updateFont(Font, Font) line: 807
Composite.updateFont(Font, Font) line: 807
Composite.updateFont(Font, Font) line: 807
Composite.updateFont(Font, Font) line: 807
Composite.updateFont(Font, Font) line: 807
Composite.updateFont(Font, Font) line: 807
Shell(Composite).
updateFont(Font, Font) line: 807
Display.updateFont() line: 3379
Display.messageProc(int, int, int, int) line: 2276
OS.PeekMessageW(MSG, int, int, int, int) line: not available [native method]
OS.PeekMessage(MSG, int, int, int, int) line: 2016
Display.readAndDispatch() line: 2510
Workbench.runEventLoop(Window$IExceptionHandler, Display) line: 1584
Workbench.runUI() line: 1550
Workbench.createAndRunWorkbench(Display, WorkbenchAdvisor) line: 288
PlatformUI.createAndRunWorkbench(Display, WorkbenchAdvisor) line: 144
IDEApplication.run(Object) line: 102
1 run(Object) line: 225
EclipseStarter.run(Object) line: 274
EclipseStarter.run(String[], Runnable) line: 129
NativeMethodAccessorImpl.invoke0(Method, Object, Object[]) line: not available
[native method]
NativeMethodAccessorImpl.invoke(Object, Object[]) line: 39
DelegatingMethodAccessorImpl.invoke(Object, Object[]) line: 25
Method.invoke(Object, Object[]) line: 324
Main.basicRun(String[]) line: 255
Main.run(String[]) line: 811
Main.main(String[]) line: 795",org.eclipse.swt.widgets.Control
FILE,swt-3.1,84609,2005-02-07T13:35:00.000-06:00,TableColumn has NPE while calling pack()  on last column,"lvtTable.getColumn(0).pack();
lvtTable.getColumn(1).pack();
lvtTable.getColumn(2).pack();

   
 parent.getColumns()
// refresh table on new data lvtTable.getColumn(0).
pack();
lvtTable.getColumn(1).
pack();
lvtTable.getColumn(2).
pack();
On third call I get caught NPE (in debugger) in TableColumn (line 356), because parent.getColumns() (in TableColumn:354) returns array with 4 elements (always one more as existing in the table), and the last element is always null.
My system is WinXP, Eclipse Version: 3.1.0, Build id: I20050202-0800, JDK 1.5.0.
1","org.eclipse.swt.widgets.TableColumn
org.eclipse.swt.widgets.Table"
FILE,swt-3.1,86000,2005-02-21T14:47:00.000-06:00,ImageLoader Save - produces invalid JPEG images,"package com.ibm.test.image;

import org.eclipse.swt.*;
import org.eclipse.swt.graphics.*;

public class ImageLoaderTest {
		
	public static void main(String[] args) {
		ImageLoader loader;
		String dir=""c:\\image-problems\\"";
		String files[]={
				""s34i3p04"",
				""s34n3p04"",
				""s35i3p04"",
				""s35n3p04"",
				""s36i3p04"",
				""s36n3p04"",
				""s37i3p04"",
				""s37n3p04"",
				""s38i3p04"",
				""s38n3p04"",
				""s39i3p04"",
				""s39n3p04""
		};
		
		try {
			for (int i=0; i<files.length; i++) {
			String filein  = dir+files[i]+"".png"";
			String fileout = dir+files[i]+"".jpg"";
			
			loader = new ImageLoader();
			loader.load(filein);
			loader.save(fileout,SWT.IMAGE_JPEG);
			}
		} catch (SWTException e) {
		  e.printStackTrace();
		}
	}
}
The ImageLoader Save function appears to be producing bad JPG images.
I have only verified this with JPEG output.
Many files were tested and the majority 
 did produced the proper JPG images as expected.
The attached Zip file contains
 only those files that did not save correctly to JPEG.
package com.ibm.test.image;
import org.eclipse.swt.
*;
import org.eclipse.swt.graphics.
*;
public class ImageLoaderTest {
		
	public static void main(String[] args) {
		ImageLoader loader;
		String dir=""c:\\image-problems\\"";
		String files[]={
				""s34i3p04"",
				""s34n3p04"",
				""s35i3p04"",
				""s35n3p04"",
				""s36i3p04"",
				""s36n3p04"",
				""s37i3p04"",
				""s37n3p04"",
				""s38i3p04"",
				""s38n3p04"",
				""s39i3p04"",
				""s39n3p04""
		};
		
		try {
			for (int i=0; i<files.length; i++) {
			String filein  = dir+files[i]+"".
png"";
			String fileout = dir+files[i]+"".
jpg"";
			
			loader = new ImageLoader();
			loader.load(filein);
			loader.save(fileout,SWT.IMAGE_JPEG);
			}
		} catch (SWTException e) {
		  e.printStackTrace();
		}
	}
}",org.eclipse.swt.internal.image.JPEGFileFormat
FILE,swt-3.1,87460,2005-03-08T21:22:00.000-06:00,StyledText: Caret location not updated when line style is used,"import org.eclipse.swt.*;
import org.eclipse.swt.custom.*;
import org.eclipse.swt.graphics.*;
import org.eclipse.swt.layout.*;
import org.eclipse.swt.widgets.*;

public class LineStyleCaretTest {
  public static void main(String[] args) {
    Display display = new Display();
    
    Shell shell = new Shell(display);
    shell.setLayout(new FillLayout());
    
    Font font = new Font(display, ""Arial"", 12, SWT.NORMAL);
      
    final StyledText text = new StyledText(shell, SWT.MULTI);
    text.setFont(font);
    text.setText(""Standard Widget Toolkit"");
    text.setCaretOffset(text.getText().length());
    
    text.addLineStyleListener(new LineStyleListener() {
      public void lineGetStyle(LineStyleEvent event) {
        StyleRange[] styles = new StyleRange[1];
        
        styles[0] = new StyleRange();
        styles[0].start  = 0;
        styles[0].length = text.getText().length();
        styles[0].fontStyle = SWT.BOLD;
        
        event.styles = styles;
      }
    });
    
    shell.setSize(300, 100);
    shell.open();
    
    while (!shell.isDisposed()) {
      if (!display.readAndDispatch()) {
        display.sleep();
      }
    }
    
    font.dispose();
    display.dispose();
  }
}
SWT-win32, v3124
In the line style listener, a bold font style is set, changing the width of the rendered text.
However, this does not happen.
For an italic style, it does not look right either.
Might be a bug?
---
import org.eclipse.swt.
*;
import org.eclipse.swt.custom.
*;
import org.eclipse.swt.graphics.
*;
import org.eclipse.swt.layout.
*;
import org.eclipse.swt.widgets.
*;
public class LineStyleCaretTest { public static void main(String[] args) {
Display display = new Display();
Shell shell = new Shell(display);
shell.setLayout(new FillLayout());
Font font = new Font(display, ""Arial"", 12, SWT.NORMAL);
final StyledText text = new StyledText(shell, SWT.MULTI);
text.setFont(font);
text.setText(""Standard Widget Toolkit"");
text.setCaretOffset(text.getText().
length());
text.addLineStyleListener(new LineStyleListener() { public void lineGetStyle(LineStyleEvent event) {
StyleRange[] styles = new StyleRange[1];
styles[0] = new StyleRange();
styles[0].
start  = 0;
styles[0].
length = text.getText().
length();
styles[0].
fontStyle = SWT.BOLD;
event.styles = styles;
}
});
shell.setSize(300, 100);
shell.open();
while (! shell.isDisposed()) { if (! display.readAndDispatch()) { display.sleep();
}
} font.dispose();
display.dispose();
}
}",org.eclipse.swt.custom.StyledText
FILE,swt-3.1,87997,2005-03-14T19:21:00.000-06:00,TableEditor.dispose( ) causes NPE if linked Table is being disposed,"TableEdtior.dispose( )  
  
   

import org.eclipse.swt.custom.TableEditor;
import org.eclipse.swt.events.*;
import org.eclipse.swt.widgets.*;

public class Test
{
    public static void main( String[ ] args )
    {
        Shell shell = new Shell( );
        Table table = new Table( shell, 0 );
        new TableColumn( table, 0 );
        TableItem item = new TableItem( table, 0 );
        final TableEditor editor = new TableEditor( table );
        final Text text = new Text( table, 0 );
        editor.setEditor( text, item, 0 );
        item.addDisposeListener( new DisposeListener( ) {
            public void widgetDisposed( DisposeEvent e )
            {
                text.dispose( );
                editor.dispose( ); // Triggers a NPE
            }
        } );
        shell.dispose( );
    }
}
Found in 3.1 I20050308-0835.
TableEdtior.dispose( ) calls methods on it's owning Table to remove some
listeners from the table's columns.
If the table is in the process of being
disposed, the columns will have already been disposed and this will result in a
NPE.
Further if the dispose listener is set on the parent of the Table, a
""Widget is disposed"" exception will be thrown instead of the NPE.
This leaves
no place to hook to trigger the disposal of the TableEditor.
import org.eclipse.swt.custom.TableEditor;
import org.eclipse.swt.events.
*;
import org.eclipse.swt.widgets.
*;
public class Test
{
    public static void main( String[ ] args )
    {
        Shell shell = new Shell( );
        Table table = new Table( shell, 0 );
        new TableColumn( table, 0 );
        TableItem item = new TableItem( table, 0 );
        final TableEditor editor = new TableEditor( table );
        final Text text = new Text( table, 0 );
        editor.setEditor( text, item, 0 );
        item.addDisposeListener( new DisposeListener( ) {
            public void widgetDisposed( DisposeEvent e )
            {
                text.dispose( );
                editor.dispose( ); // Triggers a NPE
            }
        } );
        shell.dispose( );
    }
}","org.eclipse.swt.widgets.Tree
org.eclipse.swt.widgets.Table"
FILE,swt-3.1,90258,2005-04-05T04:56:00.000-05:00,Table item not updated when item count == 1,"clearAll() 
 table.setItemCount(1);
table.clearAll();

 
 private void handleSetData(Event event) {

	TableItem item= (TableItem) event.item;
	int index= fProposalTable.indexOf(item);
	
	ICompletionProposal current= fFilteredProposals[index];
	
	item.setText(current.getDisplayString());
	item.setImage(current.getImage());
	item.setData(current);
}
I20050401 (M6)
I am using a Table with SWT.VIRTUAL.
Everything works fine, except for the case
I set the item count to 1, in which case I do not receive an SWT.SetData notification.
Tried to reproduce using a modified version of Snippet151, but everything works as expected there.
Do you have any idea what could be going wrong?
One funny thing is that in the variable view, the debugger displays the updated contents of table.items[0] after calling clearAll(), but I have verified that the data is never ever set.
The display fails to update.
----------------
Table table...
table.setItemCount(1);
table.clearAll();
...
private void handleSetData(Event event) {
TableItem item= (TableItem) event.item;
int index= fProposalTable.indexOf(item);
ICompletionProposal current= fFilteredProposals[index];
item.setText(current.getDisplayString());
item.setImage(current.getImage());
item.setData(current);
}
-----------------",org.eclipse.swt.widgets.Table
FILE,swt-3.1,93724,2005-05-04T17:35:00.000-05:00,Drag-and-drop creates signal names every time,"byte[] buffer = Converter.wcsToMbcs(null, ""drag_data_get"", true);
OS.g_signal_connect(control.handle, buffer, DragGetData.getAddress(), 0);	
buffer = Converter.wcsToMbcs(null, ""drag_end"", true);
OS.g_signal_connect(control.handle, buffer, DragEnd.getAddress(), 0);
buffer = Converter.wcsToMbcs(null, ""drag_data_delete"", true);
OS.g_signal_connect(control.handle, buffer, DragDataDelete.getAddress(), 0);
byte[] buffer = Converter.wcsToMbcs(null, ""drag_data_get"", true);
OS.g_signal_connect(control.handle, buffer, DragGetData.getAddress(), 0);
buffer = Converter.wcsToMbcs(null, ""drag_end"", true);
OS.g_signal_connect(control.handle, buffer, DragEnd.getAddress(), 0);
buffer = Converter.wcsToMbcs(null, ""drag_data_delete"", true);
OS.g_signal_connect(control.handle, buffer, DragDataDelete.getAddress(), 0);
Rather than converting the names for the signals every time, these signal names should be defined in OS.java so that they can be only created once.","org.eclipse.swt.dnd.DropTarget
org.eclipse.swt.dnd.DragSource"
FILE,swt-3.1,97651,2005-05-31T14:43:00.000-05:00,tree insert mark cheese,"Tree.redraw() 
 public static void main(String[] args) {
	final Display display = new Display();
	final Shell shell = new Shell(display);
	shell.setBounds(10, 10, 300, 300);
	final Tree tree = new Tree(shell, SWT.NONE);
	tree.setBounds(10, 10, 200, 200);
	new TreeItem(tree, SWT.NONE).setText(""pre-root"");
	TreeItem root1 = new TreeItem(tree, SWT.NONE);
	root1.setText(""root"");
	TreeItem child = new TreeItem(root1, SWT.NONE);
	child.setText(""child"");
	Button button = new Button(shell, SWT.PUSH);
	button.setBounds(230,10,30,30);
	button.addSelectionListener(new SelectionAdapter() {
		public void widgetSelected(SelectionEvent e) {
			tree.redraw();
		}
	});
	root1.setExpanded(true);
	tree.setInsertMark(root1, false);
	shell.open();
	while (!shell.isDisposed()) {
		if (!display.readAndDispatch()) display.sleep();
	}
	display.dispose();
}
3.1RC1
-> problem 1: this makes most of the insert line go away, except for its pointy ends.
- press the button to the right of the Table: this does a Tree.redraw(), and note that the insert line reappears, so I guess it never really meant to go away
-> problem 2: now expand the root item again and its insert mark gets copied to below the child item in addition to its initial location.
This is cheese, as can be seen by damaging part of this line with another window
public static void main(String[] args) { final Display display = new Display();
final Shell shell = new Shell(display);
shell.setBounds(10, 10, 300, 300);
final Tree tree = new Tree(shell, SWT.NONE);
tree.setBounds(10, 10, 200, 200);
new TreeItem(tree, SWT.NONE).
setText(""pre-root"");
TreeItem root1 = new TreeItem(tree, SWT.NONE);
root1.setText(""root"");
TreeItem child = new TreeItem(root1, SWT.NONE);
child.setText(""child"");
Button button = new Button(shell, SWT.PUSH);
button.setBounds(230,10,30,30);
button.addSelectionListener(new SelectionAdapter() { public void widgetSelected(SelectionEvent e) { tree.redraw();
}
});
root1.setExpanded(true);
tree.setInsertMark(root1, false);
shell.open();
while (! shell.isDisposed()) { if (! display.readAndDispatch()) display.sleep();
} display.dispose();
}","org.eclipse.swt.dnd.TreeDragUnderEffect
org.eclipse.swt.widgets.Tree"
FILE,CONFIGURATION,CONFIGURATION-214,2006-05-26T21:35:46.000-05:00,Adding an integer and getting it as a long causes an exception,"bsh % p = new org.apache.commons.configuration.PropertiesConfiguration();
bsh % p.setProperty(""foo"", 6);
bsh % p.getLong(""foo"");
// Error: // Uncaught Exception: Method Invocation p.getLong : at Line: 3 : in file: <unknown file> : p .getLong ( ""foo"" )
   
  PropertyConverter.toLong()
bsh % p = new org.apache.commons.configuration.PropertiesConfiguration();
bsh % p.setProperty(""foo"", 6);
bsh % p.getLong(""foo"");
// Error: // Uncaught Exception: Method Invocation p.getLong : at Line: 3 : in file: <unknown file> : p .
getLong ( ""foo"" )
Target exception: org.apache.commons.configuration.ConversionException: 'foo' doesn't map to a Long object org.apache.commons.configuration.ConversionException: 'foo' doesn't map to a Long object
at org.apache.commons.configuration.AbstractConfiguration.getLong(AbstractConfiguration.java:667)
The problem is that when an object in a property is not a Long, the only attempt of PropertyConverter.toLong() is that of treating it as a string.
It is a very confusing behaviour, because if you save and reload the properties everything works fine (as now the integer is a string).","org.apache.commons.configuration.TestPropertyConverter
org.apache.commons.configuration.PropertyConverter
org.apache.commons.configuration.TestBaseConfiguration"
FILE,CONFIGURATION,CONFIGURATION-241,2006-12-02T00:03:48.000-06:00,clearProperty() does not generate events,"clearProperty() 
 ConfigurationFactory configurationFactory = new ConfigurationFactory();
   
 configurationFactory.setConfigurationURL(configFileURL);
Configuration configuration = ConfigurationFactory.getConfiguration();
configuration.addConfigurationListener(new ConfigurationListener() {
    public void configurationChanged(ConfigurationEvent e) 
{
        System.out.println(e.getPropertyName() + "": "" + e.getPropertyValue());
    }
});
System.out.println(configuration.getProperty(""name.first"")); // prints ""Mike""
 configuration.claerProperty(""name.first"")  ; // no output whatsoever
System.out.println(configuration.getProperty(""name.first"")); // prints ""null""
Unfortunately the listener does not receive ""clear property"" events.
I've confirmed that it can properly receive other events (like ""set property""), and that calls to ""clearProperty()"" do actually clear the property, so I believe this may be a bug in commons-configuration.
I've tried setting ""details"" to true, which had no effect.
ConfigurationFactory configurationFactory = new ConfigurationFactory();
URL configFileURL = ... get the config file ...
configurationFactory.setConfigurationURL(configFileURL);
Configuration configuration = ConfigurationFactory.getConfiguration();
configuration.addConfigurationListener(new ConfigurationListener() { public void configurationChanged(ConfigurationEvent e)
{
System.out.println(e.getPropertyName() + "": "" + e.getPropertyValue());
}
});
System.out.println(configuration.getProperty(""name.first"")); // prints ""Mike"" configuration.claerProperty(""name.first"")); // no output whatsoever
System.out.println(configuration.getProperty(""name.first"")); // prints ""null""","org.apache.commons.configuration.TestCompositeConfiguration
org.apache.commons.configuration.CompositeConfiguration"
FILE,CONFIGURATION,CONFIGURATION-259,2007-03-28T08:47:56.000-05:00,ConfigurationFactory Merge is broken,"URL configURL = getClass().getResource(configFile);
ConfigurationFactory factory = new ConfigurationFactory();
factory.setConfigurationURL(configURL);
myConfig = factory.getConfiguration();
 
 
 DefaultConfigurationBuilder builder = new DefaultConfigurationBuilder();
            builder.setURL(configURL);
            myConfig = builder.getConfiguration();
It turns out that subsequent operations on the merged data provide wrong results.
In particular, after creating a particular subset from a loaded configuration, the subset is empty.
Strangely enough, when using DefaultConfigurationBuilder to load exactly the same configurations this works properly.
So when initializing the configuration as follows, I get the following error:
URL configURL = getClass().
getResource(configFile);
ConfigurationFactory factory = new ConfigurationFactory();
factory.setConfigurationURL(configURL);
myConfig = factory.getConfiguration();
60043 java.util.NoSuchElementException: 'HvNr' doesn't map to an existing object
at org.apache.commons.configuration.AbstractConfiguration.getLong(AbstractConfiguration.java:743)
at de.awd.vertriebsportal.portal.person.TestConfiguration.main(TestConfiguration.java:84)
Exception in thread ""main""
But when initializing it like this everything works properly
DefaultConfigurationBuilder builder = new DefaultConfigurationBuilder();
builder.setURL(configURL);
myConfig = builder.getConfiguration();
60043
54564
I will attach full source code and xml files",org.apache.commons.configuration.ConfigurationFactory
FILE,CONFIGURATION,CONFIGURATION-283,2007-07-02T12:38:23.000-05:00,CombinedConfiguration doesn't take escaped characters into account.,"import org.apache.commons.configuration.CombinedConfiguration;
import org.apache.commons.configuration.ConfigurationException;
import org.apache.commons.configuration.PropertiesConfiguration;
import junit.framework.TestCase;
public class TestProp extends TestCase {
	public void testprop() throws ConfigurationException 
{
		// test.properties contains :
		//    without_escape=aa,bb
		//    with_escape=aa\,bb
		//    with_2escapes=aa\\,bb
		
		String prop_filename = ""c:\\tmp\\test.properties"";
		PropertiesConfiguration properties_config = new PropertiesConfiguration(prop_filename);
		CombinedConfiguration   combined_config   = new CombinedConfiguration();
		combined_config.addConfiguration(properties_config);
		
		System.out.println(""Properties config"");
		System.out.println(properties_config.getString(""without_escape""));
		System.out.println(properties_config.getString(""with_escape""));
		System.out.println(properties_config.getString(""with_2escapes""));

		System.out.println(""\nCombined config"");
		System.out.println(combined_config.getString(""without_escape""));
		System.out.println(combined_config.getString(""with_escape""));
		System.out.println(combined_config.getString(""with_2escapes""));
		
	}
}
Hi,
I've tried to used CombinedConfiguration but it seems escaped characters are not taken into account :
import org.apache.commons.configuration.CombinedConfiguration;
import org.apache.commons.configuration.ConfigurationException;
import org.apache.commons.configuration.PropertiesConfiguration;
import junit.framework.TestCase;
public class TestProp extends TestCase { public void testprop() throws ConfigurationException
{
// test.properties contains :
//    without_escape=aa,bb
//    with_escape=aa\,bb
//    with_2escapes=aa\\,bb
String prop_filename = ""c:\\tmp\\test.properties"";
PropertiesConfiguration properties_config = new PropertiesConfiguration(prop_filename);
CombinedConfiguration   combined_config   = new CombinedConfiguration();
combined_config.
addConfiguration(properties_config);
System.out.println(""Properties config"");
System.out.println(properties_config.
getString(""without_escape""));
System.out.println(properties_config.
getString(""with_escape""));
System.out.println(properties_config.
getString(""with_2escapes""));
System.out.println(""\nCombined config"");
System.out.println(combined_config.
getString(""without_escape""));
System.out.println(combined_config.
getString(""with_escape""));
System.out.println(combined_config.
getString(""with_2escapes""));
}
}
Result :
---------
Properties config aa aa,bb aa,bb
Combined config aa aa aa
Thanks !
Franck","org.apache.commons.configuration.TestCombinedConfiguration
org.apache.commons.configuration.ConfigurationUtils
org.apache.commons.configuration.TestConfigurationUtils"
FILE,CONFIGURATION,CONFIGURATION-332,2008-07-04T15:54:10.000-05:00,PropertiesConfiguration.save() doesn't persist properties added through a DataConfiguration,"public void testSaveWithDataConfiguration() throws ConfigurationException
{
    File file = new File(""target/testsave.properties"");
    if (file.exists()) {
        assertTrue(file.delete());
    }

    PropertiesConfiguration config = new PropertiesConfiguration(file);

    DataConfiguration dataConfig = new DataConfiguration(config);

    dataConfig.setProperty(""foo"", ""bar"");
    assertEquals(""bar"", config.getProperty(""foo""));
    config.save();

    // reload the file
    PropertiesConfiguration config2 = new PropertiesConfiguration(file);
    assertFalse(""empty configuration"", config2.isEmpty());
}
There is a regression in Commons Configuration with PropertiesConfiguration wrapped into a DataConfiguration.
The properties added through a DataConfiguration aren't persisted when the configuration is saved, but they can be queried normally.
Commons Configuration 1.4 wasn't affected by this issue.
public void testSaveWithDataConfiguration() throws ConfigurationException
{
File file = new File(""target/testsave.
properties"");
if (file.exists()) { assertTrue(file.delete());
}
PropertiesConfiguration config = new PropertiesConfiguration(file);
DataConfiguration dataConfig = new DataConfiguration(config);
dataConfig.setProperty(""foo"", ""bar"");
assertEquals(""bar"", config.getProperty(""foo""));
config.save();
// reload the file
PropertiesConfiguration config2 = new PropertiesConfiguration(file);
assertFalse(""empty configuration"", config2.isEmpty());
}","org.apache.commons.configuration.TestPropertiesConfiguration
org.apache.commons.configuration.DataConfiguration"
FILE,CONFIGURATION,CONFIGURATION-347,2008-11-05T21:06:22.000-06:00,Iterating over the keys of a file-based configuration can cause a ConcurrentModificationException,"getKeys()
Some implementations of FileConfiguration return an iterator in their getKeys() method that is directly connected to the underlying data store.
When now a reload is performed (which can happen at any time) the data store is modified, and the iterator becomes invalid.
This behavior is very confusing because ConcurrentModificationExceptions are typically related to multi-threading access.
But even if the code performing the iteration is the only instance that accesses the configuration, the exception can be thrown.","org.apache.commons.configuration.TestFileConfiguration
org.apache.commons.configuration.AbstractFileConfiguration"
FILE,CONFIGURATION,CONFIGURATION-408,2010-02-11T01:01:05.000-06:00,"When I save a URL as a property value, the forward slashes are getting escaped","public static void main(String[] args)
  {
    try
    {

      PropertiesConfiguration config = new PropertiesConfiguration();     

      File newProps = new File(""foo.properties"");

      config.setProperty(""foo"", ""http://www.google.com/"");     

      config.save(newProps);

      

    }
    catch (Exception e){}
  }
When I save a URL as a property value, the forward slashes are getting escaped.
ie:
foo = http:\/\/www.google.com\/
public static void main(String[] args)
{ try
{
PropertiesConfiguration config = new PropertiesConfiguration();
File newProps = new File(""foo.properties"");
config.setProperty(""foo"", ""http://www.google.com/"");
config.save(newProps);
} catch (Exception e){}
}",org.apache.commons.configuration.TestPropertiesConfiguration
FILE,CONFIGURATION,CONFIGURATION-481,2012-02-26T20:27:46.000-06:00,Variable interpolation across files broken in 1.7 & 1.8,"{myvar}  
 
 
 
 combinedConfig.getConfiguration(""test"")  configurationAt(""products/product[@name='abc']"", true)  getString(""desc"")

  {myvar}
global.properties:
myvar=abc
test.xml:
<products>
<product name=""abc"">
<desc>${myvar}-product</desc>
</product>
</products>
config.xml:
<properties fileName=""global.properties""/>
<xml fileName=""test.xml"" config-name=""test"">
<expressionEngine config-class=""org.apache.commons.configuration.tree.xpath.XPathExpressionEngine""/>
</xml>
combinedConfig.getConfiguration(""test"").
configurationAt(""products/product[@name='abc']"", true).
getString(""desc"")
I get ""${myvar}-product"" instead of ""abc-product"".
This was working in Commons Configuration 1.6, but seems to be broken in 1.7 and 1.8.","org.apache.commons.configuration.DefaultConfigurationBuilder
org.apache.commons.configuration.interpol.ConfigurationInterpolator
org.apache.commons.configuration.TestDefaultConfigurationBuilder"
FILE,CONFIGURATION,CONFIGURATION-627,2016-05-04T22:54:12.000-05:00,BeanHelper exception on XMLConfiguration builder.getConfiguration(),"builder =

        new FileBasedConfigurationBuilder<XMLConfiguration>(

                XMLConfiguration.class)

                        .configure(params.xml()

                                .setFileName(

                                        propsFile.getCanonicalPath())

                                .setValidating(false));



config = builder.getConfiguration();



   
 private static boolean isPropertyWriteable(Object bean, String propName)    
  
   org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)
builder =
new FileBasedConfigurationBuilder<XMLConfiguration>(
XMLConfiguration.class)
.
configure(params.xml()
.
setFileName(
propsFile.getCanonicalPath())
.
setValidating(false));
config = builder.getConfiguration();
Causes a non-halting exception originating in org.apache.commons.configuration2.beanutils.BeanHelper, method private static boolean isPropertyWriteable(Object bean, String propName) with parameters XMLConfiguration, ""validating"".
The exception:
May 04, 2016 3:29:26 PM org.apache.commons.beanutils.FluentPropertyBeanIntrospector introspect
WARNING: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)!
Ignoring this property.
java.beans.IntrospectionException: bad write method arg count: public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)
at java.beans.PropertyDescriptor.findPropertyType(PropertyDescriptor.java:657)
at java.beans.PropertyDescriptor.setWriteMethod(PropertyDescriptor.java:327)
at java.beans.PropertyDescriptor.<init>(PropertyDescriptor.java:139)
at org.apache.commons.beanutils.FluentPropertyBeanIntrospector.createFluentPropertyDescritor(FluentPropertyBeanIntrospector.java:177)
at org.apache.commons.beanutils.FluentPropertyBeanIntrospector.introspect(FluentPropertyBeanIntrospector.java:140)
at org.apache.commons.beanutils.PropertyUtilsBean.fetchIntrospectionData(PropertyUtilsBean.java:2234)
at org.apache.commons.beanutils.PropertyUtilsBean.getIntrospectionData(PropertyUtilsBean.java:2215)
at org.apache.commons.beanutils.PropertyUtilsBean.getPropertyDescriptor(PropertyUtilsBean.java:950)
at org.apache.commons.beanutils.PropertyUtilsBean.isWriteable(PropertyUtilsBean.java:1466)
at org.apache.commons.configuration2.beanutils.BeanHelper.isPropertyWriteable(BeanHelper.java:521)
at org.apache.commons.configuration2.beanutils.BeanHelper.initProperty(BeanHelper.java:357)
at org.apache.commons.configuration2.beanutils.BeanHelper.initBeanProperties(BeanHelper.java:273)
at org.apache.commons.configuration2.beanutils.BeanHelper.initBean(BeanHelper.java:192)
at org.apache.commons.configuration2.beanutils.BeanHelper$BeanCreationContextImpl.initBean(BeanHelper.java:669)
at org.apache.commons.configuration2.beanutils.DefaultBeanFactory.initBeanInstance(DefaultBeanFactory.java:162)
at org.apache.commons.configuration2.beanutils.DefaultBeanFactory.createBean(DefaultBeanFactory.java:116)
at org.apache.commons.configuration2.beanutils.BeanHelper.createBean(BeanHelper.java:459)
at org.apache.commons.configuration2.beanutils.BeanHelper.createBean(BeanHelper.java:479)
at org.apache.commons.configuration2.beanutils.BeanHelper.createBean(BeanHelper.java:492)
at org.apache.commons.configuration2.builder.BasicConfigurationBuilder.createResultInstance(BasicConfigurationBuilder.java:447)
at org.apache.commons.configuration2.builder.BasicConfigurationBuilder.createResult(BasicConfigurationBuilder.java:417)
at org.apache.commons.configuration2.builder.BasicConfigurationBuilder.getConfiguration(BasicConfigurationBuilder.java:285)",org.apache.commons.configuration2.builder.TestPropertiesBuilderParametersImpl
CLASS,hibernate-3.5.0b2,HHH-4617,2009-11-28T11:42:08.000-06:00,Using materialized blobs with Postgresql causes error,"@Lob
I have entity with byte[] property annotated as @Lob and lazy fetch type, when table is createad the created column is of type oid, but when the column is read in application, the Hibernate reads the OID value instead of bytes under given oid.
It's behavior like to read / write bytea.
If i remember well, auto-creating table with Hibernate creates oid column.","org.hibernate.type.CharacterArrayClobType
org.hibernate.type.MaterializedClobType
org.hibernate.type.PrimitiveCharacterArrayClobType
org.hibernate.type.WrappedMaterializedBlobType
org.hibernate.type.MaterializedBlobType
org.hibernate.test.lob.MaterializedBlobTest
org.hibernate.type.BlobType
org.hibernate.type.ClobType
org.hibernate.test.lob.ClobLocatorTest
org.hibernate.dialect.Dialect
org.hibernate.cfg.annotations.SimpleValueBinder
org.hibernate.dialect.PostgreSQLDialect
org.hibernate.Hibernate"
CLASS,hibernate-3.5.0b2,HHH-4647,2009-12-07T19:52:36.000-06:00,Problems with @JoinColumn referencedColumnName and quoted column and table names,"testQuotedReferencedColumnName() 
     getPhysicalColumnName()      getLogicalColumnName()
There are really two separate issues here, but the test case reduction and patches are so small (and involve related functionality) they are combined.
#1: A referencedColumnName that references a quoted target column cannot be found.
The test case is app.TestReferencedColumnName#testQuotedReferencedColumnName().
The patch is hibernate-annotations.
patch.
#2: An invalid referencedColumnName (including the unquoted version of a valid column) results in an infinite loop in o.h.c.Configuration$MappingsImpl#getPhysicalColumnName().
The test case is app.TestReferencedColumnName#testInvalidReferencedColumnNameOnQuotedTable.
The patch is hibernate-core.
patch.
It looks like the same issue exists with getLogicalColumnName(), but I'm not sure where this is used (i.e. how to test it) so I left it alone.","org.hibernate.test.annotations.backquotes.BackquoteTest
org.hibernate.cfg.Configuration.MappingsImpl"
CLASS,hibernate-3.5.0b2,HHH-5042,2010-03-26T05:06:09.000-05:00,TableGenerator does not increment hibernate_sequences.next_hi_value anymore after having exhausted the current lo-range,"class MultipleHiLoPerTableGenerator 
 IntegralDataTypeHolder value;
 
 int lo;

 
  
  
 IntegralDataTypeHolder hiVal = (IntegralDataTypeHolder) doWorkInNewTransaction( session );

   
  
 varchar(255) 
     varchar(255)
This bug is new in 3.5
In version 3.5 class MultipleHiLoPerTableGenerator.java was modified introducing a new increment variable
IntegralDataTypeHolder value;
along with int lo;
The problem in the new code is that only value get's incremented whilst variable lo is still used to check when a new hiVal must be obtained.
if ( lo > maxLo ) {
IntegralDataTypeHolder hiVal = (IntegralDataTypeHolder) doWorkInNewTransaction( session );
as lo is never incremented, MultipleHiLoPerTableGenerator continues to deliver numbers without ever update hibernate_sequences.
next_hi_value on the database (only one unique update is propagates at the first insert)
This lead to duplicate keys as soon another session from another sessionfactory tries to insert new objects on the concerning table.
IMPORTANT ADVICE TO RUN THE TESTCASE:
create table A (oid bigint not null, name varchar(255), version integer not null, primary key (oid), unique (name))
create table hibernate_sequences ( sequence_name varchar(255),  sequence_next_hi_value integer )","org.hibernate.id.SequenceHiLoGenerator
org.hibernate.id.enhanced.OptimizerFactory
org.hibernate.id.SequenceGenerator
org.hibernate.id.MultipleHiLoPerTableGenerator"
METHOD,openjpa-2.0.1,OPENJPA-1613,2010-04-06T18:28:33.000-05:00,Exception thrown when enhancing a (property access) class that has an abstract @MappedSuperclass with no annotated properties,"@MappedSuperclass 
      
 @Access(AccessType.PROPERTY)
If you have a class (using property access) that has an abstract @MappedSuperclass that happens to have no annotated methods, you get the following exception when enhancing:
org.apache.openjpa.util.MetaDataException: ""implicit property access"" for class ""org.apache.openjpa.persistence.simple.SubclassPerson"" is not consistent with ""implicit field access"" used by its persistent superclass ""org.apache.openjpa.persistence.simple.AbstractSuperclass"".
All persistent classes in an inheritance hierarchy must use a single implicit field or property based access style or explicitly declare an access style.
Presumably the enhancer is deciding incorrectly that the superclass is using field access.
A workaround is to annotate the superclass with @Access(AccessType.PROPERTY)  so the enhancer doesn't make this assumption, but that is not JPA 1.0 backwards compatible.
This did not occur in any of the OpenJPA 1.
* versions",org.apache.openjpa.persistence.PersistenceMetaDataDefaults:toFieldNames(List<Field>)
METHOD,openjpa-2.0.1,OPENJPA-1627,2010-04-12T05:21:13.000-05:00,ORderBy with @ElementJoinColumn and EmbeddedId uses wrong columns in SQL,"@OneToMany(fetch = FetchType.LAZY, cascade = {CascadeType.PERSIST})
	@ElementJoinColumn(name=""maccno"", referencedColumnName=""maccno"")
	@OrderBy(value = ""_id._processDate ASC, _id._tranSequenceNumber ASC"")
	private LinkedList<Transaction> _transactions;



      
 @EmbeddedId
	private TransactionId _id;
	
	 @Column(name = ""mtrancde"")
	private int _transactionCode;
	
	 @Column(name = ""mamount"")
	private BigDecimal _amount;
	
	 @Column(name = ""mdesc"")
	private String _description;
	


	 @Column(name = ""mactdate"")
	private Date _actualDate;
	
	 @Column(name = ""mbranch"")
	private int _branch;



   
 @Embeddable
public class TransactionId  
 @Column(name = ""maccno"")
	private String _accountNumber;
	
	 @Column(name = ""mprocdate"")
	private Date _processDate;
	
	 @Column(name = ""mtranseqno"")
	private int _tranSequenceNumber;
Typical bank example, Account with Transactions.
It is a legacy db so Transaction has compound key - represented by TransactionId class.
The problem is that the order by in the generated SQL is for columns mapped in the transaction entity NOT the TransacionId as expected.
@OneToMany(fetch = FetchType.LAZY, cascade = {CascadeType.PERSIST})
	@ElementJoinColumn(name=""maccno"", referencedColumnName=""maccno"")
	@OrderBy(value = ""_id.
_processDate ASC, _id.
_tranSequenceNumber ASC"")
	private LinkedList<Transaction> _transactions;
_processDate and _tranSequenceNumber are defined in the TransactionId class.
Transaction has the following fragment....
@EmbeddedId
	private TransactionId _id;
	
	@Column(name = ""mtrancde"")
	private int _transactionCode;
	
	@Column(name = ""mamount"")
	private BigDecimal _amount;
	
	@Column(name = ""mdesc"")
	private String _description;
@Column(name = ""mactdate"")
	private Date _actualDate;
	
	@Column(name = ""mbranch"")
	private int _branch;
And TransactionId defines the primary key columns....
@Embeddable
public class TransactionId {
	
	@Column(name = ""maccno"")
	private String _accountNumber;
	
	@Column(name = ""mprocdate"")
	private Date _processDate;
	
	@Column(name = ""mtranseqno"")
	private int _tranSequenceNumber;
However the generated SQL is doing order by on columns mapped in Transaction:
executing prepstmnt 23188098 SELECT t0.maccno, t0.mprocdate, t0.mtranseqno, t0.mactdate, t0.mamount, t0.mbranch, t0.mchqcash, t0.mdesc,
 t0.mtmnlno, t0.mtrancde, t0.mtrnfeed 
FROM transaction t0 
WHERE t0.maccno = ?
ORDER BY t0.mamount ASC, t0.mbranch ASC [params=(String) 000734123]
ORDER BY t0.mprocdate ASC, t0.mtranseqno ASC [params=(String) 000734123]
Thanks
Michael","org.apache.openjpa.jdbc.meta.JDBCRelatedFieldOrder:order(Select, ClassMapping, Joins)"
METHOD,openjpa-2.0.1,OPENJPA-1784,2010-09-08T08:31:29.000-05:00,Map value updates not flushed,"@Embeddable
public class LocalizedString {


    private String language;
    private String string;


    // getters and setters omitted
}


 


 @Entity
public class MultilingualString {


    @Id
    private long id;


    @ElementCollection(fetch=FetchType.EAGER)
    private Map<String, LocalizedString> map = new HashMap<String, LocalizedString>();
}



 
   ;
    em.getTransaction().begin();
    m.getMap().get(""en"").setString(""foo"");
     em.merge(m)
     em.getTransaction()  commit();
   
 
   ;
    em.getTransaction().begin();
     m.getMap()  put(""en"")  new LocalizedString(""en"", ""foo"") 
 em.merge(m)
     em.getTransaction()  commit();


 
 hashCode()   equals()   equal()
@Embeddable
public class LocalizedString {
private String language;
    private String string;
// getters and setters omitted
}
@Entity
public class MultilingualString {
@Id
    private long id;
@ElementCollection(fetch=FetchType.EAGER)
    private Map<String, LocalizedString> map = new HashMap<String, LocalizedString>();
}
EntityManager em = ...;
    em.getTransaction().
begin();
    m.getMap().
get(""en"").
setString(""foo"");
    em.merge(m)
    em.getTransaction().
commit();
   
The problem is, the state change of the map does not get saved to the database.
With DEBUG logging on, I can see that the flush on commit does not trigger any SQL UPDATE.
To force the update, I have to put a new value into the map instead of just changing the existing one.
EntityManager em = ...;
    em.getTransaction().
begin();
    m.getMap().
put(""en""), new LocalizedString(""en"", ""foo""));
    em.merge(m)
    em.getTransaction().
commit();
After this change, I do see the expected UPDATE.
My Embeddable does have hashCode() and equals() implemented such that the changed map is not equal() to the former version in either case.
This looks like a bug in the dirty-checking logic in OpenJPA.","org.apache.openjpa.util.ProxyMaps:beforePut(ProxyMap, Object, Object)"
METHOD,openjpa-2.0.1,OPENJPA-1793,2010-09-14T01:16:17.000-05:00,@EmbeddedId class having only one field java.sql.Data,"@EmbeddedId  
 
  
  
 field.getHandler()  getResultArgument(field) 
 
  
  
 public Object getPrimaryKeyValue(Result res, Column[] cols, ForeignKey fk,
        JDBCStore store, Joins joins)
        throws SQLException {
        Column col;
        Object val = null;
        if (cols.length == 1) {
            col = cols[0];
            if (fk != null)
                col = fk.getColumn(col);
            val = res.getObject(col, field.getHandler().
                getResultArgument(field), joins);
        } else if (cols.length > 1) {
            Object[] vals = new Object[cols.length];
            Object[] args = (Object[]) field.getHandler().
                getResultArgument(field);
            for (int i = 0; i < vals.length; i++) {
                col = cols[i];
                if (fk != null)
                    col = fk.getColumn(col);
                vals[i] = res.getObject(col, (args == null) ? null : args[i],
                    joins);
            }
            val = vals;
        }
        return field.getHandler().toObjectValue(field, val);
    }


     
  
   DATE:
                return getDateInternal(obj, (Calendar) arg, joins);
@EmbeddedId class having only one field java.sql.Data
I become the error such as follows.
---------------------
Exception in thread ""main"" <openjpa-2.0.1-r422266:989424 nonfatal user error> org.apache.openjpa.persistence.ArgumentException: Failed to execute query ""SELECT m FROM Mzeiritsu m WHERE m.key.tekiyoKaishiYmd = (SELECT MAX(m2.key.tekiyoKaishiYmd) FROM Mzeiritsu m2 WHERE m2.key.tekiyoKaishiYmd < '2010-08-01')"".
Check the query syntax for correctness.
See nested exception for details.
at org.apache.openjpa.kernel.QueryImpl.execute(QueryImpl.java:870)
at org.apache.openjpa.kernel.QueryImpl.execute(QueryImpl.java:792)
at org.apache.openjpa.kernel.DelegatingQuery.execute(DelegatingQuery.java:542)
at org.apache.openjpa.persistence.QueryImpl.execute(QueryImpl.java:288)
at org.apache.openjpa.persistence.QueryImpl.getResultList(QueryImpl.java:302)
at itso.bank.entities.test.EntityTester.main(EntityTester.java:40)
Caused by: java.lang.ClassCastException: [Ljava.lang.Object; incompatible with java.util.Calendar
at org.apache.openjpa.jdbc.sql.ResultSetResult.getObjectInternal(ResultSetResult.java:431)
at org.apache.openjpa.jdbc.sql.AbstractResult.getObject(AbstractResult.java:696)
at org.apache.openjpa.jdbc.meta.strats.HandlerFieldStrategy.getPrimaryKeyValue(HandlerFieldStrategy.java:315)
at org.apache.openjpa.jdbc.meta.ClassMapping.getObjectId(ClassMapping.java:187)
at org.apache.openjpa.jdbc.meta.ClassMapping.getObjectId(ClassMapping.java:146)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager.load(JDBCStoreManager.java:1020)
at org.apache.openjpa.jdbc.sql.AbstractResult.load(AbstractResult.java:280)
at org.apache.openjpa.jdbc.sql.SelectImpl$SelectResult.load(SelectImpl.java:2344)
at org.apache.openjpa.jdbc.sql.AbstractResult.load(AbstractResult.java:274)
at org.apache.openjpa.jdbc.kernel.InstanceResultObjectProvider.getResultObject(InstanceResultObjectProvider.java:59)
at org.apache.openjpa.lib.rop.EagerResultList.<init>(EagerResultList.java:36)
at org.apache.openjpa.kernel.QueryImpl.toResult(QueryImpl.java:1246)
at org.apache.openjpa.kernel.QueryImpl.execute(QueryImpl.java:1005)
at org.apache.openjpa.kernel.QueryImpl.execute(QueryImpl.java:861)
... 5 more
---------------------
315th line of HandlerFieldStrategy class 
field.getHandler().
getResultArgument(field) 
The return value of the method  is object array.
Therefore an error occurs at a 431th line of ResultSetResult.
---------------------
[org.apache.openjpa.jdbc.meta.strats.HandlerFieldStrategy]
....
public Object getPrimaryKeyValue(Result res, Column[] cols, ForeignKey fk,
JDBCStore store, Joins joins)
throws SQLException {
Column col;
Object val = null;
if (cols.length == 1) {
col = cols[0];
if (fk !
= null)
col = fk.getColumn(col);
val = res.getObject(col, field.getHandler().
getResultArgument(field), joins);
} else if (cols.length > 1) {
Object[] vals = new Object[cols.length];
Object[] args = (Object[]) field.getHandler().
getResultArgument(field);
for (int i = 0; i < vals.length; i++) {
col = cols[i];
if (fk !
= null)
col = fk.getColumn(col);
vals[i] = res.getObject(col, (args == null) ?
null : args[i],
joins);
}
val = vals;
}
return field.getHandler().
toObjectValue(field, val);
}
....
---------------------
---------------------
[org.apache.openjpa.jdbc.sql.ResultSetResult]
....
case JavaSQLTypes.SQL_DATE:
return getDateInternal(obj, (Calendar) arg, joins);
....
---------------------","org.apache.openjpa.persistence.embed.TestEmbeddable:testEntityA_Coll_String()
org.apache.openjpa.persistence.embed.TestEmbeddable:testEntityA_Embed_Coll_Map()"
METHOD,openjpa-2.0.1,OPENJPA-1830,2010-10-11T13:05:46.000-05:00,Deserialization of EMF causes connectionPassword to be overwritten with Value.INVISIBLE,"ConfigurationImpl.writeExternal()   toProperties()       When readExternal()
ConfigurationImpl.writeExternal() serializes out the toProperties() and Map _props, which both contain the connectionPassword.
When readExternal() deserializes, the StringValue of connectionPassword gets its value set twice, which causes Value.INVISIBLE to get set as the value, which never happens if the EMF is never serialized.","org.apache.openjpa.persistence.simple.TestSerializedFactory:setUp()
org.apache.openjpa.lib.conf.ConfigurationImpl:toProperties(boolean)"
METHOD,openjpa-2.0.1,OPENJPA-1896,2010-11-23T10:32:43.000-06:00,OpenJPA cannot store POJOs if a corresponding record already exists,"merge()  
 merge()   persist()  
      
 merge()
If a POJO is created using a java constructor, merge() cannot store the newly constructed object's data if this means updating a pre-existing record with a matching identity.
This is a major bug since it means applications where the objects have a natural key cannot use OpenJPA.
In my case the example was a filesystem; each crawl of the filesystem generates its own data objects with file path as the natural key.
These objects then need to be stored into the database.
Instead, any attempt to execute either merge() or persist() on an independently constructed object with a matching record identity in the database triggers the same error in the database layer, since OpenJPA attempts to execute an insert for a pre-existing primary key, throwing...
org.apache.openjpa.lib.jdbc.ReportingSQLException: ERROR: duplicate key value violates unique constraint ""file_pkey"" {prepstmnt 32879825 INSERT INTO file (locationString, location, version, folder) VALUES (?
, ?
, ?
, ?)
[params=?
, ?
, ?
, ?]}
[code=0, state=23505]
From discussion with Rick Curtis on the users@openjpa.apache.org list, this is because the version field on a POJO which is unmanaged is not yet set.
An ASSUMPTION seems to be made that no such record exists in the database already since it wasn't loaded from the database in the first place, so a persist is attempted.
Instead, I recommend the database is QUERIED TO FIND OUT if such a record already exists, and the version field is set correspondingly before attempting the merge()
Here is the corresponding thread containing Ricks comments and links to an example in Github which can recreate the problem.
http://bit.ly/hfPjTI","org.apache.openjpa.kernel.VersionAttachStrategy:compareVersion(StateManagerImpl, PersistenceCapable)
org.apache.openjpa.persistence.relations.BasicEntity:getId()"
METHOD,openjpa-2.0.1,OPENJPA-1918,2011-01-06T08:11:24.000-06:00,MetaDataRepository.preload() ignores class loader returned by PersistenceUnitInfo.getClassLoader(),"PersistenceUnitInfo.getClassLoader() 
 MetaDataRepository.preload()      
 PersistenceUnitInfo.getClassLoader()    
  
   PersistenceProvider.createContainerEntityManagerFactory()  MetaDatRepository.preload()
We are using openjpa inside an OSGi container together with
openjpa.MetaDataRepository"" value=""Preload=true""
We pass the appliation class loeader as part of our PersistenceUnitInfo implementation by returning it from PersistenceUnitInfo.getClassLoader().
However, the code in MetaDataRepository.preload() only uses the context class loader and not the class loader from PersistenceUnitInfo, which leades to ClassNotFoundExpcetions like mentioned at the end of this report.
A fix might be quite easily establihed by appending the return value of PersistenceUnitInfo.getClassLoader() to the list of claas loaders participating in the MultiClassLoader set up in
  
  MetaDataRepository.java:310ff
In the meanwhile, we are additionally setting our classloader as context loader during the creation of the EntityManagerFactory by PersistenceProvider.createContainerEntityManagerFactory(), but a fix in MetaDatRepository.preload() is highly appreciated.
TIA for fixing this,
Wolfgang
Stack trace:
org.osgi.service.blueprint.container.ComponentDefinitionException: Error when instantiating bean entityManagerFactory of class null
at org.apache.aries.blueprint.container.BeanRecipe.getInstance(BeanRecipe.java:233)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BeanRecipe.internalCreate(BeanRecipe.java:726)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.di.AbstractRecipe.create(AbstractRecipe.java:64)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintRepository.createInstances(BlueprintRepository.java:219)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintRepository.createAll(BlueprintRepository.java:147)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintContainerImpl.instantiateEagerComponents(BlueprintContainerImpl.java:624)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintContainerImpl.doRun(BlueprintContainerImpl.java:315)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintContainerImpl.run(BlueprintContainerImpl.java:213)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)[:1.6.0_20]
at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)[:1.6.0_20]
at java.util.concurrent.FutureTask.run(FutureTask.java:166)[:1.6.0_20]
at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$101(ScheduledThreadPoolExecutor.java:165)[:1.6.0_20]
at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:266)[:1.6.0_20]
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)[:1.6.0_20]
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)[:1.6.0_20]
at java.lang.Thread.run(Thread.java:636)[:1.6.0_20]
Caused by: <openjpa-2.0.1-r422266:989424 fatal user error> org.apache.openjpa.persistence.ArgumentException: Unexpected error during early loading of entity metadata during initialization. See nested stacktrace for details.
at org.apache.openjpa.meta.MetaDataRepository.preload(MetaDataRepository.java:331)
at org.apache.openjpa.persistence.PersistenceProviderImpl.preloadMetaDataRepository(PersistenceProviderImpl.java:280)
at org.apache.openjpa.persistence.PersistenceProviderImpl.createContainerEntityManagerFactory(PersistenceProviderImpl.java:211)
at org.apache.openjpa.persistence.PersistenceProviderImpl.createContainerEntityManagerFactory(PersistenceProviderImpl.java:65)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[:1.6.0_20]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)[:1.6.0_20]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[:1.6.0_20]
at java.lang.reflect.Method.invoke(Method.java:616)[:1.6.0_20]
at org.apache.aries.blueprint.container.AbstractServiceReferenceRecipe$JdkProxyFactory$1.invoke(AbstractServiceReferenceRecipe.java:632)
at $Proxy67.createContainerEntityManagerFactory(Unknown Source)
at org.clazzes.util.jpa.provider.EntityManagerFactoryFactory.newEntityManagerFactory(EntityManagerFactoryFactory.java:108)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[:1.6.0_20]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)[:1.6.0_20]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[:1.6.0_20]
at java.lang.reflect.Method.invoke(Method.java:616)[:1.6.0_20]
at org.apache.aries.blueprint.utils.ReflectionUtils.invoke(ReflectionUtils.java:221)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BeanRecipe.invoke(BeanRecipe.java:844)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BeanRecipe.getInstance(BeanRecipe.java:231)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
... 15 more
Caused by: java.security.PrivilegedActionException: java.lang.ClassNotFoundException: org.clazzes.fancymail.server.entities.EMail
at java.security.AccessController.doPrivileged(Native Method)[:1.6.0_20]
at org.apache.openjpa.meta.MetaDataRepository.preload(MetaDataRepository.java:326)
... 32 more
Caused by: java.lang.ClassNotFoundException: org.clazzes.fancymail.server.entities.EMail
at org.apache.openjpa.lib.util.MultiClassLoader.findClass(MultiClassLoader.java:216)
at java.lang.ClassLoader.loadClass(ClassLoader.java:321)[:1.6.0_20]
at java.lang.ClassLoader.loadClass(ClassLoader.java:266)[:1.6.0_20]
at java.lang.Class.forName0(Native Method)[:1.6.0_20]
at java.lang.Class.forName(Class.java:264)[:1.6.0_20]
at org.apache.openjpa.lib.util.J2DoPrivHelper$4.run(J2DoPrivHelper.java:233)
at org.apache.openjpa.lib.util.J2DoPrivHelper$4.run(J2DoPrivHelper.java:231)
... 34 more","org.apache.openjpa.meta.FieldMetaData:hashCode()
org.apache.openjpa.meta.FieldMetaData:compareTo(Object)"
METHOD,openjpa-2.0.1,OPENJPA-526,2008-02-27T13:28:05.000-06:00,Insert text more than 4K bytes to Clob column causes SQLException: Exhausted Resultset,"public class Exam 
 @Lob 
 @Column(name = ""text"", nullable = false)  
 private String text;
 
 With nullable = false
Here are the differences with nullable = true:
INSERT INTO exam (id, text) VALUES (?
, ?)
[params=(long) 1, (Clob) oracle.sql.CLOB@d402dd]
SELECT t0.text FROM exam t0 WHERE t0.id = ?
FOR UPDATE [params=(long) 1]
With nullable = false:
INSERT INTO exam (id, text) VALUES (?
, ?)
[params=(long) 1, (Reader) java.io.StringReader@1603522]
SELECT t0.text FROM exam t0 WHERE t0.id = ?
FOR UPDATE [params=(long) 1] [code=1400, state=23000]
Here's the full stack trace:
[2008-02-27 10:43:51,232][main][org.apache.openjpa.lib.log.Log4JLogFactory$LogAdapter:72][DEBUG] <t 11050211, conn 32112901> executing prepstmnt 15029693 INSERT INTO exam (id, last_updated_by, comments, sustained_on, text, version, course_id, professor_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?) [params=(long) 11, (String) test, (null) null, (Date) 2008-02-27, (Reader) java.io.StringReader@da9ea4, (int) 1, (long) 1, (long) 8]
[2008-02-27 10:43:51,248][main][org.apache.openjpa.lib.log.Log4JLogFactory$LogAdapter:72][DEBUG] <t 11050211, conn 32112901> [16 ms] spent
[2008-02-27 10:43:51,248][main][org.apache.openjpa.lib.log.Log4JLogFactory$LogAdapter:72][DEBUG] <t 11050211, conn 32112901> executing prepstmnt 24422114 SELECT t0.text FROM exam t0 WHERE t0.id = ? FOR UPDATE [params=(long) 11]
[2008-02-27 10:43:51,279][main][org.apache.openjpa.lib.log.Log4JLogFactory$LogAdapter:72][DEBUG] <t 11050211, conn 32112901> [31 ms] spent
[2008-02-27 10:43:51,279][main][org.apache.openjpa.lib.log.Log4JLogFactory$LogAdapter:76][DEBUG] An exception occurred while ending the transaction.  This exception will be re-thrown.
<openjpa-1.0.2-r420667:627158 fatal store error> org.apache.openjpa.util.StoreException: The transaction has been rolled back.  See the nested exceptions for details on the errors that occurred.
at org.apache.openjpa.kernel.BrokerImpl.newFlushException(BrokerImpl.java:2108)
at org.apache.openjpa.kernel.BrokerImpl.flush(BrokerImpl.java:1955)
at org.apache.openjpa.kernel.BrokerImpl.flushSafe(BrokerImpl.java:1853)
at org.apache.openjpa.kernel.BrokerImpl.beforeCompletion(BrokerImpl.java:1771)
at org.apache.openjpa.kernel.LocalManagedRuntime.commit(LocalManagedRuntime.java:81)
at org.apache.openjpa.kernel.BrokerImpl.commit(BrokerImpl.java:1293)
at org.apache.openjpa.kernel.DelegatingBroker.commit(DelegatingBroker.java:861)
at org.apache.openjpa.persistence.EntityManagerImpl.commit(EntityManagerImpl.java:408)
at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:438)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:662)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:632)
at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:319)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:116)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:631)
at com.intellapps.university.service.impl.ServiceDahImpl$$EnhancerByCGLIB$$81ecf35d.insertExam(<generated>)
at com.intellapps.university.service.impl.ServiceImpl.insertExam(ServiceImpl.java:98)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:585)
at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:301)
at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:182)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:149)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:106)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:204)
at $Proxy17.insertExam(Unknown Source)
at com.intellapps.university.app.Main.testInsertExamWithLongText(Main.java:103)
at com.intellapps.university.app.Main.main(Main.java:203)
Caused by: <openjpa-1.0.2-r420667:627158 nonfatal store error> org.apache.openjpa.util.StoreException: Exhausted Resultset
at org.apache.openjpa.jdbc.sql.DBDictionary.newStoreException(DBDictionary.java:3946)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:97)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:83)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:59)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:96)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:72)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager.flush(JDBCStoreManager.java:514)
at org.apache.openjpa.kernel.DelegatingStoreManager.flush(DelegatingStoreManager.java:130)
... 29 more
Caused by: java.sql.SQLException: Exhausted Resultset
at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:112)
at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:146)
at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:208)
at oracle.jdbc.driver.ScrollableResultSet.getOracleObject(ScrollableResultSet.java:510)
at oracle.jdbc.driver.ScrollableResultSet.getCLOB(ScrollableResultSet.java:1446)
at oracle.jdbc.driver.UpdatableResultSet.getCLOB(UpdatableResultSet.java:1639)
at oracle.jdbc.driver.UpdatableResultSet.getClob(UpdatableResultSet.java:982)
at org.apache.commons.dbcp.DelegatingResultSet.getClob(DelegatingResultSet.java:515)
at org.apache.openjpa.lib.jdbc.DelegatingResultSet.getClob(DelegatingResultSet.java:576)
at org.apache.openjpa.jdbc.meta.strats.MaxEmbeddedClobFieldStrategy.putData(MaxEmbeddedClobFieldStrategy.java:69)
at org.apache.openjpa.jdbc.meta.strats.MaxEmbeddedLobFieldStrategy.customUpdate(MaxEmbeddedLobFieldStrategy.java:162)
at org.apache.openjpa.jdbc.meta.strats.MaxEmbeddedLobFieldStrategy.customInsert(MaxEmbeddedLobFieldStrategy.java:140)
at org.apache.openjpa.jdbc.meta.FieldMapping.customInsert(FieldMapping.java:684)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager$CustomMapping.execute(AbstractUpdateManager.java:358)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:94)
... 32 more
NestedThrowables:
<openjpa-1.0.2-r420667:627158 nonfatal store error> org.apache.openjpa.util.ReferentialIntegrityException: ORA-01400: cannot insert NULL into (""TEST"".""EXAM"".""TEXT"")
{prepstmnt 15029693 INSERT INTO exam (id, last_updated_by, comments, sustained_on, text, version, course_id, professor_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?) [params=(long) 11, (String) test, (null) null, (Date) 2008-02-27, (Reader) java.io.StringReader@da9ea4, (int) 1, (long) 1, (long) 8]} [code=1400, state=23000]
FailedObject: com.intellapps.university.core.model.Exam@1417690
at org.apache.openjpa.jdbc.sql.DBDictionary.newStoreException(DBDictionary.java:3944)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:97)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:67)
at org.apache.openjpa.jdbc.kernel.PreparedStatementManagerImpl.flushInternal(PreparedStatementManagerImpl.java:108)
at org.apache.openjpa.jdbc.kernel.PreparedStatementManagerImpl.flush(PreparedStatementManagerImpl.java:73)
at org.apache.openjpa.jdbc.kernel.OperationOrderUpdateManager.flushPrimaryRow(OperationOrderUpdateManager.java:203)
at org.apache.openjpa.jdbc.kernel.OperationOrderUpdateManager.flush(OperationOrderUpdateManager.java:89)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:89)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:72)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager.flush(JDBCStoreManager.java:514)
at org.apache.openjpa.kernel.DelegatingStoreManager.flush(DelegatingStoreManager.java:130)
at org.apache.openjpa.kernel.BrokerImpl.flush(BrokerImpl.java:1955)
at org.apache.openjpa.kernel.BrokerImpl.flushSafe(BrokerImpl.java:1853)
at org.apache.openjpa.kernel.BrokerImpl.beforeCompletion(BrokerImpl.java:1771)
at org.apache.openjpa.kernel.LocalManagedRuntime.commit(LocalManagedRuntime.java:81)
at org.apache.openjpa.kernel.BrokerImpl.commit(BrokerImpl.java:1293)
at org.apache.openjpa.kernel.DelegatingBroker.commit(DelegatingBroker.java:861)
at org.apache.openjpa.persistence.EntityManagerImpl.commit(EntityManagerImpl.java:408)
at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:438)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:662)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:632)
at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:319)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:116)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:631)
at com.intellapps.university.service.impl.ServiceDahImpl$$EnhancerByCGLIB$$81ecf35d.insertExam(<generated>)
at com.intellapps.university.service.impl.ServiceImpl.insertExam(ServiceImpl.java:98)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:585)
at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:301)
at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:182)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:149)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:106)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:204)
at $Proxy17.insertExam(Unknown Source)
at com.intellapps.university.app.Main.testInsertExamWithLongText(Main.java:103)
at com.intellapps.university.app.Main.main(Main.java:203)
Caused by: org.apache.openjpa.lib.jdbc.ReportingSQLException: ORA-01400: cannot insert NULL into (""TEST"".""EXAM"".""TEXT"")
{prepstmnt 15029693 INSERT INTO exam (id, last_updated_by, comments, sustained_on, text, version, course_id, professor_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?) [params=(long) 11, (String) test, (null) null, (Date) 2008-02-27, (Reader) java.io.StringReader@da9ea4, (int) 1, (long) 1, (long) 8]} [code=1400, state=23000]
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator.wrap(LoggingConnectionDecorator.java:192)
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator.access$800(LoggingConnectionDecorator.java:57)
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator$LoggingConnection$LoggingPreparedStatement.executeUpdate(LoggingConnectionDecorator.java:858)
at org.apache.openjpa.lib.jdbc.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:269)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager$CancelPreparedStatement.executeUpdate(JDBCStoreManager.java:1363)
at org.apache.openjpa.jdbc.kernel.PreparedStatementManagerImpl.flushInternal(PreparedStatementManagerImpl.java:97)
... 36 more
NestedThrowables:
java.sql.SQLException: ORA-01400: cannot insert NULL into (""TEST"".""EXAM"".""TEXT"")
at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:112)
at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:331)
at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:288)
at oracle.jdbc.driver.T4C8Oall.receive(T4C8Oall.java:745)
at oracle.jdbc.driver.T4CPreparedStatement.doOall8(T4CPreparedStatement.java:216)
at oracle.jdbc.driver.T4CPreparedStatement.executeForRows(T4CPreparedStatement.java:966)
at oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1170)
at oracle.jdbc.driver.OraclePreparedStatement.executeInternal(OraclePreparedStatement.java:3339)
at oracle.jdbc.driver.OraclePreparedStatement.executeUpdate(OraclePreparedStatement.java:3423)
at org.apache.commons.dbcp.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:102)
at org.apache.openjpa.lib.jdbc.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:269)
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator$LoggingConnection$LoggingPreparedStatement.executeUpdate(LoggingConnectionDecorator.java:856)
at org.apache.openjpa.lib.jdbc.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:269)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager$CancelPreparedStatement.executeUpdate(JDBCStoreManager.java:1363)
at org.apache.openjpa.jdbc.kernel.PreparedStatementManagerImpl.flushInternal(PreparedStatementManagerImpl.java:97)
at org.apache.openjpa.jdbc.kernel.PreparedStatementManagerImpl.flush(PreparedStatementManagerImpl.java:73)
at org.apache.openjpa.jdbc.kernel.OperationOrderUpdateManager.flushPrimaryRow(OperationOrderUpdateManager.java:203)
at org.apache.openjpa.jdbc.kernel.OperationOrderUpdateManager.flush(OperationOrderUpdateManager.java:89)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:89)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:72)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager.flush(JDBCStoreManager.java:514)
at org.apache.openjpa.kernel.DelegatingStoreManager.flush(DelegatingStoreManager.java:130)
at org.apache.openjpa.kernel.BrokerImpl.flush(BrokerImpl.java:1955)
at org.apache.openjpa.kernel.BrokerImpl.flushSafe(BrokerImpl.java:1853)
at org.apache.openjpa.kernel.BrokerImpl.beforeCompletion(BrokerImpl.java:1771)
at org.apache.openjpa.kernel.LocalManagedRuntime.commit(LocalManagedRuntime.java:81)
at org.apache.openjpa.kernel.BrokerImpl.commit(BrokerImpl.java:1293)
at org.apache.openjpa.kernel.DelegatingBroker.commit(DelegatingBroker.java:861)
at org.apache.openjpa.persistence.EntityManagerImpl.commit(EntityManagerImpl.java:408)
at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:438)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:662)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:632)
at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:319)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:116)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:631)
at com.intellapps.university.service.impl.ServiceDahImpl$$EnhancerByCGLIB$$81ecf35d.insertExam(<generated>)
at com.intellapps.university.service.impl.ServiceImpl.insertExam(ServiceImpl.java:98)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:585)
at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:301)
at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:182)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:149)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:106)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:204)
at $Proxy17.insertExam(Unknown Source)
at com.intellapps.university.app.Main.testInsertExamWithLongText(Main.java:103)
at com.intellapps.university.app.Main.main(Main.java:203)","org.apache.openjpa.persistence.kernel.common.apps.Lobs:getId()
org.apache.openjpa.persistence.kernel.common.apps.Lobs:getLob()
org.apache.openjpa.persistence.kernel.common.apps.Lobs:Lobs(String, int)
org.apache.openjpa.persistence.kernel.common.apps.Lobs:setLob(String)
org.apache.openjpa.jdbc.sql.OracleDictionary:setNull(PreparedStatement, int, int, Column)"
METHOD,adempiere-3.1.0,1240,2008-05-16T03:03:55.000-05:00,Posting not balanced when is producing more than 1 produc,"Production Quantity= 2
The accounting is not balanced  when more that 1 product BOM is produced.
when is necesary serialize, then the line must be put 1 each line.
in this case the production  cant  apply.
Step reproduce
3. Then click on  ""Create/post Production"" button in the Production header tab, this create the production line.
verify in the production line tab.
6. click on ""Not Postet"" Button, then there the botton label is changed to ""Dont Balanced""
Regards,
Layda Salas - globalqss http://globalqss.com",org.compiere.acct.Doc_Production:createFacts(MAcctSchema)
CLASS,pig-0.8.0,PIG-1188,2010-01-14T13:32:46.000-06:00,Padding nulls to the input tuple according to input schema,"{code}
  as (a0, a1);
dump a;
{code}
 
 {code}
 
 {code}
 
 {code}
 
 {code}

 
 {code}
 
 {code}
Currently, the number of fields in the input tuple is determined by the data.
{code}
a = load '1.
txt' as (a0, a1);
dump a;
{code}
{code}
1       2
1       2       3
1
{code}
Current result:
{code}
(1 2)
(1 2,3)
(1
{code}","test.org.apache.pig.test.TestMergeForEachOptimization
src.org.apache.pig.newplan.logical.rules.TypeCastInserter
test.org.apache.pig.test.TestNewPlanLogicalOptimizer
test.org.apache.pig.test.TestNewPlanFilterRule
test.org.apache.pig.test.TestNewPlanPushDownForeachFlatten
test.org.apache.pig.test.TestEvalPipeline2
test.org.apache.pig.test.TestMultiQueryCompiler
test.org.apache.pig.test.TestPartitionFilterPushDown
test.org.apache.pig.test.TestNewPlanFilterAboveForeach"
CLASS,pig-0.8.0,PIG-1277,2010-03-05T13:02:03.000-06:00,Pig should give error message when cogroup on tuple keys of different inner type,"UDF:
{code}
public class MapGenerate extends EvalFunc<Map> {
    @Override
    public Map exec(Tuple input) throws IOException {
        // TODO Auto-generated method stub
        Map m = new HashMap();
        m.put(""key"", new Integer(input.size()));
        return m;
    }
    
    @Override
    public Schema outputSchema(Schema input) {
        return new Schema(new Schema.FieldSchema(null, DataType.MAP));
    }
}
{code}

 
 {code}
 
  
 by (c0, c1);
dump e;
{code}

 
 {code}
 
 {code}

 
 {code}
 
 {code}

 
 {code}
  {(1,1)}  {(1,1)} 
 {code}

 
 {code}
  {(1,1)}  {} 
 {}  {(1,1)} 
 {code}
When we cogroup on a tuple, if the inner type of tuple does not match, we treat them as different keys.
This is confusing.
txt' as (a0);
b = foreach a generate a0, MapGenerate(*) as m:map[];
c = foreach b generate a0, m#'key' as key;
d = load '2.
txt' as (c0, c1);
e = cogroup c by (a0, key), d by (c0, c1);
dump e;
{code}
1 txt
{code}
1
{code}
2 txt
{code}
1 1
{code}
Real result:
{code}
((1 1),{(1,1)},{})
((1 1),{},{(1,1)})
{code}","src.org.apache.pig.impl.io.NullableBytesWritable
test.org.apache.pig.test.TestPackage
test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigBytesRawComparator
src.org.apache.pig.backend.hadoop.HDataType
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POMultiQueryPackage
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce
test.org.apache.pig.test.TestSecondarySort
src.org.apache.pig.newplan.logical.relational.LOUnion"
CLASS,pig-0.8.0,PIG-1771,2010-12-16T14:45:37.000-06:00,"New logical plan: Merge schema fail if LoadFunc.getSchema return different schema with ""Load...AS""","{code}
 
 BinStorage() 
         tuple()  ;
dump auxData;
{code}
The following script fail:
{code}
a = load '1.
txt' as (a0:chararray, a1:chararray, a3, a4:map[]);
store a into '1.
bin' using BinStorage();
auxData = LOAD '1.
bin' USING BinStorage('Utf8StorageConverter') AS (cookieId:chararray, type:chararray, record:tuple(), state:map[]);
dump auxData;
{code}
Error message:
Caused by: org.apache.pig.impl.logicalLayer.FrontendException: ERROR 2246: Error merging schema record#-1:tuple{} and null#-1:bytearray
at org.apache.pig.newplan.logical.relational.LogicalSchema.merge(LogicalSchema.java:337)
at org.apache.pig.newplan.logical.relational.LOLoad.getSchema(LOLoad.java:103)
at org.apache.pig.newplan.logical.optimizer.SchemaResetter.visit(SchemaResetter.java:59)
at org.apache.pig.newplan.logical.relational.LOLoad.accept(LOLoad.java:159)
at org.apache.pig.newplan.DependencyOrderWalker.walk(DependencyOrderWalker.java:75)
at org.apache.pig.newplan.PlanVisitor.visit(PlanVisitor.java:50)
at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.compile(HExecutionEngine.java:261)
... 12 more","test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.newplan.logical.relational.LogicalSchema"
CLASS,pig-0.8.0,PIG-1776,2010-12-17T16:28:09.000-06:00,"changing statement corresponding to alias after explain , then doing dump gives incorrect result","{code}
 
  
 {code}
{code}
grunt> a = load '/tmp/t2.
txt' as (str:chararray, num1:int, alph : chararray);
grunt> dump a;
(ABC,1,a)
(ABC,1,b)
(ABC,1,a)
(ABC,2,b)
(DEF,1,d)
(XYZ,1,x)
grunt> c = foreach b  generate group.str, group.
$1, COUNT(a.alph) ;          
grunt> dump c; -- gives correct results
(ABC,1,3)
(ABC,2,1)
(DEF,1,1)
(XYZ,1,1)
/* but dumping c after following steps gives incorrect results */
grunt> c = foreach b  generate group.
$0 , (CHARARRAY)group.
$1;                                                                                 
grunt> explain c;
...
...
grunt> c = foreach b  generate group.str, group.
$1, COUNT(a.alph) ;
grunt> dump c;             
(ABC,1,0)
(ABC,2,0)
(DEF,1,0)
(XYZ,1,0)
{code}","src.org.apache.pig.PigServer
src.org.apache.pig.newplan.logical.relational.LOLoad
test.org.apache.pig.test.TestUDFContext"
CLASS,pig-0.8.0,PIG-1785,2011-01-04T17:20:28.000-06:00,New logical plan: uid conflict in flattened fields,"{code}
 
 b0>b2;
dump c;
{code}

 
 {(1,2),(2,3)}
txt' as (a0:bag{t:tuple(i0:int, i1:int)});
b = foreach a generate flatten(a0) as (b0, b1), flatten(a0) as (b2, b3);
c = filter b by b0>b2;
dump c;
{code}
{(1 2),(2,3)}
(2 3,1,2)
We get nothing.","src.org.apache.pig.newplan.logical.rules.ImplicitSplitInserter
test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.newplan.logical.rules.DuplicateForEachColumnRewrite
src.org.apache.pig.newplan.optimizer.PlanOptimizer
src.org.apache.pig.newplan.optimizer.Rule"
CLASS,pig-0.8.0,PIG-1808,2011-01-17T08:50:48.000-06:00,Error message in 0.8 not much helpful as compared to 0.7,"null;
DUMP D;
A = LOAD 'i1' ;
B = LOAD 'i2' ;
C = JOIN A by $92 left outer,B by $92  ;
D =  filter C by $100 is null;
DUMP D;
The below script fails both in 0.7 and 0.8 since A requires a valid schema to be defined.
But the error message in 0.8 is not helpful.
Error message in 0.8
-----------------------------
ERROR 2000: Error processing rule PushUpFilter.
Try -t PushUpFilter org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1066: Unable to open iterator for alias D
....
Caused by: org.apache.pig.impl.logicalLayer.FrontendException: ERROR 2042: Error in new logical plan. Try -Dpig.usenewlogicalplan=false.
....
Caused by: org.apache.pig.impl.logicalLayer.FrontendException: ERROR 2000: Error processing rule PushUpFilter. Try -t PushUpFilter
....
Caused by: java.lang.NullPointerException
at org.apache.pig.newplan.logical.rules.PushUpFilter$PushUpFilterTransformer.hasAll(PushUpFilter.java:308)
at org.apache.pig.newplan.logical.rules.PushUpFilter$PushUpFilterTransformer.check(PushUpFilter.java:141)
at org.apache.pig.newplan.optimizer.PlanOptimizer.optimize(PlanOptimizer.java:108)
... 13 more
Error message in 0.7
----------------------------- org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1066: Unable to open iterator for alias D
....
....
Caused by: org.apache.pig.backend.hadoop.executionengine.physicalLayer.LogicalToPhysicalTranslatorException:
ERROR 1109: Input (B) on which outer join is desired should have a valid schema","test.org.apache.pig.test.TestPushUpFilter
src.org.apache.pig.newplan.logical.rules.PushUpFilter"
CLASS,pig-0.8.0,PIG-1812,2011-01-19T20:06:36.000-06:00,Problem with DID_NOT_FIND_LOAD_ONLY_MAP_PLAN,"{t:(id:chararray, wht:float)} 
    
 flatten(cat_bag.id)    
    
 {
        I = order M by ts;
        J = order B by ts;
        generate flatten(group) as (pkg:chararray, cat_id:chararray), J.ts as tsorig, I.ts as tsmap;
}
Hi,
pkg.txt
a       3       {(123,1.0),(236,2.0)} a       3       {(236,1.0)}
model.txt
a       123     2       0.33 a       236     2       0.5
My script is listed below:
A = load 'pkg.txt' using PigStorage('\t') as (pkg:chararray, ts:int, cat_bag:{t:(id:chararray, wht:float)});
M = load 'model.txt' using PigStorage('\t') as (pkg:chararray, cat_id:chararray, ts:int, score:double);
B = foreach A generate ts, pkg, flatten(cat_bag.
id) as (cat_id:chararray);
B = distinct B;
H1 = cogroup M by (pkg, cat_id) inner, B by (pkg, cat_id);
H2 = foreach H1 {
I = order M by ts;
J = order B by ts;
generate flatten(group) as (pkg:chararray, cat_id:chararray), J.ts as tsorig, I.ts as tsmap;
}
dump H2;
When running this script, I got a warning about ""Encountered Warning DID_NOT_FIND_LOAD_ONLY_MAP_PLAN 1 time(s)"" and pig error log as below:
Pig Stack Trace
---------------
ERROR 2043: Unexpected error during execution.
org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1066: Unable to open iterator for alias H2
at org.apache.pig.PigServer.openIterator(PigServer.java:764)
at org.apache.pig.tools.grunt.GruntParser.processDump(GruntParser.java:612)
at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:303)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:165)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:141)
at org.apache.pig.tools.grunt.Grunt.exec(Grunt.java:90)
at org.apache.pig.Main.run(Main.java:500)
at org.apache.pig.Main.main(Main.java:107)
Caused by: org.apache.pig.PigException: ERROR 1002: Unable to store alias H2
at org.apache.pig.PigServer.storeEx(PigServer.java:888)
at org.apache.pig.PigServer.store(PigServer.java:826)
at org.apache.pig.PigServer.openIterator(PigServer.java:738)
... 7 more
Caused by: org.apache.pig.backend.executionengine.ExecException: ERROR 2043: Unexpected error during execution.
at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.execute(HExecutionEngine.java:403)
at org.apache.pig.PigServer.executeCompiledLogicalPlan(PigServer.java:1208)
at org.apache.pig.PigServer.storeEx(PigServer.java:884)
... 9 more
Caused by: java.lang.ClassCastException: org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLoad cannot be cast to org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLocalRearrange
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizer.visitMROp(SecondaryKeyOptimizer.java:352)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceOper.visit(MapReduceOper.java:246)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceOper.visit(MapReduceOper.java:41)
at org.apache.pig.impl.plan.DepthFirstWalker.depthFirst(DepthFirstWalker.java:69)
at org.apache.pig.impl.plan.DepthFirstWalker.depthFirst(DepthFirstWalker.java:71)
at org.apache.pig.impl.plan.DepthFirstWalker.walk(DepthFirstWalker.java:52)
at org.apache.pig.impl.plan.PlanVisitor.visit(PlanVisitor.java:51)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.compile(MapReduceLauncher.java:498)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.launchPig(MapReduceLauncher.java:117)
at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.execute(HExecutionEngine.java:378)
... 11 more
But, when I removed the DISTINCT statement before COGROUP, i.e. ""B = distinct B;""  this script can run smoothly.
I have also tried other reducer side operations like ORDER, it seems that they will also trigger above error.
This is really very confusing.","src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler.LimitAdjuster
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.KeyTypeDiscoveryVisitor
test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler.RearrangeAdjuster
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler
test.org.apache.pig.test.TestMRCompiler"
CLASS,pig-0.8.0,PIG-1813,2011-01-20T10:25:01.000-06:00,Pig 0.8 throws ERROR 1075 while trying to refer a map in the result of  eval udf.Works with 0.7,"flatten(org.myudf.GETFIRST(value))  
 PigStorage()
register myudf.jar;
A = load 'input' MyZippedStorage('\u0001') as ($inputSchema);
B = foreach A generate id , value  ;
C = foreach B generate id , org.myudf.ExplodeHashList( (chararray)value, '\u0002', '\u0004', '\u0003') as value;
D = FILTER C by value is not null;
E = foreach D generate id , flatten(org.myudf.GETFIRST(value)) as hop;
F = foreach E generate id , hop#'rmli' as rmli:bytearray ;
store F into 'output.bz2' using PigStorage();
The above script fails when run with Pig 0.8 but runs fine with Pig 0.7 or if pig.usenewlogicalplan=false.
The below is the exception thrown in 0.8 :
org.apache.pig.backend.executionengine.ExecException: ERROR 1075: Received a bytearray from the UDF. Cannot determine how to convert the bytearray to map.
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POCast.getNext(POCast.java:952)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POMapLookUp.processInput(POMapLookUp.java:87)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POMapLookUp.getNext(POMapLookUp.java:98)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POMapLookUp.getNext(POMapLookUp.java:117)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.processPlan(POForEach.java:346)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.getNext(POForEach.java:291)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.runPipeline(PigMapBase.java:236)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.map(PigMapBase.java:231)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.map(PigMapBase.java:53)
at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)
at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:638)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:314)
at org.apache.hadoop.mapred.Child$4.run(Child.java:217)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1062)
at org.apache.hadoop.mapred.Child.main(Child.java:211)","src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc
test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.newplan.logical.relational.LOGenerate"
CLASS,pig-0.8.0,PIG-1831,2011-01-28T04:02:31.000-06:00,Indeterministic behavior in local mode due to static variable PigMapReduce.sJobConf,"PigStorage()
The below script when run in local mode gives me a different output.
It looks like in local mode I have to store a relation obtained through streaming in order to use it afterwards.
DEFINE MySTREAMUDF `test.sh`;
A  = LOAD 'myinput' USING PigStorage() AS (myId:chararray, data2, data3,data4 );
B = STREAM A THROUGH MySTREAMUDF AS (wId:chararray, num:int);
--STORE B into 'output.B';
C = JOIN B by wId LEFT OUTER, A by myId;
D = FOREACH C GENERATE B::wId,B::num,data4 ;
D = STREAM D THROUGH MySTREAMUDF AS (f1:chararray,f2:int);
--STORE D into 'output.D';
E = foreach B GENERATE wId,num;
F = DISTINCT E;
G = GROUP F ALL;
H = FOREACH G GENERATE COUNT_STAR(F) as TotalCount;
I = CROSS D,H;
STORE I  into 'output.I';
test.sh
---------
#/bin/bash
cut -f1,3
Here if I store relation B and D then everytime i get the result  :
acbd            3
abcd            3
adbc            3
But if i dont store relations B and D then I get an empty output.
Here again I have observed that this behaviour is random ie sometimes like 1out of 5 runs there will be output.","src.org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POMergeCogroup
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POPackage
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POPartitionRearrange
src.org.apache.pig.builtin.Distinct
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.PODistinct
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POJoinPackage
src.org.apache.pig.data.InternalSortedBag
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POMergeJoin
src.org.apache.pig.impl.builtin.DefaultIndexableLoader
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce.Map
src.org.apache.pig.impl.io.FileLocalizer
test.org.apache.pig.test.TestFinish
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.partitioners.SkewedPartitioner
src.org.apache.pig.backend.hadoop.streaming.HadoopExecutableManager
src.org.apache.pig.data.InternalCachedBag
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce
test.org.apache.pig.test.TestPruneColumn
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POCombinerPackage
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase
test.org.apache.pig.test.TestFRJoin
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POSort
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POCollectedGroup
test.org.apache.pig.test.utils.FILTERFROMFILE
src.org.apache.pig.data.InternalDistinctBag"
CLASS,pig-0.8.0,PIG-1843,2011-02-04T20:42:39.000-06:00,NPE in schema generation,"{code}
   
   ;
{code}
{code}
public class MapGenerate extends EvalFunc<Map> {
    @Override
    public Map exec(Tuple input) throws IOException {
        Map m = new HashMap();
        m.put(""key"", new Integer(input.size()));
        return m;
    }
    
    @Override
    public Schema outputSchema(Schema input) {
        return new Schema(new Schema.FieldSchema(getSchemaName(""parselong"", input), DataType.MAP));
    }
}
{code}
Hit NPE in following script:
{code}
a = load 'table_testBagDereferenceInMiddle2' as (a0:chararray);
b = foreach a generate MapGenerate(STRSPLIT(a0).
$0));
{code}
{code}
public class MapGenerate extends EvalFunc<Map> {
    @Override
    public Map exec(Tuple input) throws IOException {
        Map m = new HashMap();
        m.put(""key"", new Integer(input.size()));
        return m;
    }
    
    @Override
    public Schema outputSchema(Schema input) {
        return new Schema(new Schema.FieldSchema(getSchemaName(""parselong"", input), DataType.MAP));
    }
}
{code}
Error message:
Caused by: java.lang.NullPointerException
at org.apache.pig.EvalFunc.getSchemaName(EvalFunc.java:76)
at string.PARSELONG.outputSchema(PARSELONG.java:63)
at org.apache.pig.newplan.logical.expression.UserFuncExpression.getFieldSchema(UserFuncExpression.java:154)
at org.apache.pig.newplan.logical.optimizer.FieldSchemaResetter.execute(SchemaResetter.java:192)
at org.apache.pig.newplan.logical.expression.AllSameExpressionVisitor.visit(AllSameExpressionVisitor.java:143)
at org.apache.pig.newplan.logical.expression.UserFuncExpression.accept(UserFuncExpression.java:71)
at org.apache.pig.newplan.ReverseDependencyOrderWalker.walk(ReverseDependencyOrderWalker.java:70)
at org.apache.pig.newplan.PlanVisitor.visit(PlanVisitor.java:50)
at org.apache.pig.newplan.logical.optimizer.SchemaResetter.visit(SchemaResetter.java:104)
at org.apache.pig.newplan.logical.relational.LOGenerate.accept(LOGenerate.java:240)
at org.apache.pig.newplan.DependencyOrderWalker.walk(DependencyOrderWalker.java:75)
at org.apache.pig.newplan.logical.optimizer.SchemaResetter.visit(SchemaResetter.java:93)
at org.apache.pig.newplan.logical.relational.LOForEach.accept(LOForEach.java:73)
at org.apache.pig.newplan.DependencyOrderWalker.walk(DependencyOrderWalker.java:75)
at org.apache.pig.newplan.PlanVisitor.visit(PlanVisitor.java:50)
at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.compile(HExecutionEngine.java:279)
at org.apache.pig.PigServer.compilePp(PigServer.java:1480)
at org.apache.pig.PigServer.explain(PigServer.java:1042)","test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.EvalFunc"
CLASS,pig-0.8.0,PIG-1856,2011-02-15T17:26:16.000-06:00,Custom jar is not packaged with the new job created by LimitAdjuster,"{code}
 
  
 {code}
{code}
A = load 'data' as (s, m);
B = order A by s parallel 2;
C = limit B 20;
store C into 'output' using org.apache.pig.piggybank.storage.PigStorageSchema('\t')
{code}
where piggybank jar is in the classpath.
The script, however,  fails since the piggybank jar isn't shipped to the backend with the additional job created by the LimitAdjuster.
The workaround is to explicitly register the piggybank jar in the script.","src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler
test.org.apache.pig.test.TestMRCompiler"
CLASS,pig-0.8.0,PIG-1858,2011-02-17T02:27:48.000-06:00,UDF in nested plan results frontend exception,"{code}
 
 PigStorage()  
 {
        Pvs = order B by pvs;
        Const = org.vivek.MyAnotherUDF(Pvs.pvs).(count,sum);
        generate Const.sum as sum;
        } 
   ;
{code}
(count,sum);
        generate Const.sum as sum;
        };
store D into 'out_D';
{code}
The script is failing during compilation of the plan.
The usage of the udf inside the foreach is causing the problem.
The udf implements algebraic and the 
output schema is also defined.
The below is the exception that I get :
ERROR 2042: Error in new logical plan.
Try -Dpig.usenewlogicalplan=false.
org.apache.pig.impl.logicalLayer.FrontendException: ERROR 2042: Error in new logical plan. Try -Dpig.usenewlogicalplan=false.
at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.compile(HExecutionEngine.java:309)
at org.apache.pig.PigServer.compilePp(PigServer.java:1364)
at org.apache.pig.PigServer.executeCompiledLogicalPlan(PigServer.java:1206)
at org.apache.pig.PigServer.execute(PigServer.java:1200)
at org.apache.pig.PigServer.access$100(PigServer.java:128)
at org.apache.pig.PigServer$Graph.execute(PigServer.java:1527)
at org.apache.pig.PigServer.executeBatchEx(PigServer.java:372)
at org.apache.pig.PigServer.executeBatch(PigServer.java:339)
at org.apache.pig.tools.grunt.GruntParser.executeBatch(GruntParser.java:112)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:169)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:141)
at org.apache.pig.tools.grunt.Grunt.exec(Grunt.java:90)
at org.apache.pig.Main.run(Main.java:500)
at org.apache.pig.Main.main(Main.java:107)
Caused by: java.lang.NullPointerException
at org.apache.pig.newplan.ReverseDependencyOrderWalker.walk(ReverseDependencyOrderWalker.java:70)
at org.apache.pig.newplan.PlanVisitor.visit(PlanVisitor.java:50)
at org.apache.pig.newplan.logical.optimizer.SchemaResetter.visit(SchemaResetter.java:105)
at org.apache.pig.newplan.logical.relational.LOGenerate.accept(LOGenerate.java:229)
at org.apache.pig.newplan.DependencyOrderWalker.walk(DependencyOrderWalker.java:75)
at org.apache.pig.newplan.logical.optimizer.SchemaResetter.visit(SchemaResetter.java:94)
at org.apache.pig.newplan.logical.relational.LOForEach.accept(LOForEach.java:71)
at org.apache.pig.newplan.DependencyOrderWalker.walk(DependencyOrderWalker.java:75)
at org.apache.pig.newplan.PlanVisitor.visit(PlanVisitor.java:50)
at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.compile(HExecutionEngine.java:261)
... 13 more
When i trun off new logical plan the script executes successfully.
The issue is observed in both 0.8 and 0.9",test.org.apache.pig.test.TestEvalPipeline2
CLASS,pig-0.8.0,PIG-1861,2011-02-18T12:39:53.000-06:00,The pig script stored in the Hadoop History logs is stored as a concatenated string without whitespace this causes problems when attempting to extract and execute the script,"{}  {}  {} 
 statement1;statement2;
a = load '$in' using com.yahoo.grid.sath.JobHistoryLoader() as
(job:map[],maps:bag{},reducers:bag{},other:bag{},conf:map[]);
The pig script stored in: conf#'pig.script' has the whitespace removed, this makes it difficult to extract and run the
script.
In particular, statements that terminate in "";"" work correctly as
""statement1;statement2;statement99""  but statements that do not end in "";"" result in
""statement1statement2statement3"" and it's difficult to parse the pig script and fix the concatenated string.
There's also a problem with comments as in:
/*mycomment*//*more comments*/ PIG_CODE //comment PIG_CODE
On a side note, I also noticed that in many of the scripts the last statement is missing "";""","test.org.apache.pig.test.TestPigStats
src.org.apache.pig.tools.pigstats.ScriptState"
CLASS,pig-0.8.0,PIG-1866,2011-02-23T14:01:13.000-06:00,Dereference a bag within a tuple does not work,"{code}
     
 t.b1;
dump b;
{code}
{code}
a = load '1.
txt' as (t : tuple(i: int, b1: bag { b_tuple : tuple ( b_str: chararray) }));
b = foreach a generate t.b1;
dump b;
{code}
1 txt:
(1 {(one),(two)})
Error from old logical plan:
java.lang.ClassCastException: org.apache.pig.data.BinSedesTuple cannot be cast to org.apache.pig.data.DataBag
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject.processInputBag(POProject.java:482)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject.getNext(POProject.java:197)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject.processInputBag(POProject.java:480)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject.getNext(POProject.java:197)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.processPlan(POForEach.java:339)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.getNext(POForEach.java:291)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.runPipeline(PigMapBase.java:237)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.map(PigMapBase.java:232)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.map(PigMapBase.java:53)
at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)
at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:621)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:305)
at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:177)
Error from new logical plan:
java.lang.NullPointerException
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject.consumeInputBag(POProject.java:246)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject.getNext(POProject.java:200)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.processPlan(POForEach.java:339)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.getNext(POForEach.java:291)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.runPipeline(PigMapBase.java:237)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.map(PigMapBase.java:232)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.map(PigMapBase.java:53)
at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)
at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:621)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:305)
at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:177)
If we change ""b = foreach a generate t.b1;"" to ""b = foreach a generate t.i;"", it works fine, only refer to a bag does not work.","src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject
test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.newplan.logical.relational.LogToPhyTranslationVisitor
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler"
CLASS,pig-0.8.0,PIG-1868,2011-02-24T00:42:05.000-06:00,New logical plan fails when I have complex data types from udf,"{code}
 
 {
 Tuples = order B1 by ts;
 generate Tuples;
} 
   { t: ( previous, current, next ) } 
 as id;
dump C3;
{code}

 
 {code}
 
 {code}

  on C1 ;
{code}
C1: {seq: {t: (previous: (id: chararray,ts: int,url: chararray),current: (id: chararray,ts: int,url: chararray),next: (id: chararray,ts: int,url: chararray))}}
{code}
The new logical plan fails when I have complex data types returning from my eval function.
{code}
register myudf.jar;   
B1 = load 'myinput' as (id:chararray,ts:int,url:chararray);
B2 = group B1 by id;
B = foreach B2 {
 Tuples = order B1 by ts;
 generate Tuples;
};
C1 = foreach B generate TransformToMyDataType(Tuples,-1,0,1) as seq: { t: ( previous, current, next ) };
C2 = foreach C1 generate FLATTEN(seq);
C3 = foreach C2 generate  current.id as id;
dump C3;
{code}
On C3 it fails with below message :
{code}
Couldn't find matching uid -1 for project (Name: Project Type: bytearray Uid: 45 Input: 0 Column: 1)
{code}
The script works if I turn off new logical plan or use Pig 0.7.","src.org.apache.pig.newplan.logical.relational.LogicalSchema
test.org.apache.pig.test.TestSchema"
CLASS,pig-0.8.0,PIG-1892,2011-03-10T02:44:12.000-06:00,Bug in new logical plan : No output generated even though there are valid records,"Maploader()
I have the below script which provides me no output even though there are valid records in relation B which is used for the left out join.
A0 = load 'input' using Maploader()  as ( map1, map2, map3 );
A = filter A0 by ( (map2#'params'#'prop' == 464)   and (map2#'params'#'query' is not null) );
B0 = filter A by (map1#'type' == 'c');
B = filter B0 by ( map2#'info'#'s' matches 'aaaa|bbb|cccc');
C =  filter A by (map1#'type' == 'p');
D = join B by map2#'params'#'query' LEFT OUTER , C by map2#'params'#'query';
store D into 'output';
This is a bug with the newlogical plan.
From the plan i can see that  map1#'type'  and map2#'info'#'s' is not marked as RequiredKeys ,
but where as all the fields reffered in the firts filter statement is marked as required.","test.org.apache.pig.test.TestPruneColumn.PigStorageWithTrace
src.org.apache.pig.newplan.logical.rules.MapKeysPruneHelper
test.org.apache.pig.test.TestPruneColumn"
CLASS,pig-0.8.0,PIG-1893,2011-03-10T20:43:13.000-06:00,Pig report input size -1 for empty input file,"{code}
 
 by b0;
dump c;
{code}
{code} a = load '1.txt' as (a0, a1);
b = load '2.txt' as (b0, b1);
c = join a by a0, b by b0;
dump c;
{code}
If 1.txt is empty, Pig will report
Successfully read -1 records from: ""1.txt""
In WebUI, we can see we only have one MultiInputCounters: ""Input records from _0_2.txt"".","src.org.apache.pig.tools.pigstats.JobStats
test.org.apache.pig.test.TestPigRunner"
CLASS,pig-0.8.0,PIG-1910,2011-03-16T12:50:00.000-05:00,incorrect schema shown when project-star is used with other projections,"{code}
 
 describe f;
f: {a: bytearray,(null),b: bytearray}   
 {code}
{code}
grunt> l = load 'x' ;                                       
grunt> f = foreach l generate $1 as a, *, $2 as b;          
grunt> describe f;
f: {a: bytearray,(null),b: bytearray}  -- The tuple returned by * is automatically flattened, so this schema is not correct.
{code}","src.org.apache.pig.newplan.logical.expression.DereferenceExpression
src.org.apache.pig.newplan.logical.expression.ExpToPhyTranslationVisitor
src.org.apache.pig.newplan.logical.relational.LOCogroup
src.org.apache.pig.newplan.logical.expression.ProjectExpression
test.org.apache.pig.test.TestPigServer
test.org.apache.pig.test.Util"
CLASS,pig-0.8.0,PIG-1912,2011-03-16T16:11:46.000-05:00,non-deterministic output when a file is loaded multiple times,"while (( i < 10 ));  
  
 {results[*]}

 
  
  
  
 
 
  
  
 @operasolutions.com
(360)
I have a small demonstration script (actually, a directory with one main script and several other scripts that it calls) where the output (STOREd to a file) is not consistent between runs.
I will paste the files below this message, and I can also email the tarball to anybody who would like it; I wanted to just upload the tarball but I don't see a way to do that.
The problem appears to be that when a dataset X gets LOADed twice, with things other than LOADs occurring between the loads (like a FOREACH GENERATE), a FOREACH GENERATE that is later performed on X doesn't always choose the correct columns.
The correctness of the output was highly variable on my computer, for one of my co-workers it *almost* always failed, and for two other of my co-workers they didn't see any failures, so it's likely to be a race condition or something like that.
-- I will paste the name of the file as a comment, with the content of the file beneath it.
-- I will put the contents of the following files:
- 1) The Pig scripts (main.pig, calc_x_W.
pig, calc_x_Y.
pig, and load_raw_data.
pig)
- 2) The input data file (data.csv)
- 3) The correct output file (correct_output.
csv)
- 4) The shell script that runs the pig files and compares their output to what it should be
- 5) README
-- main.pig
RUN calc_x_W.
pig;
RUN calc_x_Y.
pig;
STORE x_W INTO 'output/W' USING PigStorage(',');
STORE x_Y INTO 'output/Y' USING PigStorage(',');  -- this is wrong sometimes
-- calc_x_W.
pig
RUN load_raw_data.
pig;
x_W = FOREACH raw_data GENERATE x, w;
-- calc_x_Y.
pig
RUN load_raw_data.
pig;
x_Y = FOREACH raw_data GENERATE x, y;
-- load_raw_data.
pig
raw_data = LOAD 'data.csv' USING PigStorage(',')
AS (
x,
y,
w
);
-- data.csv
x1,CORRECT  ANSWER,21148.59
x2,CORRECT  OUTPUT,27219.98
x3,RIGHT    ANSWER,10818.15
-- correct_output.
csv
x1,CORRECT  ANSWER
x2,CORRECT  OUTPUT
x3,RIGHT    ANSWER
-- testmany.sh
typeset -a results
i=0
while (( i < 10 )); do
rm -rf output/*
pig -x local -d WARN -e ""set debug off;run main.pig"" || break
diff correct_output.
csv output/Y/part-m-00000 && echo good
results[$i]=$?
i=$((i+1))
done;
echo ${results[*]}
-- README
This directory is intended to show a non-deterministic bug in pig.
Non-deterministic in the sense that the output of the script is not
the same between different times it is run on the same input; usually
the input is right, but sometimes it's wrong for no apparent reason.
The scripts and dataset included in this directory demonstrate the
issue.
The scripts load the file data.csv and write to the output
directory, but the file output/Y/part-m-00000 is sometimes different
between consecutive runs.
The root of the problem appears to be that there is an intermediate
LOAD of data.csv, after some relations have already been defined.
The following things will make the error stop:
* commenting out ""STORE x_W INTO 'output/W' USING PigStorage(',');"" in main.pig
* making a copy of data.csv called data2.csv, and a file load_daw_data2.
pig
that loads data2.csv and having having calc_x_W.
pig use that instead.
It's possible that this isn't a bug and I'm just mis-using Pig;
if that is the case I would greatly appreciate hearing about it.
I believe this issue was also discussed here:
http://mail-archives.apache.org/mod_mbox/pig-user/201102.mbox/%3CAANLkTi=2ZtkVGJevKLYSSzSH--KCcX38+Xaw2d2STNiS@mail.gmail.com%3E
I have a shell script testmany.sh which runs my script multiple times
and reports for which runs the output agrreed with the file correct_output.
csv.
IMPORTANT NOTE: We have run this code on 4 different laptops, all running
pig 0.8.0.
On one laptop (the one I'm using) the output of this script
was highly non-deterministic, generally giving both the wrong and the right
output several times each during 10 runs.
Another laptop consistently got
the wrong output up until the 28th run, when it finally gave the right output.
The other two computer never actually observed the wrong output.
We suspect
this is likely a race condition.
Thanks!
USAGE
$ cd pigbug
$ bash testmany.sh
$ # the last line of output will be a sequence of 0s and 1s, with 1
$ # meaning that there was disagreement between the output and
$ # correct_output.
csv
Field Cady
field.cady@gmail.com
fcady@operasolutions.com
(360)621-4810","src.org.apache.pig.backend.hadoop.executionengine.HExecutionEngine
test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.newplan.logical.relational.LogToPhyTranslationVisitor
src.org.apache.pig.newplan.logical.relational.LOLoad"
CLASS,pig-0.8.0,PIG-1927,2011-03-21T19:23:54.000-05:00,Dereference partial name failed,"{code}
 
 generate e0;
describe f;
{code}
The following script fail:
{code}
a = load '1.txt' as (a0:int, a1);
b = group a by a0;
c = foreach b generate flatten(a);
d = cogroup c by (a0);
e = foreach d generate c.a0 as e0;
f = foreach e generate e0;
describe f;
{code}
Error message:
Caused by: Failed to generate logical plan. Nested exception: org.apache.pig.impl.logicalLayer.FrontendException: ERROR 0: Cannot find field a0 in a::a0#17:int,a::a1#18:bytearray
at org.apache.pig.parser.LogicalPlanGenerator.alias_col_ref(LogicalPlanGenerator.java:12835)
at org.apache.pig.parser.LogicalPlanGenerator.col_ref(LogicalPlanGenerator.java:12697)
at org.apache.pig.parser.LogicalPlanGenerator.projectable_expr(LogicalPlanGenerator.java:7715)
at org.apache.pig.parser.LogicalPlanGenerator.var_expr(LogicalPlanGenerator.java:7491)
at org.apache.pig.parser.LogicalPlanGenerator.expr(LogicalPlanGenerator.java:6904)
at org.apache.pig.parser.LogicalPlanGenerator.flatten_generated_item(LogicalPlanGenerator.java:5235)
at org.apache.pig.parser.LogicalPlanGenerator.generate_clause(LogicalPlanGenerator.java:11022)
at org.apache.pig.parser.LogicalPlanGenerator.foreach_plan(LogicalPlanGenerator.java:10789)
at org.apache.pig.parser.LogicalPlanGenerator.foreach_clause(LogicalPlanGenerator.java:10670)
at org.apache.pig.parser.LogicalPlanGenerator.op_clause(LogicalPlanGenerator.java:1280)
at org.apache.pig.parser.LogicalPlanGenerator.general_statement(LogicalPlanGenerator.java:646)
at org.apache.pig.parser.LogicalPlanGenerator.statement(LogicalPlanGenerator.java:467)
at org.apache.pig.parser.LogicalPlanGenerator.query(LogicalPlanGenerator.java:365)
at org.apache.pig.parser.QueryParserDriver.parse(QueryParserDriver.java:64)","test.org.apache.pig.test.TestUnionOnSchema
src.org.apache.pig.PigServer
test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.newplan.logical.expression.DereferenceExpression
src.org.apache.pig.newplan.logical.relational.LogicalSchema"
CLASS,pig-0.8.0,PIG-1955,2011-03-31T13:26:15.000-05:00,"PhysicalOperator has a member variable (non-static) Log object that is non-transient, this causes serialization errors","private final transient Log log = LogFactory.getLog(getClass());
 
 private transient Log log = LogFactory.getLog(getClass());
I found this while trying to write unit tests.
Creating a local PigServer to test my LoadFunc caused a serialization of the PhysicalOperator class, which failed due to:
.
.
Caused by: java.io.NotSerializableException: org.apache.commons.logging.impl.Log4JCategoryLog
.
.
this is easily fixed by adding the transient keyword to the definition of log.
e.g.
on trunk:
private final transient Log log = LogFactory.getLog(getClass());
on the 0.8 tag:
private transient Log log = LogFactory.getLog(getClass());","src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserComparisonFunc
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.PODemux
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLoad
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POSkewedJoin
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.PODistinct
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLocalRearrange
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POPreCombinerLocalRearrange
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POFRJoin
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POFilter
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POCombinerPackage
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POMergeJoin
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.ExpressionOperator
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POCast
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POSort
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLimit
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POMultiQueryPackage
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POCollectedGroup
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POSplit"
CLASS,pig-0.8.0,PIG-1963,2011-04-04T17:18:24.000-05:00,"in nested foreach, accumutive udf taking input from order-by does not get results in order","{code}
 
 explain d;
dump d;
{code}
b = cogroup a1 by f1, a2 by f1;
d = foreach b {
   sort1 = order a1 by f2;
   sort2 = order a2 by f2; -- secondary sort not getting used here, MYCONCATBAG gets results in wrong order
   generate group, MYCONCATBAG(sort1.f1), MYCONCATBAG(sort2.f2);
}
-- explain d;
dump d;
{code}","test.org.apache.pig.test.TestAccumulator
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.AccumulatorOptimizer"
CLASS,pig-0.8.0,PIG-1977,2011-04-07T17:27:11.000-05:00,"""Stream closed"" error while reading Pig temp files (results of intermediate jobs)","{code}
   {code}
In certain cases when compression of temporary files is on Pig scripts fail with following exception:
{code}
java.io.IOException: Stream closed at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:145) at
java.io.BufferedInputStream.fill(BufferedInputStream.java:189) at
java.io.BufferedInputStream.read(BufferedInputStream.java:237) at
java.io.DataInputStream.readByte(DataInputStream.java:248) at
org.apache.hadoop.io.file.tfile.Utils.readVLong(Utils.java:196) at
org.apache.hadoop.io.file.tfile.Utils.readVInt(Utils.java:168) at
org.apache.hadoop.io.file.tfile.Chunk$ChunkDecoder.readLength(Chunk.java:103) at
org.apache.hadoop.io.file.tfile.Chunk$ChunkDecoder.checkEOF(Chunk.java:124) at
org.apache.hadoop.io.file.tfile.Chunk$ChunkDecoder.close(Chunk.java:190) at
java.io.FilterInputStream.close(FilterInputStream.java:155) at
org.apache.pig.impl.io.TFileRecordReader.nextKeyValue(TFileRecordReader.java:85) at
org.apache.pig.impl.io.TFileStorage.getNext(TFileStorage.java:76) at
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader.nextKeyValue(PigRecordReader.java:187) at
org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:474) at
org.apache.hadoop.mapreduce.MapContext.nextKeyValue(MapContext.java:67) at
org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143) at
org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:676) at
org.apache.hadoop.mapred.MapTask.run(MapTask.java:336) at org.apache.hadoop.mapred.Child$4.run(Child.java:242) at
java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059) at
org.apache.hadoop.mapred.Child.main(Child.java:236)
{code}
The workaround is to turn off the compression (pig.tmpfilecompression=false).","test.org.apache.pig.test.TestTmpFileCompression
src.org.apache.pig.impl.io.TFileRecordReader"
CLASS,pig-0.8.0,PIG-1979,2011-04-08T02:24:01.000-05:00,New logical plan failing with ERROR 2229: Couldn't find matching uid -1,"{code}
 
  
    
    
      
     PigStorage() 
  
  
  
   PigStorage() ;
{code}

   
  
    
 {code}

 import java.io.IOException;
import org.apache.pig.EvalFunc;
import org.apache.pig.data.*;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.logicalLayer.schema.Schema.FieldSchema;

public class MyExtractor extends EvalFunc<DataBag>
{
  @Override
	public Schema outputSchema(Schema arg0) {
	  try {
			return Schema.generateNestedSchema(DataType.BAG, DataType.CHARARRAY);
		} catch (FrontendException e) {
			System.err.println(""Error while generating schema. ""+e);
			return new Schema(new FieldSchema(null, DataType.BAG));
		}
	}

  @Override
  public DataBag exec(Tuple inputTuple)
    throws IOException
  {
    try {
      Tuple tp2 = TupleFactory.getInstance().newTuple(1);
      tp2.set(0, (inputTuple.get(0).toString()+inputTuple.hashCode()));
      DataBag retBag = BagFactory.getInstance().newDefaultBag();
      retBag.add(tp2);
      return retBag;
    }
    catch (Exception e) {
      throw new IOException("" Caught exception"", e);
    }
  }
}

 {code}
= '' ;
c03 = FOREACH c02 GENERATE url, formatted, FLATTEN(usage);
c04 = FOREACH c03 GENERATE usage::domain AS domain, url, formatted;
doc_001 = FOREACH c04 GENERATE domain,url, FLATTEN(MyExtractor(formatted)) AS category;
doc_004_1 = GROUP doc_001 BY (domain,url);
doc_005 = FOREACH doc_004_1 GENERATE group.domain as domain, group.url as url, doc_001.
category as category;
STORE doc_005 INTO 'out_final' USING PigStorage();
review1 = FOREACH c04 GENERATE domain,url, MyExtractor(formatted) AS rev;
review2 = FILTER review1 BY SIZE(rev)>0;
joinresult = JOIN review2 by (domain,url), doc_005 by (domain,url);
finalresult = FOREACH joinresult GENERATE  doc_005::category;
STORE finalresult INTO 'out_final' using PigStorage();
{code}
The script is failing in building the plan, while applying for logical optimization rule for AddForEach.
ERROR org.apache.pig.tools.grunt.Grunt - ERROR 2229: Couldn't find matching uid -1 for project (Name: Project Type: bytearray Uid: 106 Input: 0 Column: 5)
This is field is orginated from the udf org.vivek.udfs.MyExtractor (source given below).
{code}
import java.io.IOException;
import org.apache.pig.EvalFunc;
import org.apache.pig.data.
*;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.logicalLayer.schema.Schema.FieldSchema;
public class MyExtractor extends EvalFunc<DataBag>
{
  @Override
	public Schema outputSchema(Schema arg0) {
	  try {
			return Schema.generateNestedSchema(DataType.BAG, DataType.CHARARRAY);
		} catch (FrontendException e) {
			System.err.println(""Error while generating schema. ""
+e);
			return new Schema(new FieldSchema(null, DataType.BAG));
		}
	}
@Override
  public DataBag exec(Tuple inputTuple)
    throws IOException
  {
    try {
      Tuple tp2 = TupleFactory.getInstance().
newTuple(1);
      tp2.set(0, (inputTuple.get(0).
toString()+inputTuple.hashCode()));
      DataBag retBag = BagFactory.getInstance().
newDefaultBag();
      retBag.add(tp2);
      return retBag;
    }
    catch (Exception e) {
      throw new IOException("" Caught exception"", e);
    }
  }
}
{code}
The script goes through fine if I disable AddForEach rule by -t AddForEach","test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.newplan.logical.expression.DereferenceExpression"
CLASS,pig-0.8.0,PIG-1993,2011-04-12T19:47:41.000-05:00,PigStorageSchema throw NPE with ColumnPruning,"{code}
 
  
  
 GENERATE a1;
dump b;
{code}
{code} a = load '1.txt' as (a0:int, a1:int, a2:int);
store a into 'temp' using org.apache.pig.piggybank.storage.PigStorageSchema();
exec a = LOAD 'temp' using org.apache.pig.piggybank.storage.PigStorageSchema();
b = FOREACH a GENERATE a1;
dump b;
{code}
Error message:
java.lang.ArrayIndexOutOfBoundsException: 2
at org.apache.pig.piggybank.storage.PigStorageSchema.getNext(PigStorageSchema.java:94)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader.nextKeyValue(PigRecordReader.java:187)
at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:423)
at org.apache.hadoop.mapreduce.MapContext.nextKeyValue(MapContext.java:67)
at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143)
at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:621)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:305)
at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:177)","contrib.piggybank.java.src.test.java.org.apache.pig.piggybank.test.TestPigStorageSchema
contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.PigStorageSchema"
CLASS,pig-0.8.0,PIG-313,2008-07-14T19:20:04.000-05:00,Error handling aggregate of a computation,"{code}
 
 {code}

 
 {quote}
   
   
   
   
   
    
    
    
    
 {quote}
{code}
a = load ':INPATH:/singlefile/studenttab10k' as (name:chararray, age:int, gpa:double);
b = group a by name;
c = foreach b generate group, SUM(a.age*a.gpa);                            
store c into ':OUTPATH:';\,
{code}
Error output:
{quote}
2008-07-14 16:34:08,684 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: testhost.com:8020
2008-07-14 16:34:08,741 [main] WARN  org.apache.hadoop.fs.FileSystem - ""testhost.com:8020"" is a deprecated filesystem name. Use ""hdfs://testhost:8020/"" instead.
2008-07-14 16:34:08,995 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to map-reduce job tracker at: testhost.com:50020
2008-07-14 16:34:09,251 [main] WARN  org.apache.hadoop.fs.FileSystem - ""testhost.com:8020"" is a deprecated filesystem name. Use ""hdfs://testhost:8020/"" instead.
2008-07-14 16:34:09,559 [main] ERROR org.apache.pig.PigServer - Cannot evaluate output type of Mul/Div Operator
2008-07-14 16:34:09,559 [main] ERROR org.apache.pig.PigServer - Problem resolving LOForEach schema
2008-07-14 16:34:09,559 [main] ERROR org.apache.pig.PigServer - Severe problem found during validation org.apache.pig.impl.plan.PlanValidationException: An unexpected exception caused the validation to stop
2008-07-14 16:34:09,560 [main] ERROR org.apache.pig.tools.grunt.Grunt - java.io.IOException: Unable to store for alias: c
2008-07-14 16:34:09,560 [main] ERROR org.apache.pig.Main - java.io.IOException: Unable to store for alias: c
{quote}",test.org.apache.pig.test.TestEvalPipeline2
CLASS,pig-0.8.0,PIG-730,2009-03-24T14:36:45.000-05:00,"problem combining schema from a union of several LOAD expressions, with a nested bag inside the schema.","flatten(outlinks.target);
  flatten(outlinks.target);
grunt> a = load 'foo' using BinStorage as (url:chararray,outlinks:{t:(target:chararray,text:chararray)});
grunt> b = union (load 'foo' using BinStorage as (url:chararray,outlinks:{t:(target:chararray,text:chararray)})), (load 'bar' using BinStorage as (url:chararray,outlinks:{t:(target:chararray,text:chararray)}));
grunt> c = foreach a generate flatten(outlinks.target);
grunt> d = foreach b generate flatten(outlinks.target);
---> Would expect both C and D to work, but only C works.
D gives the error shown below.
---> Turns out using outlinks.t.target (instead of outlinks.target) works for D but not for C.
2009-03-24 13:15:05,376 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1000: Error during parsing.
Invalid alias: target in {t: (target: chararray,text: chararray)}
Details at logfile: /echo/olston/data/pig_1237925683748.
log
grunt> quit
$ cat pig_1237925683748.log
ERROR 1000: Error during parsing. Invalid alias: target in {t: (target: chararray,text: chararray)}
org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1000: Error during parsing. Invalid alias: target in {t: (target: chararray,text: chararray)}
at org.apache.pig.PigServer.parseQuery(PigServer.java:317)
at org.apache.pig.PigServer.registerQuery(PigServer.java:276)
at org.apache.pig.tools.grunt.GruntParser.processPig(GruntParser.java:529)
at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:280)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:99)
at org.apache.pig.tools.grunt.Grunt.run(Grunt.java:69)
at org.apache.pig.Main.main(Main.java:321)
Caused by: org.apache.pig.impl.logicalLayer.parser.ParseException: Invalid alias: target in {t: (target: chararray,text: chararray)}
at org.apache.pig.impl.logicalLayer.parser.QueryParser.AliasFieldOrSpec(QueryParser.java:6042)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.ColOrSpec(QueryParser.java:5898)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.BracketedSimpleProj(QueryParser.java:5423)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.BaseEvalSpec(QueryParser.java:4100)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.UnaryExpr(QueryParser.java:3967)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.CastExpr(QueryParser.java:3920)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.MultiplicativeExpr(QueryParser.java:3829)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.AdditiveExpr(QueryParser.java:3755)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.InfixExpr(QueryParser.java:3721)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.FlattenedGenerateItem(QueryParser.java:3617)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.FlattenedGenerateItemList(QueryParser.java:3557)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.GenerateStatement(QueryParser.java:3514)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.NestedBlock(QueryParser.java:2985)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.ForEachClause(QueryParser.java:2395)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.BaseExpr(QueryParser.java:1028)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.Expr(QueryParser.java:804)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.Parse(QueryParser.java:595)
at org.apache.pig.impl.logicalLayer.LogicalPlanBuilder.parse(LogicalPlanBuilder.java:60)
at org.apache.pig.PigServer.parseQuery(PigServer.java:310)
... 6 more","src.org.apache.pig.impl.logicalLayer.schema.Schema
src.org.apache.pig.newplan.logical.expression.DereferenceExpression
src.org.apache.pig.newplan.logical.relational.LogicalSchema
test.org.apache.pig.test.TestSchema"
CLASS,pig-0.8.0,PIG-767,2009-04-15T23:43:29.000-05:00,Schema reported from DESCRIBE and actual schema of inner bags are different.,"BinStorage()  
 DESCRIBE urlContents;
DUMP urlContents;

     BY url;
DESCRIBE urlContentsG;

     urlContents.pg;

DESCRIBE urlContentsF;
DUMP urlContentsF;


 
   {url: chararray,pg: chararray}
   {group: chararray,urlContents: {url: chararray,pg: chararray}}
   {group: chararray,pg: {pg: chararray}}

      
 
    
   {group: chararray,urlContents: {t1:(url: chararray,pg: chararray)}}

  {chararray}   {(chararray)}
urlContents = LOAD 'inputdir' USING BinStorage() AS (url:bytearray, pg:bytearray);
-- describe and dump are in-sync
DESCRIBE urlContents;
DUMP urlContents;
urlContentsG = GROUP urlContents BY url;
DESCRIBE urlContentsG;
urlContentsF = FOREACH urlContentsG GENERATE group,urlContents.pg;
DESCRIBE urlContentsF;
DUMP urlContentsF;
Prints for the DESCRIBE commands:
urlContents: {url: chararray,pg: chararray}
urlContentsG: {group: chararray,urlContents: {url: chararray,pg: chararray}}
urlContentsF: {group: chararray,pg: {pg: chararray}}
The reported schemas for urlContentsG and urlContentsF are wrong.
They are also against the section ""Schemas for Complex Data Types"" in http://wiki.apache.org/pig-data/attachments/FrontPage/attachments/plrm.htm#_Schemas.
This may sound like a technicality, but it isn't.
For instance, a UDF that assumes an inner bag of {chararray} will not work with {(chararray)}.","test.org.apache.pig.test.TestNewPlanLogToPhyTranslationVisitor
src.org.apache.pig.newplan.logical.expression.DereferenceExpression
src.org.apache.pig.newplan.logical.relational.LOInnerLoad
src.org.apache.pig.newplan.logical.rules.DuplicateForEachColumnRewrite
test.org.apache.pig.test.TestLogicalPlanMigrationVisitor
src.org.apache.pig.newplan.logical.relational.LOCogroup
test.org.apache.pig.test.TestSchema
src.org.apache.pig.newplan.logical.relational.LOGenerate"
METHOD,math,MATH-1021,2013-08-10T00:00:22.000-05:00,HypergeometricDistribution.sample suffers from integer overflow,"HypergeometricDistribution.sample()  
 {code}
 import org.apache.commons.math3.distribution.HypergeometricDistribution;

public class Foo {
  public static void main(String[] args) {
    HypergeometricDistribution a = new HypergeometricDistribution(
        43130568, 42976365, 50);
    System.out.printf(""%d %d%n"", a.getSupportLowerBound(), a.getSupportUpperBound()); // Prints ""0 50""
    System.out.printf(""%d%n"",a.sample());                                             // Prints ""-50""
  }
}
 {code}

  HypergeometricDistribution.getNumericalMean()  
 {code}
 return (double) (getSampleSize() * getNumberOfSuccesses()) / (double) getPopulationSize();
{code}
 
 {code}
 return getSampleSize() * ((double) getNumberOfSuccesses() / (double) getPopulationSize());
{code}
Hi, I have an application which broke when ported from commons math 2.2 to 3.2.
It looks like the HypergeometricDistribution.sample() method doesn't work as well as it used to with large integer values -- the example code below should return a sample between 0 and 50, but usually returns -50.
{code}
import org.apache.commons.math3.distribution.HypergeometricDistribution;
public class Foo {
  public static void main(String[] args) {
    HypergeometricDistribution a = new HypergeometricDistribution(
        43130568, 42976365, 50);
    System.out.printf(""%d %d%n"", a.getSupportLowerBound(), a.getSupportUpperBound()); // Prints ""0 50""
    System.out.printf(""%d%n"",a.sample());                                             // Prints ""-50""
  }
}
{code}
In the debugger, I traced it as far as an integer overflow in HypergeometricDistribution.getNumericalMean() -- instead of doing
{code}
return (double) (getSampleSize() * getNumberOfSuccesses()) / (double) getPopulationSize();
{code}
it could do:
{code}
return getSampleSize() * ((double) getNumberOfSuccesses() / (double) getPopulationSize());
{code}
This seemed to fix it, based on a quick test.",org.apache.commons.math3.distribution.HypergeometricDistribution:getNumericalMean()
METHOD,math,MATH-209,2008-06-17T03:02:48.000-05:00,RealMatrixImpl#operate gets result vector dimensions wrong,"{{double[] out = new double[nRows];}}
 
 {{double[] out = new double[v.length];}}
{{org.apache.commons.math.linear.RealMatrixImpl#operate}} tries to create a result vector that always has the same length as the input vector.
This can result in runtime exceptions if the matrix is non-square and it always yields incorrect results if the matrix is non-square.
The correct behaviour would of course be to create a vector with the same length as the row dimension of the matrix.
Thus line 640 in RealMatrixImpl.java should read
  {{double[] out = new double[nRows];}}
instead of
  {{double[] out = new double[v.length];}}","org.apache.commons.math.linear.RealMatrixImpl:operate(double[])
org.apache.commons.math.linear.BigMatrixImpl:operate(BigDecimal[])"
METHOD,math,MATH-221,2008-08-29T13:31:56.000-05:00,Result of multiplying and equals for complex numbers is wrong,"class Complex  
 {code}
 import org.apache.commons.math.complex.*;
public class TestProg {
        public static void main(String[] args) {

                ComplexFormat f = new ComplexFormat();
                Complex c1 = new Complex(0,1);
                Complex c2 = new Complex(-1,0);

                Complex res = c1.multiply(c2);
                Complex comp = new Complex(0,-1);

                System.out.println(""res:  ""+f.format(res));
                System.out.println(""comp: ""+f.format(comp));

                System.out.println(""res=comp: ""+res.equals(comp));
        }
}
 {code}
Hi.
The bug relates on complex numbers.
The methods ""multiply"" and ""equals"" of the class Complex are involved.
mathematic background:  (0,i) * (-1,0i) = (0,-i).
-----------------------------------------------------------------------
{code}
import org.apache.commons.math.complex.
*;
public class TestProg {
public static void main(String[] args) {
ComplexFormat f = new ComplexFormat();
                Complex c1 = new Complex(0,1);
                Complex c2 = new Complex(-1,0);
Complex res = c1.multiply(c2);
                Complex comp = new Complex(0,-1);
System.out.println(""res:  ""+f.format(res));
                System.out.println(""comp: ""+f.format(comp));
System.out.println(""res=comp: ""+res.equals(comp));
}
}
{code}
-----------------------------------------------------------------------
res:  -0 - 1i
comp: 0 - 1i
res=comp: false
-----------------------------------------------------------------------
The problem could either be the ""multiply"" method that gives (-0,-1i) instead of (0,-1i),
or if you think thats right, the equals method has to be modified.
Good Luck
Dieter",org.apache.commons.math.complex.Complex:equals(Object)
METHOD,math,MATH-238,2009-01-16T22:24:24.000-06:00,"MathUtils.gcd(u, v) fails when u and v both contain a high power of 2","MathUtils.gcd(u, v)  
 assertEquals(3 * (1<<15), MathUtils.gcd(3 * (1<<20), 9 * (1<<15)));

  MathUtils.gcd()
The test at the beginning of MathUtils.gcd(u, v) for arguments equal to zero fails when u and v contain high enough powers of 2 so that their product overflows to zero.
assertEquals(3 * (1<<15), MathUtils.gcd(3 * (1<<20), 9 * (1<<15)));
Fix: Replace the test at the start of MathUtils.gcd()
if (u * v == 0) {
by
if (u == 0 || v == 0) {","org.apache.commons.math.util.MathUtils:gcd(int, int)"
METHOD,math,MATH-280,2009-07-06T21:26:57.000-05:00,bug in inverseCumulativeProbability() for Normal Distribution,"public class NormalDistributionImpl extends AbstractContinuousDistribution 


  
 public abstract class AbstractContinuousDistribution


 
 DistributionFactory factory = app.getDistributionFactory();
        	NormalDistribution normal = factory.createNormalDistribution(0,1);
        	double result = normal.inverseCumulativeProbability(0.9772498680518209);

 
 normal.inverseCumulativeProbability(0.977249868051820);
* @version $Revision: 617953 $ $Date: 2008-02-02 22:54:00 -0700 (Sat, 02 Feb 2008) $
*/
public class NormalDistributionImpl extends AbstractContinuousDistribution
* @version $Revision: 506600 $ $Date: 2007-02-12 12:35:59 -0700 (Mon, 12 Feb 2007) $
*/
public abstract class AbstractContinuousDistribution
DistributionFactory factory = app.getDistributionFactory();
        	NormalDistribution normal = factory.createNormalDistribution(0,1);
        	double result = normal.inverseCumulativeProbability(0.9772498680518209);
gives the exception below.
These also give errors:
org.apache.commons.math.MathException: Number of iterations=1, maximum iterations=2,147,483,647, initial=1, lower bound=0, upper bound=179,769,313,486,231,570,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000, final a value=0, final b value=2, f(a)=-0.477, f(b)=0
at org.apache.commons.math.distribution.AbstractContinuousDistribution.inverseCumulativeProbability(AbstractContinuousDistribution.java:103)
at org.apache.commons.math.distribution.NormalDistributionImpl.inverseCumulativeProbability(NormalDistributionImpl.java:145)","org.apache.commons.math.analysis.solvers.UnivariateRealSolverUtils:bracket(UnivariateRealFunction, double, double, double, int)"
METHOD,math,MATH-305,2009-10-22T06:35:08.000-05:00,NPE in  KMeansPlusPlusClusterer unittest,"package org.fao.fisheries.chronicles.calcuation.cluster;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;

import java.util.Arrays;
import java.util.List;
import java.util.Random;

import org.apache.commons.math.stat.clustering.Cluster;
import org.apache.commons.math.stat.clustering.EuclideanIntegerPoint;
import org.apache.commons.math.stat.clustering.KMeansPlusPlusClusterer;
import org.fao.fisheries.chronicles.input.CsvImportProcess;
import org.fao.fisheries.chronicles.input.Top200Csv;
import org.junit.Test;

public class ClusterAnalysisTest {


	@Test
	public void testPerformClusterAnalysis2() {
		KMeansPlusPlusClusterer<EuclideanIntegerPoint> transformer = new KMeansPlusPlusClusterer<EuclideanIntegerPoint>(
				new Random(1746432956321l));
		EuclideanIntegerPoint[] points = new EuclideanIntegerPoint[] {
				new EuclideanIntegerPoint(new int[] { 1959, 325100 }),
				new EuclideanIntegerPoint(new int[] { 1960, 373200 }), };
		List<Cluster<EuclideanIntegerPoint>> clusters = transformer.cluster(Arrays.asList(points), 1, 1);
		assertEquals(1, clusters.size());

	}

}
When running this unittest, I am facing this NPE:
java.lang.NullPointerException
at org.apache.commons.math.stat.clustering.KMeansPlusPlusClusterer.assignPointsToClusters(KMeansPlusPlusClusterer.java:91)
package org.fao.fisheries.chronicles.calcuation.cluster;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;
import java.util.Arrays;
import java.util.List;
import java.util.Random;
import org.apache.commons.math.stat.clustering.Cluster;
import org.apache.commons.math.stat.clustering.EuclideanIntegerPoint;
import org.apache.commons.math.stat.clustering.KMeansPlusPlusClusterer;
import org.fao.fisheries.chronicles.input.CsvImportProcess;
import org.fao.fisheries.chronicles.input.Top200Csv;
import org.junit.Test;
public class ClusterAnalysisTest {
@Test
	public void testPerformClusterAnalysis2() {
		KMeansPlusPlusClusterer<EuclideanIntegerPoint> transformer = new KMeansPlusPlusClusterer<EuclideanIntegerPoint>(
				new Random(1746432956321l));
		EuclideanIntegerPoint[] points = new EuclideanIntegerPoint[] {
				new EuclideanIntegerPoint(new int[] { 1959, 325100 }),
				new EuclideanIntegerPoint(new int[] { 1960, 373200 }), };
		List<Cluster<EuclideanIntegerPoint>> clusters = transformer.cluster(Arrays.asList(points), 1, 1);
		assertEquals(1, clusters.size());
}
}","org.apache.commons.math.util.MathUtils:distance(int[], int[])"
METHOD,math,MATH-318,2009-11-06T15:09:36.000-06:00,wrong result in eigen decomposition,"{code}
     public void testMathpbx02() {

        double[] mainTridiagonal = {
        	  7484.860960227216, 18405.28129035345, 13855.225609560746,
        	 10016.708722343366, 559.8117399576674, 6750.190788301587, 
        	    71.21428769782159
        };
        double[] secondaryTridiagonal = {
        	 -4175.088570476366,1975.7955858241994,5193.178422374075, 
        	  1995.286659169179,75.34535882933804,-234.0808002076056
        };

        // the reference values have been computed using routine DSTEMR
        // from the fortran library LAPACK version 3.2.1
        double[] refEigenValues = {
        		20654.744890306974412,16828.208208485466457,
        		6893.155912634994820,6757.083016675340332,
        		5887.799885688558788,64.309089923240379,
        		57.992628792736340
        };
        RealVector[] refEigenVectors = {
        		new ArrayRealVector(new double[] {-0.270356342026904, 0.852811091326997, 0.399639490702077, 0.198794657813990, 0.019739323307666, 0.000106983022327, -0.000001216636321}),
        		new ArrayRealVector(new double[] {0.179995273578326,-0.402807848153042,0.701870993525734,0.555058211014888,0.068079148898236,0.000509139115227,-0.000007112235617}),
        		new ArrayRealVector(new double[] {-0.399582721284727,-0.056629954519333,-0.514406488522827,0.711168164518580,0.225548081276367,0.125943999652923,-0.004321507456014}),
        		new ArrayRealVector(new double[] {0.058515721572821,0.010200130057739,0.063516274916536,-0.090696087449378,-0.017148420432597,0.991318870265707,-0.034707338554096}),
        		new ArrayRealVector(new double[] {0.855205995537564,0.327134656629775,-0.265382397060548,0.282690729026706,0.105736068025572,-0.009138126622039,0.000367751821196}),
        		new ArrayRealVector(new double[] {-0.002913069901144,-0.005177515777101,0.041906334478672,-0.109315918416258,0.436192305456741,0.026307315639535,0.891797507436344}),
        		new ArrayRealVector(new double[] {-0.005738311176435,-0.010207611670378,0.082662420517928,-0.215733886094368,0.861606487840411,-0.025478530652759,-0.451080697503958})
        };

        // the following line triggers the exception
        EigenDecomposition decomposition =
            new EigenDecompositionImpl(mainTridiagonal, secondaryTridiagonal, MathUtils.SAFE_MIN);

        double[] eigenValues = decomposition.getRealEigenvalues();
        for (int i = 0; i < refEigenValues.length; ++i) {
            assertEquals(refEigenValues[i], eigenValues[i], 1.0e-3);
            if (refEigenVectors[i].dotProduct(decomposition.getEigenvector(i)) < 0) {
                assertEquals(0, refEigenVectors[i].add(decomposition.getEigenvector(i)).getNorm(), 1.0e-5);
            } else {
                assertEquals(0, refEigenVectors[i].subtract(decomposition.getEigenvector(i)).getNorm(), 1.0e-5);
            }
        }

    }
 {code}
Some results computed by EigenDecompositionImpl are wrong.
The following case computed by Fortran Lapack fails with version 2.0
{code}
    public void testMathpbx02() {
double[] mainTridiagonal = {
7484.860960227216, 18405.28129035345, 13855.225609560746,
10016.708722343366, 559.8117399576674, 6750.190788301587,
71.21428769782159
};
double[] secondaryTridiagonal = {
-4175.088570476366,1975.7955858241994,5193.178422374075,
1995.286659169179,75.34535882933804,-234.0808002076056
};
// the reference values have been computed using routine DSTEMR
// from the fortran library LAPACK version 3.2.1
double[] refEigenValues = {
20654.744890306974412,16828.208208485466457,
6893.155912634994820,6757.083016675340332,
5887.799885688558788,64.309089923240379,
57.992628792736340
};
RealVector[] refEigenVectors = {
new ArrayRealVector(new double[] {-0.270356342026904, 0.852811091326997, 0.399639490702077, 0.198794657813990, 0.019739323307666, 0.000106983022327, -0.000001216636321}),
new ArrayRealVector(new double[] {0.179995273578326,-0.402807848153042,0.701870993525734,0.555058211014888,0.068079148898236,0.000509139115227,-0.000007112235617}),
new ArrayRealVector(new double[] {-0.399582721284727,-0.056629954519333,-0.514406488522827,0.711168164518580,0.225548081276367,0.125943999652923,-0.004321507456014}),
new ArrayRealVector(new double[] {0.058515721572821,0.010200130057739,0.063516274916536,-0.090696087449378,-0.017148420432597,0.991318870265707,-0.034707338554096}),
new ArrayRealVector(new double[] {0.855205995537564,0.327134656629775,-0.265382397060548,0.282690729026706,0.105736068025572,-0.009138126622039,0.000367751821196}),
new ArrayRealVector(new double[] {-0.002913069901144,-0.005177515777101,0.041906334478672,-0.109315918416258,0.436192305456741,0.026307315639535,0.891797507436344}),
new ArrayRealVector(new double[] {-0.005738311176435,-0.010207611670378,0.082662420517928,-0.215733886094368,0.861606487840411,-0.025478530652759,-0.451080697503958})
};
// the following line triggers the exception
        EigenDecomposition decomposition =
            new EigenDecompositionImpl(mainTridiagonal, secondaryTridiagonal, MathUtils.SAFE_MIN);
double[] eigenValues = decomposition.getRealEigenvalues();
        for (int i = 0; i < refEigenValues.length; ++i) {
            assertEquals(refEigenValues[i], eigenValues[i], 1.0e-3);
            if (refEigenVectors[i].
dotProduct(decomposition.getEigenvector(i)) < 0) {
                assertEquals(0, refEigenVectors[i].
add(decomposition.getEigenvector(i)).
getNorm(), 1.0e-5);
            } else {
                assertEquals(0, refEigenVectors[i].
subtract(decomposition.getEigenvector(i)).
getNorm(), 1.0e-5);
            }
        }
}
{code}","org.apache.commons.math.linear.EigenDecompositionImpl:flipIfWarranted(int, int)"
METHOD,math,MATH-326,2009-12-29T00:09:20.000-06:00,getLInfNorm() uses wrong formula in both ArrayRealVector and OpenMapRealVector (in different ways),"{code}
     public double getLInfNorm() {
        double max = 0;
        for (double a : data) {
            max += Math.max(max, Math.abs(a));
        }
        return max;
    }
 {code}

 
  
 {code}   
     public double getLInfNorm() {
        double max = 0;
        Iterator iter = entries.iterator();
        while (iter.hasNext()) {
            iter.advance();
            max += iter.value();
        }
        return max;
    }
 {code}

    sparseIterator() 
 {code}
   public double getLInfNorm() {
    double norm = 0;
    Iterator<Entry> it = sparseIterator();
    Entry e;
    while(it.hasNext() && (e = it.next()) != null) {
      norm = Math.max(norm, Math.abs(e.getValue()));
    }
    return norm;
  }
 {code}
the L_infinity norm of a finite dimensional vector is just the max of the absolute value of its entries.
The current implementation in ArrayRealVector has a typo:
{code} public double getLInfNorm() { double max = 0;
for (double a : data) { max += Math.max(max, Math.abs(a));
} return max;
}
{code}
There is sadly a unit test assuring us that this is the correct behavior (effectively a regression-only test, not a test for correctness).
Worse, the implementation in OpenMapRealVector is not even positive semi-definite:
{code} public double getLInfNorm() { double max = 0;
Iterator iter = entries.iterator();
while (iter.hasNext()) { iter.advance();
max += iter.value();
} return max;
}
{code}
{code} public double getLInfNorm() { double norm = 0;
Iterator<Entry> it = sparseIterator();
Entry e;
while(it.hasNext() && (e = it.next()) !
= null) { norm = Math.max(norm, Math.abs(e.getValue()));
} return norm;
}
{code}
Unit tests with negative valued vectors would be helpful to check for this kind of thing in the future.","org.apache.commons.math.linear.ArrayRealVector:getLInfNorm()
org.apache.commons.math.linear.OpenMapRealVector:getLInfNorm()"
METHOD,math,MATH-358,2010-03-24T17:25:37.000-05:00,ODE integrator goes past specified end of integration range,"{code}
   public void testMissedEvent() throws IntegratorException, DerivativeException {
          final double t0 = 1878250320.0000029;
          final double t =  1878250379.9999986;
          FirstOrderDifferentialEquations ode = new FirstOrderDifferentialEquations() {
            
            public int getDimension() {
                return 1;
            }
            
            public void computeDerivatives(double t, double[] y, double[] yDot)
                throws DerivativeException {
                yDot[0] = y[0] * 1.0e-6;
            }
        };

        DormandPrince853Integrator integrator = new DormandPrince853Integrator(0.0, 100.0,
                                                                               1.0e-10, 1.0e-10);

        double[] y = { 1.0 };
        integrator.setInitialStepSize(60.0);
        double finalT = integrator.integrate(ode, t0, y, t, y);
        Assert.assertEquals(t, finalT, 1.0e-6);
    }

 {code}
End of integration range in ODE solving is handled as an event.
In some cases, numerical accuracy in events detection leads to error in events location.
The following test case shows the end event is not handled properly and an integration that should cover a 60s range in fact covers a 160s range, more than twice the specified range.
{code}
public void testMissedEvent() throws IntegratorException, DerivativeException {
final double t0 = 1878250320.0000029;
final double t =  1878250379.9999986;
FirstOrderDifferentialEquations ode = new FirstOrderDifferentialEquations() {
public int getDimension() {
return 1;
}
public void computeDerivatives(double t, double[] y, double[] yDot)
throws DerivativeException {
yDot[0] = y[0] * 1.0e-6;
}
};
DormandPrince853Integrator integrator = new DormandPrince853Integrator(0.0, 100.0,
1 0e-10, 1.0e-10);
double[] y = { 1.0 };
        integrator.setInitialStepSize(60.0);
        double finalT = integrator.integrate(ode, t0, y, t, y);
        Assert.assertEquals(t, finalT, 1.0e-6);
    }
{code}","org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator:integrate(FirstOrderDifferentialEquations, double, double[], double, double[])
org.apache.commons.math.ode.nonstiff.RungeKuttaIntegrator:integrate(FirstOrderDifferentialEquations, double, double[], double, double[])"
METHOD,math,MATH-369,2010-05-03T15:48:27.000-05:00,"BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial) throws NullPointerException","new BisectionSolver()  solve(someUnivariateFunctionImpl, 0.0, 1.0, 0.5);
Method
BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial)
invokes
BisectionSolver.solve(double min, double max)
which throws NullPointerException, as member variable
UnivariateRealSolverImpl.f
is null.
Instead the method:
BisectionSolver.solve(final UnivariateRealFunction f, double min, double max)
should be called.
Steps to reproduce:
new BisectionSolver().
solve(someUnivariateFunctionImpl, 0.0, 1.0, 0.5);
NullPointerException will be thrown.","org.apache.commons.math.analysis.solvers.BisectionSolver:solve(UnivariateRealFunction, double, double, double)"
METHOD,math,MATH-393,2010-07-25T00:14:20.000-05:00,"Method ""getResult()"" in ""MultiStartUnivariateRealOptimizer""","{code} 
 public double getResult() {
    return optima[0];
}
 {code}
 
 {code}
 public double getFunctionValue() {
    return optimaValues[0];
}
 {code}
In ""MultiStartUnivariateRealOptimizer"" (package ""optimization""), the method ""getResult"" returns the result of the last run of the ""underlying"" optimizer; this last result might not be the best one, in which case it will not correspond to the value returned by the ""optimize"" method.
This is confusing and does not seem very useful.
I think that ""getResult"" should be defined as
{code} 
public double getResult() {
    return optima[0];
}
{code}
and similarly
{code}
public double getFunctionValue() {
    return optimaValues[0];
}
{code}","org.apache.commons.math.optimization.MultiStartUnivariateRealOptimizer:getFunctionValue()
org.apache.commons.math.optimization.MultiStartUnivariateRealOptimizer:getResult()"
METHOD,math,MATH-482,2011-01-17T19:52:10.000-06:00,"FastMath.max(50.0f, -50.0f) => -50.0f; should be +50.0f","FastMath.max(50.0f, -50.0f)  
 testMinMaxFloat()
FastMath.max(50.0f, -50.0f) => -50.0f; should be +50.0f.
This is because the wrong variable is returned.
The bug was not detected by the test case ""testMinMaxFloat()"" because that has a bug too - it tests doubles, not floats.","org.apache.commons.math.util.FastMath:max(float, float)"
METHOD,math,MATH-546,2011-03-12T04:52:54.000-06:00,Truncation issue in KMeansPlusPlusClusterer,"int sum = 0;
The for loop inside KMeansPlusPlusClusterer.chooseInitialClusters defines a variable
  int sum = 0;
This variable should have type double, rather than int.
Using an int causes the method to truncate the distances between points to (square roots of) integers.
It's especially bad when the distances between points are typically less than 1.
As an aside, in version 2.2, this bug manifested itself by making the clusterer return empty clusters.
I wonder if the EmptyClusterStrategy would still be necessary if this bug were fixed.","org.apache.commons.math.stat.clustering.KMeansPlusPlusClusterer:chooseInitialCenters(Collection<T>, int, Random)"
METHOD,math,MATH-552,2011-03-31T22:36:56.000-05:00,MultidimensionalCounter.getCounts(int) returns wrong array of indices,"MultidimensionalCounter counter = new MultidimensionalCounter(2, 4);
for (Integer i : counter) {
    int[] x = counter.getCounts(i);
    System.out.println(i + "" "" + Arrays.toString(x));
}
MultidimensionalCounter counter = new MultidimensionalCounter(2, 4);
for (Integer i : counter) {
    int[] x = counter.getCounts(i);
    System.out.println(i + "" "" + Arrays.toString(x));
}
Output is:
0 [0, 0]
1 [0, 1]
2 [0, 2]
3 [0, 2]   <=== should be [0, 3]
4 [1, 0]
5 [1, 1]
6 [1, 2]
7 [1, 2]   <=== should be [1, 3]",org.apache.commons.math.util.MultidimensionalCounter:getCounts(int)
METHOD,math,MATH-554,2011-04-03T14:14:38.000-05:00,Vector3D.crossProduct is sensitive to numerical cancellation,"{code}
 Vector3D v1 = new Vector3D(9070467121.0, 4535233560.0, 1);
Vector3D v2 = new Vector3D(9070467123.0, 4535233561.0, 1);
System.out.println(Vector3D.crossProduct(v1, v2));
{code}

  { -1, 2, 0 }   { -1, 2, 1 }
Cross product implementation uses the naive formulas (y1 z2 - y2 z1, ...).
These formulas fail when vectors are almost colinear, like in the following example:
{code}
Vector3D v1 = new Vector3D(9070467121.0, 4535233560.0, 1);
Vector3D v2 = new Vector3D(9070467123.0, 4535233561.0, 1);
System.out.println(Vector3D.crossProduct(v1, v2));
{code}
The previous code displays { -1, 2, 0 } instead of the correct answer { -1, 2, 1 }","org.apache.commons.math.geometry.Vector3D:crossProduct(Vector3D, Vector3D)"
METHOD,math,MATH-567,2011-05-05T17:49:00.000-05:00,"class Dfp toDouble method return -inf whan Dfp value is 0 ""zero""","toDouble()  
 toDouble()  
 import org.apache.commons.math.dfp.DfpField;


 
 
 
 public static void main(String[] args)  
 DfpField field = new DfpField(100);
		    getZero()   field.getZero()  toDouble() 
   newDfp(0.0)  
 field.newDfp(0.0)  toDouble() 
 toDouble()
I found a bug in the toDouble() method of the Dfp class.
If the Dfp's value is 0 ""zero"", the toDouble() method returns a  negative infini.
This is because the double value returned has an exposant equal to 0xFFF and a significand is equal to 0.
In the IEEE754 this is a -inf.
To be equal to zero, the exposant and the significand must be equal to zero.
---------------------------------------------- import org.apache.commons.math.dfp.DfpField;
public class test {
/**
* @param args
*/ public static void main(String[] args) {
DfpField field = new DfpField(100);
System.out.println(""toDouble value of getZero() =""+field.getZero().
toDouble()+
"" toDouble value of newDfp(0.0) =""+ field.newDfp(0.0).
toDouble());
}
}
May be the simplest way to fix it is to test the zero equality at the begin of the toDouble() method, to be able to return the correctly signed zero ?","org.apache.commons.math.dfp.Dfp:Dfp(DfpField, double)
org.apache.commons.math.dfp.Dfp:toDouble()"
METHOD,math,MATH-60,2006-05-14T04:20:21.000-05:00,"[math] Function math.fraction.ProperFractionFormat.parse(String, ParsePosition) return illogical result","Fraction parse(String source, 
ParsePostion pos)  class ProperFractionFormat  
 ProperFractionFormat properFormat = new ProperFractionFormat();
result = null;
String source = ""1 -1 / 2"";
ParsePosition pos = new ParsePosition(0);

//Test 1 : fail 
 public void testParseNegative(){
 
   String source = ""-1 -2 / 3"";
   ParsePosition pos = new ParsePosition(0);

   Fraction actual = properFormat.parse(source, pos);
   assertNull(actual);
}

// Test2: success
 public void testParseNegative(){
 
   String source = ""-1 -2 / 3"";
   ParsePosition pos = new ParsePosition(0);

   Fraction actual = properFormat.parse(source, pos);  // return Fraction 1/3
   assertEquals(1, source.getNumerator());
   assertEquals(3, source.getDenominator());
}

 
 parse(String, ParsePosition)
Hello,
I find illogical returned result from function ""Fraction parse(String source,
ParsePostion pos)"" (in class ProperFractionFormat of the Fraction Package) of the Commons Math library.
""
ProperFractionFormat properFormat = new ProperFractionFormat();
result = null;
String source = ""1 -1 / 2"";
ParsePosition pos = new ParsePosition(0);
//Test 1 : fail public void testParseNegative(){
String source = ""-1 -2 / 3"";
ParsePosition pos = new ParsePosition(0);
Fraction actual = properFormat.parse(source, pos);
assertNull(actual);
}
// Test2: success public void testParseNegative(){
String source = ""-1 -2 / 3"";
ParsePosition pos = new ParsePosition(0);
Fraction actual = properFormat.parse(source, pos);  // return Fraction 1/3 assertEquals(1, source.getNumerator());
assertEquals(3, source.getDenominator());
}
""
Function ""Fraction parse(String, ParsePosition)"" returned Fraction 1/3 (means the result Fraction had numerator = 1 and  denominator = 3)for all 3 inputs above.
I think the function does not handle parsing the numberator/ denominator properly incase input string provide invalid numerator/denominator.
Thank you!","org.apache.commons.math.fraction.ProperFractionFormat:parse(String, ParsePosition)"
METHOD,math,MATH-618,2011-07-13T20:23:43.000-05:00,"Complex Add and Subtract handle NaN arguments differently, but javadoc contracts are the same","{code}
       
 {@link #NaN}  
 {@link java.lang.Double}  
 {code}
For both Complex add and subtract, the javadoc states that
{code}
* If either this or <code>rhs</code> has a NaN value in either part,
* {@link #NaN} is returned; otherwise Inifinite and NaN values are
* returned in the parts of the result according to the rules for
* {@link java.lang.Double} arithmetic
{code}
Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.
The test should be added to the add implementation (actually restored, since this looks like a code merge problem going back to 1.1).",org.apache.commons.math.complex.Complex:add(Complex)
METHOD,math,MATH-631,2011-07-23T23:48:27.000-05:00,"""RegulaFalsiSolver"" failure","{code}
 @Test
public void testBug() {
    final UnivariateRealFunction f = new UnivariateRealFunction() {
            @Override
            public double value(double x) {
                return Math.exp(x) - Math.pow(Math.PI, 3.0);
            }
        };

    UnivariateRealSolver solver = new RegulaFalsiSolver();
    double root = solver.solve(100, f, 1, 10);
}
 {code}
 
 {noformat}
 
 {noformat}
{code}
@Test
public void testBug() {
    final UnivariateRealFunction f = new UnivariateRealFunction() {
            @Override
            public double value(double x) {
                return Math.exp(x) - Math.pow(Math.PI, 3.0);
            }
        };
UnivariateRealSolver solver = new RegulaFalsiSolver();
    double root = solver.solve(100, f, 1, 10);
}
{code}
fails with
{noformat}
illegal state: maximal count (100) exceeded: evaluations
{noformat}
Using ""PegasusSolver"", the answer is found after 17 evaluations.",org.apache.commons.math.analysis.solvers.BaseSecantSolver:doSolve()
METHOD,math,MATH-645,2011-08-13T16:18:48.000-05:00,MathRuntimeException with simple ebeMultiply on OpenMapRealVector,"{code:java}
 import org.apache.commons.math.linear.OpenMapRealVector;
import org.apache.commons.math.linear.RealVector;

public class DemoBugOpenMapRealVector {
    public static void main(String[] args) {
        final RealVector u = new OpenMapRealVector(3, 1E-6);
        u.setEntry(0, 1.);
        u.setEntry(1, 0.);
        u.setEntry(2, 2.);
        final RealVector v = new OpenMapRealVector(3, 1E-6);
        v.setEntry(0, 0.);
        v.setEntry(1, 3.);
        v.setEntry(2, 0.);
        System.out.println(u);
        System.out.println(v);
        System.out.println(u.ebeMultiply(v));
    }
}
 {code}
 
 {noformat}
  
 {noformat}
{code:java} import org.apache.commons.math.linear.OpenMapRealVector;
import org.apache.commons.math.linear.RealVector;
public class DemoBugOpenMapRealVector { public static void main(String[] args) { final RealVector u = new OpenMapRealVector(3, 1E-6);
u.setEntry(0, 1.)
;
u.setEntry(1, 0.)
;
u.setEntry(2, 2.)
;
final RealVector v = new OpenMapRealVector(3, 1E-6);
v.setEntry(0, 0.)
;
v.setEntry(1, 3.)
;
v.setEntry(2, 0.)
;
System.out.println(u);
System.out.println(v);
System.out.println(u.ebeMultiply(v));
}
}
{code} raises an exception
{noformat} org.apache.commons.math.linear.OpenMapRealVector@7170a9b6
Exception in thread ""main"" org.apache.commons.math.MathRuntimeException$6: map has been modified while iterating
at org.apache.commons.math.MathRuntimeException.createConcurrentModificationException(MathRuntimeException.java:373)
at org.apache.commons.math.util.OpenIntToDoubleHashMap$Iterator.advance(OpenIntToDoubleHashMap.java:564)
at org.apache.commons.math.linear.OpenMapRealVector.ebeMultiply(OpenMapRealVector.java:372)
at org.apache.commons.math.linear.OpenMapRealVector.ebeMultiply(OpenMapRealVector.java:1)
at DemoBugOpenMapRealVector.main(DemoBugOpenMapRealVector.java:17)
{noformat}","org.apache.commons.math.linear.OpenMapRealVector:ebeMultiply(double[])
org.apache.commons.math.linear.OpenMapRealVector:ebeDivide(double[])
org.apache.commons.math.linear.OpenMapRealVector:ebeMultiply(RealVector)
org.apache.commons.math.linear.OpenMapRealVector:ebeDivide(RealVector)"
METHOD,math,MATH-679,2011-10-03T05:36:20.000-05:00,Integer overflow in OpenMapRealMatrix,"computeKey()
computeKey() has an integer overflow.
Since it is a sparse matrix, this is quite easily encountered long before heap space is exhausted.
The attached code demonstrates the problem, which could potentially be a security vulnerability (for example, if one was to use this matrix to store access control information).
Workaround: never create an OpenMapRealMatrix with more cells than are addressable with an int.","org.apache.commons.math.linear.OpenMapRealMatrix:OpenMapRealMatrix(int, int)"
METHOD,math,MATH-691,2011-10-16T17:18:34.000-05:00,Statistics.setVarianceImpl makes getStandardDeviation produce NaN,"new Variance(true/false)    
 {code:java}
 int[] scores = {1, 2, 3, 4};
SummaryStatistics stats = new SummaryStatistics();
stats.setVarianceImpl(new Variance(false)); //use ""population variance""
for(int i : scores) {
  stats.addValue(i);
}
double sd = stats.getStandardDeviation();
System.out.println(sd);
{code}

 
 {code:java}
   double sd = FastMath.sqrt(stats.getSecondMoment() / stats.getN());
{code}
Invoking SummaryStatistics.setVarianceImpl(new Variance(true/false) makes getStandardDeviation produce NaN.
{code:java}
int[] scores = {1, 2, 3, 4};
SummaryStatistics stats = new SummaryStatistics();
stats.setVarianceImpl(new Variance(false)); //use ""population variance""
for(int i : scores) {
  stats.addValue(i);
}
double sd = stats.getStandardDeviation();
System.out.println(sd);
{code}
A workaround suggested by Mikkel is:
{code:java}
  double sd = FastMath.sqrt(stats.getSecondMoment() / stats.getN());
{code}",org.apache.commons.math.stat.descriptive.SummaryStatistics:addValue(double)
METHOD,math,MATH-713,2011-11-25T16:35:02.000-06:00,Negative value with restrictNonNegative,"SimplexSolver.optimize(function, constraints, GoalType.MINIMIZE, true);

 
 x = 1; y = -1;
Problem: commons-math-2.2 SimplexSolver.
A variable with 0 coefficient may be assigned a negative value nevertheless restrictToNonnegative flag in call:
SimplexSolver.optimize(function, constraints, GoalType.MINIMIZE, true);
Result:
x = 1; y = -1;
Probably variables with 0 coefficients are omitted at some point of computation and because of that the restrictions do not affect their values.",org.apache.commons.math.optimization.linear.SimplexTableau:getSolution()
METHOD,math,MATH-836,2012-07-31T17:04:25.000-05:00,"Fraction(double, int) constructor_ strange behaviour","public Fraction(double value, int maxDenominator)
        throws FractionConversionException
    {
       this(value, 0, maxDenominator, 100);
    }
The Fraction constructor_ Fraction(double, int) takes a double value and a int maximal denominator, and approximates a fraction.
1: the constructor_ returns a positive Fraction.
Calling Fraction(-33655.1677817278, 371880) returns the fraction 410517235/243036, which both has the wrong sign, and is far away from the absolute value of the given value
2: the constructor_ does not manage to reduce the Fraction properly.
Calling Fraction(-43979.60679604749, 366081) returns the fraction -1651878166/256677, which should have* been reduced to -24654898/3831.
I have, as of yet, not found a solution.
The constructor_ looks like this:
public Fraction(double value, int maxDenominator)
throws FractionConversionException
{ this(value, 0, maxDenominator, 100);
}
Increasing the 100 value (max iterations) does not fix the problem for all cases.
Changing the 0-value (the epsilon, maximum allowed error) to something small does not work either, as this breaks the tests in FractionTest.
The problem is not neccissarily that the algorithm is unable to approximate a fraction correctly.
A solution where a FractionConversionException had been thrown in each of these examples would probably be the best solution if an improvement on the approximation algorithm turns out to be hard to find.
This bug has been found when trying to explore the idea of axiom-based testing (http://bldl.ii.uib.no/testing.html).
Attached is a java test class FractionTestByAxiom (junit, goes into org.apache.commons.math3.fraction) which shows these bugs through a simplified approach to this kind of testing, and a text file describing some of the value/maxDenominator combinations which causes one of these failures.
* It is never specified in the documentation that the Fraction class guarantees that completely reduced rational numbers are constructed, but a comment inside the equals method claims that ""since fractions are always in lowest terms, numerators and can be compared directly for equality"", so it seems like this is the intention.","org.apache.commons.math3.fraction.Fraction:Fraction(double, double, int, int)"
METHOD,math,MATH-904,2012-11-20T20:51:23.000-06:00,"FastMath.pow deviates from Math.pow for negative, finite base values with an exponent 2^52 < y < 2^53","Math.pow(-1.0,5.000000000000001E15)  
 FastMath.pow(-1.0,5.000000000000001E15)
As reported by Jeff Hain:
pow(double,double):
Math.pow(-1.0,5.000000000000001E15) = -1.0
FastMath.pow(-1.0,5.000000000000001E15) = 1.0
===> This is due to considering that power is an even
integer if it is >= 2^52, while you need to test
that it is >= 2^53 for it.
===> replace
""if (y >= TWO_POWER_52 || y <= -TWO_POWER_52)""
with
""if (y >= 2*TWO_POWER_52 || y <= -2*TWO_POWER_52)""
and that solves it.","org.apache.commons.math3.util.FastMath:pow(double, double)"
METHOD,math,MATH-929,2013-01-15T11:45:28.000-06:00,MultivariateNormalDistribution.density(double[]) returns wrong value when the dimension is odd,"{code}
 Assert.assertEquals(0.398942280401433, new MultivariateNormalDistribution(new double[]{0}, new double[][]{{1}}).density(new double[]{0}), 1e-15);
{code}
density(new double[]{0}), 1e-15);
{code}",org.apache.commons.math3.distribution.MultivariateNormalDistribution:density(double[])
METHOD,math,MATH-942,2013-03-09T15:05:04.000-06:00,DiscreteDistribution.sample(int) may throw an exception if first element of singletons of sub-class type,"Array.newInstance(singletons.get(0).getClass(), sampleSize)   
 singleons.get(0) 
 {{DiscreteDistribution.sample()}}  
 {code}
 List<Pair<Object,Double>> list = new ArrayList<Pair<Object, Double>>();
list.add(new Pair<Object, Double>(new Object() {}, new Double(0)));
list.add(new Pair<Object, Double>(new Object() {}, new Double(1)));
new DiscreteDistribution<Object>(list).sample(1);
{code}
Creating an array with {{Array.newInstance(singletons.get(0).
getClass(), sampleSize)}} in DiscreteDistribution.sample(int) is risky.
An exception will be thrown if:
* {{singleons.get(0)}} is of type T1, an sub-class of T, and
* {{DiscreteDistribution.sample()}} returns an object which is of type T, but not of type T1.
sample(1);
{code}
Attaching a patch.",org.apache.commons.math3.distribution.DiscreteDistribution:sample(int)
METHOD,math,MATH-949,2013-03-15T18:11:56.000-05:00,LevenbergMarquardtOptimizer reports 0 iterations,"LevenbergMarquardtOptimizer.getIterations()     BaseOptimizer.incrementEvaluationsCount()

 
 {noformat}
     @Test
    public void testGetIterations() {
        // setup
        LevenbergMarquardtOptimizer otim = new LevenbergMarquardtOptimizer();

        // action
        otim.optimize(new MaxEval(100), new Target(new double[] { 1 }),
                new Weight(new double[] { 1 }), new InitialGuess(
                        new double[] { 3 }), new ModelFunction(
                        new MultivariateVectorFunction() {
                            @Override
                            public double[] value(double[] point)
                                    throws IllegalArgumentException {
                                return new double[] { FastMath.pow(point[0], 4) };
                            }
                        }), new ModelFunctionJacobian(
                        new MultivariateMatrixFunction() {
                            @Override
                            public double[][] value(double[] point)
                                    throws IllegalArgumentException {
                                return new double[][] { { 0.25 * FastMath.pow(
                                        point[0], 3) } };
                            }
                        }));

        // verify
        assertThat(otim.getEvaluations(), greaterThan(1));
        assertThat(otim.getIterations(), greaterThan(1));
    }

 {noformat}
The method LevenbergMarquardtOptimizer.getIterations() does not report the correct number of iterations; It always returns 0.
A quick look at the code shows that only SimplexOptimizer calls BaseOptimizer.incrementEvaluationsCount()
Notice how the evaluations count is correctly incremented, but the iterations count is not.
{noformat}
    @Test
    public void testGetIterations() {
        // setup
        LevenbergMarquardtOptimizer otim = new LevenbergMarquardtOptimizer();
// action
otim.optimize(new MaxEval(100), new Target(new double[] { 1 }),
new Weight(new double[] { 1 }), new InitialGuess(
new double[] { 3 }), new ModelFunction(
new MultivariateVectorFunction() {
@Override
public double[] value(double[] point)
throws IllegalArgumentException {
return new double[] { FastMath.pow(point[0], 4) };
}
}), new ModelFunctionJacobian(
new MultivariateMatrixFunction() {
@Override
public double[][] value(double[] point)
throws IllegalArgumentException {
return new double[][] { { 0.25 * FastMath.pow(
point[0], 3) } };
}
}));
// verify
        assertThat(otim.getEvaluations(), greaterThan(1));
        assertThat(otim.getIterations(), greaterThan(1));
    }
{noformat}","org.apache.commons.math3.optim.nonlinear.scalar.gradient.NonLinearConjugateGradientOptimizer:doOptimize()
org.apache.commons.math3.optim.nonlinear.scalar.noderiv.CMAESOptimizer:doOptimize()
org.apache.commons.math3.optim.nonlinear.vector.jacobian.GaussNewtonOptimizer:doOptimize()
org.apache.commons.math3.optim.nonlinear.scalar.noderiv.SimplexOptimizer:doOptimize()
org.apache.commons.math3.optim.BaseOptimizer:BaseOptimizer(ConvergenceChecker<PAIR>)
org.apache.commons.math3.optim.nonlinear.scalar.noderiv.PowellOptimizer:doOptimize()
org.apache.commons.math3.optim.nonlinear.vector.jacobian.LevenbergMarquardtOptimizer:doOptimize()"
FILE,WFCORE,WFCORE-267,2014-11-19T19:47:31.000-06:00,CLI prints output twice if using cli client jar,"INFO: {




    ""outcome"" => ""success"",




    ""result"" => [




        ""core-service"",




        ""deployment"",




        ""deployment-overlay"",




        ""extension"",




        ""interface"",




        ""path"",




        ""socket-binding-group"",




        ""subsystem"",




        ""system-property""




    ]




}




{




    ""outcome"" => ""success"",




    ""result"" => [




        ""core-service"",




        ""deployment"",




        ""deployment-overlay"",




        ""extension"",




        ""interface"",




        ""path"",




        ""socket-binding-group"",




        ""subsystem"",




        ""system-property""




    ]




}
If you are using the CLI client jar, all output is printed twice.
This is because JBoss logging is not set up and by default CommandContextImpl is printing log messages to standard out.
The output will look something like this:
[standalone@localhost:9999 /] :read-children-types
Nov 19, 2014 8:57:19 AM org.jboss.as.cli.impl.CommandContextImpl printLine
INFO: {
""outcome"" => ""success"",
""result"" => [
""core-service"",
""deployment"",
""deployment-overlay"",
""extension"",
""interface"",
""path"",
""socket-binding-group"",
""subsystem"",
""system-property""
]
}
{
""outcome"" => ""success"",
""result"" => [
""core-service"",
""deployment"",
""deployment-overlay"",
""extension"",
""interface"",
""path"",
""socket-binding-group"",
""subsystem"",
""system-property""
]
}",org.jboss.as.cli.CommandLineMain
FILE,WFCORE,WFCORE-495,2015-01-12T08:48:29.000-06:00,"WFLY won't startup due to ""WFLYCTL0212: Duplicate resource [(\""deployment\"" => \""xxx.war\"")]""","file(standalone.xml)  file(standalone.xml)
WFLY won't startup due to ""WFLYCTL0212: Duplicate resource [(\""deployment\"" => \""xxx.war\"")]""
After server restart, it shows:
15:26:26,913 INFO  [org.jboss.as] (MSC service thread 1-8) WFLYSRV0049: WildFly Full 9.0.0.Alpha2-SNAPSHOT (WildFly Core 1.0.0.
Alpha15) starting
15:26:27,133 ERROR [org.jboss.as.controller.management-operation] (Controller Boot Thread) WFLYCTL0013: Operation (""add"") failed - address: ([(""deployment"" => ""xxx.war"")]) - failure description: ""WFLYCTL0212: Duplicate resource [(\""deployment\"" => \""xxx.war\"")]""
15:26:27,136 FATAL [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0056: Server boot has failed in an unrecoverable manner; exiting.
See previous messages for details.
15:26:27,138 INFO  [org.jboss.as.server] (Thread-2) WFLYSRV0220: Server shutdown has been requested.
15:26:27,153 INFO  [org.jboss.as] (MSC service thread 1-1) WFLYSRV0050: WildFly Full 9.0.0.Alpha2-SNAPSHOT (WildFly Core 1.0.0.
Alpha15) stopped in 4ms
steps to reproduce:
3. restart wildfly to see the error message.
This happens because step 2 does a ""full-replace-deployment"" operation which does not remove content from standalone/data/content/aa/2d0425dd53572294d591b56efdee2680539eaf/content and deployment info from configuration file(standalone.xml).
Therefore, you will have xxx.war in standalone/data/content and configuration file(standalone.xml), also a xxx.war and xxx.war.deployed file inside /standalone/deployments.
A second time server restart will cause a duplicate resource error.",org.jboss.as.server.deployment.DeploymentFullReplaceHandler
FILE,WFCORE,WFCORE-604,2015-03-18T09:19:35.000-05:00,"After failed to deploy, remain deployment information in JBOSS_HOME/{standalone|domaine}/data/content directory","{standalone|domaine} 
 {standalone|domaine}  
 {standalone|domaine} 
 {standalone|domaine} 
 {standalone|domaine}
Description of problem:
===
- After failed to deploy, remain deployment information in JBOSS_HOME/{standalone|domaine}/data/content directory
- Please see following reproduce steps.
How reproducible:
===
Steps to Reproduce:
4. Find ""new"" deployment info in JBOSS_HOME/{standalone|domaine}/data/content, and the old deployment info will be still there.
- I know that as we changed application in step-3, its hash value was changed.
And then, old info is remained in JBOSS_HOME/{standalone|domaine}/data/content.
But I think it always happens and should be fixed.
Actual results:
- The deployment information which created when deploy was failed remains in JBOSS_HOME/{standalone|domaine}/data/content.
Expected results:","org.jboss.as.host.controller.mgmt.MasterDomainControllerOperationHandlerImpl
org.jboss.as.server.controller.resources.ServerRootResourceDefinition
org.jboss.as.host.controller.ManagedServerOperationsFactory
org.jboss.as.host.controller.DomainModelControllerService
org.jboss.as.host.controller.RemoteDomainConnectionService
org.jboss.as.test.shared.ModelParserUtils
org.jboss.as.server.deployment.DeploymentAddHandler
org.jboss.as.domain.controller.operations.deployment.ServerGroupDeploymentAddHandler
org.jboss.as.server.logging.ServerLogger
org.jboss.as.server.deployment.DeploymentRemoveHandler
org.jboss.as.domain.controller.resources.ServerGroupResourceDefinition
org.jboss.as.repository.LocalDeploymentFileRepository
org.jboss.as.domain.controller.operations.ApplyRemoteMasterDomainModelHandler
org.jboss.as.server.deployment.DeploymentReplaceHandler
org.jboss.as.domain.controller.resources.DomainRootDefinition
org.jboss.as.server.deploymentoverlay.DeploymentOverlayContentDefinition
org.jboss.as.repository.logging.DeploymentRepositoryLogger
org.jboss.as.domain.controller.operations.deployment.DeploymentFullReplaceHandler
org.jboss.as.core.model.test.LegacyKernelServicesImpl
org.jboss.as.subsystem.test.TestModelControllerService
org.jboss.as.host.controller.HostControllerService
org.jboss.as.domain.controller.resources.DomainDeploymentResourceDefinition
org.jboss.as.core.model.test.TestModelControllerService
org.jboss.as.server.mgmt.domain.RemoteFileRepositoryService
org.jboss.as.server.deploymentoverlay.DeploymentOverlayContentAdd
org.jboss.as.server.ApplicationServerService
org.jboss.as.repository.LocalFileRepository
org.jboss.as.domain.controller.operations.deployment.ServerGroupDeploymentRemoveHandler
org.jboss.as.management.client.content.ManagedDMRContentTypeAddHandler
org.jboss.as.server.test.InterfaceManagementUnitTestCase
org.jboss.as.host.controller.model.host.HostResourceDefinition
org.jboss.as.server.deployment.DeploymentAddHandlerTestCase
org.jboss.as.repository.DeploymentFileRepository
org.jboss.as.domain.controller.operations.deployment.ServerGroupDeploymentReplaceHandler
org.jboss.as.repository.ContentRepository
org.jboss.as.domain.controller.operations.deployment.DeploymentAddHandler
org.jboss.as.domain.controller.operations.deployment.DeploymentRemoveHandler
org.jboss.as.management.client.content.ManagedDMRContentTypeResource
org.jboss.as.host.controller.mgmt.ServerToHostProtocolHandler
org.jboss.as.server.deployment.DeploymentFullReplaceHandler"
FILE,WFCORE,WFCORE-626,2015-04-06T15:53:19.000-05:00,Global list-get operation can inadvertently create list elements,"clear(name=attribute)
  get(name=attribute, index=0)
  add(name=attribute, value=test)
  get(name=attribute, index=0)
:list-clear(name=attribute)
:list-get(name=attribute, index=0)
:list-add(name=attribute, value=test)
:list-get(name=attribute, index=0)
#2 will return <undefined> as expected.
However, it returns <undefined>.
This is because #2 will create the missing element at index 0 causing #3 to operate on index 1.","org.jboss.as.controller.operations.global.ListOperations
org.jboss.as.controller.operations.global.MapOperations"
FILE,WFCORE,WFCORE-687,2015-05-11T12:39:25.000-05:00,patches with duplicate element patch-id values should be rejected,"IdentityPatchContext.recordContentLoader(patchID, contentLoader)
Patches that contain duplicate patch-id attribute values in 'element' elements in patch.xml can be applied but can't be rolled back.
An attempt to rollback such a patch will result in an error ""Content loader already registered for patch "" + patchID, thrown from IdentityPatchContext.recordContentLoader(patchID, contentLoader).
Adding support for duplicate element patch-id values is a more difficult task at this point.
If we decide to support it after all, it'll be implemented under a different issue.","org.jboss.as.patching.metadata.PatchXml
org.jboss.as.patching.metadata.PatchBuilder
org.jboss.as.patching.metadata.PatchXmlUnitTestCase
org.jboss.as.patching.installation.LayerTestCase
org.jboss.as.patching.logging.PatchLogger
org.jboss.as.patching.metadata.PatchXmlUtils"
FILE,WFCORE,WFCORE-442,2014-12-02T19:15:13.000-06:00,AbstractMultiTargetHandler-based handlers do not propagate failures to the top level failure-description,"{read-only=1} 
 {




                ""name"" => ""jboss.server.temp.dir"",




                ""path"" => ""/Users/hbraun/dev/prj/wildfly-core/core-build/target/wildfly-core-1.0.0.Alpha14-SNAPSHOT/standalone/tmp"",




                ""read-only"" => true,




                ""relative-to"" => undefined




            } 
 {




                ""name"" => ""user.home"",




                ""path"" => ""/Users/hbraun"",




                ""read-only"" => true,




                ""relative-to"" => undefined




            } 
 {




                ""name"" => ""jboss.server.base.dir"",




                ""path"" => ""/Users/hbraun/dev/prj/wildfly-core/core-build/target/wildfly-core-1.0.0.Alpha14-SNAPSHOT/standalone"",




                ""read-only"" => true,




                ""relative-to"" => undefined




            } 
  
 {




                ""name"" => ""user.dir"",




                ""path"" => ""/Users/hbraun/dev/prj/wildfly-core/core-build/target/wildfly-core-1.0.0.Alpha14-SNAPSHOT"",




                ""read-only"" => true,




                ""relative-to"" => undefined




            } 
 {




                ""name"" => ""jboss.server.data.dir"",




                ""path"" => ""/Users/hbraun/dev/prj/wildfly-core/core-build/target/wildfly-core-1.0.0.Alpha14-SNAPSHOT/standalone/data"",




                ""read-only"" => true,




                ""relative-to"" => undefined




            } 
 {




                ""name"" => ""jboss.home.dir"",




                ""path"" => ""/Users/hbraun/dev/prj/wildfly-core/core-build/target/wildfly-core-1.0.0.Alpha14-SNAPSHOT"",




                ""read-only"" => true,




                ""relative-to"" => undefined




            } 
 {




                ""name"" => ""jboss.server.log.dir"",




                ""path"" => ""/Users/hbraun/dev/prj/wildfly-core/core-build/target/wildfly-core-1.0.0.Alpha14-SNAPSHOT/standalone/log"",




                ""read-only"" => true,




                ""relative-to"" => undefined




            } 
 {




                ""name"" => ""jboss.controller.temp.dir"",




                ""path"" => ""/Users/hbraun/dev/prj/wildfly-core/core-build/target/wildfly-core-1.0.0.Alpha14-SNAPSHOT/standalone/tmp"",




                ""read-only"" => true,




                ""relative-to"" => undefined




            }
[standalone@localhost:9990 /] /path=*:query(where={read-only=1})
{
""outcome"" => ""failed"",
""result"" => [
{
""address"" => [(""path"" => ""jboss.server.temp.dir"")],
""outcome"" => ""failed"",
""result"" => {
""name"" => ""jboss.server.temp.dir"",
""path"" => ""/Users/hbraun/dev/prj/wildfly-core/core-build/target/wildfly-core-1.0.0.
Alpha14-SNAPSHOT/standalone/tmp"",
""read-only"" => true,
""relative-to"" => undefined
},
""rolled-back"" => true
},
{
""address"" => [(""path"" => ""user.home"")],
""outcome"" => ""failed"",
""result"" => {
""name"" => ""user.home"",
""path"" => ""/Users/hbraun"",
""read-only"" => true,
""relative-to"" => undefined
},
""rolled-back"" => true
},
{
""address"" => [(""path"" => ""jboss.server.base.dir"")],
""outcome"" => ""failed"",
""result"" => {
""name"" => ""jboss.server.base.dir"",
""path"" => ""/Users/hbraun/dev/prj/wildfly-core/core-build/target/wildfly-core-1.0.0.
Alpha14-SNAPSHOT/standalone"",
""read-only"" => true,
""relative-to"" => undefined
},
""rolled-back"" => true
},
{
""address"" => [(""path"" => ""java.home"")],
""outcome"" => ""failed"",
""result"" => {
""name"" => ""java.home"",
""path"" => ""/Library/Java/JavaVirtualMachines/jdk1.7.0_67.
jdk/Contents/Home/jre"",
""read-only"" => true,
""relative-to"" => undefined
},
""rolled-back"" => true
},
{
""address"" => [(""path"" => ""user.dir"")],
""outcome"" => ""failed"",
""result"" => {
""name"" => ""user.dir"",
""path"" => ""/Users/hbraun/dev/prj/wildfly-core/core-build/target/wildfly-core-1.0.0.
Alpha14-SNAPSHOT"",
""read-only"" => true,
""relative-to"" => undefined
},
""rolled-back"" => true
},
{
""address"" => [(""path"" => ""jboss.server.data.dir"")],
""outcome"" => ""failed"",
""result"" => {
""name"" => ""jboss.server.data.dir"",
""path"" => ""/Users/hbraun/dev/prj/wildfly-core/core-build/target/wildfly-core-1.0.0.
Alpha14-SNAPSHOT/standalone/data"",
""read-only"" => true,
""relative-to"" => undefined
},
""rolled-back"" => true
},
{
""address"" => [(""path"" => ""jboss.home.dir"")],
""outcome"" => ""failed"",
""result"" => {
""name"" => ""jboss.home.dir"",
""path"" => ""/Users/hbraun/dev/prj/wildfly-core/core-build/target/wildfly-core-1.0.0.
Alpha14-SNAPSHOT"",
""read-only"" => true,
""relative-to"" => undefined
},
""rolled-back"" => true
},
{
""address"" => [(""path"" => ""jboss.server.log.dir"")],
""outcome"" => ""failed"",
""result"" => {
""name"" => ""jboss.server.log.dir"",
""path"" => ""/Users/hbraun/dev/prj/wildfly-core/core-build/target/wildfly-core-1.0.0.
Alpha14-SNAPSHOT/standalone/log"",
""read-only"" => true,
""relative-to"" => undefined
},
""rolled-back"" => true
},
{
""address"" => [(""path"" => ""jboss.server.config.dir"")],
""outcome"" => ""failed"",
""result"" => {
""name"" => ""jboss.server.config.dir"",
""path"" => ""/Users/hbraun/dev/prj/wildfly-core/core-build/target/wildfly-core-1.0.0.
Alpha14-SNAPSHOT/standalone/configuration"",
""read-only"" => true,
""relative-to"" => undefined
},
""rolled-back"" => true
},
{
""address"" => [(""path"" => ""jboss.controller.temp.dir"")],
""outcome"" => ""failed"",
""result"" => {
""name"" => ""jboss.controller.temp.dir"",
""path"" => ""/Users/hbraun/dev/prj/wildfly-core/core-build/target/wildfly-core-1.0.0.
Alpha14-SNAPSHOT/standalone/tmp"",
""read-only"" => true,
""relative-to"" => undefined
},
""failure-description"" => ""Illegal argument for attribute 'read-only'.
Expected type BOOLEAN"",
""rolled-back"" => true
}
],
""rolled-back"" => true
}
One item in the set has a failure description but the overall response does not.
ReadResourceDescriptionHandler handles similar things but has logic for creating an overall failure-description.",org.jboss.as.controller.operations.global.GlobalOperationHandlers
FILE,WFCORE,WFCORE-716,2015-05-27T10:21:36.000-05:00,Once server in reload-required state capabilities no longer checked at stage Model.,"attribute(name=security-realm)




 {




    ""outcome"" => ""success"",




    ""response-headers"" => {




        ""operation-requires-reload"" => true,




        ""process-state"" => ""reload-required""




    }




 
 attribute(name=security-domain, value=MgMtDom)




 {




    ""outcome"" => ""success"",




    ""response-headers"" => {




        ""operation-requires-reload"" => true,




        ""process-state"" => ""reload-required""




    }
Once a server is in the state reload-required capabilities and requirements are no longer checked e.g.: -
[standalone@localhost:9990 /] .
/core-service=management/management-interface=http-interface:undefine-attribute(name=security-realm)
{
""outcome"" => ""success"",
""response-headers"" => {
""operation-requires-reload"" => true,
""process-state"" => ""reload-required""
}
}
[standalone@localhost:9990 /] .
/core-service=management/management-interface=http-interface:write-attribute(name=security-domain, value=MgMtDom)
{
""outcome"" => ""success"",
""response-headers"" => {
""operation-requires-reload"" => true,
""process-state"" => ""reload-required""
}
}
When I execute :reload it will fail: -
11:21:18,567 ERROR [org.jboss.as.controller.management-operation] (Controller Boot Thread) WFLYCTL0013: Operation (""add"") failed - address: ([
(""core-service"" => ""management""),
(""management-interface"" => ""http-interface"")
]): java.lang.IllegalStateException: WFLYCTL0364: Capability 'org.wildfly.security.security-domain.
MgMtDom' is unknown.
at org.jboss.as.controller.ModelControllerImpl$CapabilityRegistryImpl.getCapabilityRegistration(ModelControllerImpl.java:1388)",org.jboss.as.controller.CapabilityReferenceRecorder
FILE,WFCORE,WFCORE-815,2015-07-13T07:57:45.000-05:00,One profile can have more ancestors with same submodules,"add(name=includes, value=mail-01)
  add(name=includes, value=mail-02)

 
 {




    ""outcome"" => ""failed"",




    ""failure-description"" => {""domain-failure-description"" => ""WFLYCTL0401: Profile 'mail-01' defines subsystem 'mail' which is also defined in its ancestor profile 'mail-02'. Overriding subsystems is not supported""} 
 add(name=includes, value=mail-01)
  add(name=includes, value=mail-02)
Description of problem:
One profile can have more ancestors with same submodules.
It leads to WFLYCTL0212: Duplicate resource [(""subsystem"" => ""subsystem_name"")] .
Hierarchical composition of profiles was added to AS with EAP7-281 and WFCORE-382
How reproducible:
Always
Steps to Reproduce:
.
/domain.sh
.
/jboss-cli.sh -c
/profile=mail-01:add
/profile=mail-02:add
/profile=mail-01/subsystem=mail:add
/profile=mail-02/subsystem=mail:add
/profile=default-new:add
/profile=default-new:list-add(name=includes, value=mail-01)
/profile=default-new:list-add(name=includes, value=mail-02)
Actual results:
Expected results:
{
""outcome"" => ""failed"",
""failure-description"" => {""domain-failure-description"" => ""WFLYCTL0401: Profile 'mail-01' defines subsystem 'mail' which is also defined in its ancestor profile 'mail-02'.
Overriding subsystems is not supported""},
""rolled-back"" => true
}
Workaround:
Add any subsystem to default-new profile:
/profile=mail-01:add
/profile=mail-02:add
/profile=mail-01/subsystem=mail:add
/profile=mail-02/subsystem=mail:add
/profile=default-new:add
/profile=default-new/subsystem=jdr:add
/profile=default-new:list-add(name=includes, value=mail-01)
/profile=default-new:list-add(name=includes, value=mail-02)","org.jboss.as.domain.controller.operations.ProfileIncludesHandlerTestCase
org.jboss.as.domain.controller.operations.SocketBindingGroupIncludesHandlerTestCase
org.jboss.as.host.controller.logging.HostControllerLogger"
FILE,WFCORE,WFCORE-955,2015-08-27T14:34:07.000-05:00,Server is not responding after attempt to set parent of profile to non-existent profile,"add()
 
 {




    ""outcome"" => ""failed"",




    ""failure-description"" => ""java.lang.NullPointerException:null""




}




 
 add()
Description of problem:
Server is not responding after attempt to set parent of profile to non-existent profile.
Server is not responding also after attempt to set parent of socket-binding-group to non-existent socket-binding-group.
This works correctly on wildfly-core (2.0.0.
Beta4).
But this occurs on wildfly (master branch) and on EAP 7.0.0.
DR9. It may be some integration issue.
Priority of this jira tends to be critical.
How reproducible:
Always
Steps to Reproduce (profile):
.
/domain.sh
.
/jboss-cli.sh
/profile=new:add()
/profile=new:write-attribute(name=includes,value=[nonsence])
/profile=new:remove
Actual results:
[domain@localhost:9990 /] /profile=new:write-attribute(name=includes,value=[nonsence])
{
""outcome"" => ""failed"",
""failure-description"" => ""java.lang.NullPointerException:null""
}
[domain@localhost:9990 /] /profile=new:remove
server needs to be restarted
Expected results:
[domain@localhost:9990 /] /profile=new:write-attribute(name=includes,value=[nonsence])
{
""outcome"" => ""failed"",
""failure-description"" => {""domain-failure-description"" => ""WFLYCTL0369: Required capabilities are not available:
org.wildfly.domain.profile.nonsence in context 'profiles'""},
""rolled-back"" => true
}
[domain@localhost:9990 /] /profile=new:remove
{
""outcome"" => ""success"",
""result"" => undefined,
""server-groups"" => undefined
}
Steps to reproduce (socket-binding-group):
.
/domain.sh
.
/jboss-cli.sh
/profile=new:add()
/socket-binding-group=testt:add(default-interface=public,includes=[nonsence])
/profile=new:remove","org.jboss.as.controller.OperationContextImpl
org.jboss.as.controller.AbstractOperationContext
org.jboss.as.controller.logging.ControllerLogger
org.jboss.as.controller.SocketCapabilityResolutionUnitTestCase
org.jboss.as.controller.capability.registry.IncludingResourceCapabilityScope
org.jboss.as.controller.AbstractCapabilityResolutionTestCase"
FILE,WFCORE,WFCORE-876,2015-08-12T07:52:43.000-05:00,Reload or Shutdown inside IF statement is performed before the if/else block batch is executed,"resource()
Executing a reload or shutdown inside an if/else block results in the reload or restart occurring before the other commands in the batch are executed.
if (outcome == success) of /subsystem=logging/logger=org.jboss.as.cli:read-resource()
/subsystem=logging:write-attribute(name=use-deployment-logging-config
shutdown --restart=true
end-if
This command will actually leave the server in a reload-required state.
The shutdown, or reload, will occur before the write-attribute is executed.","org.jboss.as.cli.handlers.trycatch.TryCatchFinallyControlFlow
org.jboss.as.test.integration.management.cli.ifelse.NonExistingPathComparisonTestCase
org.jboss.as.test.integration.management.cli.TryCatchFinallyTestCase
org.jboss.as.cli.handlers.ifelse.IfElseControlFlow
org.jboss.as.test.integration.management.cli.ifelse.BasicIfElseTestCase"
FILE,WFCORE,WFCORE-949,2015-09-03T05:08:35.000-05:00,Removing http-interface autocompletes but fails,"remove()
Executing /core-service=management/management-interface=http-interface:remove() autocompletes but does not succeed.
This is a link to a paste of the server stacktrace.
http://pastebin.test.redhat.com/310136","org.jboss.as.server.operations.NativeRemotingManagementRemoveHandler
org.jboss.as.host.controller.operations.HttpManagementRemoveHandler
org.jboss.as.jmx.RemotingConnectorResource
org.jboss.as.test.integration.domain.HTTPSManagementInterfaceTestCase
org.jboss.as.server.mgmt.NativeManagementResourceDefinition
org.jboss.as.subsystem.test.AdditionalInitialization
org.jboss.as.remoting.management.ManagementRemotingServices
org.jboss.as.server.operations.HttpManagementRemoveHandler
org.jboss.as.server.operations.NativeManagementRemoveHandler
org.wildfly.core.test.standalone.mgmt.HTTPSConnectionWithCLITestCase
org.wildfly.core.test.standalone.mgmt.HTTPSManagementInterfaceTestCase
org.jboss.as.remoting.logging.RemotingLogger
org.jboss.as.server.mgmt.HttpManagementResourceDefinition
org.jboss.as.host.controller.resources.NativeManagementResourceDefinition
org.jboss.as.host.controller.resources.HttpManagementResourceDefinition"
FILE,WFCORE,WFCORE-1007,2015-09-24T06:45:11.000-05:00,Warnings about missing notification descriptions when an operation removes an extension,"migrate()




 {




    ""outcome"" => ""success"",




    ""result"" => {""migration-warnings"" => []}




 
 migrate()




 {




    ""outcome"" => ""success"",




    ""result"" => {""migration-warnings"" => []}




 
 migrate()




 {




    ""outcome"" => ""success"",




    ""result"" => {""migration-warnings"" => []}
When I use migration operation the console log is filled with warning messages of type
WARN  [org.jboss.as.controller] (management-handler-thread - 1) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [(""subsystem"" => ""jacorb"")]
This is the same either for jacorb or web or messaging subsystem.
[standalone@localhost:9999 /] /subsystem=jacorb:migrate()
{
""outcome"" => ""success"",
""result"" => {""migration-warnings"" => []}
}
[standalone@localhost:9999 /] /subsystem=messaging:migrate()
{
""outcome"" => ""success"",
""result"" => {""migration-warnings"" => []}
}
[standalone@localhost:9999 /] /subsystem=we
web  webservices  weld
[standalone@localhost:9999 /] /subsystem=web
web  webservices
[standalone@localhost:9999 /] /subsystem=web:migrate()
{
""outcome"" => ""success"",
""result"" => {""migration-warnings"" => []}
}
then I the log looks like
2015-09-24 08:41:09,729 WARN  [org.jboss.as.controller] (management-handler-thread - 1) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [(""subsystem"" => ""jacorb"")]
2015-09-24 08:43:13,229 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""jms-queue"" => ""DLQ"")
]
2015-09-24 08:43:13,230 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""jms-queue"" => ""ExpiryQueue"")
]
2015-09-24 08:43:13,230 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""pooled-connection-factory"" => ""hornetq-ra"")
]
2015-09-24 08:43:13,230 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""connection-factory"" => ""RemoteConnectionFactory"")
]
2015-09-24 08:43:13,231 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""connection-factory"" => ""InVmConnectionFactory"")
]
2015-09-24 08:43:13,231 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""address-setting"" => ""#"")
]
2015-09-24 08:43:13,231 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""security-setting"" => ""#""),
(""role"" => ""guest"")
]
2015-09-24 08:43:13,232 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""security-setting"" => ""#"")
]
2015-09-24 08:43:13,232 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""in-vm-acceptor"" => ""in-vm"")
]
2015-09-24 08:43:13,232 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-acceptor"" => ""netty-throughput""),
(""param"" => ""direct-deliver"")
]
2015-09-24 08:43:13,233 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-acceptor"" => ""netty-throughput""),
(""param"" => ""batch-delay"")
]
2015-09-24 08:43:13,233 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-acceptor"" => ""netty-throughput"")
]
2015-09-24 08:43:13,233 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-acceptor"" => ""netty"")
]
2015-09-24 08:43:13,234 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""in-vm-connector"" => ""in-vm"")
]
2015-09-24 08:43:13,234 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-connector"" => ""netty-throughput""),
(""param"" => ""batch-delay"")
]
2015-09-24 08:43:13,234 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-connector"" => ""netty-throughput"")
]
2015-09-24 08:43:13,235 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-connector"" => ""netty"")
]
2015-09-24 08:43:13,235 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default"")
]
2015-09-24 08:43:13,235 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [(""subsystem"" => ""messaging"")]
2015-09-24 08:43:20,957 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""web""),
(""configuration"" => ""jsp-configuration"")
]
2015-09-24 08:43:20,957 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""web""),
(""configuration"" => ""static-resources"")
]
2015-09-24 08:43:20,958 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""web""),
(""configuration"" => ""container"")
]
2015-09-24 08:43:20,958 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""web""),
(""virtual-server"" => ""default-host"")
]
2015-09-24 08:43:20,958 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""web""),
(""connector"" => ""http"")
]
2015-09-24 08:43:20,959 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [(""subsystem"" => ""web"")]","org.jboss.as.controller.AbstractOperationContext
org.jboss.as.controller.logging.ControllerLogger"
FILE,WFCORE,WFCORE-1027,2015-10-01T18:16:10.000-05:00,Inconsistent read-resource results with host scoped roles,"{roles=master-monitor}




 
 {




                ""directory-grouping"" => ""by-server"",




                ""domain-controller"" => {""local"" => {} 
  
 {""org.jboss.as.jmx"" => undefined} 
 {




                    ""management"" => undefined,




                    ""public"" => undefined,




                    ""unsecure"" => undefined




                } 
 {""default"" => undefined} 
 {""jmx"" => undefined} 
 {roles=slave-maintainer}




 
 {roles=slave-maintainer}




 
  
 {""org.jboss.as.jmx"" => undefined} 
 {




                ""management"" => undefined,




                ""public"" => undefined,




                ""unsecure"" => undefined




            } 
 {""default"" => undefined} 
 {""jmx"" => undefined}
When using a role which only selects the master there is no access-control response header showing the filtered resources, and the slave wrongly appears in the results:
[domain@localhost:9990 /] /host=*:read-resource{roles=master-monitor}
{
""outcome"" => ""success"",
""result"" => [
{
""address"" => [(""host"" => ""master"")],
""outcome"" => ""success"",
""result"" => {
""directory-grouping"" => ""by-server"",
""domain-controller"" => {""local"" => {}},
""management-major-version"" => 4,
""management-micro-version"" => 0,
""management-minor-version"" => 0,
""master"" => true,
""name"" => ""master"",
""namespaces"" => [],
""organization"" => undefined,
""product-name"" => ""WildFly Core"",
""product-version"" => ""2.0.0.CR6-SNAPSHOT"",
""release-codename"" => ""Kenny"",
""release-version"" => ""2.0.0.CR6-SNAPSHOT"",
""schema-locations"" => [],
""core-service"" => {
""host-environment"" => undefined,
""platform-mbean"" => undefined,
""management"" => undefined,
""discovery-options"" => undefined,
""ignored-resources"" => undefined,
""patching"" => undefined,
""module-loading"" => undefined
},
""extension"" => {""org.jboss.as.jmx"" => undefined},
""interface"" => {
""management"" => undefined,
""public"" => undefined,
""unsecure"" => undefined
},
""jvm"" => {""default"" => undefined},
""path"" => undefined,
""server"" => {
""server-one"" => undefined,
""server-two"" => undefined,
""server-three"" => undefined
},
""server-config"" => {
""server-one"" => undefined,
""server-two"" => undefined,
""server-three"" => undefined
},
""socket-binding-group"" => undefined,
""subsystem"" => {""jmx"" => undefined},
""system-property"" => undefined
}
},
{
""address"" => [(""host"" => ""localhost"")],
""outcome"" => ""success"",
""result"" => undefined
}
]
}
When using a role that only selects the slave we get a proper access-control header
[domain@localhost:9990 /] /host=*:read-resource{roles=slave-maintainer}
{
""outcome"" => ""success"",
""result"" => [{
""address"" => [(""host"" => ""localhost"")],
""outcome"" => ""success"",
""result"" => undefined
}],
""response-headers"" => {""access-control"" => [{
""absolute-address"" => [],
""relative-address"" => [],
""filtered-children-types"" => [""host""]
}]}
The same output on master with WFCORE-994 applied:
[domain@localhost:9990 /] /host=*:read-resource{roles=slave-maintainer}
{
""outcome"" => ""success"",
""result"" => [{
""address"" => [(""host"" => ""slave"")],
""outcome"" => ""success"",
""result"" => {
""directory-grouping"" => ""by-server"",
""domain-controller"" => {""remote"" => {
""protocol"" => undefined,
""port"" => undefined,
""host"" => undefined,
""username"" => undefined,
""ignore-unused-configuration"" => undefined,
""admin-only-policy"" => undefined,
""security-realm"" => ""ManagementRealm""
}},
""management-major-version"" => 4,
""management-micro-version"" => 0,
""management-minor-version"" => 0,
""master"" => false,
""name"" => ""slave"",
""namespaces"" => [],
""organization"" => undefined,
""product-name"" => undefined,
""product-version"" => undefined,
""release-codename"" => ""Kenny"",
""release-version"" => ""2.0.0.CR6-SNAPSHOT"",
""schema-locations"" => [],
""core-service"" => {
""host-environment"" => undefined,
""platform-mbean"" => undefined,
""management"" => undefined,
""discovery-options"" => undefined,
""ignored-resources"" => undefined,
""patching"" => undefined,
""module-loading"" => undefined
},
""extension"" => {""org.jboss.as.jmx"" => undefined},
""interface"" => {
""management"" => undefined,
""public"" => undefined,
""unsecure"" => undefined
},
""jvm"" => {""default"" => undefined},
""path"" => undefined,
""server"" => {
""server-one"" => undefined,
""server-two"" => undefined
},
""server-config"" => {
""server-one"" => undefined,
""server-two"" => undefined
},
""socket-binding-group"" => undefined,
""subsystem"" => {""jmx"" => undefined},
""system-property"" => undefined
}
}],
""response-headers"" => {""access-control"" => [{
""absolute-address"" => [],
""relative-address"" => [],
""filtered-children-types"" => [""host""]
}]}
}","org.jboss.as.test.integration.domain.rbac.RBACProviderHostScopedRolesTestCase
org.jboss.as.test.integration.domain.rbac.AbstractHostScopedRolesTestCase
org.jboss.as.controller.operations.global.GlobalOperationHandlers
org.jboss.as.test.integration.domain.rbac.JmxRBACProviderHostScopedRolesTestCase
org.jboss.as.test.integration.domain.rbac.ListRoleNamesTestCase
org.jboss.as.test.integration.domain.rbac.WildcardReadsTestCase"
FILE,WFCORE,WFCORE-989,2015-09-19T03:11:07.000-05:00,Premature registration of reconnecting server,"{""server-group"" => {




        ""main-server-group"" => {""host"" => {""slave"" => {""main-three"" => ""WFLYHC0153: Channel closed""}
ServerInventoryImpl.reconnectServer is registering the ProxyController for the reconnecting server with the DomainModelControllerService.
The problem is that ProxyController is not yet in a state where it can forward requests to the server.
That won't happen until the server calls back with a DomainServerProtocol.SERVER_RECONNECT_REQUEST and the ServerToHostProtocolHandler.ServerReconnectRequestHandler handles it.
The effect is if a request for the server comes in during this window, it will fail.
If that request is part of a domain operation rollout (because during the window the HC regarded the server as 'live' and instructed the DC to send rollout ops to it), then the domain rollout will be affected.
This happened in the testsuite failure I just saw.
Most significant logging is as follows:
2015-09-18 17:59:32,229 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0025: WildFly Core 2.0.0.CR2-SNAPSHOT ""Kenny"" (Host Controller) started in 93ms - Started 48 of 51 services (15 services are lazy, passive or on-demand)
2015-09-18 17:59:32,247 INFO  [org.jboss.as.controller.management-operation] (Remoting ""slave:MANAGEMENT"" task-16) Initialized for 1849055188
2015-09-18 17:59:32,247 INFO  [org.jboss.as.host.controller] (Remoting ""slave:MANAGEMENT"" task-14) WFLYHC0021: Server [Server:main-three] connected using connection [Channel ID 08aa200b (inbound) of Remoting connection 27e3d90d to /127.0.0.1:49272]
2015-09-18 17:59:32,247 INFO  [org.jboss.as.host.controller] (Remoting ""slave:MANAGEMENT"" task-15) WFLYHC0021: Server [Server:other-two] connected using connection [Channel ID 02bd2646 (inbound) of Remoting connection 64a8b7f2 to /127.0.0.1:49273]
2015-09-18 17:59:32,247 INFO  [org.jboss.as.controller.management-operation] (Host Controller Service Threads - 34) Initialized for 1849055188
2015-09-18 17:59:32,252 INFO  [org.jboss.as.controller.management-operation] (Host Controller Service Threads - 34) sending prepared response for 1849055188  --- interrupted: false
2015-09-18 17:59:32,254 INFO  [org.jboss.as.controller.management-operation] (Remoting ""slave:MANAGEMENT"" task-1) Initialized for 1933145457
2015-09-18 17:59:32,254 INFO  [org.jboss.as.controller.management-operation] (Remoting ""slave:MANAGEMENT"" task-1) Initialized for 481103151
2015-09-18 17:59:32,254 INFO  [org.jboss.as.controller.management-operation] (Host Controller Service Threads - 36) Initialized for 1933145457
2015-09-18 17:59:32,254 INFO  [org.jboss.as.controller.management-operation] (Host Controller Service Threads - 37) Initialized for 481103151
2015-09-18 17:59:32,255 INFO  [org.jboss.as.controller.management-operation] (Host Controller Service Threads - 36) sending pre-prepare failed response for 1933145457  --- interrupted: false
2015-09-18 17:59:32,256 INFO  [org.jboss.as.controller.management-operation] (Host Controller Service Threads - 37) sending pre-prepare failed response for 481103151  --- interrupted: false
The HC completes boot.
Then servers main-three and other-two register.
The HC sends a prepared response to a request.
This is the host rollout request to the slave from the DC with the response being the ops to invoke on the servers.
The HC reports sending a ""pre-prepare failed response"" to two requests.
These are the requests the DC has asked it to proxy to the servers.
The result of all this for the client is the following failure of a management op:
Failed operation:
{
""operation"" => ""add"",
""address"" => [(""extension"" => ""org.jboss.as.test.hc.extension"")]
}
Response:
{
""outcome"" => ""failed"",
""result"" => undefined,
""failure-description"" => {""WFLYDC0074: Operation failed or was rolled back on all servers.
Server failures:"" => {""server-group"" => {
""main-server-group"" => {""host"" => {""slave"" => {""main-three"" => ""WFLYHC0153: Channel closed""}}},
""other-server-group"" => {""host"" => {""slave"" => {""other-two"" => ""WFLYHC0153: Channel closed""}}}
}}},
""rolled-back"" => true,
""server-groups"" => {
""main-server-group"" => {""host"" => {
""master"" => {""main-one"" => {""response"" => {
""outcome"" => ""failed"",
""result"" => [(""HC"" => ""1.1.1"")],
""rolled-back"" => true
}}},
""slave"" => {""main-three"" => {""response"" => {
""outcome"" => ""failed"",
""result"" => undefined,
""failure-description"" => ""WFLYHC0153: Channel closed"",
""rolled-back"" => true
}}}
}},
""other-server-group"" => {""host"" => {""slave"" => {""other-two"" => {""response"" => {
""outcome"" => ""failed"",
""result"" => undefined,
""failure-description"" => ""WFLYHC0153: Channel closed"",
""rolled-back"" => true
}}}}}
}
}
The ""WFLYHC0153: Channel closed"" failure is what is produced when an attempt is made to invoke on a disconnected proxy controller.","org.jboss.as.host.controller.ServerInventoryImpl
org.jboss.as.host.controller.mgmt.ServerToHostProtocolHandler"
FILE,WFCORE,WFCORE-1067,2015-10-21T12:22:10.000-05:00,CVE-2015-5304 Missing authorization check for Monitor/Deployer/Auditor role when shutting down server or canceling op,"context.getServiceRegistry(true)
It was found that the server or host controller did not properly authorize a user performing a shut down.
A user with the role Monitor, Deployer, or Auditor could use this flaw to shut down the EAP server, which is an action restricted to users in other roles.
The following commit introduced this issue:
https://github.com/wildfly/wildfly-core/commit/6e5611b4c6
The context.getServiceRegistry(true) call, which throws an exception when write authorization fails, was replaced with a call to context.authorize, which only returns an authorization result.
Nothing was then done with the authorization result.
The same flaw exists in the handling of the cancel-active-operation op, although there this only means the admin could cancel an in-progress operation, perhaps initiated by a different admin.
It also lets the admin cancel his own operation, which is arguably a benefit.
But losing that benefit is an acceptable price to having a consistent RBAC scheme.
(Note: CLI users whose own operations are hanging can always cancel them by doing a soft kill of the CLI process.
Users of custom clients that use ModelControllerClient can cancel their own ops by using the ModelControllerClient executeAsync API and cancelling the Future returned thereby.)","org.jboss.as.domain.management.controller.CancelActiveOperationHandler
org.jboss.as.server.operations.ServerShutdownHandler
org.jboss.as.test.integration.mgmt.access.StandardRolesBasicTestCase
org.jboss.as.test.integration.domain.rbac.AbstractStandardRolesTestCase
org.jboss.as.host.controller.operations.HostShutdownHandler"
FILE,WFCORE,WFCORE-1214,2015-12-11T23:17:45.000-06:00,Operation headers not propagated to domain servers when 'composite' op is used,"{blocking-timeout=5;rollback-on-runtime-failure=false}  
 {

[Host Controller] 10:53:40,697 INFO  [stdout] (management-handler-thread - 3)     ""blocking-timeout"" => ""5"",

[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""rollback-on-runtime-failure"" => ""false"",

[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""caller-type"" => ""user"",

[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""access-mechanism"" => ""NATIVE""

[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3) }
When the user adds request headers to an op, they are not propagated to the servers during domain rollout if the 'composite' op is involved.
[domain@localhost:9990 /] deploy ~/tmp/helloworld.
war --headers={blocking-timeout=5;rollback-on-runtime-failure=false} --all-server-groups
Then on a HC with two servers, this is logged:
[Host Controller] 10:53:40,697 INFO  [stdout] (management-handler-thread - 3) ""composite"" headers:
{
[Host Controller] 10:53:40,697 INFO  [stdout] (management-handler-thread - 3)     ""blocking-timeout"" => ""5"",
[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""rollback-on-runtime-failure"" => ""false"",
[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""caller-type"" => ""user"",
[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""access-mechanism"" => ""NATIVE""
[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3) }
[Host Controller] 10:53:40,727 INFO  [org.jboss.as.repository] (management-handler-thread - 3) WFLYDR0001: Content added at location /Users/bstansberry/dev/wildfly/wildfly-core/dist/target/wildfly-core-2.0.5.
Final-SNAPSHOT/domain/data/content/6f/cd9eae343ed6d5aa9fffa83012d155b1ef911c/content
[Server:server-one] 10:53:40,772 INFO  [stdout] (ServerService Thread Pool  11) ""composite"" headers: null
[Server:server-two] 10:53:40,772 INFO  [stdout] (ServerService Thread Pool  11) ""composite"" headers: null
The HC logs, then the servers report.
The user-specified headers are not included.
Invoke the same op without the batch and this is logged:
[Host Controller] 10:43:50,400 INFO  [stdout] (management-handler-thread - 4) ""composite"" headers: {
[Host Controller] 10:43:50,401 INFO  [stdout] (management-handler-thread - 4)     ""blocking-timeout"" => ""5"",
[Host Controller] 10:43:50,401 INFO  [stdout] (management-handler-thread - 4)     ""rollback-on-runtime-failure"" => ""false"",
[Host Controller] 10:43:50,401 INFO  [stdout] (management-handler-thread - 4)     ""caller-type"" => ""user"",
[Host Controller] 10:43:50,401 INFO  [stdout] (management-handler-thread - 4)     ""access-mechanism"" => ""NATIVE""
[Host Controller] 10:43:50,401 INFO  [stdout] (management-handler-thread - 4) }
[Host Controller] 10:43:50,425 INFO  [org.jboss.as.repository] (management-handler-thread - 4) WFLYDR0001: Content added at location /Users/bstansberry/dev/wildfly/wildfly-core/dist/target/wildfly-core-2.0.5.
Final-SNAPSHOT/domain/data/content/6f/cd9eae343ed6d5aa9fffa83012d155b1ef911c/content
[Server:server-two] 10:43:50,464 INFO  [stdout] (ServerService Thread Pool -- 11) ""composite"" headers: {
[Server:server-two] 10:43:50,464 INFO  [stdout] (ServerService Thread Pool -- 11)     ""blocking-timeout"" => ""5"",
[Server:server-two] 10:43:50,464 INFO  [stdout] (ServerService Thread Pool -- 11)     ""rollback-on-runtime-failure"" => ""false"",
[Server:server-one] 10:43:50,464 INFO  [stdout] (ServerService Thread Pool -- 11) ""composite"" headers: {
[Server:server-two] 10:43:50,464 INFO  [stdout] (ServerService Thread Pool -- 11)     ""access-mechanism"" => ""NATIVE"",
[Server:server-one] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11)     ""blocking-timeout"" => ""5"",
[Server:server-two] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11)     ""domain-uuid"" => ""216d2e99-dba5-4c89-8020-b0c16bd553c5""
[Server:server-one] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11)     ""rollback-on-runtime-failure"" => ""false"",
[Server:server-two] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11) }
[Server:server-one] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11)     ""access-mechanism"" => ""NATIVE"",
[Server:server-one] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11)     ""domain-uuid"" => ""216d2e99-dba5-4c89-8020-b0c16bd553c5""
[Server:server-one] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11) }
Expected headers are present.
Note the CLI 'deploy' is far from the only time the 'composite' op is used.
Among other places, the high level CLI 'batch' command in a domain involves use of 'composite'.","org.jboss.as.domain.controller.operations.coordination.DomainRolloutStepHandler
org.jboss.as.domain.controller.operations.coordination.OperationCoordinatorStepHandler"
FILE,WFCORE,WFCORE-1212,2015-12-11T18:04:50.000-06:00,TestModule does not clean up after itself properly,"TestModule.create()   mkdirs()   remove()  
  
 Once remove()   getModulesDir()
TestModule.create() calls mkdirs() to create its filesystem structure, but remove() only removes the dir above 'main' and below, leaving behind intermediate dirs.
The result of this is if you run the full testsuite with -Dts.basic, the dist/target/wildflyxxx/modules dir ends up with child dir 'test' in addition to the proper 'system'.
I'm not sure why this spurious dir doesn't end up in the final dists we publish.
Perhaps its just luck due to the release process not running the testsuite when the final build with the 'deploy' target is invoked.
I know my process for releasing WildFly Core doesn't re-run tests in that step.
https://issues.jboss.org/browse/JBEAP-2374",org.jboss.as.test.module.util.TestModule
FILE,WFCORE,WFCORE-1198,2015-12-09T09:30:00.000-06:00,CLI does not resolve multiple properties if one property is undefined,"{PROFILE-NAME}  {APP-VERSION}  {VAR}  add(auto-start=true, group=""${PROFILE-NAME}${APP-VERSION}-server-group"")
https://bugzilla.redhat.com/show_bug.cgi?id=1289316 description:
Multiple property substitution is working with EAP 6.4.3+, however, if a variable amongst the multiple variables is empty or has no value, then the subsequent property in the CLI command is not substituted.
cat props.properties
-----------------------------------------
PROFILE-NAME=TestProfile
SERVER-INSTANCE-NUMBER=TestInstance
APP-VERSION=
VAR=test
-----------------------------------------
cat test.cli :
---------------------------------------
/host=master/server-config=${PROFILE-NAME}${APP-VERSION}${SERVER-INSTANCE-NUMBER}${VAR}:add(auto-start=true, group=""${PROFILE-NAME}${APP-VERSION}-server-group"")
---------------------------------------
/jboss-cli.sh --connect --file=test.cli --properties=props.properties"" then I have the following in the host.xml "":
----------
...
<server name=""TestProfile${SERVER-INSTANCE-NUMBER}test"" group=""TestProfile-server-group"" auto-start=""true""/>
...
-----------
Note APP-VERSION had no value, and so the subsequent SERVER-INSTANCE-NUMBER was not properly resolved","org.jboss.as.cli.parsing.test.PropertyReplacementTestCase
org.jboss.as.cli.parsing.ExpressionBaseState"
FILE,WFCORE,WFCORE-1261,2016-01-04T17:37:05.000-06:00,Changing the max-history attribute value for configuration-changes fails,"attribute(name=max-history,value=20)
 {

""outcome"" => ""failed"",

""failure-description"" => ""WFLYCTL0158: Operation handler failed: java.lang.IllegalStateException: WFLYCTL0188: Stage MODEL is already complete"",

""rolled-back"" => true

}
[standalone@localhost:9990 /] /core-service=management/service=configuration-changes:write-attribute(name=max-history,value=20)
{
""outcome"" => ""failed"",
""failure-description"" => ""WFLYCTL0158: Operation handler failed: java.lang.IllegalStateException: WFLYCTL0188: Stage MODEL is already complete"",
""rolled-back"" => true
}","org.wildfly.core.test.standalone.mgmt.api.core.ConfigurationChangesHistoryTestCase
org.jboss.as.domain.management.ConfigurationChangeResourceDefinition"
FILE,WFCORE,WFCORE-1354,2016-02-03T00:19:08.000-06:00,Cannot clone a profile with a remoting subsystem but no io subsystem,"clone(to-profile=test)
The remoting subsystem added a requirement for the new io subsystem's worker capability, but it has special logic such that the requirement is only added if an endpoint resource is configured.
So, legacy configs (pre-io) won't have that resource, so there is no requirement.
This breaks down in the case of the profile 'clone' op, as a placeholder resource we add for the endpoint (to allow reads of the default endpoint config data) ends up getting 'described' and added by the cloning process.
So that added resource triggers an unmet requirement for the io worker:
[domain@localhost:9990 /] /profile=default:clone(to-profile=test)
{
""outcome"" => ""failed"",
""failure-description"" => {""domain-failure-description"" => ""WFLYCTL0369: Required capabilities are not available:
org.wildfly.io.worker.default in context 'profile=test'; There are no known registration points which can provide this capability.""}
,
""rolled-back"" => true
}","org.jboss.as.remoting.RemotingExtension
org.jboss.as.subsystem.test.AbstractSubsystemBaseTest"
FILE,WFCORE,WFCORE-1114,2015-11-06T02:08:35.000-06:00,NPE in DeploymentStatusHandler,"AbstractDeploymentUnitService.getStatus()  
   
                            
 TransformListener()
Saw an NPE in a test run.
This is because AbstractDeploymentUnitService.getStatus() references the possibly null 'monitor' field.
org.jboss.as.test.manualmode.deployment.DeploymentScannerOperationTestCase.testStartup: java.lang.AssertionError: null
at org.jboss.as.test.manualmode.deployment.DeploymentScannerOperationTestCase.testStartup(DeploymentScannerOperationTestCase.java:92)
------- Stdout: -------
23:55:18,131 INFO  [org.wildfly.core.testrunner.Server] (main) Starting container with: /usr/java/jdk1.8.0_65/jre/bin/java -D[Standalone] -javaagent:/store/repository/org/jboss/byteman/byteman/2.2.1/byteman-2.2.1.jar=port:9091,boot:/store/repository/org/jboss/byteman/byteman/2.2.1/byteman-2.2.1.jar,sys:/opt/buildAgent/work/8d74ae55e497982e/testsuite/shared/target/wildfly-core-testsuite-shared-3.0.0.Alpha1-SNAPSHOT.jar -Dorg.jboss.byteman.transform.all -Dorg.jboss.byteman.verbose=true -Dmaven.repo.local=/store/repository -Xmx512m -Djboss.dist=/opt/buildAgent/work/8d74ae55e497982e/testsuite/manualmode/target/wildfly-core -Djava.net.preferIPv4Stack=false -Djava.net.preferIPv6Addresses=true -server -Dts.timeout.factor=100 -Djbossas.ts.dir=/opt/buildAgent/work/8d74ae55e497982e/testsuite/manualmode -ea -Dorg.jboss.boot.log.file=/opt/buildAgent/work/8d74ae55e497982e/testsuite/manualmode/target/wildfly-core/standalone/log/server.log -Dlogging.configuration=file:/opt/buildAgent/work/8d74ae55e497982e/testsuite/manualmode/target/wildfly-core/standalone/configuration/logging.
properties -jar /opt/buildAgent/work/8d74ae55e497982e/testsuite/manualmode/target/wildfly-core/jboss-modules.jar -mp /opt/buildAgent/work/8d74ae55e497982e/testsuite/manualmode/target/wildfly-core/modules org.jboss.as.standalone -Djboss.home.dir=/opt/buildAgent/work/8d74ae55e497982e/testsuite/manualmode/target/wildfly-core -Djboss.server.base.dir=/opt/buildAgent/work/8d74ae55e497982e/testsuite/manualmode/target/wildfly-core/standalone -Djboss.server.log.dir=/opt/buildAgent/work/8d74ae55e497982e/testsuite/manualmode/target/wildfly-core/standalone/log -Djboss.server.config.dir=/opt/buildAgent/work/8d74ae55e497982e/testsuite/manualmode/target/wildfly-core/standalone/configuration -c=standalone.xml -bmanagement=::1 -Djboss.http.port=8080 -Djboss.bind.address=::1
23:55:18,299 INFO  [org.xnio] (main) XNIO version 3.3.2.
Final
TransformListener() : accepting requests on localhost:9091
23:55:18,427 INFO  [org.xnio.nio] (main) XNIO NIO Implementation Version 3.3.2.
Final
23:55:18,469 INFO  [org.jboss.remoting] (main) JBoss Remoting version 4.0.14.
Final
[0m23:55:18,781 INFO  [org.jboss.modules] (main) JBoss Modules version 1.4.4.
Final
[0m [0m23:55:19,059 INFO  [org.jboss.msc] (main) JBoss MSC version 1.2.6.
Final
[0m [0m23:55:19,150 INFO  [org.jboss.as] (MSC service thread 1-4) WFLYSRV0049: WildFly Core 3.0.0.Alpha1-SNAPSHOT ""Kenny"" starting
[0m [0m23:55:19,716 INFO  [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0039: Creating http management service using socket-binding (management-http)
[0m [0m23:55:19,739 INFO  [org.xnio] (MSC service thread 1-2) XNIO version 3.3.2.
Final
[0m [0m23:55:19,747 INFO  [org.xnio.nio] (MSC service thread 1-2) XNIO NIO Implementation Version 3.3.2.
Final
[0m [0m23:55:19,799 INFO  [org.jboss.remoting] (MSC service thread 1-2) JBoss Remoting version 4.0.14.
Final
[0m [33m23:55:19,896 WARN  [org.jboss.as.domain.http.api.undertow] (MSC service thread 1-4) WFLYDMHTTP0003: Unable to load console module for slot main, disabling console
[0m [0m23:55:20,084 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0060: Http management interface listening on http://[::1]:9990/management
[0m [0m23:55:20,084 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0051: Admin console listening on http://[::1]:9990
[0m [0m23:55:20,084 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0025: WildFly Core 3.0.0.Alpha1-SNAPSHOT ""Kenny"" started in 1710ms - Started 55 of 57 services (15 services are lazy, passive or on-demand)
[0m [0m23:55:20,610 INFO  [org.jboss.as.repository] (DeploymentScanner-threads - 2) WFLYDR0001: Content added at location /opt/buildAgent/work/8d74ae55e497982e/testsuite/manualmode/target/wildfly-core/standalone/data/content/21/5cf647697bfbd1ed32b458a4568c01fb6e8dd6/content
[0m [0m23:55:20,628 INFO  [org.jboss.as.server.deployment] (MSC service thread 1-4) WFLYSRV0027: Starting deployment of ""deployment-one.jar"" (runtime-name: ""deployment-one.jar"")
[0m [0m23:55:20,669 INFO  [org.jboss.as.server] (DeploymentScanner-threads - 2) WFLYSRV0010: Deployed ""deployment-one.jar"" (runtime-name : ""deployment-one.jar"")
[0m [0m23:55:21,399 INFO  [org.jboss.as.server.deployment] (MSC service thread 1-4) WFLYSRV0028: Stopped deployment deployment-one.jar (runtime-name: deployment-one.jar) in 6ms
[0m [31m23:55:21,403 ERROR [org.jboss.as.controller.management-operation] (management-handler-thread - 2) WFLYCTL0013: Operation (""read-attribute"") failed - address: ([(""deployment"" => ""deployment-one.jar"")]): java.lang.NullPointerException
at org.jboss.as.server.deployment.AbstractDeploymentUnitService.getStatus(AbstractDeploymentUnitService.java:111)
at org.jboss.as.server.deployment.DeploymentStatusHandler$1.execute(DeploymentStatusHandler.java:61)
at org.jboss.as.controller.AbstractOperationContext.executeStep(AbstractOperationContext.java:890)
at org.jboss.as.controller.AbstractOperationContext.processStages(AbstractOperationContext.java:659)
at org.jboss.as.controller.AbstractOperationContext.executeOperation(AbstractOperationContext.java:370)
at org.jboss.as.controller.OperationContextImpl.executeOperation(OperationContextImpl.java:1341)
at org.jboss.as.controller.ModelControllerImpl.internalExecute(ModelControllerImpl.java:392)
at org.jboss.as.controller.ModelControllerImpl.execute(ModelControllerImpl.java:217)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler.doExecute(ModelControllerClientOperationHandler.java:207)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler.access$300(ModelControllerClientOperationHandler.java:129)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler$1$1.run(ModelControllerClientOperationHandler.java:151)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler$1$1.run(ModelControllerClientOperationHandler.java:147)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:92)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler$1.execute(ModelControllerClientOperationHandler.java:147)
at org.jboss.as.protocol.mgmt.AbstractMessageHandler$ManagementRequestContextImpl$1.doExecute(AbstractMessageHandler.java:363)
at org.jboss.as.protocol.mgmt.AbstractMessageHandler$AsyncTaskRunner.run(AbstractMessageHandler.java:465)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at java.lang.Thread.run(Thread.java:745)
at org.jboss.threads.JBossThread.run(JBossThread.java:320)",org.jboss.as.server.deployment.AbstractDeploymentUnitService
FILE,WFCORE,WFCORE-1428,2016-03-04T14:45:35.000-06:00,log-file.stream attribute is of type LONG but contains a string,"resource(include-runtime=true)
The stream attribute of the log-file resource is of type LONG, but contains a UUID (string).
This leads to an error in the console where I rely on proper attribute data types.
/subsystem=logging/log-file=*:read-resource-description
/subsystem=logging/log-file=*:read-resource(include-runtime=true)",org.jboss.as.logging.LogFileResourceDefinition
FILE,WFCORE,WFCORE-1346,2016-02-02T07:24:08.000-06:00,extension remove reports sucess even if the extension does not exist,"{""outcome"" => ""success""}
[standalone@localhost:9999 /] /extension=garbage:remove
{""outcome"" => ""success""}","org.wildfly.core.test.standalone.extension.remove.ExtensionRemoveTestCase
org.jboss.as.controller.extension.ExtensionRemoveHandler"
FILE,WFCORE,WFCORE-701,2015-05-19T15:06:17.000-05:00,Inconsistent domain server status reports between server-config resource and server resource,"attribute(name=status)




 {




    ""outcome"" => ""success"",




    ""result"" => ""FAILED""




}




  attribute(name=server-state)




 {




    ""outcome"" => ""success"",




    ""result"" => ""STOPPED""




}
When a managed server fails in some way, the server status reporting is inconsistent between the /host=<host>/server-config=<server> resources and the /host=<host>/server=<server> resource.
[domain@localhost:9990 /] /host=master/server-config=server-two:read-attribute(name=status)
{
""outcome"" => ""success"",
""result"" => ""FAILED""
}
[domain@localhost:9990 /] /host=master/server=server-two:read-attribute(name=server-state)
{
""outcome"" => ""success"",
""result"" => ""STOPPED""
}",org.jboss.as.host.controller.ManagedServer
FILE,WFCORE,WFCORE-1028,2015-10-01T19:12:08.000-05:00,Poor handling of invalid roles,"{roles=slave-monitor}
A CLI request with an invalid value in the ""roles"" header results in improper behavior:
[domain@localhost:9990 /] /host=*:read-resource{roles=slave-monitor}
{
""outcome"" => ""failed"",
""result"" => [],
""rolled-back"" => true
}
The op should fail because the role doesn't exist, but there is no failure-description.
The following is dumped in the HC log:
[Host Controller] 12:22:12,314 ERROR [org.jboss.as.controller.management-operation] (management-handler-thread - 3) WFLYCTL0013: Operation (""resolve"") failed - address: ([]): java.lang.IllegalArgumentException: WFLYCTL0327: Unknown role 'slave-monitor'
[Host Controller] 	at org.jboss.as.controller.access.rbac.StandardRoleMapper.canRunAs(StandardRoleMapper.java:95)
[Host Controller] 	at org.jboss.as.controller.access.rbac.RunAsRoleMapper.mapRoles(RunAsRoleMapper.java:143)
[Host Controller] 	at org.jboss.as.controller.access.rbac.RunAsRoleMapper.mapRoles(RunAsRoleMapper.java:71)
[Host Controller] 	at org.jboss.as.controller.access.rbac.DefaultPermissionFactory.getUserPermissions(DefaultPermissionFactory.java:109)
[Host Controller] 	at org.jboss.as.controller.access.permission.ManagementPermissionAuthorizer.authorize(ManagementPermissionAuthorizer.java:91)
[Host Controller] 	at org.jboss.as.controller.access.management.DelegatingConfigurableAuthorizer.authorize(DelegatingConfigurableAuthorizer.java:99)
[Host Controller] 	at org.jboss.as.controller.OperationContextImpl.getBasicAuthorizationResponse(OperationContextImpl.java:1753)
[Host Controller] 	at org.jboss.as.controller.OperationContextImpl.authorize(OperationContextImpl.java:1651)
[Host Controller] 	at org.jboss.as.controller.OperationContextImpl.readResourceFromRoot(OperationContextImpl.java:833)
[Host Controller] 	at org.jboss.as.controller.OperationContextImpl.readResource(OperationContextImpl.java:818)
[Host Controller] 	at org.jboss.as.controller.operations.global.GlobalOperationHandlers$ModelAddressResolver.execute(GlobalOperationHandlers.java:402)
[Host Controller] 	at org.jboss.as.controller.operations.global.GlobalOperationHandlers$ModelAddressResolver.execute(GlobalOperationHandlers.java:306)
[Host Controller] 	at org.jboss.as.controller.AbstractOperationContext.executeStep(AbstractOperationContext.java:890)
[Host Controller] 	at org.jboss.as.controller.AbstractOperationContext.processStages(AbstractOperationContext.java:659)
[Host Controller] 	at org.jboss.as.controller.AbstractOperationContext.executeOperation(AbstractOperationContext.java:370)
[Host Controller] 	at org.jboss.as.controller.OperationContextImpl.executeOperation(OperationContextImpl.java:1336)
[Host Controller] 	at org.jboss.as.controller.ModelControllerImpl.internalExecute(ModelControllerImpl.java:391)
[Host Controller] 	at org.jboss.as.controller.ModelControllerImpl.execute(ModelControllerImpl.java:217)
[Host Controller] 	at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler.doExecute(ModelControllerClientOperationHandler.java:207)
[Host Controller] 	at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler.access$300(ModelControllerClientOperationHandler.java:129)
[Host Controller] 	at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler$1$1.run(ModelControllerClientOperationHandler.java:151)
[Host Controller] 	at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler$1$1.run(ModelControllerClientOperationHandler.java:147)
[Host Controller] 	at java.security.AccessController.doPrivileged(Native Method)
[Host Controller] 	at javax.security.auth.Subject.doAs(Subject.java:422)
[Host Controller] 	at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:92)
[Host Controller] 	at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler$1.execute(ModelControllerClientOperationHandler.java:147)
[Host Controller] 	at org.jboss.as.protocol.mgmt.AbstractMessageHandler$2$1.doExecute(AbstractMessageHandler.java:299)
[Host Controller] 	at org.jboss.as.protocol.mgmt.AbstractMessageHandler$AsyncTaskRunner.run(AbstractMessageHandler.java:519)
[Host Controller] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
[Host Controller] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
[Host Controller] 	at java.lang.Thread.run(Thread.java:745)
[Host Controller] 	at org.jboss.threads.JBossThread.run(JBossThread.java:320)","org.jboss.as.controller.logging.ControllerLogger
org.jboss.as.controller.operations.global.GlobalOperationHandlers
org.jboss.as.controller.access.rbac.RoleMapper
org.jboss.as.test.integration.domain.ServerManagementTestCase"
FILE,WFCORE,WFCORE-1546,2016-05-11T07:07:27.000-05:00,Whitespaces in the middle of the value are siletly ignored,"{




    ""outcome"" => ""failed"",




    ""failure-description"" => ""JBAS011539: Log level I   N   F   O is invalid."",




    ""rolled-back"" => true




}




 
 attribute(name=value)




 {




    ""outcome"" => ""success"",




    ""result"" => ""ha ha ha""




}






 
 attribute(name=level)




 {




    ""outcome"" => ""success"",




    ""result"" => ""INFO""




}




 
 attribute(name=value)




 {




    ""outcome"" => ""success"",




    ""result"" => ""hahaha""




}
Whitespace in the middle of value (e.g. adding a system property with a value like ""my property"") is silently ignored.
Going to the history, this behaviour changed was introduced in EAP 6.0.1
6.0.0
/subsystem=logging/console-handler=CONSOLE:write-attribute(name=level, value=   I   N   F   O)
{
""outcome"" => ""failed"",
""failure-description"" => ""JBAS011539: Log level I   N   F   O is invalid.""
,
""rolled-back"" => true
}
/system-property=test:add(value=ha ha ha)
/system-property=test:read-attribute(name=value)
{
""outcome"" => ""success"",
""result"" => ""ha ha ha""
}
6.0.1 up to 7.0.0
/subsystem=logging/console-handler=CONSOLE:write-attribute(name=level, value=   I   N   F   O)
/subsystem=logging/console-handler=CONSOLE:read-attribute(name=level)
{
""outcome"" => ""success"",
""result"" => ""INFO""
}
/system-property=test:add(value=ha ha ha)
/system-property=test:read-attribute(name=value)
{
""outcome"" => ""success"",
""result"" => ""hahaha""
}
Main concern here is whether it is a correct behaviour to silently ignore the whitespace in the middle.","org.jboss.as.cli.parsing.test.OperationParsingTestCase
org.jboss.as.cli.parsing.operation.PropertyValueState"
FILE,WFCORE,WFCORE-1493,2016-04-20T20:05:27.000-05:00,org.jboss.as.host.controller.Main.getHostSystemProperties() doesn't propagate -Djdk.launcher.addexports.%d=%s value properly,"org.jboss.as.host.controller.Main.getHostSystemProperties()
JDK9 provides -XaddExports launch option to workaround potential migration problems to modularized JDK.
When modularized JDK forks new process all -XaddExports values are translated into
-Djdk.launcher.addexports.
%d=%s JVM options.
But method org.jboss.as.host.controller.Main.getHostSystemProperties()
has problems with its values.
The format of -XaddExports (and thus for -Djdk.launcher.addexports.
%d=%s too) is:
-XaddExports:<source-module>/<package>=<target-module>(,<target-module>)*
See http://openjdk.java.net/jeps/261 for more information.",org.jboss.as.host.controller.Main
FILE,WFCORE,WFCORE-1570,2016-05-27T12:51:56.000-05:00,Saved rollout-plan 'name' or 'id' attribute discrepancy,"group(rolling-to-servers=false,max-failed-servers=1)  group(rolling-to-servers=true,max-failure-percentage=20)  
 {rollout id=my-rollout-plan}
When using rollout plans for EAP deployment scenarios I can create my own named rollout-plan for ease of use.
There is minor discrepancy in the way I create and use such rollout plan though.
rollout-plan add --name=my-rollout-plan --content={rollout main-server-group(rolling-to-servers=false,max-failed-servers=1),other-server-group(rolling-to-servers=true,max-failure-percentage=20) rollback-across-groups=true}
see --name attribute given to name my rollout plan
deploy /path/to/test-application.
war --all-server-groups --headers={rollout id=my-rollout-plan}
see id attribute given to rollout header operation
Note: examples are used from our documentation.
Note: I do not know whether I am missing something but I was not able to retrieve more info how to use rollout header operation in deploy command directly in CLI.","org.jboss.as.cli.parsing.operation.header.RolloutPlanState
org.jboss.as.cli.parsing.operation.header.RolloutPlanHeaderCallbackHandler
org.jboss.as.cli.operation.impl.RolloutPlanCompleter"
FILE,WFCORE,WFCORE-1578,2016-06-07T05:13:13.000-05:00,Better check of names of existing resources when adding '{local|remote-destination-outbound-socket-binding',"{remote|local} 
   add()




    add(host=localhost,port=8765)




 
   add(socket-binding-ref=http)




 
  
  
     
  
 
  
 {remote|local}
Then when I create some /socket-binding-group=standard-sockets/remote-destination-outbound-socket-binding or /socket-binding-group=standard-sockets/local-destination-outbound-socket-binding using same name as of already existing socket-binding resource, add operation is successful but when I perform server reload, it crashes as it is not able to parse configuration.
See:
/socket-binding-group=standard-sockets/socket-binding=myBinding:add()
/socket-binding-group=standard-sockets/remote-destination-outbound-socket-binding=myBinding:add(host=localhost,port=8765)
or
/socket-binding-group=standard-sockets/local-destination-outbound-socket-binding=myBinding:add(socket-binding-ref=http)
reload
server crashes with following stacktrace in console log:
17:31:40,447 INFO  [org.jboss.as.connector.deployers.jdbc] (MSC service thread 1-7) WFLYJCA0019: Stopped Driver service with driver-name = h2
17:31:40,453 INFO  [org.wildfly.extension.undertow] (MSC service thread 1-8) WFLYUT0008: Undertow HTTP listener default suspending
17:31:40,454 INFO  [org.wildfly.extension.undertow] (MSC service thread 1-8) WFLYUT0007: Undertow HTTP listener default stopped, was bound to 127.0.0.1:8080
17:31:40,454 INFO  [org.wildfly.extension.undertow] (MSC service thread 1-3) WFLYUT0004: Undertow 1.3.21.Final-redhat-1 stopping
17:31:40,458 INFO  [org.jboss.as.mail.extension] (MSC service thread 1-7) WFLYMAIL0002: Unbound mail session [java:jboss/mail/Default]
17:31:40,461 INFO  [org.jboss.as] (MSC service thread 1-5) WFLYSRV0050: JBoss EAP 7.0.0.
GA (WildFly Core 2.1.2.Final-redhat-1) stopped in 22ms
17:31:40,461 INFO  [org.jboss.as] (MSC service thread 1-5) WFLYSRV0049: JBoss EAP 7.0.0.
GA (WildFly Core 2.1.2.Final-redhat-1) starting
17:31:40,489 ERROR [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0055: Caught exception during boot: org.jboss.as.controller.persistence.ConfigurationPersistenceException: WFLYCTL0085: Failed to parse configuration
at org.jboss.as.controller.persistence.XmlConfigurationPersister.load(XmlConfigurationPersister.java:131)
at org.jboss.as.server.ServerService.boot(ServerService.java:356)
at org.jboss.as.controller.AbstractControllerService$1.run(AbstractControllerService.java:299)
at java.lang.Thread.run(Thread.java:745)
Caused by: javax.xml.stream.XMLStreamException: ParseError at [row,col]:[410,9]
Message: WFLYCTL0042: A socket-binding or a outbound-socket-binding myBinding already declared has already been declared in socket-binding-group standard-sockets
at org.jboss.as.server.parsing.StandaloneXml_4.
parseSocketBindingGroup(StandaloneXml_4.java:518)
at org.jboss.as.server.parsing.StandaloneXml_4.
readServerElement(StandaloneXml_4.java:254)
at org.jboss.as.server.parsing.StandaloneXml_4.
readElement(StandaloneXml_4.java:141)
at org.jboss.as.server.parsing.StandaloneXml.readElement(StandaloneXml.java:103)
at org.jboss.as.server.parsing.StandaloneXml.readElement(StandaloneXml.java:49)
at org.jboss.staxmapper.XMLMapperImpl.processNested(XMLMapperImpl.java:110)
at org.jboss.staxmapper.XMLMapperImpl.parseDocument(XMLMapperImpl.java:69)
at org.jboss.as.controller.persistence.XmlConfigurationPersister.load(XmlConfigurationPersister.java:123)
... 3 more
17:31:40,490 FATAL [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0056: Server boot has failed in an unrecoverable manner; exiting.
See previous messages for details.
17:31:40,491 INFO  [org.jboss.as.server] (Thread-2) WFLYSRV0220: Server shutdown has been requested.
17:31:40,496 INFO  [org.jboss.as] (MSC service thread 1-2) WFLYSRV0050: JBoss EAP 7.0.0.
GA (WildFly Core 2.1.2.Final-redhat-1) stopped in 3ms
After this occurs, one needs to fix .
/standalone/configuration/standalone.xml manually by removing duplicate resources.
Note: not sure whether CLI component is appropriate, please change if there is better component for this.","org.jboss.as.controller.logging.ControllerLogger
org.jboss.as.server.services.net.LocalDestinationOutboundSocketBindingAddHandler
org.jboss.as.server.services.net.SocketBindingAddHandler
org.jboss.as.server.services.net.RemoteDestinationOutboundSocketBindingAddHandler"
FILE,WFCORE,WFCORE-1607,2016-06-17T12:23:38.000-05:00,"Removing children of security-realm always finishes with {""outcome"" => ""success""}","{""outcome"" => ""success""}
Removing children of security-realm (e.g. authentication) always finishes with
{""outcome"" => ""success""}
.
This happens even if type of children of security-realm does not exist in server configuration.",org.jboss.as.domain.management.security.SecurityRealmChildRemoveHandler
FILE,WFCORE,WFCORE-1635,2016-07-05T07:04:51.000-05:00,Write attribute on a new deployment scanner fails in batch,"add(path=log, relative-to=""jboss.server.base.dir"", auto-deploy-exploded=false, scan-enabled=false)




  attribute(name=scan-interval, value=6000)




 
 
 add(path=log, relative-to=""jboss.server.base.dir"", auto-deploy-exploded=false, scan-enabled=false)




  attribute(name=scan-interval, value=6000)
Creating a new deployment-scanner and altering it's attribute fails if done in single batch.
Running the commands without batch or running batch on CLI embed-server works fine.
reproduce
batch
/subsystem=deployment-scanner/scanner=scan:add(path=log, relative-to=""jboss.server.base.dir"", auto-deploy-exploded=false, scan-enabled=false)
/subsystem=deployment-scanner/scanner=scan:write-attribute(name=scan-interval, value=6000)
run-batch
fails with
08:09:19,076 ERROR [org.jboss.as.controller.management-operation] (management-handler-thread - 4) WFLYCTL0013: Operation (""write-attribute"") failed - address: ([
(""subsystem"" => ""deployment-scanner""),
(""scanner"" => ""scan"")
]): java.lang.IllegalStateException
at org.jboss.as.server.deployment.scanner.DeploymentScannerService.getValue(DeploymentScannerService.java:234)
at org.jboss.as.server.deployment.scanner.DeploymentScannerService.getValue(DeploymentScannerService.java:62)
at org.jboss.msc.service.ServiceControllerImpl.getValue(ServiceControllerImpl.java:1158)
at org.jboss.as.controller.OperationContextImpl$OperationContextServiceController.getValue(OperationContextImpl.java:2282)
at org.jboss.as.server.deployment.scanner.AbstractWriteAttributeHandler.applyUpdateToRuntime(AbstractWriteAttributeHandler.java:58)
at org.jboss.as.controller.AbstractWriteAttributeHandler$1.execute(AbstractWriteAttributeHandler.java:104)
at org.jboss.as.controller.AbstractOperationContext.executeStep(AbstractOperationContext.java:890)
at org.jboss.as.controller.AbstractOperationContext.processStages(AbstractOperationContext.java:659)
at org.jboss.as.controller.AbstractOperationContext.executeOperation(AbstractOperationContext.java:370)
at org.jboss.as.controller.OperationContextImpl.executeOperation(OperationContextImpl.java:1344)
at org.jboss.as.controller.ModelControllerImpl.internalExecute(ModelControllerImpl.java:392)
at org.jboss.as.controller.ModelControllerImpl.execute(ModelControllerImpl.java:217)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler.doExecute(ModelControllerClientOperationHandler.java:208)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler.access$300(ModelControllerClientOperationHandler.java:130)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler$1$1.run(ModelControllerClientOperationHandler.java:152)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler$1$1.run(ModelControllerClientOperationHandler.java:148)
at java.security.AccessController.doPrivileged(AccessController.java:686)
at javax.security.auth.Subject.doAs(Subject.java:569)
at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:92)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler$1.execute(ModelControllerClientOperationHandler.java:148)
at org.jboss.as.protocol.mgmt.AbstractMessageHandler$ManagementRequestContextImpl$1.doExecute(AbstractMessageHandler.java:363)
at org.jboss.as.protocol.mgmt.AbstractMessageHandler$AsyncTaskRunner.run(AbstractMessageHandler.java:472)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at java.lang.Thread.run(Thread.java:785)
at org.jboss.threads.JBossThread.run(JBossThread.java:320)
using the embed server works
embed-server
batch
/subsystem=deployment-scanner/scanner=scan:add(path=log, relative-to=""jboss.server.base.dir"", auto-deploy-exploded=false, scan-enabled=false)
/subsystem=deployment-scanner/scanner=scan:write-attribute(name=scan-interval, value=6000)
run-batch
Setting only as minor as there is no real use case behind this (scan-interval can be set while adding a new scanner) - run into it quite accidentally.
No regression against previous release.",org.jboss.as.server.deployment.scanner.AbstractWriteAttributeHandler
FILE,WFCORE,WFCORE-1590,2016-06-12T14:18:43.000-05:00,Default parameter length validating ignores setMinSize(0),"static final SimpleAttributeDefinition REPLACEMENT = new SimpleAttributeDefinitionBuilder(ElytronDescriptionConstants.REPLACEMENT, ModelType.STRING, false)




        .setAllowExpression(true)




        .setMinSize(0)




        .setFlags(AttributeAccess.Flag.RESTART_RESOURCE_SERVICES)




        .build();






 
 add(pattern=""@ELYTRON.ORG"", replacement="""", replace-all=true)
static final SimpleAttributeDefinition REPLACEMENT = new SimpleAttributeDefinitionBuilder(ElytronDescriptionConstants.REPLACEMENT, ModelType.STRING, false)
.
setAllowExpression(true)
.
setMinSize(0)
.
setFlags(AttributeAccess.Flag.RESTART_RESOURCE_SERVICES)
.
build();
The following error is reported if an empty string is used as a parameter: -
[standalone@localhost:9990 /] .
/subsystem=elytron/regex-name-rewriter=strip-realm:add(pattern=""@ELYTRON.
ORG"", replacement="""", replace-all=true)
{
""outcome"" => ""failed"",
""failure-description"" => ""WFLYCTL0113: '' is an invalid value for parameter replacement.
Values must have a minimum length of 1 characters"",
""rolled-back"" => true
}","org.jboss.as.controller.operations.validation.BytesValidator
org.jboss.as.controller.SimpleAttributeDefinitionUnitTestCase
org.jboss.as.controller.test.WriteAttributeOperationTestCase
org.jboss.as.controller.AbstractAttributeDefinitionBuilder
org.jboss.as.controller.AttributeDefinition"
FILE,WFCORE,WFCORE-1718,2016-08-16T09:49:11.000-05:00,Handlers within Audit Logger are not removed properly when Audit Logger is removed,"remove()
  remove()
 
 {




    ""outcome"" => ""failed"",




    ""failure-description"" => ""WFLYCTL0158: Operation handler failed: java.lang.NullPointerException"",




    ""rolled-back"" => true




}






   
 attribute(name=level,value=DEBUG)
If Audit Logger is removed, destination handlers (i.e. its child nodes) are not removed properly.
They are not present in the config file.
They seem to be not removed ""internally"" though.
This leads to a couple of issues:
1. It is not possible to remove referenced File/Syslog handlers.
If user tries to remove them the NullPointerException is given as a result.
/core-service=management/access=audit/file-handler=file:remove()
/core-service=management/access=audit/syslog-handler=my-syslog-handler:remove()
Their output is:
{
""outcome"" => ""failed"",
""failure-description"" => ""WFLYCTL0158: Operation handler failed: java.lang.NullPointerException"",
""rolled-back"" => true
}
2. AuditLog continues to send auditable events to previously referenced File/Syslog handlers.
See log in the file (WILDFLY_HOME/standalone/data/audit-log.log)
See log in the syslog (/var/log/messages)","org.jboss.as.domain.management.audit.AuditLogLoggerResourceDefinition
org.jboss.as.domain.management.audit.AccessAuditResourceDefinition
org.jboss.as.domain.management.audit.AuditLogHandlerReferenceResourceDefinition"
FILE,WFCORE,WFCORE-1715,2016-08-15T19:04:54.000-05:00,HostProcessReloadHandler does not reset the HostRunningModeControl's restartMode,"The doReload()     ServerInventoryService.stop()
The ReloadContext created by HostProcessReloadHandler sets the HostRunningModeControl's restartMode but then it never gets restored to the default value.
A concern here is that ServerInventoryService only goes into its ""shutdownServers"" logic if the restartMode == RestartMode.SERVERS.
Which, due to this bug, it will be following any HC reload.
But should it?
Should the default value of restartMode be ""null""?
Or should it be RestartMode.SERVERS?
If we change the default from null, then the behavior when no reload has happened will change.
Basically we need to decide whether the ""shutdownServers"" logic should happen by default.",org.jboss.as.host.controller.operations.StartServersHandler
FILE,WFCORE,WFCORE-1765,2016-09-05T16:22:02.000-05:00,unclear NullPointerException if the deployment-scanner element is removed from the configuration,"{xml}
         {xml}
If the deployment scanner element is removed from the configuration of the standalone server a NullPointerException is logged which is unclear and difficult to find as the stack does not show any hint.
Config:
{xml}
<subsystem xmlns=""urn:jboss:domain:deployment-scanner:2.0"">
<!-- deployment-scanner path=""deployments"" relative-to=""jboss.server.base.dir"" scan-interval=""5000"" runtime-failure-causes-rollback=""${jboss.deployment.scanner.rollback.on.failure:false}""/ -->
</subsystem>{xml}
Log message:
ERROR [org.jboss.as.controller.management-operation] (ServerService Thread Pool  34) WFLYCTL0403: Unexpected failure during execution of the following operation(s): []: java.lang.NullPointerException
at org.jboss.as.controller.AbstractOperationContext$Step.access$300(AbstractOperationContext.java:1185)
at org.jboss.as.controller.AbstractOperationContext.executeResultHandlerPhase(AbstractOperationContext.java:767)
at org.jboss.as.controller.AbstractOperationContext.executeDoneStage(AbstractOperationContext.java:753)
at org.jboss.as.controller.AbstractOperationContext.processStages(AbstractOperationContext.java:680)
at org.jboss.as.controller.AbstractOperationContext.executeOperation(AbstractOperationContext.java:370)
at org.jboss.as.controller.ParallelBootOperationStepHandler$ParallelBootTask.run(ParallelBootOperationStepHandler.java:359)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at java.lang.Thread.run(Thread.java:745)
at org.jboss.threads.JBossThread.run(JBossThread.java:320)",org.jboss.as.controller.ParallelBootOperationStepHandler
FILE,WFCORE,WFCORE-1793,2016-09-14T08:08:21.000-05:00,add-content operation fails to overwrite existing content with overwrite=true set when passing content by file path,"{""outcome"" => ""success""}




 
 {""outcome"" => ""success""}




 
 {""outcome"" => ""success""}




  {path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt} 
  
 {path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt} 
  
 {path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt}
Upon overwriting content in managed exploded deployments on wildfly-core, the following errors are produced:
CLI
[standalone@localhost:9990 /] deploy /home/mjurc/testing/eap7-204/jboss-kitchensink-ear.
ear
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:undeploy
{""outcome"" => ""success""}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:explode
{""outcome"" => ""success""}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:deploy
{""outcome"" => ""success""}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:add-content(content=[{path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt}], overwrite=true)
{
""outcome"" => ""failed"",
""failure-description"" => ""org.jboss.as.repository.ExplodedContentException: WFLYDR0021: Error updating content of exploded deployment"",
""rolled-back"" => true
}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:add-content(content=[{path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt}], overwrite=false)
{
""outcome"" => ""failed"",
""failure-description"" => ""org.jboss.as.repository.ExplodedContentException: WFLYDR0021: Error updating content of exploded deployment"",
""rolled-back"" => true
}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:add-content(content=[{path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt}])
{
""outcome"" => ""failed"",
""failure-description"" => ""org.jboss.as.repository.ExplodedContentException: WFLYDR0021: Error updating content of exploded deployment"",
""rolled-back"" => true
}
Server
09:41:36,029 WARN  [org.jboss.as.repository] (management-handler-thread - 5) java.nio.file.FileAlreadyExistsException: /home/mjurc/testing/wildfly-core/build/target/wildfly-core-3.0.0.
Alpha8-SNAPSHOT/standalone/data/content/content7797527203290314566/content/test.txt
09:45:27,505 WARN  [org.jboss.as.repository] (management-handler-thread - 12) java.nio.file.FileAlreadyExistsException: /home/mjurc/testing/wildfly-core/build/target/wildfly-core-3.0.0.
Alpha8-SNAPSHOT/standalone/data/content/content721393778736298367/content/test.txt
09:45:36,352 WARN  [org.jboss.as.repository] (management-handler-thread - 10) java.nio.file.FileAlreadyExistsException: /home/mjurc/testing/wildfly-core/build/target/wildfly-core-3.0.0.
Alpha8-SNAPSHOT/standalone/data/content/content344811471223714239/content/test.txt
This issue does not seem to arise when the content is passed to the server by input stream index.","org.jboss.as.server.controller.resources.DeploymentAttributes
org.jboss.as.server.deployment.ExplodedDeploymentAddContentHandler"
FILE,WFCORE,WFCORE-1851,2016-10-04T12:28:40.000-05:00,Inconsistent behaviour with browse-content(depth=1) operation between archived and exploded deployments,"content(depth=1)  
 {




    ""outcome"" => ""success"",




    ""result"" => [




        {




            ""path"" => ""jboss-kitchensink-ear-web.war"",




            ""directory"" => false,




            ""file-size"" => 63190L




        } 
 {




            ""path"" => ""jboss-kitchensink-ear-ejb.jar"",




            ""directory"" => false,




            ""file-size"" => 12256L




        } 
 {




            ""path"" => ""META-INF/"",




            ""directory"" => true




        }




     
 {




    ""outcome"" => ""success"",




    ""result"" => [




        {




            ""path"" => ""META-INF/"",




            ""directory"" => true




        } 
 {




            ""path"" => ""META-INF/MANIFEST.MF"",




            ""directory"" => false,




            ""file-size"" => 130L




        } 
 {




            ""path"" => ""jboss-kitchensink-ear-web.war"",




            ""directory"" => false,




            ""file-size"" => 63190L




        } 
 {




            ""path"" => ""jboss-kitchensink-ear-ejb.jar"",




            ""directory"" => false,




            ""file-size"" => 12256L




        } 
 {




            ""path"" => ""META-INF/application.xml"",




            ""directory"" => false,




            ""file-size"" => 802L




        } 
 {




            ""path"" => ""META-INF/kitchensink-ear-quickstart-ds.xml"",




            ""directory"" => false,




            ""file-size"" => 1955L




        }
/deployment=jboss-kitchensink-ear.
ear:browse-content(depth=1) operation returns inconsistent result depending on whether the deployment is exploded or not.
Deployment attached.
Archived:
{
""outcome"" => ""success"",
""result"" => [
{
""path"" => ""jboss-kitchensink-ear-web.
war"",
""directory"" => false,
""file-size"" => 63190L
},
{
""path"" => ""jboss-kitchensink-ear-ejb.jar"",
""directory"" => false,
""file-size"" => 12256L
},
{
""path"" => ""META-INF/"",
""directory"" => true
}
]
}
Exploded:
{
""outcome"" => ""success"",
""result"" => [
{
""path"" => ""META-INF/"",
""directory"" => true
},
{
""path"" => ""META-INF/MANIFEST.
MF"",
""directory"" => false,
""file-size"" => 130L
},
{
""path"" => ""jboss-kitchensink-ear-web.
war"",
""directory"" => false,
""file-size"" => 63190L
},
{
""path"" => ""jboss-kitchensink-ear-ejb.jar"",
""directory"" => false,
""file-size"" => 12256L
},
{
""path"" => ""META-INF/application.xml"",
""directory"" => false,
""file-size"" => 802L
},
{
""path"" => ""META-INF/kitchensink-ear-quickstart-ds.xml"",
""directory"" => false,
""file-size"" => 1955L
},
{
""path"" => ""META-INF/maven/org.jboss.quickstarts.eap/jboss-kitchensink-ear-ear/pom.xml"",
""directory"" => false,
""file-size"" => 5582L
},
{
""path"" => ""META-INF/maven/org.
jboss.quickstarts.eap/jboss-kitchensink-ear-ear/pom.properties"",
""directory"" => false,
""file-size"" => 143L
}
]
}","org.jboss.as.repository.PathUtil
org.jboss.as.repository.ContentRepositoryTest"
FILE,WFCORE,WFCORE-1864,2016-10-13T09:12:31.000-05:00,Whitespaces are not removed from dependencies in module add command,"{{
...
    <dependencies>
        <module name=""org.a""/>
        <module name="" org.b ""/>
    </dependencies>
...
}}
Running module add --name=foo.bar --resources=foo.jar --dependencies=[org.a, org.b ] will result in following dependencies in module.xml
{{
...
<dependencies>
<module name=""org.a""/>
<module name="" org.b ""/>
</dependencies>
...
}}","org.jboss.as.cli.handlers.module.ASModuleHandler
org.jboss.as.test.integration.management.cli.ModuleTestCase"
FILE,WFCORE,WFCORE-1908,2016-10-31T08:13:57.000-05:00,Tab completion suggest writing attribute which has access type metric and is not writable,"attribute(name=message-count, value=5)




 {




    ""outcome"" => ""failed"",




    ""failure-description"" => ""WFLYCTL0048: Attribute message-count is not writable"",




    ""rolled-back"" => true




}
CLI tab completion suggests attributes that are not writable and their access-type is metric
/subsystem=messaging-activemq/server=default/jms-queue=DLQ:write-attribute(name=<TAB>
consumer-count  delivering-count  entries  legacy-entries  message-count  messages-added  scheduled-count
From executing :read-resource-description we can see, attributes consumer-count, delivering-count, message-count, messages-added, scheduled-count are of type metric.
On attempt to write metric attribute, for example message-count, non writable error is printed
[standalone@localhost:9990 jms-queue=q] :write-attribute(name=message-count, value=5)
{
""outcome"" => ""failed"",
""failure-description"" => ""WFLYCTL0048: Attribute message-count is not writable"",
""rolled-back"" => true
}","org.jboss.as.cli.impl.AttributeNamePathCompleter
org.jboss.as.cli.parsing.test.AttributeNamePathCompletionTestCase
org.jboss.as.cli.Util"
FILE,WFCORE,WFCORE-1936,2016-11-04T10:57:06.000-05:00,"Value of parameters ""restart-required"" for fixed-*port attributes does not match reality for socket-binding and *-destination-outbound-socket-binding in CLI","description(recursive=true)
But reality is different.
If you tries to change such attributes you are informed that reload is necessary.
The attributes are defined as ""restart-required"" => ""no-services"", see /socket-binding-group=standard-sockets:read-resource-description(recursive=true)","org.jboss.as.server.services.net.OutboundSocketBindingResourceDefinition
org.jboss.as.controller.resource.AbstractSocketBindingResourceDefinition"
FILE,WFCORE,WFCORE-1896,2016-10-26T09:44:51.000-05:00,Deployment operation browse-content(archive=true) does not return archives in archived deployments,"content(archive=true)  
 content()




 {




    ""outcome"" => ""success"",




    ""result"" => [




        {




            ""path"" => ""jboss-kitchensink-ear-web.war"",




            ""directory"" => false,




            ""file-size"" => 63190L




        } 
 {




            ""path"" => ""jboss-kitchensink-ear-ejb.jar"",




            ""directory"" => false,




            ""file-size"" => 12256L




        } 
 {




            ""path"" => ""META-INF/maven/"",




            ""directory"" => true




        } 
 {




            ""path"" => ""META-INF/MANIFEST.MF"",




            ""directory"" => false,




            ""file-size"" => 130L




        } 
 {




            ""path"" => ""META-INF/application.xml"",




            ""directory"" => false,




            ""file-size"" => 802L




        } 
 {




            ""path"" => ""META-INF/kitchensink-ear-quickstart-ds.xml"",




            ""directory"" => false,




            ""file-size"" => 1955L




        } 
 {




            ""path"" => ""META-INF/"",




            ""directory"" => true




        }




     
 content(archive=true)




 {""outcome"" => ""success""}






 
 {""outcome"" => ""success""}




 
 {""outcome"" => ""success""}




 
 {""outcome"" => ""success""}




  content(archive=true)




 {




    ""outcome"" => ""success"",




    ""result"" => [




        {




            ""path"" => ""jboss-kitchensink-ear-web.war"",




            ""directory"" => false,




            ""file-size"" => 63190L




        } 
 {




            ""path"" => ""jboss-kitchensink-ear-ejb.jar"",




            ""directory"" => false,




            ""file-size"" => 12256L




        }
Deployment operation browse-content(archive=true) does not return archives in archived deployments:
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:browse-content()
{
""outcome"" => ""success"",
""result"" => [
{
""path"" => ""jboss-kitchensink-ear-web.
war"",
""directory"" => false,
""file-size"" => 63190L
},
{
""path"" => ""jboss-kitchensink-ear-ejb.jar"",
""directory"" => false,
""file-size"" => 12256L
},
{
""path"" => ""META-INF/maven/org.jboss.quickstarts.eap/jboss-kitchensink-ear-ear/pom.xml"",
""directory"" => false,
""file-size"" => 5582L
},
{
""path"" => ""META-INF/maven/org.
jboss.quickstarts.eap/jboss-kitchensink-ear-ear/pom.properties"",
""directory"" => false,
""file-size"" => 143L
},
{
""path"" => ""META-INF/maven/org.
jboss.quickstarts.eap/jboss-kitchensink-ear-ear/"",
""directory"" => true
},
{
""path"" => ""META-INF/maven/org.
jboss.quickstarts.eap/"",
""directory"" => true
},
{
""path"" => ""META-INF/maven/"",
""directory"" => true
},
{
""path"" => ""META-INF/MANIFEST.
MF"",
""directory"" => false,
""file-size"" => 130L
},
{
""path"" => ""META-INF/application.xml"",
""directory"" => false,
""file-size"" => 802L
},
{
""path"" => ""META-INF/kitchensink-ear-quickstart-ds.xml"",
""directory"" => false,
""file-size"" => 1955L
},
{
""path"" => ""META-INF/"",
""directory"" => true
}
]
}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:browse-content(archive=true)
{""outcome"" => ""success""}
It works correctly with exploded deployments:
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:undeploy
{""outcome"" => ""success""}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:explode
{""outcome"" => ""success""}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:deploy
{""outcome"" => ""success""}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:browse-content(archive=true)
{
""outcome"" => ""success"",
""result"" => [
{
""path"" => ""jboss-kitchensink-ear-web.
war"",
""directory"" => false,
""file-size"" => 63190L
},
{
""path"" => ""jboss-kitchensink-ear-ejb.jar"",
""directory"" => false,
""file-size"" => 12256L
}
]
}","org.jboss.as.repository.ContentFilter
org.jboss.as.repository.PathUtil
org.jboss.as.repository.PathUtilTest"
FILE,WFCORE,WFCORE-1959,2016-11-08T16:28:30.000-06:00,Deploying an empty managed exploded deployment to server group in domain fails,"{empty=true} 
 add()
Deploying an empty exploded deployment created on domain controller fails with the following:
[domain@localhost:9990 /] /deployment=empty-deployment.jar:add(content=[{empty=true}])
{
""outcome"" => ""success"",
""result"" => undefined,
""server-groups"" => undefined
}
[domain@localhost:9990 /] /server-group=main-server-group/deployment=empty-deployment.jar:add()
{
""outcome"" => ""failed"",
""result"" => undefined,
""failure-description"" => {""WFLYDC0074: Operation failed or was rolled back on all servers.
Server failures:"" => {""server-group"" => {""main-server-group"" => {""host"" => {""master"" => {
""server-one"" => ""WFLYSRV0201: Cannot have more than one of [bytes, input-stream-index, hash, url, empty]"",
""server-two"" => ""WFLYSRV0201: Cannot have more than one of [bytes, input-stream-index, hash, url, empty]""
}}}}}},
""rolled-back"" => true,
""server-groups"" => {""main-server-group"" => {""host"" => {""master"" => {
""server-one"" => {""response"" => {
""outcome"" => ""failed"",
""failure-description"" => ""WFLYSRV0201: Cannot have more than one of [bytes, input-stream-index, hash, url, empty]"",
""rolled-back"" => true
}},
""server-two"" => {""response"" => {
""outcome"" => ""failed"",
""failure-description"" => ""WFLYSRV0201: Cannot have more than one of [bytes, input-stream-index, hash, url, empty]"",
""rolled-back"" => true
}}
}}}}
}",org.jboss.as.domain.controller.operations.coordination.ServerOperationResolver
FILE,WFCORE,WFCORE-1992,2016-11-15T14:35:44.000-06:00,CLI inconsistently parse {} in another object as UNDEFINED,"{}    
 {path=$SOME_PATH}  {} 
 {}












  {rdn-identifier=uid,otp-credential-mapper={}
CLI interprets {} as blank object in resource attribute (correct), but as UNDEFINED in object attribute.
(in model parameter of performRuntime of ADD operation)
/subsystem=elytron/properties-realm=realm:add(users-properties={path=$SOME_PATH},groups-properties={})
=> groups-properties = OBJECT {}
/subsystem=elytron/ldap-realm=ldap-realm8:add(dir-context=local-ldap,identity-mapping={rdn-identifier=uid,otp-credential-mapper={}})
=> otp-credential-mapper=UNDEFINED","org.jboss.as.cli.parsing.test.ArgumentValueConverterTestCase
org.jboss.as.cli.parsing.arguments.ArgumentValueCallbackHandler"
METHOD,tika-1.3,TIKA-1152,2013-07-23T08:45:11.000-05:00,Process loops infinitely on parsing of a CHM file,"{code}
 
    
     
    
    
    
    
    
    
    
    
 {code}
By parsing [the attachment CHM file|^eventcombmt.chm] (MS Microsoft Help Files), Java process stuck.
{code}
Thread[main,5,main]
org.apache.tika.parser.chm.lzx.ChmLzxBlock.extractContent(ChmLzxBlock.java:203)
org.apache.tika.parser.chm.lzx.ChmLzxBlock.<init>(ChmLzxBlock.java:77)
org.apache.tika.parser.chm.core.ChmExtractor.extractChmEntry(ChmExtractor.java:338)
org.apache.tika.parser.chm.CHMDocumentInformation.getContent(CHMDocumentInformation.java:72)
org.apache.tika.parser.chm.CHMDocumentInformation.getText(CHMDocumentInformation.java:141)
org.apache.tika.parser.chm.CHM2XHTML.process(CHM2XHTML.java:34)
org.apache.tika.parser.chm.ChmParser.parse(ChmParser.java:51)
org.apache.tika.parser.ParserDecorator.parse(ParserDecorator.java:91)
org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:242)
org.apache.tika.parser.AbstractParser.parse(AbstractParser.java:53)
com.polyspot.document.converter.DocumentConverter.realizeConversion(DocumentConverter.java:192)
...
{code}","org.apache.tika.parser.chm.lzx.ChmLzxBlock:decompressAlignedBlock(int, byte[])
org.apache.tika.parser.chm.lzx.ChmLzxBlock:extractContent()
org.apache.tika.parser.chm.lzx.ChmLzxBlock:decompressUncompressedBlock(int, byte[])"
METHOD,tika-1.3,TIKA-1192,2013-11-06T15:31:41.000-06:00,ArrayIndexOutOfBoundsException: 9 parsing RTF,"{noformat}
  
    
    
    
    
    
    
  
    
    
  
  
  
    
  
  
  
    
  
  
  
    
    
 {noformat}
When trying to parse an RTF file I'm getting the following exception.
I am not able to attach the file for privacy reasons:
{noformat}
java.lang.ArrayIndexOutOfBoundsException: 9
TextExtractor.java:872 org.apache.tika.parser.rtf.TextExtractor.processControlWord
TextExtractor.java:566 org.apache.tika.parser.rtf.TextExtractor.parseControlWord
TextExtractor.java:492 org.apache.tika.parser.rtf.TextExtractor.parseControlToken
TextExtractor.java:459 org.apache.tika.parser.rtf.TextExtractor.extract
TextExtractor.java:448 org.apache.tika.parser.rtf.TextExtractor.extract
RTFParser.java:56 org.apache.tika.parser.rtf.RTFParser.parse
(Unknown Source) sun.reflect.NativeMethodAccessorImpl.invoke0
NativeMethodAccessorImpl.java:57 sun.reflect.NativeMethodAccessorImpl.invoke
DelegatingMethodAccessorImpl.java:43 sun.reflect.DelegatingMethodAccessorImpl.invoke
Method.java:606 java.lang.reflect.Method.invoke
Reflector.java:93 clojure.lang.Reflector.invokeMatchingMethod
Reflector.java:28 clojure.lang.Reflector.invokeInstanceMethod
tika_parser.clj:20 rtf-parser.tika-parser/parse
form-init2921349737948661927.clj:1 rtf-parser.tika-parser/eval4200
Compiler.java:6619 clojure.lang.Compiler.eval
Compiler.java:6582 clojure.lang.Compiler.eval
core.clj:2852 clojure.core/eval
main.clj:259 clojure.main/repl[fn]
main.clj:259 clojure.main/repl[fn]
main.clj:277 clojure.main/repl[fn]
main.clj:277 clojure.main/repl
RestFn.java:1096 clojure.lang.RestFn.invoke
interruptible_eval.clj:56 clojure.tools.nrepl.middleware.interruptible-eval/evaluate[fn]
AFn.java:159 clojure.lang.AFn.applyToHelper
AFn.java:151 clojure.lang.AFn.applyTo
core.clj:617 clojure.core/apply
core.clj:1788 clojure.core/with-bindings*
RestFn.java:425 clojure.lang.RestFn.invoke
interruptible_eval.clj:41 clojure.tools.nrepl.middleware.interruptible-eval/evaluate
interruptible_eval.clj:171 clojure.tools.nrepl.middleware.interruptible-eval/interruptible-eval[fn]
core.clj:2330 clojure.core/comp[fn]
interruptible_eval.clj:138 clojure.tools.nrepl.middleware.interruptible-eval/run-next[fn]
AFn.java:24 clojure.lang.AFn.run
ThreadPoolExecutor.java:1145 java.util.concurrent.ThreadPoolExecutor.runWorker
ThreadPoolExecutor.java:615 java.util.concurrent.ThreadPoolExecutor$Worker.run
Thread.java:724 java.lang.Thread.run
{noformat}",org.apache.tika.parser.rtf.RTFParserTest:getResult(String)
METHOD,eclipse-2.0,13926,2002-04-16T13:41:00.000-05:00,JFace Text Editor Leaves a Black Rectangle on Content Assist text insertion,"class ContextInformationPopup
	 public void showContextInformation(final IContextInformation info, 
final int position) {
		Control control= fViewer.getTextWidget();
		BusyIndicator.showWhile(control.getDisplay(), new Runnable() {
			public void run() {
				internalShowContextInfo(info, position);
				hideContextSelector();
			}
		});
	}
We found a problem when migrating editors based on JFace Text from V10 to V20 
(driver 20020412).
We found that after inserting a selected completion 
proposal, from the context information popup, that causes a black rectangle to 
appear on top of the display.
See the attached screen shot.
Tracing the appearance of the rectangle down, we see the rectangle just after 
going in the BusyIndicator.showWhile.
----------  The rectangle appears in the execution of this ----------------
class ContextInformationPopup
public void showContextInformation(final IContextInformation info,
final int position) {
Control control= fViewer.getTextWidget();
BusyIndicator.showWhile(control.getDisplay(), new Runnable() {
public void run() {
internalShowContextInfo(info, position);
hideContextSelector();
}
});
}","org.eclipse.jface.text.contentassist.ContextInformationPopup:internalShowContextFrame(ContextFrame, boolean)"
METHOD,eclipse-2.0,15277,2002-05-05T00:01:00.000-05:00,Recreate test suite allows you to add the suite to itself,"suite() 
 suite()
If you have a test suite that is also a test case (done to allow cascading tests), and recreate the 
test suite, you're allowed to add the suite to itself.
This results in a recursive call to 
.
suite(), which ends up causing a stack overflow when run.
I'm not too sure on this, but I 
believe previously in this situtation the suite was added to itself a test case (new Suite(class) 
as opposed to class.suite()), which prevented this from happening.
I do prefer this new 
behaviour, as it makes chaining suites together much easier (now if it only searched sub-packages 
for suites).
This one special case just needs to be handled better.","org.eclipse.jdt.internal.junit.wizards.NewTestSuiteCreationWizardPage:handleFieldChanged(String)
org.eclipse.jdt.internal.junit.wizards.NewTestSuiteCreationWizardPage:setVisible(boolean)
org.eclipse.jdt.internal.junit.wizards.NewTestSuiteCreationWizardPage:testSuiteChanged()"
METHOD,eclipse-2.0,16787,2002-05-22T08:55:00.000-05:00,[Wizards] Wizards are recreated when returning to New page,"showPage()   showStartingPage() 
 page.getControl()  
 page.getControl()    
  
 public void dispose() {
	   super.dispose();
	   this.setControl(null);
	}
The WizardDialog ask's in showPage() or showStartingPage():
    if (page.getControl() == null)
to support a lazy page control creation.
This works fine when the wizard is called first time.
After disposing a page 
page.getControl() still returns a (disposed) control and page.createControl
(pageContainer) is not called again.
I overwrote the method:
	public void dispose() {
	   super.dispose();
	   this.setControl(null);
	}
in all my pages as workaround.
I suggest to add this method to WizardPage.",org.eclipse.ui.internal.dialogs.NewWizardNewPage:handleWizardSelection(SelectionChangedEvent)
METHOD,eclipse-2.0,31779,2003-02-13T09:55:00.000-06:00,[resources] UnifiedTree should ensure file/folder exists,"getStat()
Build: I20030211 using natives (Linux/Windows)
When the UnifiedTree finds a new file from the file system, it assumes that if the file is not an existing file, then it is a folder.
This is not always true, because for different reasons a file returned by java.io.File.list/listFiles may not actually exist (our CoreFileSystemLibrary#getStat() returns 0).
At the first moment, the file is found in the file system and assumed to be a folder, and a corresponding resource is created in the workspace.
At the second refresh, the folder corresponding to that resource is not found in the file system, and then it is removed from the workspace.
And so on.
Bugs that revealed this problem: bug 21217 and bug 13463.","org.eclipse.core.internal.localstore.UnifiedTree:addChildrenFromFileSystem(UnifiedTreeNode, String, Object[], int)
org.eclipse.core.internal.localstore.UnifiedTree:createChildNodeFromFileSystem(UnifiedTreeNode, String, String)"
