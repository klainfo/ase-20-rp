Dataset,System,Bug ID,Creation Date,Title,Description,Ground Truth
CLASS,lucene-4.0,LUCENE-4461,2012-10-05T10:21:38.000-05:00,Multiple FacetRequest with the same path creates inconsistent results,"FacetSearchParams facetSearchParams = new FacetSearchParams();
		facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(""author""), 10));
		facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(""author""), 10));
Multiple FacetRequest are getting merged into one creating wrong results in this case:
FacetSearchParams facetSearchParams = new FacetSearchParams();
		facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(""author""), 10));
		facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(""author""), 10));
Problem can be fixed by defining hashcode and equals in certain way that Lucene recognize we are talking about different requests.
Attached test case.",org.apache.lucene.facet.search.StandardFacetsAccumulator
CLASS,tika-1.3,TIKA-1070,2013-01-31T05:43:33.000-06:00,StackOverflow error in org.apache.tika.sax.ToXMLContentHandler$ElementInfo.getPrefix(ToXMLContentHandler.java:58),"new ElementInfo(currentElement, namespaces);
The error occurs when parsing big ""XLS"" files and is caused by the ElementInfo stored in ""currentElement"".
Each time a new element is started (method startElement) the current elment is newly overwritten with
currentElement = new ElementInfo(currentElement, namespaces);
where the existing element is used as the parent element.
Since the currentElement is not reset to the parent element after finishing the element (method: endElement) the method getPrefix recursively traverses the parents and finally causes the StackOverFlowError
For my understanding: something like:
currentElement = currentElement.parent;
in the endElement method solves the issue!
Best",tika-core.src.main.java.org.apache.tika.sax.ToXMLContentHandler
CLASS,tika-1.3,TIKA-1152,2013-07-23T08:45:11.000-05:00,Process loops infinitely on parsing of a CHM file,"{code}
 
    
     
    
    
    
    
    
    
    
    
 {code}
By parsing [the attachment CHM file|^eventcombmt.chm] (MS Microsoft Help Files), Java process stuck.
{code}
Thread[main,5,main]
org.apache.tika.parser.chm.lzx.ChmLzxBlock.extractContent(ChmLzxBlock.java:203)
org.apache.tika.parser.chm.lzx.ChmLzxBlock.<init>(ChmLzxBlock.java:77)
org.apache.tika.parser.chm.core.ChmExtractor.extractChmEntry(ChmExtractor.java:338)
org.apache.tika.parser.chm.CHMDocumentInformation.getContent(CHMDocumentInformation.java:72)
org.apache.tika.parser.chm.CHMDocumentInformation.getText(CHMDocumentInformation.java:141)
org.apache.tika.parser.chm.CHM2XHTML.process(CHM2XHTML.java:34)
org.apache.tika.parser.chm.ChmParser.parse(ChmParser.java:51)
org.apache.tika.parser.ParserDecorator.parse(ParserDecorator.java:91)
org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:242)
org.apache.tika.parser.AbstractParser.parse(AbstractParser.java:53)
com.polyspot.document.converter.DocumentConverter.realizeConversion(DocumentConverter.java:192)
...
{code}",tika-parsers.src.main.java.org.apache.tika.parser.chm.lzx.ChmLzxBlock
FILE,DATAMONGO,DATAMONGO-467,2012-06-24T08:58:49.000-05:00,"String @id field is not mapped to ObjectId when using QueryDSL "".id"" path","@Document 
 @Id String id;






 
 QUser.id.eq(""4f43b6a384aea4e77d403709"")
use entity definition with String
User.class
...
@Id String id;
and following query
QUser.id.eq(""4f43b6a384aea4e77d403709"")
Always returns null for a repository find.
Looking at the mongoDb query log (mongod -v) it appears that the spring-data-mongodb/QueryDSL layers are not translating the String 4f43b6a384aea4e77d403709 to ObjectId(""4f43b6a384aea4e77d403709"") as one would normally do in the mongo shell.",org.springframework.data.mongodb.repository.support.SpringDataMongodbSerializerUnitTests
FILE,DATAMONGO,DATAMONGO-505,2012-08-14T03:07:56.000-05:00,Conversion of associations doesn't work for collection values,"class Entity {









  Long id;




  @DBRef




  Property property;




}









 class Property {




  Long id;




}









 interface EntityRepository extends Repository<Entity, Long> {









  Entity findByPropertyIn(Property... property);




}






  findByProperty()
have following scenario
class Entity {
Long id;
@DBRef
Property property;
}
class Property {
Long id;
}
interface EntityRepository extends Repository<Entity, Long> {
Entity findByPropertyIn(Property... property);
}
The execution of findByProperty() will fail as the given array (or collection) is not correctly translated into a collection of DBRefs.
The reason is that ConvertingIterator treats the value as is and wants to create a DBRef from it.","org.springframework.data.mongodb.repository.query.ConvertingParameterAccessor
org.springframework.data.mongodb.repository.query.ConvertingParameterAccessorUnitTests"
FILE,DATAMONGO,DATAMONGO-523,2012-09-01T03:39:51.000-05:00,@TypeAlias annotation not used with AbstractMongoConfiguration,"@TypeAlias      @Document  @TypeAlias
When using the AbstractMongoConfiguration without any further modifications regarding the converter (afterMappingMongoConverterCreation) the @TypeAlias annotation is not used when writing the _class property.
Seems like it always uses the SimpleTypeInformationMapper.
The documentation suggests that you just annotate your @Document classes with the @TypeAlias annotations and everything should be fine.",org.springframework.data.mongodb.core.convert.MappingMongoConverterUnitTests
FILE,DATAMONGO,DATAMONGO-585,2012-12-01T08:28:43.000-06:00,Exception during authentication in multithreaded access,"class which implements Runnable.  
Those
Bug & further details are here:
http://forum.springsource.org/showthread.php?132878-can-t-authenticate-twice-on-same-database
use ThreadPoolExecutor set minpool maxpool value add objects use specifically for test case
implement runnable implement class
perform bunch into mongoDB perform bunch of inserts use DocumentDao call mongoOperations.insert. call DocumentDao
thanks",org.springframework.data.mongodb.core.MongoDbUtils
FILE,DATAMONGO,DATAMONGO-629,2013-03-22T04:08:25.000-05:00,Different results when using count and find with the same criteria with 'id' field,"Query q = query 
    
  
 
 
 {




		""id"" : /zzz/




	} 
 
 
 
 
 
  
  
 
 
 {




		""count"" : ""test"",




		""query"" : {




			""_id"" : /zzz/




		}




	 
 
 
 
 
 
     find()     count()
have following query
Query q = query(where('id').
regex('zzz'))
mongoTemplate.find(q,java.util.HashMap.class,'test') gives following query (peeked in mongo console):
{ ""ts"" : ISODate(""2013-03-22T10:00:51.685Z""),
""op"" : ""query"",
""ns"" : ""test.test"",
""query"" : {
""id"" : /zzz/
},
""nscanned"" : 1,
""responseLength"" : 20,
""millis"" : 0,
""client"" : ""127.0.0.1"",
""user"" : """"
}
The same query, when used in count (mongoTemplate.count(q,'test')) gives:
{
""ts"" : ISODate(""2013-03-22T10:00:36.299Z""),
""op"" : ""command"",
""ns"" : ""test.
$cmd"",
""command"" : {
""count"" : ""test"",
""query"" : {
""_id"" : /zzz/
}
},
""ntoreturn"" : 1,
""responseLength"" : 48,
""millis"" : 0,
""client"" : ""127.0.0.1"",
""user"" : """"
}
This is inconsistent since we could have records with field id and they will be retrieved properly from the db.
Count on the other hand will give bad results since it uses _id field.
In org.springframework.data.mongodb.core.convert.QueryMapper the method determineKey, for some reason treats id and _id as the same field.
This is probably the cause of the strange behaviour because find() method does not use QueryMapper and count() does.","org.springframework.data.mongodb.core.mapping.MongoMappingContext
org.springframework.data.mongodb.core.MongoTemplateTests
org.springframework.data.mongodb.core.convert.QueryMapper
org.springframework.data.mongodb.core.convert.QueryMapperUnitTests"
FILE,DATAMONGO,DATAMONGO-571,2012-11-09T08:00:10.000-06:00,Spring Data for MongoDb doesn't save null values when @Version is added to domain class,"Scenario 
 CrudRepository.findOne()  
 @Version 
 CrudRepository.save()  
 @Version
Scenario:
use CrudRepository.findOne() method load domain class from mongodb
set loaded instances to null
use CrudRepository.save() method save loaded instance to same mongodb
set field to null doesnt write to database
Important: The problem doesnt occur when @Version annotation is not used in the domain class definition.","org.springframework.data.mongodb.core.MongoTemplateTests
org.springframework.data.mongodb.core.query.Update"
FILE,DATAMONGO,DATAMONGO-392,2012-02-07T04:28:15.000-06:00,Updating an object does not write type information for objects to be updated,"MappingMongoConverter.writeInternal(...)   addCustomTypeIfNecessary(...)     convertToMongoType(...)   removeTypeInfoRecursively(...)
use complex domain model consist complex domain model of instantiable domain classes
I used 1.0.0.
M5 version, and the type information (under _class key) was stored with object when it was necessary to be able to read it from database later.
That worked perfectly for me till my upgrade to 1.0.0.
RELEASE version that broke my application as it saves the objects without type information and later it is impossible to read it back to java model.
What I found is that MappingMongoConverter.writeInternal(...) method that in turn calls addCustomTypeIfNecessary(...) (line 330) which puts type information into DBObject.
During execution of convertToMongoType(...) (at line 851) removeTypeInfoRecursively(...) is called which clears type data saved earlier under _class key.
I had to comment out this call in order to
The first point is that there is a contradiction: why to save type information to DBObject if it is later removed by other method?","org.springframework.data.mongodb.core.MongoTemplateTests
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-721,2013-07-11T11:36:06.000-05:00,Polymorphic attribute type not persisted on update operations,"@Document
public class ParentClass {
   private List<ChildClass> list;
}
    @Document   
        
  
 mongoTemplate.updateFirst(Query.query(criteria), 
  new Update().push(""list"", child));
We found a problem with Spring Data for Mongo DB.
have entity have attribute have entity
@Document public class ParentClass { private List<ChildClass> list;
} the ChildClass is annotated with @Document too, but we want to store it's content as an embed document of ParentClass.
When using MongoTemplate class with code such as below, the _class attribute is not inserted on the embedded document, so, if one of the items of the list attribute is a subclass of ChildClass, and ChildClass is an abstract class, we begin to face instantiation problems.
mongoTemplate.updateFirst(Query.query(criteria), new Update().
push(""list"", child));
If child is a subclass of ChildClass, the _class attribute is not added to the embedded document.",org.springframework.data.mongodb.core.convert.QueryMapper
FILE,DATAMONGO,DATAMONGO-602,2013-01-30T02:22:53.000-06:00,Querying with $in operator on the id field of type BigInteger returns zero results,"List<BigInteger> profileIds = findProfileIds();




Predicate predicate = QProfileDocument.profileDocument.id.in(profileIds);




Iterable<ProfileDocument> profiles = profileRepository.findAll(predicate);
query for documents be in given list
Id field is mapped as a BigInteger.
contain item
List<BigInteger> profileIds = findProfileIds();
Predicate predicate = QProfileDocument.profileDocument.id.in(profileIds);
Iterable<ProfileDocument> profiles = profileRepository.findAll(predicate);
The underlying MongodbQuery is different if there is only one item in profileIds.
The query looks like this for a profileIds with multiple elements
{ ""_id"" : { ""$in"" : [ ""25069473312490162649510603609"" , ""25045916045544535958655878835""]}}
and it looks like this when there is only one item in the list.
{ ""_id"" : { ""$oid"" : ""5100fb776c67e7e092be6b59""}}
In the first case, query will return no results and in the second it will work and return an Iterable with one item.
As you can see, the problem is with the representation of the BigInteger.
using decimal format will not work with MongoDB.",org.springframework.data.mongodb.core.MongoTemplateTests
FILE,DATAMONGO,DATAMONGO-805,2013-12-02T06:34:36.000-06:00,Excluding DBRef field in a query causes a MappingException,"Query query = new Query(Criteria.where(""parentField"").is(""test""));
        query.fields().exclude(""children"");
        ParentClass parentClass = mongoOperations.findOne(query, ParentClass.class);
Excluding a field in a query where the field is a DBRef as below throws a MappingException.
Query query = new Query(Criteria.where(""parentField"").
is(""test""));
query.fields().
exclude(""children"");
ParentClass parentClass = mongoOperations.findOne(query, ParentClass.class);
Exception trace:
org.springframework.data.mapping.model.MappingException: No mapping metadata found for class java.lang.Integer
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.createDBRef(MappingMongoConverter.java:729)
at com.digitalshadows.collation.persistence.impl.CollectionNameProvidedMongoConverter.createDBRef(CollectionNameProvidedMongoConverter.java:28)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.toDBRef(MappingMongoConverter.java:288)
at org.springframework.data.mongodb.core.convert.QueryMapper.convertAssociation(QueryMapper.java:273)
at org.springframework.data.mongodb.core.convert.QueryMapper.getMappedValue(QueryMapper.java:204)
at org.springframework.data.mongodb.core.convert.QueryMapper.getMappedObject(QueryMapper.java:113)
at org.springframework.data.mongodb.core.MongoTemplate.doFindOne(MongoTemplate.java:1439)
at org.springframework.data.mongodb.core.MongoTemplate.findOne(MongoTemplate.java:489)
at org.springframework.data.mongodb.core.MongoTemplate.findOne(MongoTemplate.java:484)
at ExcludeDBRefFieldTest.testExcludeChildren(ExcludeDBRefFieldTest.java:28)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
at java.lang.reflect.Method.invoke(Unknown Source)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:74)
at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:83)
at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:72)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:231)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:88)
at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:174)
at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
attach simple test case throw MappingException throw simple test case
The workaround for this I can currently see is to use include for all the other fields instead.","org.springframework.data.mongodb.core.convert.QueryMapper
org.springframework.data.mongodb.core.mapping.MappingTests
org.springframework.data.mongodb.core.convert.QueryMapperUnitTests"
FILE,DATAMONGO,DATAMONGO-897,2014-04-01T04:38:51.000-05:00,FindAndUpdate broken when using @DbRef and interface as target,"MongoTemplate.findAndModify(...)   @DbRef  @DbRef
NullPointerException is thrown when using MongoTemplate.findAndModify(...) with @DbRef and interface as @DbRef target.
See attached project for more details.
Probably regression issue since same test is passing with Spring Data Commons 1.6.3.
RELEASE and Spring Data MongoDB 1.3.3.
RELEASE.","org.springframework.data.mongodb.core.convert.UpdateMapperUnitTests
org.springframework.data.mongodb.core.convert.QueryMapper"
FILE,DATAMONGO,DATAMONGO-892,2014-03-28T09:08:03.000-05:00,<mongo:mapping-converter> can't be configured as nested bean definition,"parserContext.isNested()
work sample config in 1.1.1 version
<beans:bean id=""messageStore"" class=""org.springframework.integration.mongodb.store.ConfigurableMongoDbMessageStore"">
<beans:constructor-arg ref=""mongoDbFactory""/>
<beans:constructor-arg>
<mongo:mapping-converter>
<mongo:custom-converters>
<mongo:converter>
<beans:bean class=""org.springframework.integration.mongodb.store.ConfigurableMongoDbMessageGroupStoreTests$MessageReadConverter""/>
</mongo:converter>
</mongo:custom-converters>
</mongo:mapping-converter>
</beans:constructor-arg>
<beans:constructor-arg value=""testConfigurableMongoDbMessageStore""/>
</beans:bean>
That's because MappingMongoConverterParser doesn't check if the parserContext.isNested(), registers BeanDefinition and returns null","org.springframework.data.mongodb.config.MappingMongoConverterParser
org.springframework.data.mongodb.config.MappingMongoConverterParserIntegrationTests"
FILE,DATAMONGO,DATAMONGO-647,2013-04-09T17:29:02.000-05:00,"Using ""OrderBy"" in ""query by method name"" ignores the @Field annotation for field alias.","@Field(""sr"")
 
 List<Answer> findByQuestionIdOrderByScoreDesc(String questionId)
create method use query approach
have field inside Answer object call score annotate score
@Field(""sr"")
int Score
List<Answer> findByQuestionIdOrderByScoreDesc(String questionId)
When the query is run, the database attempts to sort the results by ""score"" rather than my ""sr"" field name.",org.springframework.data.mongodb.core.convert.QueryMapperUnitTests
FILE,DATAMONGO,DATAMONGO-745,2013-09-03T02:15:08.000-05:00,@Query($in) and Pageable in result Page total = 0,"@Query(""{'snapshotId' : ?0 ,'defects.id':{ $in:?1}}"")
Page<Test> findBySnapshotIdAndDefects(ObjectId snapshotId, List<Integer> defectIds, Pageable pageable) 
 {5225a5ece4b0a01629fce9c6={ ""_id"" : 
{ ""$oid"" : ""5225a5ece4b0a01629fce9c6""}
Hi If I used MongoRepository and anotation Quary and Pageable in response I get true result but getTotalElements == 0
@Query(""{'snapshotId' : ?
0 ,'defects.id':{ $in:?
1}}"")
Page<Test> findBySnapshotIdAndDefects(ObjectId snapshotId, List<Integer> defectIds, Pageable pageable);
Base Struct
{5225a5ece4b0a01629fce9c6={ ""_id"" :
{ ""$oid"" : ""5225a5ece4b0a01629fce9c6""}
, ""snapshotId"" :
{ ""$oid"" : ""5225a5ece4b0a01629fce9c5""}
, ""defects"" : [
{ ""_id"" : 1 }
]}","org.springframework.data.mongodb.repository.Person
org.springframework.data.mongodb.repository.AbstractPersonRepositoryIntegrationTests
org.springframework.data.mongodb.repository.PersonRepository"
FILE,DATAMONGO,DATAMONGO-938,2014-05-21T06:09:48.000-05:00,Exception when creating geo within Criteria using MapReduce,"Criteria.where(""location"")  within(new Box(lowerLeft, upperRight));
I am getting an IllegalArgumentException when I try to query a MongoDB collection using a Criteria.within and a Box.
Criteria.where(""location"").
within(new Box(lowerLeft, upperRight));
The exception reads:
java.lang.IllegalArgumentException: can't serialize class org.springframework.data.mongodb.core.query.GeoCommand","org.springframework.data.mongodb.core.mapreduce.MapReduceTests
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-952,2014-06-10T22:45:47.000-05:00,@Query annotation does not work with only field restrictions,"@Query 
 @Query(fields = ""{ 'email' : 1 }"")




User findByEmail(String email)






  @Query
If you are using repository based queries and try to use @Query annotation to limit the fetched fields, it has zero effect.
@Query(fields = ""{ 'email' : 1 }"")
User findByEmail(String email)
The query above returns all fields of the User and the fields definition has no effect at all.
If you are using @Query with value attribute to define the query, then the fields limitation is applied though.",org.springframework.data.mongodb.repository.query.PartTreeMongoQuery
FILE,DATAMONGO,DATAMONGO-987,2014-07-14T12:01:52.000-05:00,Problem with lazy loading in @DBRef when getting data using MongoTemplate,"@Document 
 @Document




class Parent {




     @Id




     private String id;




     private String name;




     @DBref(lazy=true)




     private Child child;









    // getters and setters ommited




}






 
 @Document




class Child {




      @Id




       private String id;




       private String name;




      //getters and setters ommited




}






 
 Parent parent = new Parent();




parent.setName(""Daddy"");




mongoTemplate.save(parent); //ok, it is persisted like we expected.




// Than we try to load this same entity from the database




Criteria criteria = Criteria.where(""_id"").is(parent.getId());




Parent persisted = mongoTemplate.findOne(new Query(criteria), Parent.class);




// The child attribute should be null, right?




assertNull(persisted.getChild()); // it fails
call Parent call child reference on entity class
@Document
class Parent {
@Id
private String id;
private String name;
@DBref(lazy=true)
private Child child;
// getters and setters ommited
}
and the Child class
@Document
class Child {
@Id
private String id;
private String name;
//getters and setters ommited
}
Parent parent = new Parent();
parent.setName(""Daddy"");
load same entity from database
Criteria criteria = Criteria.where(""_id"").
is(parent.getId());
Parent persisted = mongoTemplate.findOne(new Query(criteria), Parent.class);
assertNull(persisted.getChild()); // it fails
The null attribute is actually an enhanced class generated by CGLib.
It should not be.
This brings a lot of problems when you, by accident, persist the same entity.
I attached a project with the JUnit test which reproduces the problem for you.","org.springframework.data.mongodb.core.convert.MappingMongoConverter
org.springframework.data.mongodb.core.convert.DbRefMappingMongoConverterUnitTests"
FILE,DATAMONGO,DATAMONGO-1068,2014-10-08T19:43:32.000-05:00,elemMatch of Class Criteria fails to build special cirteria,"public class Room {




		private String name;




		private List<Date> occupied;




	}






 
 {




		occupied : {




			$not : {




				$elemMatch : {




					$gte : start,




					$lte : end




				}




			}




		}




	}






 
 Criteria c1 = new Criteria().gte(start).lte(end);




	Criteria c = Criteria.where(""occupied"").not().elemMatch(c1);






 
 {




	occupied : {




		$not : {




			$elemMatch : {




			}




		}




	}




}






  elemMatch(Criteria)
public class Room {
private String name;
private List<Date> occupied;
}
fetch documents fall documents into specified date range
{
occupied : {
$not : {
$elemMatch : {
$gte : start,
$lte : end
}
}
}
}
Criteria c1 = new Criteria().
gte(start).
lte(end);
Criteria c = Criteria.where(""occupied"").
not().
elemMatch(c1);
But the serialization to JSON for c is:
{
occupied : {
$not : {
$elemMatch : {
}
}
}
}
It seems that c1 will be explained to empty Map by invoking elemMatch(Criteria) because I haven't assign a key to it.
But really no key I can assign to it.","org.springframework.data.mongodb.core.query.CriteriaTests
org.springframework.data.mongodb.core.query.Criteria"
FILE,DATAMONGO,DATAMONGO-1088,2014-11-07T03:08:58.000-06:00,"@Query $in does not remove ""_class"" property on collection of embedded objects","@Query(value = ""{ embedded : { $in : ?0} }"")




	List<Foo> findByEmbeddedIn2(Collection<EmbeddedObject> c)
@Query(value = ""{ embedded : { $in : ?
0} }"")
List<Foo> findByEmbeddedIn2(Collection<EmbeddedObject> c);
generates incorrect query.
{ ""embedded"" : { ""$in"" : [ {  ""_class"" : ""demo.EmbeddedObject"" , ""s"" : ""hello""}]}}
{ ""embedded"" : { ""$in"" : [ { ""s"" : ""hello""}]}}
attach test project demonstrate bug
This bug is related to https://jira.spring.io/browse/DATAMONGO-893","org.springframework.data.mongodb.core.convert.MappingMongoConverter
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-1123,2014-12-17T09:39:36.000-06:00,"geoNear, does not return all matching elements, it returns only a max of 100 documents","public GeoResults<MyObject> findByTypeAndLocationNear(MyObjectType type, Point p, Distance distance) {




   final NearQuery nearQuery = NearQuery.near(p).maxDistance(distance);




   log.info(""{}"",nearQuery.toDBObject());




   return mongoTemplate.geoNear(nearQuery, MyObject.class);




}






   
 {@link GeoResults}   {@link NearQuery}
Aloha,
have following query
public GeoResults<MyObject> findByTypeAndLocationNear(MyObjectType type, Point p, Distance distance) {
final NearQuery nearQuery = NearQuery.near(p).
maxDistance(distance);
log.info(""{}"",nearQuery.toDBObject());
return mongoTemplate.geoNear(nearQuery, MyObject.class);
}
The geoNear method is documented like this:
Returns {@link GeoResults} for all entities matching the given {@link NearQuery}.
I expect 1000 ""matching"" documents But i only get 100.
There is some default being set, that restricts the result to 100.
That should be stated in the method.
And another method having a pageable should be added.
What do you think?",org.springframework.data.mongodb.core.MongoOperations
FILE,DATAMONGO,DATAMONGO-1126,2014-12-21T06:03:21.000-06:00,Repository keyword query findByInId with pageable not returning correctly,"getTotalElements()   getTotalPages()  
 @Document




public class Item {









    @Id




    private String id;




    private String type;




}












 public interface ItemRepository extends MongoRepository<Item, String> {









    Page<Item> findByIdIn(Collection ids, Pageable pageable);




    Page<Item> findByTypeIn(Collection types, Pageable pageable);




}












 @RunWith(SpringJUnit4ClassRunner.class)




@ContextConfiguration(classes = {MongoDbConfig.class})




@TransactionConfiguration(defaultRollback = false)




public class TestPageableIdIn {









    @Autowired




    private ItemRepository itemRepository;




    




    private List<String> allIds = new LinkedList<>();









    @Before




    public void setUp() {




        itemRepository.deleteAll();




        String[] types = {""SWORD"", ""SHIELD"", ""ARMOUR""};









        // 10 items per type




        for (String type : types) {




            for (int i = 0; i < 10; i++) {




                String id = UUID.randomUUID().toString();




                allIds.add(id);




                itemRepository.save(new Item(id, type));




            }




        }




    }









    @Test




    public void testPageableIdIn() {




        




        Pageable pageable = new PageRequest(0, 5);




        




        // expect 5 Items returned, total of 10 Items(SWORDS) in 2 Pages




        Page<Item> results = itemRepository.findByTypeIn(Arrays.asList(""SWORD""), pageable);




        Assert.assertEquals(5, results.getContent().size());




        Assert.assertEquals(10, results.getTotalElements());




        Assert.assertEquals(2, results.getTotalPages());




        




        // expect 5 Items returned, total of 30 Items in 6 Pages




        results = itemRepository.findByIdIn(allIds, pageable);




        Assert.assertEquals(5, results.getContent().size());




        Assert.assertEquals(30, results.getTotalElements()); // this is returning 0




        Assert.assertEquals(6, results.getTotalPages());     // this is returning 0




    }




}
use with identifiers make query pageable
The query returns results but getTotalElements() and getTotalPages() always returns 0.
Also when you try to get any other page than 0, no results return.
I've tried using In with another member other than id and it works as expected.
use for testing
create types in total create types per types create items in total create items per types
@Document
public class Item {
@Id
private String id;
private String type;
}
public interface ItemRepository extends MongoRepository<Item, String> {
Page<Item> findByIdIn(Collection ids, Pageable pageable);
Page<Item> findByTypeIn(Collection types, Pageable pageable);
}
@RunWith(SpringJUnit4ClassRunner.class)
@ContextConfiguration(classes = {MongoDbConfig.class})
@TransactionConfiguration(defaultRollback = false)
public class TestPageableIdIn {
@Autowired
private ItemRepository itemRepository;
private List<String> allIds = new LinkedList<>();
@Before
public void setUp() {
itemRepository.deleteAll();
String[] types = {""SWORD"", ""SHIELD"", ""ARMOUR""};
// 10 items per type
for (String type : types) {
for (int i = 0; i < 10; i++) {
String id = UUID.randomUUID().
toString();
allIds.add(id);
itemRepository.save(new Item(id, type));
}
}
}
@Test
public void testPageableIdIn() {
Pageable pageable = new PageRequest(0, 5);
Page<Item> results = itemRepository.findByTypeIn(Arrays.asList(""SWORD""), pageable);
Assert.assertEquals(5, results.getContent().
size());
Assert.assertEquals(10, results.getTotalElements());
Assert.assertEquals(2, results.getTotalPages());
results = itemRepository.findByIdIn(allIds, pageable);
Assert.assertEquals(5, results.getContent().
size());
Assert.assertEquals(30, results.getTotalElements()); // this is returning 0
Assert.assertEquals(6, results.getTotalPages());     // this is returning 0
}
}","org.springframework.data.mongodb.repository.Person
org.springframework.data.mongodb.repository.query.AbstractMongoQueryUnitTests
org.springframework.data.mongodb.core.MongoOperations
org.springframework.data.mongodb.core.MongoTemplate
org.springframework.data.mongodb.repository.query.AbstractMongoQuery"
FILE,DATAMONGO,DATAMONGO-1202,2015-04-14T02:36:40.000-05:00,Indexed annotation problems under generics,"@Indexed
There is a problem with the @Indexed annotation with the model classes.
Under simple scenarios with reflexive DBRef relations works as expected, but if used in conjunction with generics it doesn't create the index expected.
provide github project with scenarios
use GenericCustomer as base class have many different kinds of customers
create index fail at creating
This test runs without a Mongo server because it uses embedmongo-spring (https://github.com/jirutka/embedmongo-spring) at a random port each time the test runs.
If you run Application it will just create indexes and put some data in customer collection assuming a MongoD is running locally at 27017","org.springframework.data.mongodb.core.index.MongoPersistentEntityIndexResolver
org.springframework.data.mongodb.core.index.MongoPersistentEntityIndexCreator
org.springframework.data.mongodb.core.index.MongoPersistentEntityIndexCreatorIntegrationTests
org.springframework.data.mongodb.core.index.IndexResolver"
FILE,DATAMONGO,DATAMONGO-1250,2015-07-03T21:07:44.000-05:00,Custom converter implementation not used in updates,"@Document 
 
 
 @Document




public class MyPersistantObject  
 public Allocation allocation;




     public BigDecimal value;









     
 private final String code;









         Allocation(String code) {




            this.code = code;




        }









         public static Converter<Allocation, String> writer() {




            return new Converter<Allocation, String>() {




                public String convert(Allocation allocation) {




                    return allocation.getCode();




                }




            };




        }









         public static Converter<String, Allocation> reader() {




            return new Converter<String, Allocation>() {




                public Allocation convert(String source) {




                    return Allocation.getByCode(source);




                }




            };




        }









         public static Allocation getByCode(String code)  
 return AVAILABLE;




                 
 return ALLOCATED;




             
 throw new IllegalArgumentException(""Unable to get Allocation from: "" + code);




         
 public String getCode() {




            return code;




        }




     
 @Bean




    public CustomConversions customConversions() {




        return new CustomConversions(Arrays.asList(




                MyPersistantObject.Allocation.reader(),




                MyPersistantObject.Allocation.writer()




        ));




    }






 
 @Test




    public void testConversion() {




        Update update;




        Query query;




        MyPersistantObject returned;




        MyPersistantObject myPersistantObject = new MyPersistantObject();




        myPersistantObject.allocation = AVAILABLE;




        myPersistantObject.value = new BigDecimal(1234567);









        mongoTemplate.save(myPersistantObject);









        // Check it was saved correctly - first with invalid allocation to confirm conversion in query




        query = query(where(""allocation"").is(ALLOCATED));




        assertThat(mongoTemplate.findOne(query, MyPersistantObject.class), is(nullValue()));









        // Check it was saved correctly - now with valid allocation to confirm conversion in query




        query = query(where(""allocation"").is(AVAILABLE));




        returned = mongoTemplate.findOne(query, MyPersistantObject.class);




        assertThat(returned.allocation, is(AVAILABLE));




        assertThat(returned.value.longValue(), is(1234567L));









        try {




            // Update allocation from constant - will fail




            update = update(""allocation"", ALLOCATED);




            mongoTemplate.updateMulti(query, update, MyPersistantObject.class);




        } catch (Exception e) {




            System.err.println(""failed to convert allocation: java.lang.IllegalArgumentException: can't serialize class converter_test.MyPersistantObject$Allocation"");




        }









        // Update allocation from string value - succeeds




        update = update(""allocation"", ALLOCATED.getCode());




        mongoTemplate.updateMulti(query, update, MyPersistantObject.class);




        // Check allocation update




        query = query(where(""allocation"").is(ALLOCATED));




        returned = mongoTemplate.findOne(query, MyPersistantObject.class);




        assertThat(returned.allocation, is(ALLOCATED));









        // Update value only - will fail: Caused by: java.lang.IllegalArgumentException: Unable to get MyPersistantObject.Allocation from: 54321




        // Tries to use MyPersistantObject.Allocation converter to String




        update = update(""value"", new BigDecimal(54321));




        mongoTemplate.updateMulti(query, update, MyPersistantObject.class);




        // Check value update




        returned = mongoTemplate.findAll(MyPersistantObject.class).get(0);




        assertThat(returned.value.longValue(), is(54321L));




    }
There does seem to be an issue with the use of customer converters when used in mongoTemplate.update* via an Update object.
have custom serialiser for enumerated type work custom serialiser for enumerated type save @Document annotated POJO load @Document annotated POJO
It also works when building and executing a Query object.
However when used in an Update, it is either ignored, or called in situations where it shouldn't.
clone https://github.com/patrickherrera/converter_test.git for full test application
have static enum with desired converters be in brief
@Document
public class MyPersistantObject {
public Allocation allocation;
public BigDecimal value;
public enum Allocation {
AVAILABLE(""V""),
ALLOCATED(""A"");
private final String code;
Allocation(String code) {
this.code = code;
}
public static Converter<Allocation, String> writer() {
return new Converter<Allocation, String>() {
public String convert(Allocation allocation) {
return allocation.getCode();
}
};
}
public static Converter<String, Allocation> reader() {
return new Converter<String, Allocation>() {
public Allocation convert(String source) {
return Allocation.getByCode(source);
}
};
}
public static Allocation getByCode(String code) {
switch (code) {
case ""V"":
return AVAILABLE;
case ""A"":
return ALLOCATED;
}
throw new IllegalArgumentException(""Unable to get Allocation from: "" + code);
}
public String getCode() {
return code;
}
}
}
It simply converts back and forward using a short code rather than the full Enum name.
These are registered in the Spring Boot application entry point:
@Bean
public CustomConversions customConversions() {
return new CustomConversions(Arrays.asList(
MyPersistantObject.Allocation.reader(),
MyPersistantObject.Allocation.writer()
));
}
drive few scenarios drive unit test
@Test
public void testConversion() {
Update update;
Query query;
MyPersistantObject returned;
MyPersistantObject myPersistantObject = new MyPersistantObject();
myPersistantObject.allocation = AVAILABLE;
myPersistantObject.value = new BigDecimal(1234567);
mongoTemplate.save(myPersistantObject);
// Check it was saved correctly - first with invalid allocation to confirm conversion in query
query = query(where(""allocation"").
is(ALLOCATED));
assertThat(mongoTemplate.findOne(query, MyPersistantObject.class), is(nullValue()));
// Check it was saved correctly - now with valid allocation to confirm conversion in query
query = query(where(""allocation"").
is(AVAILABLE));
returned = mongoTemplate.findOne(query, MyPersistantObject.class);
assertThat(returned.allocation, is(AVAILABLE));
assertThat(returned.value.longValue(), is(1234567L));
try {
// Update allocation from constant - will fail
update = update(""allocation"", ALLOCATED);
mongoTemplate.updateMulti(query, update, MyPersistantObject.class);
} catch (Exception e) {
System.err.println(""failed to convert allocation: java.lang.IllegalArgumentException: can't serialize class converter_test.
MyPersistantObject$Allocation"");
}
// Update allocation from string value - succeeds
update = update(""allocation"", ALLOCATED.getCode());
mongoTemplate.updateMulti(query, update, MyPersistantObject.class);
// Check allocation update
query = query(where(""allocation"").
is(ALLOCATED));
returned = mongoTemplate.findOne(query, MyPersistantObject.class);
assertThat(returned.allocation, is(ALLOCATED));
// Update value only - will fail: Caused by: java.lang.IllegalArgumentException: Unable to get MyPersistantObject.Allocation from: 54321
// Tries to use MyPersistantObject.Allocation converter to String
update = update(""value"", new BigDecimal(54321));
mongoTemplate.updateMulti(query, update, MyPersistantObject.class);
// Check value update
returned = mongoTemplate.findAll(MyPersistantObject.class).
get(0);
assertThat(returned.value.longValue(), is(54321L));
}
Hopefully that makes sense.
Firstly it saves and queries for the object to demonstrate that the converters are called correctly on the document.
I have confirmed that the document in the database correctly stores the Enum code rather than the name.
By use of a positive and negative case, it appears that the converter is being called correctly when used in the Query builder.
When it comes to an Update, the Enum is unable to be serialised correctly, and an exception is thrown to that effect.
If I change it to use the code (a String), it works and we confirm that by Querying it back from the DB.
So it appears that the customer converter for converting from my Enum is not called in this situation.
Next I try and update the other value in the Document.
The BigDecimal is converted to a String by an existing converter I assume, but then my customer converter is called to try and convert the numeric String into an Allocation Enum which of course fails.
I tried to debug the code and it seems that there is an overloaded method in CustomConversions: getCustomWriteTarget that takes one or two arguments, the second being a requestedTargetType.
That second variant never seems to be called in MappingMongoConverter, but perhaps if that type information was passed then it would not use my Allocation converter.
Without type information it seems the default is just to use the first converter that can handle the input type, in this case a String.
It is my custom one which is picked up first but can't actually handle it.
Please advise if there is something I am missing, as I can't find a workaround either - I have resorted to the Mongo Driver itself to do the update.","org.springframework.data.mongodb.core.convert.UpdateMapperUnitTests
org.springframework.data.mongodb.core.convert.UpdateMapper"
FILE,DATAMONGO,DATAMONGO-1263,2015-07-30T09:03:41.000-05:00,Missing indexes in associations involving generic types,"class Book  
 class AbstractProduct  
 class ProductWrapper    
 class Catalog
When an association between documents involves generic types, the type information is not correctly inferred at startup time resulting in missing indexes.
Please, see https://github.com/agustisanchez/SpringDataMongoDBBug, for code samples.
class Book with index on ""ISBN"" attribute super class AbstractProduct with index on ""name"" attribute class ProductWrapper holding attribute ""content"" of generic type ""T extends AbstractProduct""
define class Catalog with list
List<ProductWrapper<Book>> books2 = new ArrayList<>
The index ""name"" inherited from AbstractProduct is created (book2.content.name) inside ""catalog"" , but the index defined on the Book class itself (isbn) is not created as Spring Data Mongo is only inferring type infromation from the ProductWrapper class definition (ProductWrapper <T extends AbstractProduct>).
If the wrapper class is defined as ProductWrapper<T>, then no indexes are created at all on Catalog.books2.content.","org.springframework.data.mongodb.core.index.MongoPersistentEntityIndexResolver
org.springframework.data.mongodb.core.index.MongoPersistentEntityIndexResolverUnitTests"
FILE,DATAMONGO,DATAMONGO-1290,2015-09-17T15:30:23.000-05:00,@Query annotation with byte[] parameter does not work,"Optional<SampleDomainObject> findBySampleData(byte[] sampleDate) 
 @Query(""{ 'sampleData' : ?0 }"")




Optional<SampleDomainObject> findBySampleDateWithAnnotation(byte[] sampleData)
Optional<SampleDomainObject> findBySampleData(byte[] sampleDate);
@Query(""{ 'sampleData' : ?
0 }"")
Optional<SampleDomainObject> findBySampleDateWithAnnotation(byte[] sampleData);
... but only the first works.
find example project with test","org.springframework.data.mongodb.repository.query.StringBasedMongoQuery
org.springframework.data.mongodb.repository.query.StringBasedMongoQueryUnitTests"
FILE,DATAMONGO,DATAMONGO-1360,2016-01-16T07:47:34.000-06:00,Cannot query with JSR310,"query.addCriteria(where(""createdDate"").lte(LocalDateTime.now()));
have MongoDb document use Spring data MongoDb
{
""_id"" : ""1"",
""_class"" : ""SomeClass"",
""createdDate"" : ISODate(""2016-01-16T07:05:45.656Z""),
""lastUpdate"" : ISODate(""2016-01-16T07:05:45.656Z"")
}
create custom Criteria query look custom Criteria query
query.addCriteria(where(""createdDate"").
lte(LocalDateTime.now()));
The resulting MongoDb query looks like this:
{ ""createdDate"" : { ""$lte"" : { $java : 2016-01-16T14:36:50.656 } } }
It consequently fails with this message:
java.lang.IllegalArgumentException: can't serialize class java.time.LocalDateTime at org.bson.BasicBSONEncoder.
_putObjectField(BasicBSONEncoder.java:299)
It does not fail when I use a java.util.Date in my query even though I have stilled persisted my document with a java.time.LocalDateTime object.
The query then looks slightly different like this:
{ ""createdDate"" : { ""$lte"" : { ""$date"" : ""2016-01-16T07:35:19.985Z""}}}
I'm hoping there is a way to not have to convert my LocalDateTime objects to Date objects for querying.
Please advise.
Cheers,
Bjorn","org.springframework.data.mongodb.core.Venue
org.springframework.data.mongodb.core.geo.AbstractGeoSpatialTests
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-1438,2016-05-26T14:01:14.000-05:00,I get a warning in my logs since switched to Spring Data MongoDB Hopper-SR1 Release Train in Spring Boot 1.3.5,"@Document
When I start my Spring Boot 1.3.5 application with no custom conversions and with Spring Data MongoDB Release Train Hopper-SR1 I get following warning in my logs:
Registering converter from class java.lang.Number to class java.lang.Number as writing converter although it doesn't convert to a Mongo supported type!
You might wanna check you annotation setup at the converter implementation.
With the in Spring Boot 1.3.5 integrated version the warning is not exists.
.
alle Domain classes save with @Document save in MongoDB annotated","org.springframework.data.mongodb.core.convert.MongoConvertersUnitTests
org.springframework.data.mongodb.core.convert.MongoConverters"
FILE,DATAMONGO,DATAMONGO-1394,2016-03-09T10:36:46.000-06:00,References not handled correctly when using QueryDSL,"public class Book {




     @DBRef




     private Library library;




} 












 
 public class Library {




     @Id




     private String id;




}












  
   ;




QBook book = QBook.book;




BooleanExpression exp = book.library.id.eq(library_id);




    




List<Book> list = bookRepository.findAll(exp);  // EMPTY






 
  
 Library library = libraryRepository.findById(library_id);




QBook book = QBook.book;




BooleanExpression exp = book.library.eq(library);









List<Book> list = bookRepository.findAll(exp);  // EXPECTED ITEMS






 
  
 List<Book> list = bookRepository.findByLibraryId(library_id) // EXPECTED ITEMS
use eq with luck use eq on $id
Book.java
public class Book {
@DBRef
private Library library;
}
Library.java
public class Library {
@Id
private String id;
}
BookService.java
String library_id = [SOME_ID];
QBook book = QBook.book;
BooleanExpression exp = book.library.id.eq(library_id);
List<Book> list = bookRepository.findAll(exp);  // EMPTY
BookService.java
Library library = libraryRepository.findById(library_id);
QBook book = QBook.book;
BooleanExpression exp = book.library.eq(library);
List<Book> list = bookRepository.findAll(exp);  // EXPECTED ITEMS
BookService.java
List<Book> list = bookRepository.findByLibraryId(library_id) // EXPECTED ITEMS","org.springframework.data.mongodb.repository.support.SpringDataMongodbSerializer
org.springframework.data.mongodb.repository.support.QuerydslRepositorySupportTests"
FILE,DATAMONGO,DATAMONGO-1406,2016-04-04T18:59:49.000-05:00,Query mapper does not use @Field field name when querying nested fields in combination with nested keywords,";






@Document(collection = ""Computer"")




public class Computer




{




   @Id




   private String _id;









   private String batchId;









  @Field(""stat"")




   private String status;









   @Field(""disp"")




   private List<Monitor> displays;









   //setters and getters




}









public class Monitor {




   @Field(""res"")




   private String resolution;









  // setters/getters




}






   
 protected <S, T> List<T> doFind(String collectionName, DBObject query, DBObject fields, Class<S> entityClass,




			CursorPreparer preparer, DbObjectCallback<T> objectCallback)









 DBObject mappedQuery = queryMapper.getMappedObject(query, entity);






  @Field   
  
  
 
  
  @Field
have document class
@Document(collection = ""Computer"")
public class Computer
{
@Id
private String _id;
private String batchId;
@Field(""stat"")
private String status;
@Field(""disp"")
private List<Monitor> displays;
//setters and getters
}
public class Monitor {
@Field(""res"")
private String resolution;
// setters/getters
}
call in MongoTemplate.java
protected <S, T> List<T> doFind(String collectionName, DBObject query, DBObject fields, Class<S> entityClass,
CursorPreparer preparer, DbObjectCallback<T> objectCallback)
DBObject mappedQuery = queryMapper.getMappedObject(query, entity);
resolves the fields to the input query to the ones in the @Field annotations, except for these in embedded arrays.
So, in the example above, resolution fields in DBObject remains resolution.
While, the status field resolves to stat.
Note the queries in the inner list, are setup as elemMatch.
submit to mongo
{ ""$and"" : [ { ""stat"" : ""A""} , { ""disp"" : { ""$elemMatch"" : { ""$and"" : [ { ""resolution"" : { ""$ne"" :  null }} , { ""resolution"" : { ""$ne"" : """"}}]}}}] , ""batchId"" : ""5d0f1c53-92a2-48cb-8c84-1061769962c1""}
Which doesn't get any data, because there is no field called resolution (the field in mongo is res).
note query input to getMappedObject
{ ""$and"" : [ { ""status"" : ""A""} , { ""displays"" : { ""$elemMatch"" : { ""$and"" : [ { ""resolution"" : { ""$ne"" :  null }} , { ""resolution"" : { ""$ne"" : """"}}]}}}] , ""batchId"" : ""5d0f1c53-92a2-48cb-8c84-1061769962c1""}
Notice the status and displays fields correctly get converted to the value in the @Field annotation.
{ ""$and"" : [ { ""stat"" : ""A""} , { ""disp"" : { ""$elemMatch"" : { ""$and"" : [ { ""res"" : { ""$ne"" :  null }} , { ""res"" : { ""$ne"" : """"}}]}}}] , ""batchId"" : ""5d0f1c53-92a2-48cb-8c84-1061769962c1""}
This basically means that any queries that operate on fields (with a name different from the peristed name) in the inner list will fail.","org.springframework.data.mongodb.core.convert.QueryMapper
org.springframework.data.mongodb.core.convert.QueryMapperUnitTests"
FILE,DATAMONGO,DATAMONGO-1486,2016-09-07T16:46:53.000-05:00,Changes to MappingMongoConverter Result in Class Cast Exception,"Map<Integer, Map<Platform, String>> descriptions = new HashMap<>();






 
 public void setAlternateDescriptionMap(int compositeId, Map<Integer, Map<Platform, String>> alternateDescriptionsMap) {




		Query query = new Query();




		query.addCriteria(Criteria.where(""_id"").is(compositeId));




		Update update = new Update();




		update.set(""alternateDescriptionMap"", alternateDescriptionsMap);









		coreMongoTemplate.updateFirst(query, update, ""product"");




	}






   
    
 
 MappingMongoConverter.convertMongoType()
I am upgrading our software to use Spring Boot 1.4 + Spring 4.3.
As part of this upgrade, we are also using Spring Data Mongo 1.9.2.
RELEASE.
I am assuming that is 1.9.2 (Hopper SR2)?
have situation have model object have situation look model object like following
Map<Integer, Map<Platform, String>> descriptions = new HashMap<>();
Where ""Platform is Enum"", although this is not the core issue.
public void setAlternateDescriptionMap(int compositeId, Map<Integer, Map<Platform, String>> alternateDescriptionsMap) {
Query query = new Query();
query.addCriteria(Criteria.where(""_id"").
is(compositeId));
Update update = new Update();
update.set(""alternateDescriptionMap"", alternateDescriptionsMap);
coreMongoTemplate.updateFirst(query, update, ""product"");
}
We end up getting the following exception:
java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.String
at com.mongodb.DBObjectCodec.encodeMap(DBObjectCodec.java:222)
at com.mongodb.DBObjectCodec.writeValue(DBObjectCodec.java:199)
at com.mongodb.DBObjectCodec.encodeMap(DBObjectCodec.java:223)
at com.mongodb.DBObjectCodec.writeValue(DBObjectCodec.java:199)
at com.mongodb.DBObjectCodec.encode(DBObjectCodec.java:131)
at com.mongodb.DBObjectCodec.encode(DBObjectCodec.java:62)
at org.bson.codecs.BsonDocumentWrapperCodec.encode(BsonDocumentWrapperCodec.java:63)
at org.bson.codecs.BsonDocumentWrapperCodec.encode(BsonDocumentWrapperCodec.java:29)
at com.mongodb.connection.RequestMessage.addDocument(RequestMessage.java:253)
at com.mongodb.connection.RequestMessage.addDocument(RequestMessage.java:205)
at com.mongodb.connection.UpdateMessage.encodeMessageBodyWithMetadata(UpdateMessage.java:80)
at com.mongodb.connection.RequestMessage.encodeWithMetadata(RequestMessage.java:160)
at com.mongodb.connection.WriteProtocol.execute(WriteProtocol.java:89)
at com.mongodb.connection.UpdateProtocol.execute(UpdateProtocol.java:67)
at com.mongodb.connection.UpdateProtocol.execute(UpdateProtocol.java:42)
at com.mongodb.connection.DefaultServer$DefaultServerProtocolExecutor.execute(DefaultServer.java:168)
at com.mongodb.connection.DefaultServerConnection.executeProtocol(DefaultServerConnection.java:289)
at com.mongodb.connection.DefaultServerConnection.update(DefaultServerConnection.java:88)
at com.mongodb.operation.UpdateOperation.executeProtocol(UpdateOperation.java:66)
at com.mongodb.operation.BaseWriteOperation$1.call(BaseWriteOperation.java:144)
at com.mongodb.operation.BaseWriteOperation$1.call(BaseWriteOperation.java:134)
at com.mongodb.operation.OperationHelper.withConnectionSource(OperationHelper.java:232)
at com.mongodb.operation.OperationHelper.withConnection(OperationHelper.java:223)
at com.mongodb.operation.BaseWriteOperation.execute(BaseWriteOperation.java:134)
at com.mongodb.operation.BaseWriteOperation.execute(BaseWriteOperation.java:61)
at com.mongodb.Mongo.execute(Mongo.java:827)
at com.mongodb.Mongo$2.execute(Mongo.java:810)
at com.mongodb.DBCollection.executeWriteOperation(DBCollection.java:333)
at com.mongodb.DBCollection.updateImpl(DBCollection.java:495)
at com.mongodb.DBCollection.update(DBCollection.java:455)
at com.mongodb.DBCollection.update(DBCollection.java:432)
at org.springframework.data.mongodb.core.MongoTemplate$12.doInCollection(MongoTemplate.java:1153)
at org.springframework.data.mongodb.core.MongoTemplate$12.doInCollection(MongoTemplate.java:1132)
at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:462)
at org.springframework.data.mongodb.core.MongoTemplate.doUpdate(MongoTemplate.java:1132)
at org.springframework.data.mongodb.core.MongoTemplate.updateFirst(MongoTemplate.java:1110)
at com.build.dao.product.ProductStorageDaoImpl.setAlternateDescriptionMap(ProductStorageDaoImpl.java:1170)
at com.build.dao.product.ProductStorageDaoImpl$$FastClassBySpringCGLIB$$4e03147e.
invoke(<generated>)
at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:720)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:136)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:655)
at com.build.dao.product.ProductStorageDaoImpl$$EnhancerBySpringCGLIB$$8602f8b4.
setAlternateDescriptionMap(<generated>)
at com.build.dao.product.ProductStorageDaoIT.testSaveAlternateDescriptionsToCacheAndFetch(ProductStorageDaoIT.java:335)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:497)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75)
at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86)
at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84)
at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:252)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:94)
at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70)
at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:191)
at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86)
at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)
We do not get this exception in spring-data-mongodb-1.9.1-RELEASE.
After a lot of debugging, It appears to be related to the code in MappingMongoConverter.convertMongoType().
It looks like the Issue DATAMONGO-1423 may have introduced this issue:
https://github.com/spring-projects/spring-data-mongodb/commit/0e60630393980cf2bb4634c8a9c1a5a50407c471
I am going to work on just overriding this default method with a custom mapper.
I suspect this code will also break in other cases where the key is mapped into anything other than a string.
Let me know if you need any further input.","org.springframework.data.mongodb.core.convert.MappingMongoConverter
org.springframework.data.mongodb.core.convert.UpdateMapperUnitTests"
CLASS,derby-10.7.1.1,DERBY-4835,2010-10-06T11:05:13.000-05:00,Trigger plan does not recompile with upgrade from 10.5.3.0 to 10.6.1.0 causing  java.lang.NoSuchMethodError,"tidlggls(blt_number,create_date,update_date,propagation_date,glossary_status,
     time_stamp,min_max_size )
    
      
 
  
 tidlrblt(BLT,BLT_SIZE,MIN_MAX_SIZE)  
 
     
  
   GeneratedMe
thod;    
  
  
 if (fromVersion.majorVersionNumber >= DataDictionary.DD_VERSION_DERBY_10_5)
				bootingDictionary.updateMetadataSPSes(tc);
			else
				bootingDictionary.clearSPSPlans();

  clearSPSPlans()
Trigger plan does not recompile on upgrade from 10.5.3.0 to 10.6.1.0  causing the following exception  the first time the trigger is fired after upgrade.
ATABASE = wombat), (DRDAID = null), Failed Statement is: INSERT INTO tidlggls(blt_number,create_date,update_date,propagation_date,glossary_status,
     time_stamp,min_max_size )
 VALUES ( (select max(blt_number) from tidlrblt), CURRENT_DATE,
CURRENT_DATE, CURRENT_DATE, '00' , CURRENT_TIMESTAMP, (select min_max_size from tidlrblt where blt_number = (select max(blt_number) from tidlrblt)))
java.lang.NoSuchMethodError: org/apache/derby/iapi/sql/execute/ResultSetFactory.getProjectRestrictResultSet(Lorg/apache/derby/iapi/sql/execute/NoPutResultSet;Lorg/apache/derby/iapi/services/loader/GeneratedMethod;Lorg/apache/derby/iapi/services/loader/GeneratedMethod;ILorg/apache/derby/iapi/services/loader/GeneratedMethod;IZZDD)Lorg/apache/derby/iapi/sql/execute/NoPutResultSet;
at org.apache.derby.exe.acf81e0010x012bx823cxd0d3x00000026c4a00.g0(Unknown Source)
at org.apache.derby.exe.acf81e0010x012bx823cxd0d3x00000026c4a00.execute(Unknown Source)
at org.apache.derby.impl.sql.GenericActivationHolder.execute(Unknown Source)
at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
at org.apache.derby.impl.sql.GenericPreparedStatement.executeSubStatement(Unknown Source)
at org.apache.derby.impl.sql.execute.GenericTriggerExecutor.executeSPS(Unknown Source)
at org.apache.derby.impl.sql.execute.StatementTriggerExecutor.fireTrigger(Unknown Source)
at org.apache.derby.impl.sql.execute.TriggerEventActivator.notifyEvent(Unknown Source)
at org.apache.derby.impl.sql.execute.InsertResultSet.normalInsertCore(Unknown Source)
at org.apache.derby.impl.sql.execute.InsertResultSet.open(Unknown Source)
at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)
at org.apache.derby.impl.tools.ij.ij.executeImmediate(Unknown Source)
at org.apache.derby.impl.tools.ij.utilMain.doCatch(Unknown Source)
at org.apache.derby.impl.tools.ij.utilMain.runScriptGuts(Unknown Source)
at org.apache.derby.impl.tools.ij.utilMain.go(Unknown Source)
at org.apache.derby.impl.tools.ij.Main.go(Unknown Source)
at org.apache.derby.impl.tools.ij.Main.mainCore(Unknown Source)
at org.apache.derby.impl.tools.ij.Main.main(Unknown Source)
at org.apache.derby.tools.ij.main(Unknown Source)
Cleanup action completed
run attached script 10_5_3_work.sql with 10.5.3.0 release connect with 10.6.1.0 insert into table
connect 'jdbc:derby:wombat;upgrade=true';
 
INSERT INTO tidlrblt(BLT,BLT_SIZE,MIN_MAX_SIZE) VALUES('Mamatha Testing2', 15, 20);
ERROR XJ001: Java exception: 'org/apache/derby/iapi/sql/execute/ResultSetFactory
.
getProjectRestrictResultSet(Lorg/apache/derby/iapi/sql/execute/NoPutResultSet;L
org/apache/derby/iapi/services/loader/GeneratedMethod;Lorg/apache/derby/iapi/ser
vices/loader/GeneratedMethod;ILorg/apache/derby/iapi/services/loader/GeneratedMe
thod;IZZDD)Lorg/apache/derby/iapi/sql/execute/NoPutResultSet;: java.lang.NoSuchM
ethodError'.
I think this may be related to the DERBY-1107 change in handleMinorRevisionChange which has the code:
if (fromVersion.majorVersionNumber >= DataDictionary.DD_VERSION_DERBY_10_5)
				bootingDictionary.updateMetadataSPSes(tc);
			else
				bootingDictionary.clearSPSPlans();
Likely, clearSPSPlans() should not be in the else clause but rather executed unconditionally.
To work around the issue, after connecting with 10.6.1, drop and recreate the trigger as in workaround.sql","org.apache.derby.impl.sql.catalog.DD_Version
org.apache.derbyTesting.functionTests.tests.upgradeTests.BasicSetup"
CLASS,derby-10.7.1.1,DERBY-4873,2010-10-28T18:45:13.000-05:00,NullPointerException in testBoundaries with ibm jvm 1.6,"testBoundaries(org.apache.derbyTesting.functionTests.tests.jdbcapi.InternationalConnectTest)
With the line skipping the testBoundaries fixture of the InternationalConnectTest commented out, I get the following stack when I run the test with ibm 1.6:
1 testBoundaries(org.apache.derbyTesting.functionTests.tests.jdbcapi.InternationalConnectTest)java.sql.SQLException: DERBY SQL error: SQLCODE: -1, SQLSTATE: XJ001, SQLERRMC: java.lang.NullPointerExceptionXJ001.U
at org.apache.derby.client.am.SQLExceptionFactory40.getSQLException(SQLExceptionFactory40.java:96)
at org.apache.derby.client.am.SqlException.getSQLException(SqlException.java:358)
at org.apache.derby.jdbc.ClientDriver.connect(ClientDriver.java:149)
at java.sql.DriverManager.getConnection(DriverManager.java:322)
at java.sql.DriverManager.getConnection(DriverManager.java:273)
at org.apache.derbyTesting.functionTests.tests.jdbcapi.InternationalConnectTest.testBoundaries(InternationalConnectTest.java:111)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:48)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:109)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
Caused by: org.apache.derby.client.am.SqlException: DERBY SQL error: SQLCODE: -1, SQLSTATE: XJ001, SQLERRMC: java.lang.NullPointerExceptionXJ001.U
at org.apache.derby.client.am.Connection.completeSqlca(Connection.java:2117)
at org.apache.derby.client.net.NetConnectionReply.parseRdbAccessFailed(NetConnectionReply.java:541)
at org.apache.derby.client.net.NetConnectionReply.parseAccessRdbError(NetConnectionReply.java:434)
at org.apache.derby.client.net.NetConnectionReply.parseACCRDBreply(NetConnectionReply.java:297)
at org.apache.derby.client.net.NetConnectionReply.readAccessDatabase(NetConnectionReply.java:121)
at org.apache.derby.client.net.NetConnection.readSecurityCheckAndAccessRdb(NetConnection.java:846)
at org.apache.derby.client.net.NetConnection.flowSecurityCheckAndAccessRdb(NetConnection.java:769)
at org.apache.derby.client.net.NetConnection.flowUSRIDONLconnect(NetConnection.java:601)
at org.apache.derby.client.net.NetConnection.flowConnect(NetConnection.java:408)
at org.apache.derby.client.net.NetConnection.<init>(NetConnection.java:218)
at org.apache.derby.client.net.NetConnection40.<init>(NetConnection40.java:77)
at org.apache.derby.client.net.ClientJDBCObjectFactoryImpl40.newNetConnection(ClientJDBCObjectFactoryImpl40.java:269)
at org.apache.derby.jdbc.ClientDriver.connect(ClientDriver.java:140)
... 35 more
This is after the latest check in for DERBY-4836 (revision 1028035).
I'll attach derby.log.",org.apache.derby.impl.store.raw.data.BaseDataFileFactory
CLASS,derby-10.7.1.1,DERBY-4889,2010-11-05T20:06:56.000-05:00,Different byte to boolean conversion on embedded and client,"PreparedStatement ps = c.prepareStatement(""values cast(? as boolean)"");
        ps.setByte(1, (byte) 32);
        ResultSet rs = ps.executeQuery();
        rs.next();
        System.out.println(rs.getBoolean(1));

 If setByte()   setInt()
The following code prints ""true"" with the embedded driver and ""false"" with the client driver:
PreparedStatement ps = c.prepareStatement(""values cast(?
as boolean)"");
        ps.setByte(1, (byte) 32);
        ResultSet rs = ps.executeQuery();
        rs.next();
        System.out.println(rs.getBoolean(1));
If setByte() is replaced with setInt(), they both print ""true"".","org.apache.derbyTesting.functionTests.tests.jdbcapi.ParameterMappingTest
org.apache.derby.impl.drda.DRDAConnThread"
CLASS,derby-10.7.1.1,DERBY-4892,2010-11-06T04:14:51.000-05:00,Unsafe use of BigDecimal constructors,"test_06_casts(org.apache.derbyTesting.functionTests.tests.lang.UDTTest)
We have some code that's supposed to work on Java 1.4, but that uses BigDecimal constructors that were not added until Java 5.
The problematic constructors are the ones that take a single int or long.
The constructors are used in the following classes:
org.apache.derby.client.am.Cursor
org.apache.derbyTesting.functionTests.tests.lang.Price
org.apache.derbyTesting.system.oe.client.Submitter
All of the classes are compiled against ${java14compile.classpath}, so one would expect the build to fail when java14compile.classpath pointed to proper Java 1.4 libraries.
However, there is a constructor with a double parameter in Java 1.4, and the compiler picks that constructor if it cannot find the ones for int and long.
If that happens, the compiled byte-code works on Java 1.4 and newer, and everything is fine.
The problem appears when the build does not use the Java 1.4 libraries.
This can easily happen if you build without a customized ant.properties, and PropertySetter ends up building java14compile.classpath based on the auto-detected java15compile.classpath.
In that case, the compiler finds the int and long variants of the constructor, even when building against java14compile.classpath.
The compiled byte-code will therefore use those Java 5 constructors, and the code will fail at run-time if ever executed on a Java 1.4 JVM.
build Derby without ant.properties not find JDK
build up java14compile.classpath of jar files build up java14compile.classpath from Java build up java14compile.classpath from Java directory
run org.apache.derbyTesting.functionTests.tests.lang.UDTTest use Java JVM
You'll see two errors of this kind:
1 test_06_casts(org.apache.derbyTesting.functionTests.tests.lang.UDTTest)java.lang.NoSuchMethodError: java.math.BigDecimal.
<init>(I)V
at org.apache.derbyTesting.functionTests.tests.lang.Price.makePrice(Price.java:49)
at org.apache.derbyTesting.functionTests.tests.lang.UDTTest.test_06_casts(UDTTest.java:501)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:109)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
follow same procedure with patch enable testing of booleans","org.apache.derbyTesting.functionTests.tests.lang.Price
org.apache.derby.client.am.Cursor
org.apache.derbyTesting.system.oe.client.Submitter"
CLASS,pig-0.11.1,PIG-2828,2012-07-19T05:03:16.000-05:00,Handle nulls in DataType.compare,"Object field1 = o1.get(fieldNum);
                Object field2 = o2.get(fieldNum);
                if (!typeFound) {
                    datatype = DataType.findType(field1);
                    typeFound = true;
                }
                return DataType.compare(field1, field2, datatype, datatype);
While using TOP, and if the DataBag contains null value to compare, it will generate the following exception:
Caused by: java.lang.NullPointerException
at org.apache.pig.data.DataType.compare(DataType.java:427)
at org.apache.pig.builtin.TOP$TupleComparator.compare(TOP.java:97)
at org.apache.pig.builtin.TOP$TupleComparator.compare(TOP.java:1)
at java.util.PriorityQueue.siftUpUsingComparator(PriorityQueue.java:649)
at java.util.PriorityQueue.siftUp(PriorityQueue.java:627)
at java.util.PriorityQueue.offer(PriorityQueue.java:329)
at java.util.PriorityQueue.add(PriorityQueue.java:306)
at org.apache.pig.builtin.TOP.updateTop(TOP.java:141)
at org.apache.pig.builtin.TOP.exec(TOP.java:116)
code: (TOP.java, starts with line 91)
Object field1 = o1.get(fieldNum);
Object field2 = o2.get(fieldNum);
if (! typeFound) { datatype = DataType.findType(field1);
typeFound = true;
} return DataType.compare(field1, field2, datatype, datatype);
The reason is that if the typeFound is true , and the dataType is not null, and field1 is null, the script failed.","src.org.apache.pig.data.DataType
src.org.apache.pig.builtin.TOP
test.org.apache.pig.test.TestNull"
CLASS,pig-0.11.1,PIG-3114,2013-01-03T19:49:42.000-06:00,Duplicated macro name error when using pigunit,"{code:title=test.pig|borderStyle=solid}
    {
    $C = ORDER $QUERY BY total DESC, $A;
}  
  
     AS total;

queries_ordered = my_macro_1(queries_count, query);

    
   ;
{code}
use PigUnit test pig script define macro
Pig runs fine on cluster but getting parsing error with pigunit.
So I tried very basic pig script with macro and getting similar error.
org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1000: Error during parsing.
<line 9> null.
Reason: Duplicated macro name 'my_macro_1'
at org.apache.pig.PigServer$Graph.parseQuery(PigServer.java:1607)
at org.apache.pig.PigServer$Graph.registerQuery(PigServer.java:1546)
at org.apache.pig.PigServer.registerQuery(PigServer.java:516)
at org.apache.pig.tools.grunt.GruntParser.processPig(GruntParser.java:988)
at org.apache.pig.pigunit.pig.GruntParser.processPig(GruntParser.java:61)
at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:412)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:194)
at org.apache.pig.pigunit.pig.PigServer.registerScript(PigServer.java:56)
at org.apache.pig.pigunit.PigTest.registerScript(PigTest.java:160)
at org.apache.pig.pigunit.PigTest.assertOutput(PigTest.java:231)
at org.apache.pig.pigunit.PigTest.assertOutput(PigTest.java:261)
at FirstPigTest.MyPigTest.testTop2Queries(MyPigTest.java:32)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at junit.framework.TestCase.runTest(TestCase.java:176)
at junit.framework.TestCase.runBare(TestCase.java:141)
at junit.framework.TestResult$1.protect(TestResult.java:122)
at junit.framework.TestResult.runProtected(TestResult.java:142)
at junit.framework.TestResult.run(TestResult.java:125)
at junit.framework.TestCase.run(TestCase.java:129)
at junit.framework.TestSuite.runTest(TestSuite.java:255)
at junit.framework.TestSuite.run(TestSuite.java:250)
at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:84)
at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
Caused by: Failed to parse: <line 9> null.
Reason: Duplicated macro name 'my_macro_1'
at org.apache.pig.parser.QueryParserDriver.makeMacroDef(QueryParserDriver.java:406)
at org.apache.pig.parser.QueryParserDriver.expandMacro(QueryParserDriver.java:277)
at org.apache.pig.parser.QueryParserDriver.parse(QueryParserDriver.java:178)
at org.apache.pig.PigServer$Graph.parseQuery(PigServer.java:1599)
... 30 more
{code:title=test.pig|borderStyle=solid}
DEFINE my_macro_1 (QUERY, A) RETURNS C {
$C = ORDER $QUERY BY total DESC, $A;
} ;
data =  LOAD 'input' AS (query:CHARARRAY);
queries_group = GROUP data BY query;
queries_count = FOREACH queries_group GENERATE group AS query, COUNT(data) AS total;
queries_ordered = my_macro_1(queries_count, query);
queries_limit = LIMIT queries_ordered 2;
STORE queries_limit INTO 'output';
{code}
If I remove macro pigunit works fine.
Even just defining macro without using it results in parsing error.","src.org.apache.pig.PigServer
test.org.apache.pig.test.pigunit.TestPigTest
test.org.apache.pig.pigunit.PigTest
test.org.apache.pig.pigunit.pig.PigServer"
CLASS,pig-0.11.1,PIG-3292,2013-04-24T03:06:41.000-05:00,Logical plan invalid state: duplicate uid in schema during self-join to get cross product,"{code}
 
  
   {
  y = a.x;
  pair = cross a.x, y;
  generate flatten(pair);
}

 dump b;
{code}

 
 {code}
   
 {code}

 
 {code}
 
  
   {
  y = foreach a generate -(-x);
  pair = cross a.x, y;
  generate flatten(pair);
}

 dump b;
{code}
Hi.
Looks like PIG-3020
but works in a different way.
Our pig version is: 
Apache Pig version 0.10.0-cdh4.2.0 (rexported) 
compiled Feb 15 2013, 12:20:54
Accoring to release note, PIG-3020 is included into CDH 4.2 dist
http://archive.cloudera.com/cdh4/cdh/4/pig-0.10.0-cdh4.2.0.CHANGES.txt
get cross-product { code
a_group = group a by key;
b = foreach a_group {
  y = a.x;
  pair = cross a.x, y;
  generate flatten(pair);
}
dump b;
{code}
And an error:
{code}
ERROR org.apache.pig.tools.grunt.Grunt - ERROR 2270: Logical plan invalid state: duplicate uid in schema : 1-7::x#16:bytearray,y::x#16:bytearray
{code}
Here is workaround :)
{code}
a = load '/input' as (key, x:int);
a_group = group a by key;
b = foreach a_group {
  y = foreach a generate -(-x);
  pair = cross a.x, y;
  generate flatten(pair);
}
dump b;
{code}","test.org.apache.pig.test.TestEvalPipelineLocal
src.org.apache.pig.newplan.logical.relational.LOCross"
CLASS,pig-0.11.1,PIG-3310,2013-05-03T02:59:57.000-05:00,"ImplicitSplitInserter does not generate new uids for nested schema fields, leading to miscomputations","{code}
     
    
        
        
    
           as shop;

EXPLAIN K;
DUMP K;
{code}

 
 {code}
 
 {code}

 
 {code}
 
 {code}
 
        
      
  
 {code}
                  
              
              
              
              
              
 {code}

 
 {code}
                   
  
  
 {code}

     
 LOSplitOutput.getSchema()
Hi,
consider following example
{code}
inp = LOAD '$INPUT' AS (memberId:long, shopId:long, score:int);
tuplified = FOREACH inp GENERATE (memberId, shopId) AS tuplify, score;
D1 = FOREACH tuplified GENERATE tuplify.memberId as memberId, tuplify.shopId as shopId, score AS score;
D2 = FOREACH tuplified GENERATE tuplify.memberId as memberId, tuplify.shopId as shopId, score AS score;
J = JOIN D1 By shopId, D2 by shopId;
K = FOREACH J GENERATE D1::memberId AS member_id1, D2::memberId AS member_id2, D1::shopId as shop;
EXPLAIN K;
DUMP K;
{code}
It is a bit weird written like that, but it provides a minimal reproduction case (in the real case, the ""tuplified"" phase came from a multi-key grouping).
This will give a wrongful output like .
.
{code}
(1 1001,1001)
(1 1002,1002)
(1 1002,1002)
(1 1002,1002)
{code}
In the initial case, there was a FILTER (member_id1 < member_id2) after K, and computation failed because of PushUpFilter optimization mistakenly moving the LOFilter operation before the join, at a place where it tried to work on a tuple and failed.
My understanding of the issue is that when the ImplicitSplitInserter creates the LOSplitOutputs, it will correctly reset the schema, and the LOSplitOutput will regenerate uids for the fields of D1 and D2 ... but will not do that on the tuple members.
The logical plan after the ImplicitSplitINserter will look like (simplified)
{code}
|---D1: (Name: LOForEach Schema: memberId#124:long,shopId#125:long)ColumnPrune:InputUids=[127]ColumnPrune:OutputUids=[125, 124]
|---tuplified: (Name: LOSplitOutput Schema: tuplify#127:tuple(memberId#124:long,shopId#125:long))ColumnPrune:InputUids=[123]ColumnPrune:OutputUids=[127]
|---tuplified: (Name: LOSplit Schema: tuplify#123:tuple(memberId#124:long,shopId#125:long))ColumnPrune:InputUids=[123]ColumnPrune:OutputUids=[123]
|---D2: (Name: LOForEach Schema: memberId#124:long,shopId#125:long)ColumnPrune:InputUids=[130]ColumnPrune:OutputUids=[125, 124]
|---tuplified: (Name: LOSplitOutput Schema: tuplify#130:tuple(memberId#124:long,shopId#125:long))ColumnPrune:InputUids=[123]ColumnPrune:OutputUids=[130]
|---tuplified: (Name: LOSplit Schema: tuplify#123:tuple(memberId#124:long,shopId#125:long))ColumnPrune:InputUids=[123]ColumnPrune:OutputUids=[123]
{code}
tuplified correctly gets a new uid (127 and 130) but the members of the tuple don't.
When they get reprojected, both branches have the same uid and the join looks like:
{code}
|---J: (Name: LOJoin(HASH) Schema: D1::memberId#124:long,D1::shopId#125:long,D2::memberId#139:long,D2::shopId#132:long)ColumnPrune:InputUids=[125, 124, 132]ColumnPrune:OutputUids=[125, 124, 132]
|   |
|   shopId:(Name: Project Type: long Uid: 125 Input: 0 Column: 1)
|   |
|   shopId:(Name: Project Type: long Uid: 125 Input: 1 Column: 1)
{code}
If for example instead of reprojecting ""memberId"", we project ""memberId+0"", a new node is created, and ultimately the two branches of the join will correctly get separate uids.
My understanding is that LOSplitOutput.getSchema() should recurse on nested schema fields.
However, I only have a light understanding of all of the logical plan handling, so I may be completely wrong.
Attached is a draft of patch and a test reproducing the issue.
Unfortunately, I haven't been able to run all unit tests with the ""fix"" (I have some weird hangs)
I'd be happy if you could indicate if that looks like completely the wrong way to fix the issue.",src.org.apache.pig.newplan.logical.relational.LOSplitOutput
CLASS,pig-0.11.1,PIG-3329,2013-05-16T22:44:41.000-05:00,RANK operator failed when working with SPLIT,"RANK b;
dump d;
dump d use PigStorage(' ') as SPLIT
job will fail with error message:
java.lang.RuntimeException: Unable to read counter pig.counters.counter_4929375455335572575_-1
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.PORank.addRank(PORank.java:161)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.PORank.getNext(PORank.java:134)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator.processInput(PhysicalOperator.java:308)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POSplit.getNext(POSplit.java:214)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.runPipeline(PigGenericMapBase.java:283)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.map(PigGenericMapBase.java:278)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.map(PigGenericMapBase.java:64)
at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:157)
at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:324)
at org.apache.hadoop.mapred.Child$4.run(Child.java:275)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1340)
at org.apache.hadoop.mapred.Child.main(Child.java:269)","src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceOper
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler"
CLASS,zookeeper-3.4.5,ZOOKEEPER-1535,2012-08-14T18:56:40.000-05:00,ZK Shell/Cli re-executes last command on exit,"{{ctrl+d}}   {{ls}}   {{ctrl+d}}   {{ls}}  
 {noformat}
 
 {noformat}
In the ZK 3.4.3 release's version of zkCli.sh, the last command that was executed is *re*-executed when you {{ctrl+d}} out of the shell.
In the snippet below, {{ls}} is executed, and then {{ctrl+d}} is triggered (inserted below to illustrate), the output from {{ls}} appears again, due to the command being re-run.
{noformat}
[zk: zookeeper.example.com:2181(CONNECTED) 0] ls /blah
[foo]
[zk: zookeeper.example.com:2181(CONNECTED) 1] <ctrl+d> [foo]
$
{noformat}",src.java.main.org.apache.zookeeper.ZooKeeperMain
CLASS,zookeeper-3.4.5,ZOOKEEPER-1700,2013-05-07T19:43:31.000-05:00,FLETest consistently failing - setLastSeenQuorumVerifier seems to be hanging,"{noformat}
   
  
    
    
          
      
    
    
  
  
  
  
      
  
  
     
      
      
    
    
 {noformat}
I'm consistently seeing a failure on my laptop when running the FLETest ""testJoin"" test.
What seems to be happening is that the call to setLastSeenQuorumVerifier is hanging.
See the following log from the test, notice 17:35:57 for the period in question.
Note that I turned on debug logging and added a few log messages around the call to setLastSeenQuorumVerifier (you can see the code enter but never leave)
Note: I've applied ZOOKEEPER-1324 to trunk code and then run this test but that doesn't seem to help.
Also note that this test is passing consistently when run against branch-3.4.
{noformat}
2013-05-07 17:35:57,859 [myid:] - INFO  [QuorumPeer[myid=0]/0:0:0:0:0:0:0:0:11221:Follower@65] - FOLLOWING - LEADER ELECTION TOOK - 16
2013-05-07 17:35:57,859 [myid:] - INFO  [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:Leader@436] - LEADING - LEADER ELECTION TOOK - 17
2013-05-07 17:35:57,863 [myid:] - INFO  [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:FileTxnSnapLog@270] - Snapshotting: 0x0 to /home/phunt/dev/zookeeper-trunk/build/test/tmp/test3690487600947307322.junit.dir/version-2/snapshot.0
2013-05-07 17:35:57,873 [myid:] - INFO  [LearnerHandler-/127.0.0.1:34262:LearnerHandler@269] - Follower sid: 0 : info : 0.0.0.0:11222:11223:participant;0.0.0.0:11221
2013-05-07 17:35:57,878 [myid:] - INFO  [LearnerHandler-/127.0.0.1:34262:LearnerHandler@328] - Synchronizing with Follower sid: 0 maxCommittedLog=0x0 minCommittedLog=0x0 peerLastZxid=0x0
2013-05-07 17:35:57,878 [myid:] - DEBUG [LearnerHandler-/127.0.0.1:34262:LearnerHandler@395] - committedLog is empty but leader and follower are in sync, zxid=0x0
2013-05-07 17:35:57,878 [myid:] - INFO  [LearnerHandler-/127.0.0.1:34262:LearnerHandler@404] - Sending DIFF
2013-05-07 17:35:57,879 [myid:] - DEBUG [LearnerHandler-/127.0.0.1:34262:LearnerHandler@411] - Sending NEWLEADER message to 0
2013-05-07 17:35:57,880 [myid:] - INFO  [QuorumPeer[myid=0]/0:0:0:0:0:0:0:0:11221:Learner@331] - Getting a diff from the leader 0x0
2013-05-07 17:35:57,885 [myid:] - INFO  [QuorumPeer[myid=0]/0:0:0:0:0:0:0:0:11221:Learner@457] - Learner received NEWLEADER message
2013-05-07 17:35:57,885 [myid:] - INFO  [QuorumPeer[myid=0]/0:0:0:0:0:0:0:0:11221:Learner@460] - NEWLEADER calling configfromstring
2013-05-07 17:35:57,885 [myid:] - INFO  [QuorumPeer[myid=0]/0:0:0:0:0:0:0:0:11221:Learner@462] - NEWLEADER setting quorum verifier
2013-05-07 17:35:57,886 [myid:] - WARN  [QuorumPeer[myid=0]/0:0:0:0:0:0:0:0:11221:QuorumPeer@1218] - setLastSeenQuorumVerifier called with stale config 0. Current version: 0
2013-05-07 17:36:01,880 [myid:] - INFO  [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:Leader@585] - Shutting down
2013-05-07 17:36:01,881 [myid:] - INFO  [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:Leader@591] - Shutdown called
java.lang.Exception: shutdown Leader! reason: Waiting for a quorum of followers, only synced with sids: [ [1] ]
at org.apache.zookeeper.server.quorum.Leader.shutdown(Leader.java:591)
at org.apache.zookeeper.server.quorum.Leader.lead(Leader.java:487)
at org.apache.zookeeper.server.quorum.QuorumPeer.run(QuorumPeer.java:949)
2013-05-07 17:36:01,881 [myid:] - INFO  [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:ZooKeeperServer@398] - shutting down
2013-05-07 17:36:01,881 [myid:] - INFO  [LearnerCnxAcceptor-0.0.0.0/0.0.0.0:11225:Leader$LearnerCnxAcceptor@398] - exception while shutting down acceptor: java.net.SocketException: Socket closed
2013-05-07 17:36:01,882 [myid:] - WARN  [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:QuorumPeer@979] - PeerState set to LOOKING
2013-05-07 17:36:01,882 [myid:] - INFO  [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:QuorumPeer@863] - LOOKING
2013-05-07 17:36:01,883 [myid:] - DEBUG [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:11224:QuorumPeer@792] - Initializing leader election protocol...
{noformat}",src.java.test.org.apache.zookeeper.test.FLETest
CLASS,zookeeper-3.4.5,ZOOKEEPER-1781,2013-10-03T20:19:27.000-05:00,ZooKeeper Server fails if snapCount is set to 1,"int randRoll = r.nextInt(snapCount/2);
{code}
If snapCount is set to 1, ZooKeeper Server can start but it fails with the below error:
2013-10-02 18:09:07,600 [myid:1] - ERROR [SyncThread:1:SyncRequestProcessor@151] - Severe unrecoverable error, exiting java.lang.IllegalArgumentException: n must be positive
at java.util.Random.nextInt(Random.java:300)
at org.apache.zookeeper.server.SyncRequestProcessor.run(SyncRequestProcessor.java:93)
{code:title=org.apache.zookeeper.server.SyncRequestProcessor.java|borderStyle=solid}
91             // we do this in an attempt to ensure that not all ofthe servers
92             // in the ensemble take a snapshot at the same time
93             int randRoll = r.nextInt(snapCount/2);
{code}
I think this supposition is not bad because snapCount = 1 is not realistic setting...
But, it may be better to mention this restriction in documentation or add a validation in the source code.",src.java.main.org.apache.zookeeper.server.ZooKeeperServer
METHOD,bookkeeper-4.1.0,BOOKKEEPER-387,2012-09-04T04:27:35.000-05:00,BookKeeper Upgrade is not working.,"{code}
     
 {code}
I am trying to upgrade BK from 4.1.0 to 4.2.0, but it will log as ""Directory is current, no need to upgrade? even then it will continue and fail.
and throwing following exception.
{code}
2012-09-03 17:25:12,468 - ERROR - [main:FileSystemUpgrade@229] - Error moving upgraded directories into place /home/BK4.1/bookkeeper1/ledger/upgradeTmp.2433718456734190 -> /home/BK4.1/bookkeeper1/ledger/current org.apache.commons.io.FileExistsException: Destination '/home/BK4.1/bookkeeper1/ledger/current' already exists
at org.apache.commons.io.FileUtils.moveDirectory(FileUtils.java:2304)
at org.apache.bookkeeper.bookie.FileSystemUpgrade.upgrade(FileSystemUpgrade.java:225)
at org.apache.bookkeeper.bookie.FileSystemUpgrade.main(FileSystemUpgrade.java:367)
{code}",org.apache.bookkeeper.bookie.UpgradeTest:testCommandLine()
CLASS,argouml-0.22,3923,2006-02-07T13:17:48.000-06:00,Problem importing Poseidon activity diagrams from XMI,"Collection actionStates = getModel().getAllActionStates();
  Iterator iterActionState = actionStates.iterator();
iterActionState.hasNext(); 
 ActionStateFacade actionState =
(ActionStateFacade) iterActionState.next();
There is a bug in Beta 3 which prevents you using the activity diagram for AndroMDA.
Here is what I've done:
import XMI from poseidon work poseidon with AndroMDA ( the
Everything went fine.
2) If I add my activity diagram under the use case diagram I always get a new activity graph, so I have 2 activity graphs alltogether.
I cannot add an activity diagram under the imported activity graph.
Please see the screenshot I attached.
See: http://argouml.tigris.org/servlets/ReadMsg?list=dev&msgNo=19267
Screenshot:
http://argouml.tigris.org/servlets/GetAttachment?list=dev&msgId=770688&attachId=1
work code with poseidon not work ) with argouml
Collection actionStates = getModel().
getAllActionStates();
for (Iterator iterActionState = actionStates.iterator();
iterActionState.hasNext();) {
ActionStateFacade actionState =
(ActionStateFacade) iterActionState.next();
actionState is always ""null"".
4) Importing the activity diagram from Poseidon works and the result can be processed by AndroMDA but if you are making the activity diagram from the beginning with ArgoUML, it won't work because of the error above
(nr.
3).
So, it seems that ArgoUML still has a problem with activity diagram...
Thanks,
Lofi.",org.argouml.persistence.XMIParser
METHOD,eclipse-2.0,31779,2003-02-13T09:55:00.000-06:00,[resources] UnifiedTree should ensure file/folder exists,"getStat()
Build: I20030211 using natives (Linux/Windows)
When the UnifiedTree finds a new file from the file system, it assumes that if the file is not an existing file, then it is a folder.
This is not always true, because for different reasons a file returned by java.io.File.list/listFiles may not actually exist (our CoreFileSystemLibrary#getStat() returns 0).
execute refresh operations appear to user
At the first moment, the file is found in the file system and assumed to be a folder, and a corresponding resource is created in the workspace.
At the second refresh, the folder corresponding to that resource is not found in the file system, and then it is removed from the workspace.
And so on.
Bugs that revealed this problem: bug 21217 and bug 13463.","org.eclipse.core.internal.localstore.UnifiedTree:addChildrenFromFileSystem(UnifiedTreeNode, String, Object[], int)
org.eclipse.core.internal.localstore.UnifiedTree:createChildNodeFromFileSystem(UnifiedTreeNode, String, String)"
CLASS,mahout-0.8,MAHOUT-1314,2013-08-18T09:07:48.000-05:00,StreamingKMeansReducer throws NullPointerException when REDUCE_STREAMING_KMEANS is set to true,"return input.getCentroid();  
 input.getCentroid()  clone();
when REDUCE_STREAMING_KMEANS option is set to true (-rskm) the reducer fails with NullPointerException.
the problem is in the reduce method itself: on line 60 ( return input.getCentroid(); )
similar to line 81.
full stack trace:
java.lang.NullPointerException
at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:191)
at org.apache.mahout.math.random.WeightedThing.<init>(WeightedThing.java:31)
at org.apache.mahout.math.neighborhood.BruteSearch.searchFirst(BruteSearch.java:133)
at org.apache.mahout.clustering.ClusteringUtils.estimateDistanceCutoff(ClusteringUtils.java:100)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansThread.call(StreamingKMeansThread.java:64)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:66)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:1)
at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:176)
at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:650)
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:418)
at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:260)
happen time set REDUCE_STREAMING_KMEANS to true set time to true",core.src.main.java.org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer
CLASS,mahout-0.8,MAHOUT-1349,2013-11-01T07:59:17.000-05:00,Clusterdumper/loadTermDictionary crashes when highest index in (sparse) dictionary vector is larger than dictionary vector size?,"OpenObjectIntHashMap dict = new OpenObjectIntHashMap();
//...
  String [] dictionary = new String[dict.size()];
I'm not sure if I'm doing something wrong here, or if ClusterDumper does
not support my (fairly simple) use case
I had a repository of 500K documents, for which I generated the input
vectors and a dictionary using some custom code (not seq2sparse etc).
hash features with max size 5M
The kmeans ran fine and generate sensible looking results, but when I tried
to run ClusterDumper I got the following error:
#bash> bin/mahout clusterdump -dt sequencefile -d
completed/5159bba4e4b0718d03c8cf79_/EmailContentAnalytics_dict_5159bba4e4b0718d03c8cf79/part-*
-i test-kmeans/clusters-19 -b 10 -n 10 -sp 10 -o ~/test-kmeans-out
Running on hadoop, using /usr/bin/hadoop and HADOOP_CONF_DIR=
MAHOUT-JOB: /opt/mahout-distribution-0.7/mahout-examples-0.7-job.jar
13/05/17 08:26:41 INFO common.AbstractJob: Command line arguments:
{--dictionary=[completed/5159bba4e4b0718d03c8cf79_/EmailContentAnalytics_dict_5159bba4e4b0718d03c8cf79/part-*],
--dictionaryType=[sequencefile],
--distanceMeasure=[org.apache.mahout.common.distance.SquaredEuclideanDistanceMeasure],
--endPhase=[2147483647], --input=[test-kmeans/clusters-19],
--numWords=[10], --output=[/usr/share/tomcat6/test-kmeans-out],
--outputFormat=[TEXT], --samplePoints=[10], --startPhase=[0],
--substring=[10], --tempDir=[temp]}
Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 698948
at
org.apache.mahout.clustering.AbstractCluster.formatVector(AbstractCluster.java:350)
at
org.apache.mahout.clustering.AbstractCluster.asFormatString(AbstractCluster.java:306)
at
org.apache.mahout.utils.clustering.ClusterDumperWriter.write(ClusterDumperWriter.java:54)
at
org.apache.mahout.utils.clustering.AbstractClusterWriter.write(AbstractClusterWriter.java:169)
at
org.apache.mahout.utils.clustering.AbstractClusterWriter.write(AbstractClusterWriter.java:156)
at
org.apache.mahout.utils.clustering.ClusterDumper.printClusters(ClusterDumper.java:187)
at
org.apache.mahout.utils.clustering.ClusterDumper.run(ClusterDumper.java:153)
(...)
The error is when it tries to access the dictionary for the feature with
index 698948
Looking at the dictionary loading code (
http://grepcode.com/file/repo1.maven.org/maven2/org.apache.mahout/mahout-integration/0.7/org/apache/mahout/utils/vectors/VectorHelper.java#VectorHelper.loadTermDictionary%28java.io.File%29
-  checked 0.8 and it hasn't changed)
It looks like the dictionary array is sized for the number of unique
keywords, not the highest index:
OpenObjectIntHashMap dict = new OpenObjectIntHashMap();
//...
  String [] dictionary = new String[dict.size()];
After I ran my custom dictionary/feature generation code I discovered I
only had 517,327 unique features, therefore it is not surprising it would
die on an index >= 517327 (though I don't understand why it didn't die when trying to load the dictionary file)
Is there any reason why the VectorHelper code should not create a
dictionary array that has size the highest index read from the dictionary
sequence file (which can be easily calculated during the preceding loop)?
Or am I misunderstanding something?
It worked fine when I reduced the hash size to be <= than the total number
of features, but this is not desirable in general (for me) since I don't
know the number of features before I run the job (and if I guess too high
then ClusterDumper crashes)
Alex Piggott
IKANOW",integration.src.main.java.org.apache.mahout.utils.vectors.VectorHelper
CLASS,mahout-0.8,MAHOUT-1358,2013-11-18T01:58:22.000-06:00,StreamingKMeansThread throws IllegalArgumentException when REDUCE_STREAMING_KMEANS is set to true,"{Code}

 {Code}

  StreamingKMeansThread.call()

 {Code}
     Iterator<Centroid> datapointsIterator = datapoints.iterator();
    if (estimateDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
      List<Centroid> estimatePoints = Lists.newArrayListWithExpectedSize(NUM_ESTIMATE_POINTS);
      while (datapointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) {
        estimatePoints.add(datapointsIterator.next());
      }
      estimateDistanceCutoff = ClusteringUtils.estimateDistanceCutoff(estimatePoints, searcher.getDistanceMeasure());
    }

    StreamingKMeans clusterer = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);
    while (datapointsIterator.hasNext()) {
      clusterer.cluster(datapointsIterator.next());
    }
{Code}
Running StreamingKMeans Clustering with REDUCE_STREAMING_KMEANS = true and when no estimatedDistanceCutoff is specified, throws the following error
{Code}
java.lang.IllegalArgumentException: Must have nonzero number of training and test vectors.
Asked for %.1f %% of %d vectors for test [10.000000149011612, 0]
at com.google.common.base.Preconditions.checkArgument(Preconditions.java:120)
at org.apache.mahout.clustering.streaming.cluster.BallKMeans.splitTrainTest(BallKMeans.java:176)
at org.apache.mahout.clustering.streaming.cluster.BallKMeans.cluster(BallKMeans.java:192)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.getBestCentroids(StreamingKMeansReducer.java:107)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:73)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:37)
at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:177)
at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:649)
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:418)
at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:398)
{Code}
cause issue
{Code}
Iterator<Centroid> datapointsIterator = datapoints.iterator();
if (estimateDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
List<Centroid> estimatePoints = Lists.newArrayListWithExpectedSize(NUM_ESTIMATE_POINTS);
while (datapointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) { estimatePoints.add(datapointsIterator.next());
} estimateDistanceCutoff = ClusteringUtils.estimateDistanceCutoff(estimatePoints, searcher.getDistanceMeasure());
}
StreamingKMeans clusterer = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);
while (datapointsIterator.hasNext()) { clusterer.cluster(datapointsIterator.next());
}
{Code}
The code is using the same iterator twice, and it fails on the second use for obvious reasons.",core.src.main.java.org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansThread
METHOD,mahout-0.8,MAHOUT-1301,2013-08-01T09:31:21.000-05:00,toString() method of SequentialAccessSparseVector has excess comma at the end,"SequentialAccessSparseVector toString()   toString()  
 {code:java}
 Vector v = new SequentialAccessSparseVector(capacity);
v.set(1, 0.1);
v.set(3, 0.3);
{code}
  v.toString()  
 {code:java}
 {1:0.1,3:0.3}
 {code}
 
 {code:java}
 {1:0.1,3:0.3,}
 {code}
Realization of SequentialAccessSparseVector toString() method had changed in MAHOUT-1259 patch.
Unfortunately, that patch introduced new bug: output of the toString() method had been changed - extra comma added at the end of the string
Example: 
Consider following sparse vector
{code:java}
Vector v = new SequentialAccessSparseVector(capacity);
v.set(1, 0.1);
v.set(3, 0.3);
{code}
In 0.7 v.toString() returns following string:
{code:java}
{1:0.1,3:0.3}
{code}
but in 0.8 it returns
{code:java}
{1:0.1,3:0.3,}
{code}
As you can see, there is extra comma at the end of the string.","org.apache.mahout.math.SequentialAccessSparseVector:toString()
org.apache.mahout.math.RandomAccessSparseVector:toString()"
METHOD,mahout-0.8,MAHOUT-1314,2013-08-18T09:07:48.000-05:00,StreamingKMeansReducer throws NullPointerException when REDUCE_STREAMING_KMEANS is set to true,"return input.getCentroid();  
 input.getCentroid()  clone();
when REDUCE_STREAMING_KMEANS option is set to true (-rskm) the reducer fails with NullPointerException.
the problem is in the reduce method itself: on line 60 ( return input.getCentroid(); )
it should be input.getCentroid().
clone();
similar to line 81.
full stack trace:
java.lang.NullPointerException
at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:191)
at org.apache.mahout.math.random.WeightedThing.<init>(WeightedThing.java:31)
at org.apache.mahout.math.neighborhood.BruteSearch.searchFirst(BruteSearch.java:133)
at org.apache.mahout.clustering.ClusteringUtils.estimateDistanceCutoff(ClusteringUtils.java:100)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansThread.call(StreamingKMeansThread.java:64)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:66)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:1)
at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:176)
at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:650)
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:418)
at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:260)
happen time set REDUCE_STREAMING_KMEANS to true set time to true","org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer:reduce(IntWritable, Iterable<CentroidWritable>, Context)
org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer:getBestCentroids(List<Centroid>, Configuration)"
METHOD,mahout-0.8,MAHOUT-1349,2013-11-01T07:59:17.000-05:00,Clusterdumper/loadTermDictionary crashes when highest index in (sparse) dictionary vector is larger than dictionary vector size?,"OpenObjectIntHashMap dict = new OpenObjectIntHashMap();
//...
  String [] dictionary = new String[dict.size()];
I'm not sure if I'm doing something wrong here, or if ClusterDumper does not support my (fairly simple) use case
have repository of 500K documents generate dictionary generate vectors generate 500K documents use custom code
hash features with max size 5M
The kmeans ran fine and generate sensible looking results, but when I tried to run ClusterDumper I got the following error:
#bash> bin/mahout clusterdump -dt sequencefile -d completed/5159bba4e4b0718d03c8cf79_/EmailContentAnalytics_dict_5159bba4e4b0718d03c8cf79/part-*
-i test-kmeans/clusters-19 -b 10 -n 10 -sp 10 -o ~/test-kmeans-out
Running on hadoop, using /usr/bin/hadoop and HADOOP_CONF_DIR=
MAHOUT-JOB: /opt/mahout-distribution-0.7/mahout-examples-0.7-job.jar
13/05/17 08:26:41 INFO common.AbstractJob: Command line arguments:
{--dictionary=[completed/5159bba4e4b0718d03c8cf79_/EmailContentAnalytics_dict_5159bba4e4b0718d03c8cf79/part-*],
--dictionaryType=[sequencefile],
--distanceMeasure=[org.apache.mahout.common.distance.SquaredEuclideanDistanceMeasure],
--endPhase=[2147483647], --input=[test-kmeans/clusters-19],
--numWords=[10], --output=[/usr/share/tomcat6/test-kmeans-out],
--outputFormat=[TEXT], --samplePoints=[10], --startPhase=[0],
--substring=[10], --tempDir=[temp]}
Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: 698948 at
org.apache.mahout.clustering.AbstractCluster.formatVector(AbstractCluster.java:350)
at
org.apache.mahout.clustering.AbstractCluster.asFormatString(AbstractCluster.java:306)
at
org.apache.mahout.utils.clustering.ClusterDumperWriter.write(ClusterDumperWriter.java:54)
at
org.apache.mahout.utils.clustering.AbstractClusterWriter.write(AbstractClusterWriter.java:169)
at
org.apache.mahout.utils.clustering.AbstractClusterWriter.write(AbstractClusterWriter.java:156)
at
org.apache.mahout.utils.clustering.ClusterDumper.printClusters(ClusterDumper.java:187)
at
org.apache.mahout.utils.clustering.ClusterDumper.run(ClusterDumper.java:153)
(...)
The error is when it tries to access the dictionary for the feature with index 698948
Looking at the dictionary loading code ( http://grepcode.com/file/repo1.maven.org/maven2/org.apache.mahout/mahout-integration/0.7/org/apache/mahout/utils/vectors/VectorHelper.java#VectorHelper.loadTermDictionary%28java.io.File%29
-  checked 0.8 and it hasn't changed)
It looks like the dictionary array is sized for the number of unique keywords, not the highest index:
OpenObjectIntHashMap dict = new OpenObjectIntHashMap();
//...
String [] dictionary = new String[dict.size()];
After I ran my custom dictionary/feature generation code I discovered I only had 517,327 unique features, therefore it is not surprising it would die on an index >= 517327 (though I don't understand why it didn't die when trying to load the dictionary file)
Is there any reason why the VectorHelper code should not create a dictionary array that has size the highest index read from the dictionary sequence file (which can be easily calculated during the preceding loop)?
Or am I misunderstanding something?
It worked fine when I reduced the hash size to be <= than the total number of features, but this is not desirable in general (for me) since I don't know the number of features before I run the job (and if I guess too high then ClusterDumper crashes)
Alex Piggott
IKANOW","org.apache.mahout.utils.vectors.VectorHelper:loadTermDictionary(Configuration, String)
org.apache.mahout.utils.vectors.VectorHelperTest:testJsonFormatting()"
METHOD,mahout-0.8,MAHOUT-1358,2013-11-18T01:58:22.000-06:00,StreamingKMeansThread throws IllegalArgumentException when REDUCE_STREAMING_KMEANS is set to true,"{Code}


 {Code}


  StreamingKMeansThread.call()


 {Code}
     Iterator<Centroid> datapointsIterator = datapoints.iterator();
    if (estimateDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
      List<Centroid> estimatePoints = Lists.newArrayListWithExpectedSize(NUM_ESTIMATE_POINTS);
      while (datapointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) {
        estimatePoints.add(datapointsIterator.next());
      }
      estimateDistanceCutoff = ClusteringUtils.estimateDistanceCutoff(estimatePoints, searcher.getDistanceMeasure());
    }


    StreamingKMeans clusterer = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);
    while (datapointsIterator.hasNext()) {
      clusterer.cluster(datapointsIterator.next());
    }
{Code}
Running StreamingKMeans Clustering with REDUCE_STREAMING_KMEANS = true and when no estimatedDistanceCutoff is specified, throws the following error
{Code}
java.lang.IllegalArgumentException: Must have nonzero number of training and test vectors. Asked for %.1f %% of %d vectors for test [10.000000149011612, 0]
at com.google.common.base.Preconditions.checkArgument(Preconditions.java:120)
at org.apache.mahout.clustering.streaming.cluster.BallKMeans.splitTrainTest(BallKMeans.java:176)
at org.apache.mahout.clustering.streaming.cluster.BallKMeans.cluster(BallKMeans.java:192)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.getBestCentroids(StreamingKMeansReducer.java:107)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:73)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:37)
at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:177)
at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:649)
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:418)
at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:398)
{Code}
The issue is caused by the following code in StreamingKMeansThread.call()
{Code}
    Iterator<Centroid> datapointsIterator = datapoints.iterator();
    if (estimateDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
      List<Centroid> estimatePoints = Lists.newArrayListWithExpectedSize(NUM_ESTIMATE_POINTS);
      while (datapointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) {
        estimatePoints.add(datapointsIterator.next());
      }
      estimateDistanceCutoff = ClusteringUtils.estimateDistanceCutoff(estimatePoints, searcher.getDistanceMeasure());
    }
StreamingKMeans clusterer = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);
    while (datapointsIterator.hasNext()) {
      clusterer.cluster(datapointsIterator.next());
    }
{Code}
The code is using the same iterator twice, and it fails on the second use for obvious reasons.","org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansThread:StreamingKMeansThread(Path, Configuration)
org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansThread:StreamingKMeansThread(Iterable<Centroid>, Configuration)"
CLASS,openjpa-2.0.1,OPENJPA-1787,2010-09-10T11:23:51.000-05:00,Bean validation fails merging a new entity,"EntityManager em = entityManagerFactory.createEntityManager();
        Person person = new Person();
        person.setName(""Oliver"");                               // Employee.name is annotated @NotNull 
        person = em.merge(person);
The bean validation is not working correctly
merge new entity
EntityManager em = entityManagerFactory.createEntityManager();
        Person person = new Person();
        person.setName(""Oliver"");                               // Employee.name is annotated @NotNull 
        person = em.merge(person);
you get a ConstraintValidationException, although name is set.","org.apache.openjpa.kernel.BrokerImpl
org.apache.openjpa.kernel.AttachStrategy
org.apache.openjpa.integration.validation.TestValidationGroups"
CLASS,openjpa-2.0.1,OPENJPA-1903,2010-12-06T13:05:34.000-06:00,Some queries only work the first time they are executed,"@Entity
@IdClass(MandantAndNameIdentity.class)
public class Website {
    @Id
    private String mandant;
   
    @Id
    private String name;
...
}

 @Entity
@IdClass(WebsiteProduktDatumIdentity.class)
public class Preis {
    @Id
    @ManyToOne(cascade = CascadeType.MERGE)
    private Website website;

    @Id
    @Basic
    private String datum;
...
}

 
 em.getTransaction().begin();

        Website website = em.merge(new Website(""Mandant"", ""Website""));

        em.merge(new Preis(website, DATUM));
       
        em.getTransaction().commit();

 
 TypedQuery<Preis> q = em.createQuery(
                ""select m from Preis m "" +
                ""where m.website.name = :website "", Preis.class);
       q.setParameter(""website"", website.getName());

 
 TypedQuery<Preis> q = em.createQuery(
                ""select m from Preis m "" +
                ""where m.website = :website "", Preis.class);
        q.setParameter(""website"", website);
I have a problem in my application where a query that sometimes returns data and sometimes not.
I have reduced it to the code as much as I could into an Eclipse project available at http://ubuntuone.com/p/S9n/
This happens with OpenJPA 2.0.1 as well as the daily snapshot from 2010-12-05 and an out-of-process Derby database.
have Entities use multiple ids use Entities produce Primary key contain foreign key on website
@Entity
@IdClass(MandantAndNameIdentity.class)
public class Website {
    @Id
    private String mandant;
   
    @Id
    private String name;
...
}
@Entity
@IdClass(WebsiteProduktDatumIdentity.class)
public class Preis {
    @Id
    @ManyToOne(cascade = CascadeType.MERGE)
    private Website website;
@Id
    @Basic
    private String datum;
...
}
set up website set up preis
em.getTransaction().
begin();
Website website = em.merge(new Website(""Mandant"", ""Website""));
em.merge(new Preis(website, DATUM));
       
        em.getTransaction().
commit();
TypedQuery<Preis> q = em.createQuery(
                ""select m from Preis m "" +
                ""where m.website.name = :website "", Preis.class);
       q.setParameter(""website"", website.getName());
this query works all the time, note that it uses website.name for matching, not the full Website-object.
put query
TypedQuery<Preis> q = em.createQuery(
                ""select m from Preis m "" +
                ""where m.website = :website "", Preis.class);
        q.setParameter(""website"", website);
it only works ONCE and then does not return any results any more!!
See testcase DataAccessVerifyTest for details.
Discussion on the mailinglist seems to indicate that this is a bug.",org.apache.openjpa.jdbc.kernel.PreparedQueryImpl
CLASS,openjpa-2.0.1,OPENJPA-1912,2011-01-03T13:48:09.000-06:00,enhancer generates invalid code if fetch-groups is activated,"@Entity
public abstract class AbstractGroup {
   ...
    @Temporal(TemporalType.TIMESTAMP)
    @TrackChanges
    private Date applicationBegin;
 ...
}

 
 @Entity
public class Group extends AbstractGroup {
...
}

 
 public void writeExternal(ObjectOutput objectoutput)
        throws IOException
     
 pcWriteUnmanaged(objectoutput);
        if(pcStateManager != null)
        {
            if(pcStateManager.writeDetached(objectoutput))
                return;
        } else
        {
            objectoutput.writeObject(pcGetDetachedState());
            objectoutput.writeObject(null);
        }
        objectoutput.writeObject(applicationBegin);
        objectoutput.writeObject(applicationEnd);
        objectoutput.writeObject(applicationLocked);
        objectoutput.writeObject(approvalRequired);
If openjpa.DetachState =fetch-groups is used, the enhancer will add a 'implements Externalizable' + writeExternal + readExternal.
The problem is, that writeExternal and readExternal will also try to externalize the private members of any given superclass.
Thus we get a runtime Exception that we are not allowed to access those fields.
@Entity public abstract class AbstractGroup {
...
@Temporal(TemporalType.TIMESTAMP)
@TrackChanges private Date applicationBegin;
...
}
and
@Entity public class Group extends AbstractGroup {
...
}
will result in the following code (decompiled with jad):
public void writeExternal(ObjectOutput objectoutput)
throws IOException
{ pcWriteUnmanaged(objectoutput);
if(pcStateManager !
= null)
{ if(pcStateManager.writeDetached(objectoutput))
return;
} else
{ objectoutput.writeObject(pcGetDetachedState());
objectoutput.writeObject(null);
} objectoutput.writeObject(applicationBegin);
objectoutput.writeObject(applicationEnd);
objectoutput.writeObject(applicationLocked);
objectoutput.writeObject(approvalRequired);
...",org.apache.openjpa.enhance.PCEnhancer
CLASS,openjpa-2.0.1,OPENJPA-1918,2011-01-06T08:11:24.000-06:00,MetaDataRepository.preload() ignores class loader returned by PersistenceUnitInfo.getClassLoader(),"PersistenceUnitInfo.getClassLoader() 
 MetaDataRepository.preload()      
 PersistenceUnitInfo.getClassLoader()    
  
   PersistenceProvider.createContainerEntityManagerFactory()  MetaDatRepository.preload()
We are using openjpa inside an OSGi container together with
openjpa.MetaDataRepository"" value=""Preload=true""
pass appliation class loeader as part pass appliation class loeader by returning return from PersistenceUnitInfo.getClassLoader()
However, the code in MetaDataRepository.preload() only uses the context class loader and not the class loader from PersistenceUnitInfo, which leades to ClassNotFoundExpcetions like mentioned at the end of this report.
A fix might be quite easily establihed by appending the return value of PersistenceUnitInfo.getClassLoader() to the list of claas loaders participating in the MultiClassLoader set up in
  
  MetaDataRepository.java:310ff
In the meanwhile, we are additionally setting our classloader as context loader during the creation of the EntityManagerFactory by PersistenceProvider.createContainerEntityManagerFactory(), but a fix in MetaDatRepository.preload() is highly appreciated.
TIA for fixing this,
Wolfgang
Stack trace:
org.osgi.service.blueprint.container.ComponentDefinitionException: Error when instantiating bean entityManagerFactory of class null
at org.apache.aries.blueprint.container.BeanRecipe.getInstance(BeanRecipe.java:233)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BeanRecipe.internalCreate(BeanRecipe.java:726)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.di.AbstractRecipe.create(AbstractRecipe.java:64)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintRepository.createInstances(BlueprintRepository.java:219)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintRepository.createAll(BlueprintRepository.java:147)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintContainerImpl.instantiateEagerComponents(BlueprintContainerImpl.java:624)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintContainerImpl.doRun(BlueprintContainerImpl.java:315)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintContainerImpl.run(BlueprintContainerImpl.java:213)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)[:1.6.0_20]
at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)[:1.6.0_20]
at java.util.concurrent.FutureTask.run(FutureTask.java:166)[:1.6.0_20]
at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$101(ScheduledThreadPoolExecutor.java:165)[:1.6.0_20]
at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:266)[:1.6.0_20]
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)[:1.6.0_20]
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)[:1.6.0_20]
at java.lang.Thread.run(Thread.java:636)[:1.6.0_20]
Caused by: <openjpa-2.0.1-r422266:989424 fatal user error> org.apache.openjpa.persistence.ArgumentException: Unexpected error during early loading of entity metadata during initialization. See nested stacktrace for details.
at org.apache.openjpa.meta.MetaDataRepository.preload(MetaDataRepository.java:331)
at org.apache.openjpa.persistence.PersistenceProviderImpl.preloadMetaDataRepository(PersistenceProviderImpl.java:280)
at org.apache.openjpa.persistence.PersistenceProviderImpl.createContainerEntityManagerFactory(PersistenceProviderImpl.java:211)
at org.apache.openjpa.persistence.PersistenceProviderImpl.createContainerEntityManagerFactory(PersistenceProviderImpl.java:65)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[:1.6.0_20]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)[:1.6.0_20]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[:1.6.0_20]
at java.lang.reflect.Method.invoke(Method.java:616)[:1.6.0_20]
at org.apache.aries.blueprint.container.AbstractServiceReferenceRecipe$JdkProxyFactory$1.invoke(AbstractServiceReferenceRecipe.java:632)
at $Proxy67.createContainerEntityManagerFactory(Unknown Source)
at org.clazzes.util.jpa.provider.EntityManagerFactoryFactory.newEntityManagerFactory(EntityManagerFactoryFactory.java:108)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[:1.6.0_20]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)[:1.6.0_20]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[:1.6.0_20]
at java.lang.reflect.Method.invoke(Method.java:616)[:1.6.0_20]
at org.apache.aries.blueprint.utils.ReflectionUtils.invoke(ReflectionUtils.java:221)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BeanRecipe.invoke(BeanRecipe.java:844)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BeanRecipe.getInstance(BeanRecipe.java:231)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
... 15 more
Caused by: java.security.PrivilegedActionException: java.lang.ClassNotFoundException: org.clazzes.fancymail.server.entities.EMail
at java.security.AccessController.doPrivileged(Native Method)[:1.6.0_20]
at org.apache.openjpa.meta.MetaDataRepository.preload(MetaDataRepository.java:326)
... 32 more
Caused by: java.lang.ClassNotFoundException: org.clazzes.fancymail.server.entities.EMail
at org.apache.openjpa.lib.util.MultiClassLoader.findClass(MultiClassLoader.java:216)
at java.lang.ClassLoader.loadClass(ClassLoader.java:321)[:1.6.0_20]
at java.lang.ClassLoader.loadClass(ClassLoader.java:266)[:1.6.0_20]
at java.lang.Class.forName0(Native Method)[:1.6.0_20]
at java.lang.Class.forName(Class.java:264)[:1.6.0_20]
at org.apache.openjpa.lib.util.J2DoPrivHelper$4.run(J2DoPrivHelper.java:233)
at org.apache.openjpa.lib.util.J2DoPrivHelper$4.run(J2DoPrivHelper.java:231)
... 34 more","org.apache.openjpa.meta.FieldMetaData
org.apache.openjpa.meta.MetaDataRepository
org.apache.openjpa.persistence.detach.NoVersionEntity"
CLASS,openjpa-2.0.1,OPENJPA-1986,2011-04-27T11:44:53.000-05:00,Extra queries being generated when cascading a persist,"@Entity
public class CascadePersistEntity implements Serializable {
    private static final long serialVersionUID = -8290604110046006897L;

    @Id
    long id;

    @OneToOne(cascade = CascadeType.ALL)
    CascadePersistEntity other;
...
}

 
 CascadePersistEntity cpe1 = new CascadePersistEntity(1);
CascadePersistEntity cpe2 = new CascadePersistEntity(2);
cpe1.setOther(cpe2);
em.persist(cpe1);
I found a scenario where extra queries were being generated while cascading a persist to a new Entity.
see following example
@Entity
public class CascadePersistEntity implements Serializable {
    private static final long serialVersionUID = -8290604110046006897L;
@Id
    long id;
@OneToOne(cascade = CascadeType.ALL)
    CascadePersistEntity other;
...
}
and following scenario
This results in two inserts and one select.
The extra select is what I'm going to get rid of with this JIRA.","org.apache.openjpa.kernel.BrokerImpl
org.apache.openjpa.conf.Compatibility
org.apache.openjpa.kernel.SingleFieldManager"
METHOD,lang,LANG-363,2007-10-23T07:12:48.000-05:00,"StringEscapeUtils.escapeJavaScript() method did not escape '/' into '\/', it will make IE render page uncorrectly","document.getElementById(""test"")   document.getElementById(""test"") 
  
 String s = ""<script>alert('aaa');</script>"";
  String str = org.springframework.web.util.JavaScriptUtils.javaScriptEscape(s);
  System.out.println(""Spring JS Escape : ""+str);
  str = org.apache.commons.lang.StringEscapeUtils.escapeJavaScript(s);
  System.out.println(""Apache Common Lang JS Escape : ""+ str);
value = '<script>alert(\'aaa\');</script>';this expression will make IE render page uncorrect, it should be document.getElementById(""test"").
value = '<script>alert(\'aaa\');<\/script>';
Btw, Spring's JavascriptEscape behavor is correct.
find difference run below codes","org.apache.commons.lang.StringEscapeUtils:escapeJavaStyleString(Writer, String, boolean)"
METHOD,lang,LANG-477,2009-01-09T10:05:53.000-06:00,ExtendedMessageFormat: OutOfMemory with custom format registry and a pattern containing single quotes,"{code:title=ExtendedMessageFormatTest.java|borderStyle=solid}

 private static Map<String, Object> formatRegistry = new HashMap<String, Object>();    
     static {
        formatRegistry.put(DummyFormatFactory.DUMMY_FORMAT, new DummyFormatFactory());
    }
    
     public static void main(String[] args) {
        ExtendedMessageFormat mf = new ExtendedMessageFormat(""it''s a {dummy} 'test'!"", formatRegistry);
        String formattedPattern = mf.format(new String[] {""great""});
        System.out.println(formattedPattern);
    }
 
 {code}

 
 {code:title=ExtendedMessageFormat.java|borderStyle=solid}
 
 if (escapingOn && c[start] == QUOTE) {
        return appendTo == null ? null : appendTo.append(QUOTE);
}

WORKING:
if (escapingOn && c[start] == QUOTE) {
        next(pos);
        return appendTo == null ? null : appendTo.append(QUOTE);
}
{code}
When using ExtendedMessageFormat with a custom format registry and a pattern conatining single quotes, an OutOfMemoryError will occur.
cause error
{code:title=ExtendedMessageFormatTest.java|borderStyle=solid}
private static Map<String, Object> formatRegistry = new HashMap<String, Object>();    
    static {
        formatRegistry.put(DummyFormatFactory.DUMMY_FORMAT, new DummyFormatFactory());
    }
    
    public static void main(String[] args) {
        ExtendedMessageFormat mf = new ExtendedMessageFormat(""it''s a {dummy} 'test'!""
, formatRegistry);
        String formattedPattern = mf.format(new String[] {""great""});
        System.out.println(formattedPattern);
    }
}
{code}
The following change starting at line 421 on the 2.4 release seems to fix the problem:
{code:title=ExtendedMessageFormat.java|borderStyle=solid}
CURRENT (Broken):
if (escapingOn && c[start] == QUOTE) {
        return appendTo == null ?
null : appendTo.append(QUOTE);
}
WORKING:
if (escapingOn && c[start] == QUOTE) {
        next(pos);
        return appendTo == null ?
null : appendTo.append(QUOTE);
}
{code}","org.apache.commons.lang.text.ExtendedMessageFormat:appendQuotedString(String, ParsePosition, StringBuffer, boolean)"
METHOD,lang,LANG-552,2009-11-09T12:40:57.000-06:00,StringUtils replaceEach - Bug or Missing Documentation,"{code}
 import static org.junit.Assert.assertEquals;

import org.apache.commons.lang.StringUtils;
import org.junit.Test;


public class StringUtilsTest {

	@Test
	public void replaceEach(){
		String original = ""Hello World!"";
		String[] searchList = {""Hello"", ""World""};
		String[] replacementList = {""Greetings"", null};
		String result = StringUtils.replaceEach(original, searchList, replacementList);
		assertEquals(""Greetings !"", result);
		//perhaps this is ok as well
                //assertEquals(""Greetings World!"", result);
                //or even
		//assertEquals(""Greetings null!"", result);
	}

	
}
 {code}
The following Test Case for replaceEach fails with a null pointer exception.
The use case is that i will stuff Values into the replacementList of which I do not want to check whether they are null.
I admit the use case is not perfect, because it is unclear what happens on the replace.
I outlined three expectations in the test case, of course only one should be met.
If it is decided that none of them should be possible, I propose to update the documentation with what happens when null is passed as replacement string
{code} import static org.junit.Assert.assertEquals;
import org.apache.commons.lang.StringUtils;
import org.junit.Test;
public class StringUtilsTest {
@Test public void replaceEach(){
String original = ""Hello World!""
;
String[] searchList = {""Hello"", ""World""};
String[] replacementList = {""Greetings"", null};
String result = StringUtils.replaceEach(original, searchList, replacementList);
assertEquals(""Greetings !""
, result);
//perhaps this is ok as well
//assertEquals(""Greetings World!""
, result);
//or even
//assertEquals(""Greetings null!""
, result);
}
}
{code}","org.apache.commons.lang3.StringUtils:replaceEach(String, String[], String[], boolean, int)"
METHOD,lang,LANG-645,2010-08-20T14:11:08.000-05:00,FastDateFormat.format() outputs incorrect week of year because locale isn't respected,"format()     
  
 {code}
 import java.util.Calendar;
import java.util.Date;
import java.util.Locale;
import java.text.SimpleDateFormat;

import org.apache.commons.lang.time.FastDateFormat;

public class FastDateFormatWeekBugDemo {
    public static void main(String[] args) {
        Locale.setDefault(new Locale(""en"", ""US""));
        Locale locale = new Locale(""sv"", ""SE"");

        Calendar cal = Calendar.getInstance(); // setting locale here doesn't change outcome
        cal.set(2010, 0, 1, 12, 0, 0);
        Date d = cal.getTime();
        System.out.println(""Target date: "" + d);

        FastDateFormat fdf = FastDateFormat.getInstance(""EEEE', week 'ww"", locale);
        SimpleDateFormat sdf = new SimpleDateFormat(""EEEE', week 'ww"", locale);
        System.out.println(""FastDateFormat:   "" + fdf.format(d)); // will output ""FastDateFormat:   fredag, week 01""
        System.out.println(""SimpleDateFormat: "" + sdf.format(d)); // will output ""SimpleDateFormat: fredag, week 53""
    }
}
 {code}
  Locale.setDefault()
FastDateFormat apparently doesn't respect the locale it was sent on creation when outputting week in year (e.g. ""ww"") in format().
It seems to use the settings of the system locale for firstDayOfWeek and minimalDaysInFirstWeek, which (depending on the year) may result in the incorrect week number being output.
Here is a simple test program to demonstrate the problem by comparing with SimpleDateFormat, which gets the week number right:
{code}
import java.util.Calendar;
import java.util.Date;
import java.util.Locale;
import java.text.SimpleDateFormat;
import org.apache.commons.lang.time.FastDateFormat;
public class FastDateFormatWeekBugDemo {
    public static void main(String[] args) {
        Locale.setDefault(new Locale(""en"", ""US""));
        Locale locale = new Locale(""sv"", ""SE"");
Calendar cal = Calendar.getInstance(); // setting locale here doesn't change outcome
        cal.set(2010, 0, 1, 12, 0, 0);
        Date d = cal.getTime();
        System.out.println(""Target date: "" + d);
FastDateFormat fdf = FastDateFormat.getInstance(""EEEE', week 'ww"", locale);
        SimpleDateFormat sdf = new SimpleDateFormat(""EEEE', week 'ww"", locale);
        System.out.println(""FastDateFormat:   "" + fdf.format(d)); // will output ""FastDateFormat:   fredag, week 01""
        System.out.println(""SimpleDateFormat: "" + sdf.format(d)); // will output ""SimpleDateFormat: fredag, week 53""
    }
}
{code}
If sv/SE is passed to Locale.setDefault() instead of en/US, both FastDateFormat and SimpleDateFormat output the correct week number.",org.apache.commons.lang3.time.FastDateFormat:format(Date)
METHOD,lang,LANG-662,2010-12-06T22:40:30.000-06:00,"org.apache.commons.lang3.math.Fraction does not reduce (Integer.MIN_VALUE, 2^k)","class Fraction    
    
 
  public void testReducedFactory_int_int()  
 
  f = Fraction.getReducedFraction(Integer.MIN_VALUE, 2);
		assertEquals(Integer.MIN_VALUE / 2, f.getNumerator());
		assertEquals(1, f.getDenominator());

	 public void testReduce()  
 
  f = Fraction.getFraction(Integer.MIN_VALUE, 2);
		result = f.reduce();
		assertEquals(Integer.MIN_VALUE / 2, result.getNumerator());
		assertEquals(1, result.getDenominator());
{code}
The greatestCommonDivisor method in class Fraction does not find the gcd of Integer.MIN_VALUE and 2^k, and this case can be triggered by taking Integer.MIN_VALUE as the numerator.
Note that the case of taking Integer.MIN_VALUE as the denominator is handled explicitly in the getReducedFraction factory method.
{code:title=FractionTest.java|borderStyle=solid}
	// additional test cases
	public void testReducedFactory_int_int() {
		// ...
		f = Fraction.getReducedFraction(Integer.MIN_VALUE, 2);
		assertEquals(Integer.MIN_VALUE / 2, f.getNumerator());
		assertEquals(1, f.getDenominator());
public void testReduce() {
		// ...
		f = Fraction.getFraction(Integer.MIN_VALUE, 2);
		result = f.reduce();
		assertEquals(Integer.MIN_VALUE / 2, result.getNumerator());
		assertEquals(1, result.getDenominator());
{code}","org.apache.commons.lang3.math.Fraction:greatestCommonDivisor(int, int)"
METHOD,lang,LANG-710,2011-07-01T20:57:30.000-05:00,"StringIndexOutOfBoundsException when calling unescapeHtml4(""&#03"")","unescapeHtml4()
When calling unescapeHtml4() on the String ""&#03"" (or any String that contains these characters) an Exception is thrown:
Exception in thread ""main"" java.lang.StringIndexOutOfBoundsException: String index out of range: 4
at java.lang.String.charAt(String.java:686)
at org.apache.commons.lang3.text.translate.NumericEntityUnescaper.translate(NumericEntityUnescaper.java:49)
at org.apache.commons.lang3.text.translate.AggregateTranslator.translate(AggregateTranslator.java:53)
at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:88)
at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:60)
at org.apache.commons.lang3.StringEscapeUtils.unescapeHtml4(StringEscapeUtils.java:351)","org.apache.commons.lang3.text.translate.NumericEntityUnescaper:translate(CharSequence, int, Writer)"
METHOD,lang,LANG-879,2013-03-18T21:46:29.000-05:00,"LocaleUtils test fails with new Locale ""ja_JP_JP_#u-ca-japanese"" of JDK7","import static org.hamcrest.MatcherAssert.assertThat;
import static org.hamcrest.Matchers.equalTo;

import java.util.Locale;

import org.testng.annotations.Test;

import com.scispike.foundation.i18n.StringToLocaleConverter;

public class LocaleStringConverterTest {

	StringToLocaleConverter converter = new StringToLocaleConverter();

	public void testStringToLocale(Locale l) {
		String s = l.toString();

		assertThat(converter.convert(s), equalTo(l));
	}

	@Test
	public void testAllLocales() {

		Locale[] locales = Locale.getAvailableLocales();
		for (Locale l : locales) {
			testStringToLocale(l);
		}
	}
}


  
 import java.util.Locale;

import org.apache.commons.lang3.LocaleUtils;
import org.springframework.core.convert.converter.Converter;

public class StringToLocaleConverter implements Converter<String, Locale> {

	@Override
	public Locale convert(String source) {
		if (source == null) {
			return LocaleToStringConverter.DEFAULT;
		}
		return LocaleUtils.toLocale(source);
	}
}
The Test below fails with the following error on JDK7, but succeeds on JDK6:
testAllLocales
""java.lang.AssertionError:
Expected: <ja_JP_JP_#u-ca-japanese>
but: was <ja_JP_JP_#u-ca-japanese>
at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)
at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:8)
at com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testStringToLocale(LocaleStringConverterTest.java:20)
at com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testAllLocales(LocaleStringConverterTest.java:28)
at org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:76)
at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeMulti(TestNGDirectoryTestSuite.java:161)
at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.execute(TestNGDirectoryTestSuite.java:101)
at org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:115)
at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:103)
at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:74)
... Removed 25 stack frames
java.lang.AssertionError:
Expected: <ja_JP_JP_#u-ca-japanese>
but: was <ja_JP_JP_#u-ca-japanese>
at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)
at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:8)
at com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testStringToLocale(LocaleStringConverterTest.java:20)
at com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testAllLocales(LocaleStringConverterTest.java:28)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:601)
at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:80)
at org.testng.internal.Invoker.invokeMethod(Invoker.java:715)
at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:907)
at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1237)
at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:127)
at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:111)
at org.testng.TestRunner.privateRun(TestRunner.java:767)
at org.testng.TestRunner.run(TestRunner.java:617)
at org.testng.SuiteRunner.runTest(SuiteRunner.java:334)
at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:329)
at org.testng.SuiteRunner.privateRun(SuiteRunner.java:291)
at org.testng.SuiteRunner.run(SuiteRunner.java:240)
at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:51)
at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:85)
at org.testng.TestNG.runSuitesSequentially(TestNG.java:1197)
at org.testng.TestNG.runSuitesLocally(TestNG.java:1122)
at org.testng.TestNG.run(TestNG.java:1030)
at org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:76)
at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeMulti(TestNGDirectoryTestSuite.java:161)
at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.execute(TestNGDirectoryTestSuite.java:101)
at org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:115)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:601)
at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:103)
at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:74)
""
org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)
org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:8)
com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testStringToLocale(LocaleStringConverterTest.java:20)
com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testAllLocales(LocaleStringConverterTest.java:28)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:601)
org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:80)
org.testng.internal.Invoker.invokeMethod(Invoker.java:715)
org.testng.internal.Invoker.invokeTestMethod(Invoker.java:907)
org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1237)
org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:127)
org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:111)
org.testng.TestRunner.privateRun(TestRunner.java:767)
org.testng.TestRunner.run(TestRunner.java:617)
org.testng.SuiteRunner.runTest(SuiteRunner.java:334)
org.testng.SuiteRunner.runSequentially(SuiteRunner.java:329)
org.testng.SuiteRunner.privateRun(SuiteRunner.java:291)
org.testng.SuiteRunner.run(SuiteRunner.java:240)
org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:51)
org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:85)
org.testng.TestNG.runSuitesSequentially(TestNG.java:1197)
org.testng.TestNG.runSuitesLocally(TestNG.java:1122)
org.testng.TestNG.run(TestNG.java:1030)
org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:76)
org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeMulti(TestNGDirectoryTestSuite.java:161)
org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.execute(TestNGDirectoryTestSuite.java:101)
org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:115)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:601)
org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:103)
org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:74)
========== Test
import static org.hamcrest.MatcherAssert.assertThat;
import static org.hamcrest.Matchers.equalTo;
import java.util.Locale;
import org.testng.annotations.Test;
import com.scispike.foundation.i18n.StringToLocaleConverter;
public class LocaleStringConverterTest {
StringToLocaleConverter converter = new StringToLocaleConverter();
public void testStringToLocale(Locale l) {
		String s = l.toString();
assertThat(converter.convert(s), equalTo(l));
	}
@Test
	public void testAllLocales() {
Locale[] locales = Locale.getAvailableLocales();
		for (Locale l : locales) {
			testStringToLocale(l);
		}
	}
}
========== StringToLocaleConverter
import java.util.Locale;
import org.apache.commons.lang3.LocaleUtils;
import org.springframework.core.convert.converter.Converter;
public class StringToLocaleConverter implements Converter<String, Locale> {
@Override
	public Locale convert(String source) {
		if (source == null) {
			return LocaleToStringConverter.DEFAULT;
		}
		return LocaleUtils.toLocale(source);
	}
}",org.apache.commons.lang3.LocaleUtils:toLocale(String)
FILE,SWARM,SWARM-528,2016-06-22T02:53:46.000-05:00,swarm.http.port and swarm.port.offset do not work with @ArquillianResource URL baseURL,"@ArquillianResource 
  
 
 
 
 @ArquillianResource 
  
 
 
 
 @ArquillianResource
First Example
set swarm port use swarm.http.port via arquillian.xml e.g. use swarm.port.offset via arquillian.xml e.g.
<container qualifier=""wildfly-swarm"" default=""true"">
<configuration>
<property name=""javaVmArguments"">
-Dswarm.port.offset=1
</property>
</configuration>
</container>
the arquillian swarm container is correctly started on the specified port/offset.
@ArquillianResource
private URL baseURL;
to retrieve the url the swarm container is accessible via it always returns http://localhost:8080.
Second Example
set port property in arquillian.xml
<container qualifier=""wildfly-swarm"" default=""true"">
<configuration>
<property name=""port"">8081</property>
</configuration>
</container>
it starts the swarm container on 8080 and
@ArquillianResource
private URL baseURL;
returns http://localhost:8081
Third Example
combine port property not work e.g.
<container qualifier=""wildfly-swarm"" default=""true"">
<configuration>
<property name=""javaVmArguments"">
-Dswarm.port.offset=1
</property>
<property name=""port"">8081</property>
</configuration>
</container>
the port/offset is ignored and the container is started on 8080, while
@ArquillianResource
private URL baseURL;
returns http:localhost:8081 note: while the examples above use swarm.port.offset, the same issue occurs if you use swarm.http.port",org.wildfly.swarm.arquillian.resources.SwarmURLResourceProvider
FILE,SWARM,SWARM-486,2016-05-28T18:25:37.000-05:00,Can't load project-stages.yml on classpath with Arq,"classpath(src/main/resources)  
 
 
 container.withStageConfig(Paths.get(""/tmp"", ""external-project-stages.yml"").toUri().toURL())
problem project-stages.
yml on classpath(src/main/resources) is not loaded with Arquillian tests.
attach error log in steps attach error log to section attach reproducer in steps attach reproducer to section
Though -swarm try to load it, apparently can't see it when Arq tests.
https://github.com/wildfly-swarm/wildfly-swarm-core/blob/1.0.0.CR3/container/api/src/main/java/org/wildfly/swarm/cli/CommandLine.java#L109 workaround
To load the yml explicitly like below.
container.withStageConfig(Paths.get(""/tmp"", ""external-project-stages.
yml"").
toUri().
toURL())",org.wildfly.swarm.container.ProjectStagesTest
FILE,SWARM,SWARM-863,2016-11-30T14:54:40.000-06:00,Version 2016.11.0 doesn't stop properly (with custom main class),"container = new Swarm(); // fractions being added here also




    container.start();




    container.deploy(...);






 
 container.stop();
use custom main class react custom main class on single argument
feed argument through Procrun
hold field inside main class
private static org.wildfly.swarm.Swarm container
handle as following follow during startup
container = new Swarm(); // fractions being added here also
container.start();
container.deploy(...);
container.stop();
We now have the problem that stopping such a Swarm service in version 2016.11.0 does not properly shutdown the Swarm container (or better the underlying `Server`).
I did a debug session and found out that there remains one non-daemon thread blocking the JVM shutdown.
With version 2016.10.0 everything works fine.
The shutdown is clean and fast.
An example project can be found at https://github.com/seelenvirtuose/de.mwa.testing.wfs.
But I also have attached it as a zip.
de.mwa.testing.wfs-master.zip
Procrun can be downloaded at http://mirror.serversupportforum.de/apache//commons/daemon/binaries/windows/commons-daemon-1.0.15-bin-windows.zip
Steps to reproduce:
clone github project clone mvn package start github project start mvn package produce uber-jar locate uber-jar in swarm sub-module
executable into test directory
rename file prunsrv.exe to testing-wfs.exe rename file prunsrv.exe to testing-wfsw.exe rename file prunmgr.exe to testing-wfs.exe rename file prunmgr.exe to testing-wfsw.exe
run command testing-wfs.exe //IS
run testing-wfsw.exe configure service
Tab Logging
Log path: <path-to-the-service-directory>\logs
Redirect Stdout: auto
Redirect Stderror: auto
Tab Java
Java Virtual Machine: Path to the ""jvm.dll"" of a JRE 8 (usually <path-to-jdk>\jre\bin\server\jvm.dll).Java Classpath: Full path to the uber-jar.Java Options: -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=7777 (to enable remote debugging).
Tab Startup
Class: org.wildfly.swarm.bootstrap.Main
Method: main
Arguments: start
Mode: jvm
Tab Shutdown
Class: org.wildfly.swarm.bootstrap.Main
Method: main
Arguments: stop
Mode:jvm
start service
After a succesful start you can ""GET http://localhost:8080/hello"", which should result in a ""Hello World"" response.
6) The service has many threads running.
See first attached screenshot.
stop service
Windows will hang in that stopping attempt and spit out a failure message after some time.
The process is still running afterwards.
The log file shows some output that indeed a shutdown is initalized.
The GET does not work anymore.
8) The service still has many threads (especially non-daemon threads).
See second attached screenshot.
Note, that I have other services, which show only two non-deamon threads after a shutdown attempt.
9) Killing the task ""testing-wfs.exe"" is the only way to stop the process completely.
Switching the Wildfly Swarm version to 2016.10.0 (in the POM of ""swarm"" module) makes it work great.
Starting and stopping run both smoothly.",org.wildfly.swarm.container.runtime.ServerBootstrapImpl
FILE,IO,IO-481,2015-06-19T18:19:48.000-05:00,org.apache.commons.io.FileUtils#waitFor waits too long,"public void testRealWallTime() 
{

        long start = System.currentTimeMillis();

        FileUtils.waitFor(new File(""""), 2);

        System.out.println(""elapsed = "" + (System.currentTimeMillis() - start));

    }
The timing algorithm is basically broken, since Thread.sleep is imprecise.
There is also a counter error in the looping code.
The following testcase will never run in less than 4 seconds on my machine public void testRealWallTime()
{
long start = System.currentTimeMillis();
FileUtils.waitFor(new File(""""), 2);
System.out.println(""elapsed = "" + (System.currentTimeMillis() - start));
}",org.apache.commons.io.FileUtils
FILE,eclipse-3.1,100137,2005-06-15T04:29:00.000-05:00,Variables view: code assist does not work in details pane,"public class A {
	String dog1 = ""Max"", dog2 = ""Bailey"", dog3 = ""Harriet"";
	public static void main(String[] args) {
		new A().foo();
	}
	
	void foo() {
		String p= """";
	}
}
3.1 RC2 and N20050615-0010
create fresh Java project
add new User library have rt.jar as single library have new User library as single library mark new User library as system library
add following class
public class A {
String dog1 = ""Max"", dog2 = ""Bailey"", dog3 = ""Harriet"";
public static void main(String[] args) { new A().
foo();
} void foo() {
String p= """";
}
}
add breakpoint on line
==> code runs, debugger shows correct values but:
- source is not found
- code assist does not work in Variables view's detail pane",org.eclipse.jdt.launching.StandardClasspathProvider
FILE,eclipse-3.1,100807,2005-06-20T09:30:00.000-05:00,Source not found,"JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile) 
  
 
 JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile) 
  
 
 JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile) 
  
 
 JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile) 
  
 
 JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile) 
  
 
  
 JavaModelManager.getZipFile(IPath) 
 
   
 JavaModelManager.closeZipFile(ZipFile) 
    
 
 JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile) 
  
 
 JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile) 
  
 
 JavaModelManager.getZipFile(IPath) 
 
 
 JavaModelManager.closeZipFile(ZipFile)
(from bug 99526)
I tried 3.1RC3 and the fix worked but it did result in a new failure.
The source files in the project are not being found.
I turned on the debug flags via .
options file and only the following archives were searched for the source file when a breakpoint was reached.
set source lookup path
restore default
[reading    java/io/PrintStream.class]
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/rt.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/rt.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/rt.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/sunrsasign.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/sunrsasign.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/sunrsasign.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/jsse.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/jsse.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/jsse.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/jce.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/jce.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/jce.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/charsets.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/charsets.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/charsets.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/ext/sunjce_provider.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/sunjce_provider.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/sunjce_provider.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/ext/dnsns.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/dnsns.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/dnsns.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/ext/ldapsec.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/ldapsec.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/ldapsec.jar
Thread[Worker-17,5,main] OPENING class file Test.class [in <default> [in
/usr/local/jdk1.4.2/jre/lib/ext/localedata.jar [in test]]]
(Thread[Worker-17,5,main]) [JavaModelManager.getZipFile(IPath)] Creating
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/localedata.jar
(Thread[Worker-17,5,main]) [JavaModelManager.closeZipFile(ZipFile)] Closing
ZipFile on /usr/local/jdk1.4.2/jre/lib/ext/localedata.jar",org.eclipse.debug.internal.core.sourcelookup.containers.ContainerSourceContainer
FILE,eclipse-3.1,102427,2005-06-30T20:45:00.000-05:00,Cannot inspect/display static import methods,"public class Helper {
    public static int getValue() {...}
}
  
import static Helper.*;

public class Doer {
    public void doit() {
        int i = getValue();
    }
}
 
 getValue() 
 getValue()
---
public class Helper {
public static int getValue() {...}
}
---
import static Helper.
*;
public class Doer {
public void doit() {
int i = getValue();
}
}
---
When debugging, if you select 'getValue()' in the method 'doit' and execute
display (or inspect) you get an error indicating that the method 'getValue()' is
not undefined for type Doer.",org.eclipse.jdt.internal.debug.eval.ast.engine.SourceBasedSourceGenerator
FILE,eclipse-3.1,102778,2005-07-05T15:40:00.000-05:00,Scrapbook page doesn't work with enhanced for statement,"int[] tab = new int[] {1, 2, 3, 4, 5, 6, 7, 8, 9 };
int sum = 0;
for (int i : tab) {
	sum += i;
}
create new java project
add new scrapbook page contain source contain new scrapbook page
int[] tab = new int[] {1, 2, 3, 4, 5, 6, 7, 8, 9 };
int sum = 0;
for (int i : tab) { sum += i;
} sum
You get an error about syntax error.",org.eclipse.jdt.internal.eval.CodeSnippetParser
FILE,eclipse-3.1,103379,2005-07-11T15:37:00.000-05:00,[MPE] [EditorMgmt] An editor instance is being leaked each time an editor is open and closed,"dispose()
Driver: eclipse-SDK-3.1-win32 with eclipse-test-framework-3.1
Every we open and close an editor.
That editor instance is being leaked.
We have a testcase that can demostrate the problem.
The testcase is really simple.
create new simple project create new file
open up new file in editor come editor with testcase
What's interesting is that the editor, upon open, will allocate a 200000 size
String array as a private field.
So this String array can be GC-ed if the editor itself can be GC-ed.
If you run this testcase with -Xmx256M, you will run out of memory.
However, if you explicitly set the String array to null in the dispose() method of the editor, then the same testcase will not run out of memory.
This leads us to believe that the editor instance is being leaked.",org.eclipse.ui.operations.OperationHistoryActionHandler
FILE,eclipse-3.1,103918,2005-07-14T17:25:00.000-05:00,100% CPU load while creating dynamic proxy in rich client app,"public void start(BundleContext context) throws Exception {
  super.start(context);
  XmlBeanFactory bf = new XmlBeanFactory(
     new ClassPathResource(""/bug/beans.xml""));
  bf.getBean(""hang"");
}

  bf.getBean(""hang"")  
 bf.getBean()
I've tried to integrate my ecplipse-rcp application with springframework.
I've
noticed that when spring tries to instantiate any dynamic proxy RCP falls into
infinit loop, CPU gets 100% load and the application needs to be killed.
contain following code
public void start(BundleContext context) throws Exception {
  super.start(context);
  XmlBeanFactory bf = new XmlBeanFactory(
     new ClassPathResource(""/bug/beans.
xml""));
  bf.getBean(""hang"");
}
When bf.getBean(""hang"") is executed the application hangs.
The same code
executed outside eclipse-rcp works well and without problem.
bf.getBean() tries to create a proxy class for given interface with standard JDK
dynamic proxy facility (no cglib or any other byte code manipulation takes place).
I'm not sure but I think that this may be caused by classloaders.
My environment: 
  Eclipse Version: 3.1.0
  Build id: I20050627-1435
  OS: Linux 2.6.12
  Java: Sun jdk1.5.0_04
I attach a sample project which causes the 100% CPU load and rich client hang.",org.eclipse.core.runtime.internal.adaptor.ContextFinder
FILE,eclipse-3.1,106492,2005-08-09T11:01:00.000-05:00,NPE on console during debug session,"name.equals(""IResourceTest.testDelete"")  
  
  
          
       
  
       
  
       
   testDelete()  
  
   
    
 
  
   
  
   
    
 
   runTest()  
   runBare()  
   protect()
Build: I20050808-2000
While debugging, I noticed the attached stack trace on my Java console (not in the log file).
There was nothing in the log file.
I see from the stack that it occurred during evaluation of a conditional breakpoint.
have single breakpoint with condition
name.equals(""IResourceTest.testDelete"") && count==83
After this error occurred, the debug process hung, and ""Terminate"" and
""Terminate All"" had no effect.
I was still able to ""Suspend"" the process, and it resulted in a debug view showing:
org.eclipse.core.launcher.Main at localhost:1250
Thread [main] (Suspended (breakpoint at line 69 in TestPerformer))
IResourceTest$6(TestPerformer).
performTestRecursiveLoop(Object[][], Object[], int) line: 69
<unknown receiving type>(TestPerformer).
performTestRecursiveLoop(Object[][],
Object[], int) line: 111
<unknown receiving type>(TestPerformer).
performTestRecursiveLoop(Object[][],
Object[], int) line: 111
<unknown receiving type>(TestPerformer).
performTest(Object[][]) line: 55
<unknown receiving type>(<unknown declaring type>).
testDelete() <unknown line number>
<unknown receiving type>(<unknown declaring type>).
invoke0(Method, Object,
Object[]) <unknown line number>
<unknown receiving type>(<unknown declaring type>).
invoke(Object, Object[])
<unknown line number>
<unknown receiving type>(<unknown declaring type>).
invoke(Method, Object,
Object[]) <unknown line number>
<unknown receiving type>(<unknown declaring type>).
invoke(Method, Object,
Object[]) <unknown line number>
<unknown receiving type>(<unknown declaring type>).
invoke(Object, Object[])
<unknown line number>
<unknown receiving type>(<unknown declaring type>).
runTest() <unknown line number>
<unknown receiving type>(<unknown declaring type>).
runBare() <unknown line number>
<unknown receiving type>(<unknown declaring type>).
protect() <unknown line number>
... etc ...
I had to shutdown Eclipse to remove this from the debug view.",org.eclipse.jdt.internal.debug.eval.ast.engine.ASTEvaluationEngine
FILE,eclipse-3.1,108466,2005-08-31T09:39:00.000-05:00,Dups from (Eclipse)ClassLoader.getResources(String),"EclipseClassLoader.getResources(String)  
   
 getClass()  getClassLoader()  getResources(""file.txt"")
When running runtime workspace, EclipseClassLoader.getResources(String) returns duplicate results for files found in plugin jarfiles (i.e. jar files listed in manifest.mf Bundle-ClassPath: entry or plugin.xml <library/> element).
Steps to reproduce
create plugin project
add jar with file.txt entry add jar to project
add jar plugin runtime classpath use manifest editor
update plugin classpath
add code count number of entries count code of entries
getClassLoader().
getResources(""file.txt"")
5. start eclipse application, see that getResources returns two entries
Apparently, eclipse adds the jar on plugin's classpath twice -- as a regular
OSGi classpath entry and as a development entry.",org.eclipse.pde.internal.core.ClasspathHelper
FILE,eclipse-3.1,113455,2005-10-22T11:32:00.000-05:00,[Markers] Some error markers do not appear,"problemView.getCurrentMarkers()
I20051018-0800, GTK+ 2.6.8, KDE 3.4.1, X.org 6.8.2, Linux 2.6.13
start up Eclipse synchronize with HEAD
Even with all the code from HEAD, no errors showed up in my Problems view.
open file reference in first compile error
(ResourceMappingMarkersTest), and it had several errors in it.
Now one error appears in the
Problems view: ""ModelProvider cannot be resolved"" in CompositeResourceMapping.
clean projects
The one error that was there previously then disappeared.
I had a hard time deciding whether to make this ""blocker"" or ""major"".
The big problem, as I see it, is that this can lead to broken builds (as we've seen).
So I marked it as a blocker.","org.eclipse.ui.views.markers.internal.Util
org.eclipse.ui.views.markers.internal.MarkerView"
FILE,eclipse-3.1,115363,2005-11-07T13:28:00.000-06:00,"java.lang.VerifyError in org.eclipse.ui.workbench from HEAD, using N20051107","Ljava/lang/String;Ljava/lang/String;Lorg/eclipse/jface/action/IContributionManager;
N20051107, fresh workspace, all ui plug-ins and test plug-ins from HEAD.
create new RCP application with intro try new RCP application with intro use wizard delete Activator class
Got this stack trace:
java.lang.VerifyError: (class: org/eclipse/ui/internal/PluginActionSetBuilder,
method: findInsertionPoint signature:
(Ljava/lang/String;Ljava/lang/String;Lorg/eclipse/jface/action/IContributionManager;Z)Lorg/eclipse/jface/action/IContributionItem;)
Illegal target of jump or bran [5
at
org.eclipse.ui.internal.ActionPresentation.setActionSets(ActionPresentation.java:184)
at
org.eclipse.ui.internal.WorkbenchWindow.updateActionSets(WorkbenchWindow.java:2552)
at org.eclipse.ui.internal.WorkbenchWindow$5.run(WorkbenchWindow.java:2374)
at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:69)
at org.eclipse.ui.internal.WorkbenchWindow.setActivePage(WorkbenchWindow.java:2337)
at org.eclipse.ui.internal.WorkbenchWindow.busyOpenPage(WorkbenchWindow.java:678)
at org.eclipse.ui.internal.Workbench.busyOpenWorkbenchWindow(Workbench.java:680)
at org.eclipse.ui.internal.Workbench.doOpenFirstTimeWindow(Workbench.java:1321)
at org.eclipse.ui.internal.Workbench.openFirstTimeWindow(Workbench.java:1227)
at
org.eclipse.ui.internal.WorkbenchConfigurer.openFirstTimeWindow(WorkbenchConfigurer.java:190)
at
org.eclipse.ui.application.WorkbenchAdvisor.openWindows(WorkbenchAdvisor.java:706)
at org.eclipse.ui.internal.Workbench.init(Workbench.java:1039)
at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1707)
at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:376)
at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:143)
at snip.intro.Application.run(Application.java:18)
at
org.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:226)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:376)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:165)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
at java.lang.reflect.Method.invoke(Unknown Source)
at org.eclipse.core.launcher.Main.invokeFramework(Main.java:338)
at org.eclipse.core.launcher.Main.basicRun(Main.java:282)
at org.eclipse.core.launcher.Main.run(Main.java:977)
at org.eclipse.core.launcher.Main.main(Main.java:952)",org.eclipse.jdt.internal.compiler.codegen.Label
FILE,eclipse-3.1,300054,2010-01-19T10:12:00.000-06:00,Unexpected 'Save Resource' dialog appears when copying changes from right to left,"public class Bug {
	void bar() {
		System.out.println();
	}
}
  System.out.println();
R3.5, R3.5.x and I20100112-0800.
start with new workspace
paste into Package explorer
public class Bug {
void bar() {
System.out.println();
}
}
delete System.out.println() save System.out.println()
compare current state
change from Right change to button
==> 'Save Resource' dialog appears which is a major interruption of my workflow.
NOTE: step 6 is crucial: it only happens when the compare editor is focused on a method.",org.eclipse.compare.internal.Utilities
FILE,eclipse-3.1,76472,2004-10-18T11:31:00.000-05:00,Duplicate entries in the constant pool for some methods,"public class X {
	public static void main(String[] args) {
		long[] tab = new long[] {};
		System.out.println(tab.clone());
		System.out.println(tab.clone());
	}
}

  clone()
public class X { public static void main(String[] args) { long[] tab = new long[] {};
System.out.println(tab.clone());
System.out.println(tab.clone());
}
}
Disassemble it and you can see that the call to clone() creates two entries in the constant pool.","org.eclipse.jdt.internal.compiler.ast.BreakStatement
org.eclipse.jdt.internal.compiler.flow.FlowContext
org.eclipse.jdt.internal.compiler.flow.LoopingFlowContext"
FILE,eclipse-3.1,76534,2004-10-18T22:57:00.000-05:00,Can't perform evaluations inside inner class with constructor_ parameters,"createViewer(...)
We currently disallow evaluations in inner classes that take parameters in the referenced constructor_.
see CheckBoxTreeViewer create CheckBoxTreeViewer in breakpointsview #ce 15198
Is there anything we can do to allow evaluations in these kinds of classes?",org.eclipse.jdt.internal.debug.eval.ast.engine.SourceBasedSourceGenerator
FILE,eclipse-3.1,76677,2004-10-20T13:18:00.000-05:00,Console Input incorrect,"public class ConsoleTest {
    public static void main(String[] args) {
        try {
	        byte[] b = new byte[100];
	        for(;;) {
	            int read = System.in.read(b);
	            System.out.write(b, 0, read);
	        }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
public class ConsoleTest { public static void main(String[] args) { try { byte[] b = new byte[100];
for(;;) { int read = System.in.read(b);
System.out.write(b, 0, read);
}
} catch (Exception e) { e.printStackTrace();
}
}
}
enter in console
replace with x
console output is 13x instead of 1x3.","org.eclipse.ui.internal.console.IOConsolePartition
org.eclipse.ui.internal.console.IOConsolePartitioner"
FILE,eclipse-3.1,77234,2004-10-28T15:41:00.000-05:00,Detail formatter doesn't see inherited method,"getTypeName() 
  
  
  
 getTypeName()   JavaExceptionBreakpoint

getTypeName()
create detail formatter for type JavaExceptionBreakpoint
debug RemoveBreakpointAction delete RemoveBreakpointAction
select JavaExceptionBreakpoint
I get the following in the details pane:
Detail formatter error:
The method getTypeName() is undefined for the type JavaExceptionBreakpoint
getTypeName() is declared on JavaBreakpoint, which JavaExceptionBreakpoint 
extends.",org.eclipse.jdt.internal.debug.ui.JavaDetailFormattersManager
FILE,eclipse-3.1,77573,2004-11-03T04:43:00.000-06:00,[1.5][assist] Code assist does not propose static fields,"import static java.lang.Math
200411022000
Steps to reproduce:
write import static java.lang.Math. in cu
->No proposals","org.eclipse.jdt.internal.codeassist.CompletionEngine
org.eclipse.jdt.core.CompletionProposal
org.eclipse.jdt.core.CompletionRequestor"
FILE,eclipse-3.1,78201,2004-11-09T13:43:00.000-06:00,ClassCastException on Refresh in the AntView,"RefreshBuildFilesAction$1.run(IProgressMonitor)  
 ModalContext$ModalContextThread.run()
use context menu refresh action
Thread [ModalContext] (Suspended (exception ClassCastException))
RefreshBuildFilesAction$1.
run(IProgressMonitor) line: 77
ModalContext$ModalContextThread.run() line: 105",org.eclipse.ant.internal.ui.model.AntProjectNodeProxy
FILE,eclipse-3.1,78245,2004-11-09T18:34:00.000-06:00,Breakpoints in enums not correctly created.,"public enum TestEnum {
  a;
  public static void main(String[] args) {
    System.out.println();   // <- add a breakpoint here
  }
}
We are now able to add breakpoint in enum classes, but they're not correctly created, the associated type is wrong.
It's working OK if the enum is an inner type, but not if it's a top level type.
public enum TestEnum { a;
public static void main(String[] args) {
add breakpoint
}
}
The breakpoint is created, but displayed in the breakpoint view as 'null [line
XX] - main(String[])', and the program doesn't stop on the breakpoint.",org.eclipse.jdt.internal.debug.ui.actions.ValidBreakpointLocationLocator
FILE,eclipse-3.1,78315,2004-11-10T12:53:00.000-06:00,org.eclipes.team.ui plugin's startup code forces compare to be loaded,"Platform.getAdapterManager()  registerAdapters(factory, DiffNode.class);

   
 startup()
3.1 M3
I wrote tests that ensure plug-ins like Search and Compare aren't loaded when opening a Java editor.
The one for compare fails because org.eclipes.team.ui forces compare to be loaded in its start(BundleContext) method:
Platform.getAdapterManager().
registerAdapters(factory, DiffNode.class);
The direct reference to DiffNode causes the compare plug-in to be loaded even if it is not needed yet.
Test Case:
add startup() method to compareuiplugin
put breakpoint",org.eclipse.team.internal.ui.TeamUIPlugin
FILE,eclipse-3.1,78740,2004-11-16T10:57:00.000-06:00,IDOMType.getFlags() fails to represent interface flags correctly.,"becomeDetailed()   

package org.example.jdom;

import org.eclipse.core.runtime.IPlatformRunnable;
import org.eclipse.jdt.core.Flags;
import org.eclipse.jdt.core.jdom.DOMFactory;
import org.eclipse.jdt.core.jdom.IDOMCompilationUnit;
import org.eclipse.jdt.core.jdom.IDOMType;

public class Test implements IPlatformRunnable
{
  public Object run(Object object)
  {
    DOMFactory factory = new DOMFactory();
    IDOMCompilationUnit jCompilationUnit =
factory.createCompilationUnit(""package x; /** @model */ interface X  {}"", ""NAME"");
    IDOMType jType = (IDOMType)jCompilationUnit.getFirstChild().getNextNode(); 
    System.err.println("""" + ((jType.getFlags() & Flags.AccInterface) != 0));
    jType.getComment();
    System.err.println("""" + ((jType.getFlags() & Flags.AccInterface) != 0));
    return new Integer(0);
  }
}
call getComment on IDOMType change flags from encoding encode type
package org.example.jdom;
import org.eclipse.core.runtime.IPlatformRunnable;
import org.eclipse.jdt.core.Flags;
import org.eclipse.jdt.core.jdom.DOMFactory;
import org.eclipse.jdt.core.jdom.IDOMCompilationUnit;
import org.eclipse.jdt.core.jdom.IDOMType;
public class Test implements IPlatformRunnable
{ public Object run(Object object)
{
DOMFactory factory = new DOMFactory();
IDOMCompilationUnit jCompilationUnit = factory.createCompilationUnit(""package x; /** @model */ interface X  {}"", ""NAME"");
IDOMType jType = (IDOMType)jCompilationUnit.getFirstChild().
getNextNode();
System.err.println("""" + ((jType.getFlags() & Flags.AccInterface) !
= 0));
jType.getComment();
System.err.println("""" + ((jType.getFlags() & Flags.AccInterface) !
= 0));
return new Integer(0);
}
}
This bug completely breaks EMF's JavaEcoreBuilder, which is a blocking problem for our clients and hence we see this as a blocking problem.",org.eclipse.jdt.internal.compiler.DocumentElementParser
FILE,eclipse-3.1,79545,2004-11-26T05:58:00.000-06:00,Eclipse vs Sun JDK: different class files from the same source code,"public class CharIntTest
{
    /**
     * Eclipse value: "" ""
     * JDK value:     ""32""
     */
    public static String C = """" + +' ';
    /**
     * Eclipse value: ""32""
     * JDK value:     ""32""
     */
    public static String I = """" + +32;

    public static void main(String[] args)
    {
        System.out.println(C);
        System.out.println(I);
    }
}
compile source code
use sun JDK
The results are different.
The problem is connected with +' ': Eclipse treats it as ' ' but Sun JDK converts that space into 32 (+' ' => + (int) ' ' => +32 => 32) (which IMHO is correct).
PS.
I'm not sure if I picked the proper product (JDT)...
public class CharIntTest
{
/**
* Eclipse value: "" ""
* JDK value:     ""32""
*/ public static String C = """" + +' ';
/**
* Eclipse value: ""32""
* JDK value:     ""32""
*/ public static String I = """" + +32;
public static void main(String[] args)
{
System.out.println(C);
System.out.println(I);
}
}","org.eclipse.jdt.internal.compiler.impl.Constant
org.eclipse.jdt.internal.compiler.ast.EqualExpression"
FILE,eclipse-3.1,79957,2004-12-02T00:47:00.000-06:00,[Viewers] NPE changing input usingTableViewer and virtual,"Table table=new Table(shell,SWT.VIRTUAL);
TableViewer tv=new TableViewer(table);
tv.setContentProvider(new NetworkContentProvider());
tv.setLabelProvider(new NetworkLabelProvider());
tv.setInput(model);
 
 tv.setInput(model1);
I'm using the latest code for Table viewer with a private virtual manager class
in table viewer.
straight code
.
.
in a selection event handler for a button, i've to reset the model input
.
.
tv.setInput(model1);
.
.
Same code works fine without the SWT.VIRTUAL style bit,but when VIRTUAL is set
it throws a null pointer exception...
the stack trace was
java.lang.NullPointerException
at org.eclipse.jface.viewers.TableViewer$1.handleEvent(TableViewer.java:103)
at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:82)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:796)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:820)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:805)
at org.eclipse.swt.widgets.Table.wmNotifyChild(Table.java:3158)
at org.eclipse.swt.widgets.Control.WM_NOTIFY(Control.java:4040)
at org.eclipse.swt.widgets.Composite.WM_NOTIFY(Composite.java:722)
at org.eclipse.swt.widgets.Control.windowProc(Control.java:3025)
at org.eclipse.swt.widgets.Decorations.windowProc(Decorations.java:1400)
at org.eclipse.swt.widgets.Display.windowProc(Display.java:3349)
at org.eclipse.swt.internal.win32.OS.CallWindowProcW(Native Method)
at org.eclipse.swt.internal.win32.OS.CallWindowProc(OS.java:1403)
at org.eclipse.swt.widgets.Table.callWindowProc(Table.java:137)
at org.eclipse.swt.widgets.Control.windowProc(Control.java:3056)
at org.eclipse.swt.widgets.Display.windowProc(Display.java:3349)
at org.eclipse.swt.internal.win32.OS.DispatchMessageW(Native Method)
at org.eclipse.swt.internal.win32.OS.DispatchMessage(OS.java:1479)
at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2440)
at jface.viewers.TestJfaceVirtual.main(TestJfaceVirtual.java:49)",org.eclipse.jface.viewers.TableViewer
FILE,eclipse-3.1,81045,2004-12-14T20:13:00.000-06:00,ClassNotLoadedException when trying to change a value,"public class Test {
	static class Inner {
	}
	public static void main(String[] args) {
		Inner inner= null;
		System.out.println(1);  //  <- breakpoint here
	}
}
public class Test { static class Inner {
} public static void main(String[] args) {
Inner inner= null;
System.out.println(1);  //  <- breakpoint here
}
}
debug to breakpoint
A ClassNotLoadedException dialog appears.","org.eclipse.jdt.internal.debug.ui.actions.JavaVariableValueEditor
org.eclipse.jdt.internal.debug.eval.ast.engine.ASTEvaluationEngine
org.eclipse.jdt.internal.debug.core.model.JDILocalVariable"
FILE,eclipse-3.1,83205,2005-01-19T11:25:00.000-06:00,[osgi] shutdown did not complete,"System.exit()  
  
    
  
  
    
   
  
 
  
   Object.wait()  
   
  
  
  
  
  
  
  
 
 it()  
    
 
 
 
 
  
 Object.wait()  
   
  Object.wait()
shut down Eclipse export plug-in project as deployable feature be in progress
The console window stayed open, and responsive (could use console).
No further activity seemed to be happening.
Noticed that the plug-in export failed due to classloaders being closed for business (see below), which is expected.
Took a snapshot of the VM state (see below).
It seems System.exit() was not called.
The console and an event dispatching threads were left behind.
Typing ""exit"" on the console caused the VM to exit.
Unable to reproduce.
!
SESSION 2005-01-19 11:11:22.132 -----------------------------------------------
eclipse.buildId=I20050118-1015 java.version=1.5.0 java.vendor=Sun Microsystems Inc.
BootLoader constants: OS=win32, ARCH=x86, WS=win32, NL=en_CA
Framework arguments:  -keyring d:\temp\.
keyring -showlocation
Command-line arguments:  -os win32 -ws win32 -arch x86 -keyring d:\temp\.
keyring
-consolelog -console -debug -showlocation
!
ENTRY org.eclipse.pde.build 0 1 2005-01-19 11:11:22.132
!
MESSAGE Some inter-plug-in dependencies have not been satisfied.java.lang.NoClassDefFoundError: org/eclipse/pde/internal/core/ifeature/IFeatureM odel at org.eclipse.pde.internal.ui.wizards.exports.FeatureExportJob.deleteBu ildFiles(FeatureExportJob.java:298)
at org.eclipse.pde.internal.ui.wizards.exports.PluginExportJob.doExports
(PluginExportJob.java:50)
at org.eclipse.pde.internal.ui.wizards.exports.FeatureExportJob.run(Feat ureExportJob.java:95)
at org.eclipse.core.internal.jobs.Worker.run(Worker.java:66)
osgi>
osgi>
osgi> osgi>
osgi> Full thread dump Java HotSpot(TM) Client VM (1.5.0-b64 mixed mode):
""DestroyJavaVM"" prio=5 tid=0x000361e8 nid=0xc84 waiting on condition [0x00000000
.
.0x0007fae8]
""OSGi Console"" prio=5 tid=0x19bd0e28 nid=0xa28 in Object.wait() [0x19fcf000.
.0x1
9fcfb68]
at java.lang.Object.wait(Native Method)
- waiting on <0x042db588> (a java.lang.Object)
at org.eclipse.osgi.framework.internal.core.FrameworkConsole.console(Fra meworkConsole.java:265)
- locked <0x042db588> (a java.lang.Object)
at org.eclipse.osgi.framework.internal.core.FrameworkConsole.console(Fra meworkConsole.java:236)
at org.eclipse.osgi.framework.internal.core.FrameworkConsole.run(Framewo rkConsole.java:207)
at java.lang.Thread.run(Thread.java:595)
""Framework Event Dispatcher"" daemon prio=5 tid=0x199d55a0 nid=0x878 in Object.wa it() [0x19f8f000.
.0x19f8fbe8]
at java.lang.Object.wait(Native Method)
at java.lang.Object.wait(Object.java:474)
at org.eclipse.osgi.framework.eventmgr.EventThread.getNextEvent(EventThr ead.java:162)
- locked <0x042db620> (a org.eclipse.osgi.framework.eventmgr.EventThread
)
at org.eclipse.osgi.framework.eventmgr.EventThread.run(EventThread.java:
100)
""Low Memory Detector"" daemon prio=5 tid=0x00a912f8 nid=0xe60 runnable [0x0000000
0. .0x00000000]
""CompilerThread0"" daemon prio=10 tid=0x00a8fec8 nid=0x2b8 waiting on condition [
0x00000000.
.0x198cf6c0]
""Signal Dispatcher"" daemon prio=10 tid=0x00a8f250 nid=0xd4c waiting on condition
[0x00000000.
.0x00000000]
""Finalizer"" daemon prio=9 tid=0x00a86670 nid=0xd9c in Object.wait() [0x1984f000.
.0x1984fa68]
at java.lang.Object.wait(Native Method)
at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:116)
- locked <0x042db808> (a java.lang.ref.ReferenceQueue$Lock)
at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:132)
at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)
""Reference Handler"" daemon prio=10 tid=0x00a851e0 nid=0x478 in Object.wait() [0x
1980f000.
.0x1980fae8]
at java.lang.Object.wait(Native Method)
at java.lang.Object.wait(Object.java:474)
at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:116)
- locked <0x042db888> (a java.lang.ref.Reference$Lock)
""VM Thread"" prio=10 tid=0x00a82810 nid=0x750 runnable
""VM Periodic Task Thread"" prio=10 tid=0x00a924d0 nid=0xd04 waiting on condition",org.eclipse.core.launcher.Main
FILE,eclipse-3.1,83383,2005-01-21T06:39:00.000-06:00,IllegalArgumentException in Signature.getParameterCount,"String signature= ""foo(+Ljava.lang.Comparable;)"";
Signature.getParameterCount(signature);
I20050118 + unreleased code (not showing in any build)
String signature= ""foo(+Ljava.lang.Comparable;)"";
Signature.getParameterCount(signature);
Background:
I copied code from CompletionRequestorWrapper to work with the new
CompletionRequestor API.
When completing a METHOD_REF proposal for a method that has a parameter with an open type bound, getParameterPackages I get an IAE:
The reason is the Util.scanTypeSignature does not handle bounded types.
-----------
I get this:
!
ENTRY org.eclipse.ui 4 0 2005-01-21 12:11:32.109
!
MESSAGE The command for the key you pressed failed
!
STACK 0 java.lang.IllegalArgumentException
at org.eclipse.jdt.internal.core.util.Util.scanTypeSignature(Util.java:2115)
at org.eclipse.jdt.core.Signature.getParameterCount(Signature.java:944)
at org.eclipse.jdt.core.Signature.getParameterTypes(Signature.java:1060)
at
org.eclipse.jdt.internal.ui.text.java.ResultCollector.getParameterPackages(ResultCollector.java:732)
at
org.eclipse.jdt.internal.ui.text.java.ResultCollector.internalAcceptMethod(ResultCollector.java:254)
at
org.eclipse.jdt.internal.ui.text.java.ResultCollector.accept(ResultCollector.java:654)
at
org.eclipse.jdt.internal.codeassist.CompletionEngine.findLocalMethods(CompletionEngine.java:2816)
at
org.eclipse.jdt.internal.codeassist.CompletionEngine.findIntefacesMethods(CompletionEngine.java:2551)
at
org.eclipse.jdt.internal.codeassist.CompletionEngine.findMethods(CompletionEngine.java:3270)
at
org.eclipse.jdt.internal.codeassist.CompletionEngine.findFieldsAndMethods(CompletionEngine.java:1903)
at
org.eclipse.jdt.internal.codeassist.CompletionEngine.complete(CompletionEngine.java:627)
at
org.eclipse.jdt.internal.codeassist.CompletionEngine.complete(CompletionEngine.java:1205)
at org.eclipse.jdt.internal.core.Openable.codeComplete(Openable.java:119)
at
org.eclipse.jdt.internal.core.CompilationUnit.codeComplete(CompilationUnit.java:286)
at
org.eclipse.jdt.internal.core.CompilationUnit.codeComplete(CompilationUnit.java:279)
at
org.eclipse.jdt.internal.ui.text.java.JavaCompletionProcessor.internalComputeCompletionProposals(JavaCompletionProcessor.java:363)
at
org.eclipse.jdt.internal.ui.text.java.JavaCompletionProcessor.computeCompletionProposals(JavaCompletionProcessor.java:334)
at
org.eclipse.jface.text.contentassist.ContentAssistant.computeCompletionProposals(ContentAssistant.java:1470)
at
org.eclipse.jface.text.contentassist.CompletionProposalPopup.computeProposals(CompletionProposalPopup.java:250)
at
org.eclipse.jface.text.contentassist.CompletionProposalPopup.access$7(CompletionProposalPopup.java:247)
at
org.eclipse.jface.text.contentassist.CompletionProposalPopup$9.run(CompletionProposalPopup.java:961)
at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:69)
at
org.eclipse.jface.text.contentassist.CompletionProposalPopup.incrementalComplete(CompletionProposalPopup.java:956)
at
org.eclipse.jface.text.contentassist.ContentAssistant.showPossibleCompletions(ContentAssistant.java:1318)
at
org.eclipse.jdt.internal.ui.javaeditor.CompilationUnitEditor$AdaptedSourceViewer.doOperation(CompilationUnitEditor.java:180)
at org.eclipse.ui.texteditor.ContentAssistAction$1.run(ContentAssistAction.java:82)
at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:69)
at org.eclipse.ui.texteditor.ContentAssistAction.run(ContentAssistAction.java:80)
at org.eclipse.jface.action.Action.runWithEvent(Action.java:989)
at org.eclipse.ui.commands.ActionHandler.execute(ActionHandler.java:188)
at org.eclipse.ui.internal.commands.Command.execute(Command.java:130)
at
org.eclipse.ui.internal.keys.WorkbenchKeyboard.executeCommand(WorkbenchKeyboard.java:445)
at org.eclipse.ui.internal.keys.WorkbenchKeyboard.press(WorkbenchKeyboard.java:724)
at
org.eclipse.ui.internal.keys.WorkbenchKeyboard.processKeyEvent(WorkbenchKeyboard.java:767)
at
org.eclipse.ui.internal.keys.WorkbenchKeyboard.filterKeySequenceBindings(WorkbenchKeyboard.java:536)
at
org.eclipse.ui.internal.keys.WorkbenchKeyboard.access$2(WorkbenchKeyboard.java:479)
at
org.eclipse.ui.internal.keys.WorkbenchKeyboard$1.handleEvent(WorkbenchKeyboard.java:221)
at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:82)
at org.eclipse.swt.widgets.Display.filterEvent(Display.java:1086)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1001)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1026)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1011)
at org.eclipse.swt.widgets.Widget.sendKeyEvent(Widget.java:1038)
at org.eclipse.swt.widgets.Widget.gtk_key_press_event(Widget.java:602)
at org.eclipse.swt.widgets.Control.gtk_key_press_event(Control.java:1889)
at org.eclipse.swt.widgets.Composite.gtk_key_press_event(Composite.java:527)
at org.eclipse.swt.widgets.Widget.windowProc(Widget.java:1338)
at org.eclipse.swt.widgets.Display.windowProc(Display.java:3261)
at org.eclipse.swt.internal.gtk.OS.
_gtk_main_do_event(Native Method)
at org.eclipse.swt.internal.gtk.OS.gtk_main_do_event(OS.java:4642)
at org.eclipse.swt.widgets.Display.eventProc(Display.java:926)
at org.eclipse.swt.internal.gtk.OS.
_g_main_context_iteration(Native Method)
at org.eclipse.swt.internal.gtk.OS.g_main_context_iteration(OS.java:1104)
at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2415)
at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:1575)
at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1541)
at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:287)
at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:144)
at org.eclipse.ui.internal.ide.IDEApplication.run(IDEApplication.java:102)
at
org.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:220)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:274)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:129)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:585)
at org.eclipse.core.launcher.Main.basicRun(Main.java:255)
at org.eclipse.core.launcher.Main.run(Main.java:811)
at org.eclipse.core.launcher.Main.main(Main.java:795)
The command for the key you pressed failed",org.eclipse.jdt.internal.core.util.Util
FILE,eclipse-3.1,83489,2005-01-22T17:33:00.000-06:00,[select] Code select returns IType instead of ITypeParameter on method parameters types,"class Test<T> {
  void foo(T t) {}
}
Using HEAD.
consider following test case
class Test<T> { void foo(T t) {}
}
When I select ""T"" in method declaration, selection engine returns an IType
""Test"" instead of expected ITypeParameter ""T"".",org.eclipse.jdt.internal.codeassist.SelectionEngine
FILE,eclipse-3.1,84194,2005-02-01T18:05:00.000-06:00,[content assist] Code assist in import statements insert at the end,"import org.eclipse.core.runtime.*;
Build: I-20050201
open Java file contain import statements contain Java file
import org.eclipse.core.runtime.
*;
delete * from end try * from end
You will see that upon pressing Enter to select, the text gets inserted several lines down under all the import statements.
the cursor is now in a random position also.","org.eclipse.jdt.internal.ui.text.java.JavaTypeCompletionProposal
org.eclipse.jdt.internal.ui.text.java.ExperimentalResultCollector"
FILE,eclipse-3.1,84724,2005-02-08T13:41:00.000-06:00,[1.5][search] fails to find call sites for varargs constructor_s,"public class Test {
    public void foo() {
        Cell c= new Cell("""", """"); // calls Cell.Cell(String...)
    }
}
 class Cell {
    public Cell(String... args) { }
}
The search engine fails to find the call to the varargs constructor_ in the example below.
highlight name invoke references
> ""Workspace"" from the Java editor context menu; no occurrences will be found.
Bug manifests with integration build I2005-0202.
public class Test { public void foo() {
Cell c= new Cell("""", """"); // calls Cell.Cell(String...)
}
} class Cell { public Cell(String... args) { }
}",org.eclipse.jdt.internal.core.search.matching.ConstructorLocator
FILE,eclipse-3.1,84770,2005-02-09T06:46:00.000-06:00,Formatter fails in specific case (.class in code),"public class FormatterTest {
  void doTest(
      ) {
     System.out.println(""("" + 
         Object.class + "")"");
  }
}
 
 toString()
Steps to reproduce:
make new class in default package
-----BEGIN-----
public class FormatterTest {
void doTest(
) {
System.out.println(""("" +
Object.class + "")"");
}
}
-----END-----
2 Try to format it by Ctrl+Shift+F  - nothing happens
change Object.class to Object.class.toString()
format by ctrl + shift + f
It seems that formatter crashes, when it has some string operatation (like + ) 
after the keyword class",org.eclipse.jdt.internal.formatter.BinaryExpressionFragmentBuilder
FILE,eclipse-3.1,84944,2005-02-10T16:49:00.000-06:00,[1.5][builder] Parameterized return type is sometimes not visible.,"package parser;

public interface ValueParser<T> {
	T parse(final String string);
}
This is a very strange error because it is not always reproduceable.
define interface with parameterized return type
--------------------------
package parser;
public interface ValueParser<T> {
	T parse(final String string);
}
--------------------------
However the return type seems to be not visible for some of the implementations.
The strange thing about this behavior is that a ""clean project"" may clean the
error until next compile, sometimes the error did not occur in the different
implementation.
I tried to create a minimal persion project which could be attached in bugzilla
but it doesn't seem to show the bug.
The error was shown in line 21 of ""test/BooleanParserTest.
java"".","org.eclipse.jdt.internal.compiler.lookup.BinaryTypeBinding
org.eclipse.jdt.internal.compiler.lookup.ParameterizedTypeBinding
org.eclipse.jdt.internal.compiler.lookup.WildcardBinding"
FILE,eclipse-3.1,85344,2005-02-15T17:36:00.000-06:00,Error evaluating logical structure value for Map in Java 5.0,"public class Test {
  public static void main(String[] args) {
    Map<String, Integer> map= new HashMap<String, Integer>();
    System.out.println();     // <-- breakpoint here
  }
}

  entrySet()
public class Test { public static void main(String[] args) {
Map<String, Integer> map= new HashMap<String, Integer>();
}
}
I get ""Error: The method entrySet() is undefined for the type Map__"" when I expand map in the variables view.",org.eclipse.jdt.internal.debug.eval.ast.engine.BinaryBasedSourceGenerator
FILE,eclipse-3.1,85397,2005-02-16T08:20:00.000-06:00,[1.5][enum] erroneous strictfp keyword on enum type produces error on constructor_,"strictfp enum Natural {
	ONE, TWO;
}

 
 strictfp enum Natural {
	ONE, TWO;
	
	private Natural() {
	}
}
I20050215-2300 (M5 test pass)
have code
strictfp enum Natural {
ONE, TWO;
}
expected: strictfp is not allowed on the enum type actual: no error is reported
have code
strictfp enum Natural {
ONE, TWO;
private Natural() {
}
}
expected: the wrong modifier is reported with the type name 'Natural' actual: the error is shown for the constructor_","org.eclipse.jdt.internal.compiler.lookup.SyntheticMethodBinding
org.eclipse.jdt.internal.ui.typehierarchy.TypeHierarchyViewPart
org.eclipse.jdt.internal.compiler.lookup.MethodScope"
FILE,eclipse-3.1,85402,2005-02-16T08:50:00.000-06:00,[1.5][assist] NPE while trying to complete on empty annotation,"import e.Team;
   @Author(name={Team.DAVID, Team.JEROME})
    
  public class Test {
	@Author(name=Team.PHILIPPE) void foo() {}
	@Author int t;
  }
  
  import e.Team;
  public @interface Author {
	Team[] name() default Team.FREDERIC;
  }
  
  package e;
  public enum Team {
	PHILIPPE, DAVID, JEROME, FREDERIC;
  }

 
 ResultCollector.accept(CompletionProposal)
Using build 3.1 M5 candidate (I20040215-2300).
have following test case
Test.java:
import e.Team;
@Author(name={Team.DAVID, Team.JEROME})
@| // <-- Try to complete here: NPE
public class Test {
@Author(name=Team.PHILIPPE) void foo() {}
@Author int t;
}
Author.java:
import e.Team;
public @interface Author {
Team[] name() default Team.FREDERIC;
}
Team.java:
package e;
public enum Team {
PHILIPPE, DAVID, JEROME, FREDERIC;
}
If you try to complete at caret position, then you get an Error Excuting Command
dialog.
Debug shows that there's a NPE in ResultCollector.accept(CompletionProposal)
method due to name==null for CompletionProposal","org.eclipse.jdt.internal.codeassist.complete.CompletionOnAnnotationOfType
org.eclipse.jdt.internal.codeassist.CompletionEngine
org.eclipse.jdt.internal.codeassist.complete.CompletionParser"
FILE,eclipse-3.1,85672,2005-02-17T05:53:00.000-06:00,[projection] Unfolding a folded region with no line delimiter on the last line selects too much,"package folding;

class Test {
    
}
I20050215-2300 (m5 test pass)
have code
""package folding;
class Test {
}""  <-- no delimiter on last line
put caret brace region fold region
Note that there is a phantom line in the editor since we cannot fold that one away.
put caret on last line unfold type
expected: caret is right after the closing brace actual: everything from after the *opening* brace is selected
Not a regression - it is like this in 3.0",org.eclipse.jface.text.source.projection.ProjectionViewer
FILE,eclipse-3.1,85734,2005-02-17T12:28:00.000-06:00,Debug view flickers excessively,"Runtime.exec(...)
I20050217-0800, KDE 3.3.2, GTK+ 2.4.14, X.Org 6.8.0, Linux 2.6.10
The debug view flickers excessively when debugging.
set breakpoint on Runtime.exec(...) start debugging session on eclipse
I
wish I could show you the effect; it is most disturbing.
:)","org.eclipse.debug.internal.ui.views.RemoteTreeViewer
org.eclipse.debug.internal.ui.views.launch.LaunchViewer
org.eclipse.debug.internal.ui.views.launch.LaunchViewEventHandler
org.eclipse.debug.internal.ui.views.RemoteTreeContentManager"
FILE,eclipse-3.1,86000,2005-02-21T14:47:00.000-06:00,ImageLoader Save - produces invalid JPEG images,"package com.ibm.test.image;

import org.eclipse.swt.*;
import org.eclipse.swt.graphics.*;

public class ImageLoaderTest {
		
	public static void main(String[] args) {
		ImageLoader loader;
		String dir=""c:\\image-problems\\"";
		String files[]={
				""s34i3p04"",
				""s34n3p04"",
				""s35i3p04"",
				""s35n3p04"",
				""s36i3p04"",
				""s36n3p04"",
				""s37i3p04"",
				""s37n3p04"",
				""s38i3p04"",
				""s38n3p04"",
				""s39i3p04"",
				""s39n3p04""
		};
		
		try {
			for (int i=0; i<files.length; i++) {
			String filein  = dir+files[i]+"".png"";
			String fileout = dir+files[i]+"".jpg"";
			
			loader = new ImageLoader();
			loader.load(filein);
			loader.save(fileout,SWT.IMAGE_JPEG);
			}
		} catch (SWTException e) {
		  e.printStackTrace();
		}
	}
}
The ImageLoader Save function appears to be producing bad JPG images.
I have only verified this with JPEG output.
test as JPEG
Many files were tested and the majority 
 did produced the proper JPG images as expected.
The attached Zip file contains
 only those files that did not save correctly to JPEG.
package com.ibm.test.image;
import org.eclipse.swt.
*;
import org.eclipse.swt.graphics.
*;
public class ImageLoaderTest {
		
	public static void main(String[] args) {
		ImageLoader loader;
		String dir=""c:\\image-problems\\"";
		String files[]={
				""s34i3p04"",
				""s34n3p04"",
				""s35i3p04"",
				""s35n3p04"",
				""s36i3p04"",
				""s36n3p04"",
				""s37i3p04"",
				""s37n3p04"",
				""s38i3p04"",
				""s38n3p04"",
				""s39i3p04"",
				""s39n3p04""
		};
		
		try {
			for (int i=0; i<files.length; i++) {
			String filein  = dir+files[i]+"".
png"";
			String fileout = dir+files[i]+"".
jpg"";
			
			loader = new ImageLoader();
			loader.load(filein);
			loader.save(fileout,SWT.IMAGE_JPEG);
			}
		} catch (SWTException e) {
		  e.printStackTrace();
		}
	}
}","org.eclipse.ui.internal.WorkbenchIntroManager
org.eclipse.swt.internal.image.JPEGFileFormat"
FILE,eclipse-3.1,87171,2005-03-04T14:19:00.000-06:00,Find declaring node doesn't work for methods/fields using type parameters,"public class Inline<T> {
	void foo(T t) {
		System.out.println(t);
	}
}

 class Use {
	public static void main(String[] args) {
		Inline<String> i= null;
		i.foo(""Eclipse"");
	}
}

  i.foo(""Eclipse"");
 
 root.findDeclaringNode(methodBinding);
public class Inline<T> {
	void foo(T t) {
		System.out.println(t);
	}
}
class Use {
	public static void main(String[] args) {
		Inline<String> i= null;
		i.foo(""Eclipse"");
	}
}
take method binding of invocation foo
take root node represent whole CU
call root.findDeclaringNode(methodBinding)
observe: null is returned although the CU contains the corresponding declaration.
Please note that the same happens for fields using type parameters.","org.eclipse.jdt.core.dom.CompilationUnit
org.eclipse.jdt.core.dom.DefaultBindingResolver"
FILE,eclipse-3.1,87569,2005-03-09T16:41:00.000-06:00,Infinte loop obtaining image when switching to Debug Perspective,"class which implements java.io.Serializable
I20050308-1510
create Java project create class use add generated serial version ID quickfix Switch to Debug perspective
3XMTHREADINFO      ""main"" (TID:0x02A08A00, sys_thread_t:0x000356F4, state:CW,
native ID:0x000009F4) prio=6
4XESTACKTRACE          at java/lang/Throwable.printStackTrace(Throwable.java:241)
4XESTACKTRACE          at
org/eclipse/core/runtime/CoreException.printStackTrace(CoreException.java:94)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseLog.getStackTrace(EclipseLog.java:316)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseLog.writeStack(EclipseLog.java:372)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseLog.writeLog(EclipseLog.java:337)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseLog.log(EclipseLog.java:208)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/PlatformLogWriter.logging(PlatformLogWriter.java:35)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform$1.run(InternalPlatform.java:831)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform.run(InternalPlatform.java:1015)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform.log(InternalPlatform.java:834)
4XESTACKTRACE          at org/eclipse/core/internal/runtime/Log.log(Log.java:56)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DebugUIPlugin.log(DebugUIPlugin.java:497)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DebugUIPlugin.log(DebugUIPlugin.java:506)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImageKey(DefaultLabelProvider.java:133)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:57)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
...
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/DebugViewInterimLabelProvider.getImage(DebugViewInterimLabelProvider.java:62)
4XESTACKTRACE          at
org/eclipse/jface/viewers/DecoratingLabelProvider.getImage(DecoratingLabelProvider.java:82)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/RemoteTreeViewer.doUpdateItem(RemoteTreeViewer.java:448)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer$UpdateItemSafeRunnable.run(AbstractTreeViewer.java:86)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform.run(InternalPlatform.java:1015)
4XESTACKTRACE          at org/eclipse/core/runtime/Platform.run(Platform.java:757)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.doUpdateItem(AbstractTreeViewer.java:490)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer$UpdateItemSafeRunnable.run(StructuredViewer.java:352)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform.run(InternalPlatform.java:1015)
4XESTACKTRACE          at org/eclipse/core/runtime/Platform.run(Platform.java:757)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer.updateItem(StructuredViewer.java:1655)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.updateChildren(AbstractTreeViewer.java:1621)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.internalRefreshStruct(AbstractTreeViewer.java:1109)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.internalRefresh(AbstractTreeViewer.java:1086)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.internalRefresh(AbstractTreeViewer.java:1047)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.internalRefresh(AbstractTreeViewer.java:1034)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer$7.run(StructuredViewer.java:1172)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer.preservingSelection(StructuredViewer.java:1109)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer.refresh(StructuredViewer.java:1170)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/LaunchViewer.refresh(LaunchViewer.java:80)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer.refresh(StructuredViewer.java:1129)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/AbstractDebugEventHandler.refresh(AbstractDebugEventHandler.java:255)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/AbstractDebugEventHandler.viewBecomesVisible(AbstractDebugEventHandler.java:348)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/AbstractDebugEventHandlerView.becomesVisible(AbstractDebugEventHandlerView.java:69)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/LaunchView.becomesVisible(LaunchView.java:1061)
4XESTACKTRACE          at
org/eclipse/debug/ui/AbstractDebugView$DebugViewPartListener.partVisible(AbstractDebugView.java:162)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartListenerList2$7.run(PartListenerList2.java:168)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform.run(InternalPlatform.java:1015)
4XESTACKTRACE          at org/eclipse/core/runtime/Platform.run(Platform.java:757)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartListenerList2.fireEvent(PartListenerList2.java:54)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartListenerList2.firePartVisible(PartListenerList2.java:166)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage$1.propertyChange(WorkbenchPage.java:179)
4XESTACKTRACE          at
org/eclipse/ui/internal/LayoutPart.setVisible(LayoutPart.java:305)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartPane.setVisible(PartPane.java:331)
4XESTACKTRACE          at
org/eclipse/ui/internal/ViewPane.setVisible(ViewPane.java:614)
4XESTACKTRACE          at
org/eclipse/ui/internal/presentations/PresentablePart.setVisible(PresentablePart.java:126)
4XESTACKTRACE          at
org/eclipse/ui/internal/presentations/newapi/PresentablePartFolder.select(PresentablePartFolder.java:266)
4XESTACKTRACE          at
org/eclipse/ui/internal/presentations/newapi/LeftToRightTabOrder.select(LeftToRightTabOrder.java:65)
4XESTACKTRACE          at
org/eclipse/ui/internal/presentations/newapi/TabbedStackPresentation.selectPart(TabbedStackPresentation.java:391)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartStack.refreshPresentationSelection(PartStack.java:1051)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartStack.createControl(PartStack.java:536)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartStack.createControl(PartStack.java:473)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartSashContainer.createControl(PartSashContainer.java:485)
4XESTACKTRACE          at
org/eclipse/ui/internal/PerspectiveHelper.activate(PerspectiveHelper.java:230)
4XESTACKTRACE          at
org/eclipse/ui/internal/Perspective.onActivate(Perspective.java:773)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage.setPerspective(WorkbenchPage.java:2829)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage.busySetPerspective(WorkbenchPage.java:845)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage.access$10(WorkbenchPage.java:830)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage$13.run(WorkbenchPage.java:2980)
4XESTACKTRACE          at
org/eclipse/swt/custom/BusyIndicator.showWhile(BusyIndicator.java:69)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage.setPerspective(WorkbenchPage.java:2978)
4XESTACKTRACE          at
org/eclipse/ui/internal/PerspectiveBarContributionItem.select(PerspectiveBarContributionItem.java:109)
4XESTACKTRACE          at
org/eclipse/ui/internal/PerspectiveBarManager$1.widgetSelected(PerspectiveBarManager.java:145)
4XESTACKTRACE          at
org/eclipse/swt/widgets/TypedListener.handleEvent(TypedListener.java:89)
4XESTACKTRACE          at
org/eclipse/swt/widgets/EventTable.sendEvent(EventTable.java:82)
4XESTACKTRACE          at org/eclipse/swt/widgets/Widget.sendEvent(Widget.java:842)
4XESTACKTRACE          at
org/eclipse/swt/widgets/Display.runDeferredEvents(Display.java:2894)
4XESTACKTRACE          at
org/eclipse/swt/widgets/Display.readAndDispatch(Display.java:2527)
4XESTACKTRACE          at
org/eclipse/ui/internal/PerspectiveBarManager.handleChevron(PerspectiveBarManager.java:161)
4XESTACKTRACE          at
org/eclipse/ui/internal/PerspectiveSwitcher$9.widgetSelected(PerspectiveSwitcher.java:766)
4XESTACKTRACE          at
org/eclipse/swt/widgets/TypedListener.handleEvent(TypedListener.java:89)
4XESTACKTRACE          at
org/eclipse/swt/widgets/EventTable.sendEvent(EventTable.java:82)
4XESTACKTRACE          at org/eclipse/swt/widgets/Widget.sendEvent(Widget.java:842)
4XESTACKTRACE          at
org/eclipse/swt/widgets/Display.runDeferredEvents(Display.java:2894)
4XESTACKTRACE          at
org/eclipse/swt/widgets/Display.readAndDispatch(Display.java:2527)
4XESTACKTRACE          at
org/eclipse/ui/internal/Workbench.runEventLoop(Workbench.java:1514)
4XESTACKTRACE          at
org/eclipse/ui/internal/Workbench.runUI(Workbench.java:1478)
4XESTACKTRACE          at
org/eclipse/ui/internal/Workbench.createAndRunWorkbench(Workbench.java:297)
4XESTACKTRACE          at
org/eclipse/ui/PlatformUI.createAndRunWorkbench(PlatformUI.java:143)
4XESTACKTRACE          at
org/eclipse/ui/internal/ide/IDEApplication.run(IDEApplication.java:103)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/PlatformActivator$1.run(PlatformActivator.java:228)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseStarter.run(EclipseStarter.java:338)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseStarter.run(EclipseStarter.java:151)
4XESTACKTRACE          at sun/reflect/NativeMethodAccessorImpl.invoke0(Native
Method)
4XESTACKTRACE          at
sun/reflect/NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:85)
4XESTACKTRACE          at
sun/reflect/NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:58)
4XESTACKTRACE          at
sun/reflect/DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:60)
4XESTACKTRACE          at java/lang/reflect/Method.invoke(Method.java:391)
4XESTACKTRACE          at
org/eclipse/core/launcher/Main.invokeFramework(Main.java:268)
4XESTACKTRACE          at org/eclipse/core/launcher/Main.basicRun(Main.java:260)
4XESTACKTRACE          at org/eclipse/core/launcher/Main.run(Main.java:887)
4XESTACKTRACE          at org/eclipse/core/launcher/Main.main(Main.java:871)",org.eclipse.debug.internal.ui.DefaultLabelProvider
FILE,eclipse-3.1,87665,2005-03-10T11:38:00.000-06:00,Clicking on x on performance page opens details with no errors,"testOpenJavaEditor1()
http://fullmoon.rtp.raleigh.ibm.com/downloads/drops/M-3.0.2RC2-200502161722/performance/org.eclipse.jdt.text.php?
scroll down to performance.OpenJavaEditorStressTest#testOpenJavaEditor1()
Observe: red x for RHEL 3.0 Sun 1.4.2_06.
Looks like a bug regarding the handling of negative numbers.","org.eclipse.swt.printing.PrintDialog
org.eclipse.swt.widgets.MessageBox"
FILE,eclipse-3.1,89632,2005-03-30T13:10:00.000-06:00,Exception when trying to evaluate in Snippet Editor,"Collection<String> c = new ArrayList<String>();
        c.add(""a"");
        c.add(""b"");
        c.add(""c"");

        for (Iterator<String> i = c.iterator(); i.hasNext(); )
            if (i.next().length() == 4)
            {
                String x = i.next();
                System.out.println(x);
            }
        
        return c;

 
   
  run()
Collection<String> c = new ArrayList<String>();
c.add(""a"");
c.add(""b"");
c.add(""c"");
for (Iterator<String> i = c.iterator(); i.hasNext(); )
if (i.next().
length() == 4)
{
String x = i.next();
System.out.println(x);
} return c;
add testcase to snippet editor
do set imports include java.util.
resolve collection resolve iterator
Trying a ""Display"" or ""Inspect"" resulted in the following error in the console:
java.lang.VerifyError: arguments are not type compatible (class: CodeSnippet_2 method: run()V) at pc: 57
at java.lang.Class.verifyImpl(Native Method)
at java.lang.Class.verify(Class.java:254)
at java.lang.Class.initialize(Class.java:317)
at java.lang.Class.forNameImpl(Native Method)
at java.lang.Class.forName(Class.java:128)
at org.eclipse.jdt.internal.debug.ui.snippeteditor.ScrapbookMain1.eval
(ScrapbookMain1.java:20)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke
(NativeMethodAccessorImpl.java:46)
at sun.reflect.DelegatingMethodAccessorImpl.invoke
(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:611)
at org.eclipse.jdt.internal.debug.ui.snippeteditor.ScrapbookMain.evalLoop
(ScrapbookMain.java:54)
at org.eclipse.jdt.internal.debug.ui.snippeteditor.ScrapbookMain.main
(ScrapbookMain.java:35)",org.eclipse.jdt.internal.eval.CodeSnippetMessageSend
FILE,eclipse-3.1,90283,2005-04-05T08:56:00.000-05:00,[WorkbenchParts]IPartListener2#partInputChanged is not being sent,"partActivated(IWorkbenchPartReference ref)  
 ref.getId()  
 ref.getPart(true)  getSite()  
 ASTProvider.ActivationListener.isJavaEditor()
3.1 M6
We (ASTProvider) receive partActivated(IWorkbenchPartReference ref) where:
ref.getId() -> null ref.getPart(true).
getSite() -> correct id.
Test Case:
enable mark occurrences
enable search reuse editor
match in file
select first match
activate editor by clicking click on tab
==> occurrence marking not working
To see the null value you can put a breakpoint in
ASTProvider.ActivationListener.isJavaEditor().
Might be related to bug 89374.",org.eclipse.ui.texteditor.AbstractTextEditor
FILE,eclipse-3.1,90289,2005-04-05T09:17:00.000-05:00,>1 debug worker thread calling IStackFrame.getVariables(),"IStackFrame.getVariables()
M6 driver
If I add a Suspsend VM breakpoint on the call to IStackFrame.getVariables() in 
my StackFrame object, I am seeing it hit 2 or more times.
As a result the Variables view shows duplicates of my local variables.","org.eclipse.debug.internal.ui.views.variables.VariablesViewEventHandler
org.eclipse.debug.internal.ui.views.registers.RegistersView
org.eclipse.debug.internal.ui.views.registers.RegistersViewEventHandler
org.eclipse.debug.internal.ui.views.expression.ExpressionViewEventHandler"
FILE,eclipse-3.1,91098,2005-04-12T06:07:00.000-05:00,The Mark Occurrences feature does not mark all occurrences,"String a;
String[] b;
String[][] c;
String a;
String[] b;
String[][] c;
put cursor on String put cursor on string [ ]
All occurrences of String get highlighted.
put cursor on string [ ] [ ]
No occurrence of String is highlighted.
It
looks like there is a missing loop when removing square brackets ;o)
I use 3.1M6.
Best regards,
Cyril",org.eclipse.jdt.core.dom.ASTConverter
FILE,eclipse-3.1,91346,2005-04-13T16:43:00.000-05:00,available property reference not found for marking occurrences,"{buildDirectory}
<project name=""project"" default=""default"">
	<property name=""buildDirectory"" location=""C:\buildDirectory"" />
	<target name=""default"">
		<available property=""${buildDirectory}"" file=""available2.xml"" />
		<echo message=""${C:\buildDirectory2}""></echo>
	</target>
</project>
Cursor in property=""${buildDirectory}"" does not mark the property declaration 
occurrence",org.eclipse.ant.internal.ui.model.AntPropertyNode
FILE,eclipse-3.1,92451,2005-04-22T16:36:00.000-05:00,code assist failure: new+cast+arrays,"public class Test {
	public static void main(String[] args) {
		java.util.List elements = null;
		// code assist works on this line
		new Test(Test.toStrings((Test[])elements.toArray(new Test
[0])));
		//code assist fails on this line
	}
	public Test(Object object) {
	}
	public static Object toStrings(Test[] objects) {
		return null;
	}
}
I20050419
J2SE 5 (but also fails in JDK 1.4)
Code assist fails in the following (self-contained) class (see comments for line of error)
public class Test { public static void main(String[] args) { java.util.List elements = null;
// code assist works on this line new Test(Test.toStrings((Test[])elements.toArray(new Test
[0])));
//code assist fails on this line
} public Test(Object object) {
} public static Object toStrings(Test[] objects) { return null;
}
}",org.eclipse.jdt.internal.codeassist.complete.CompletionParser
FILE,eclipse-3.1,93119,2005-04-28T10:10:00.000-05:00,code assist: proposals for wildcard types,"package codeAssist;

import java.util.List ;

public class Extends {
	void m() {
		List <? |>
	}
}
I20050426-1700
have code
package codeAssist;
import java.util.List ;
public class Extends {
	void m() {
		List <?
|>
	}
}
> actual: the only proposed item is the CU's type (Extends)
> actual: dozens of type proposals are proposed (and two template proposals, but
that is not a jdt-core problem)
< expected: only 'extends' is proposed.",org.eclipse.jdt.internal.codeassist.complete.CompletionParser
FILE,eclipse-3.1,93249,2005-04-29T05:49:00.000-05:00,Code assist doesn't propose full method stub,"IRunnableWithProgress runnable= new IRunnableWithProgress() {
};

  
  
 public void run(org.eclipse.core.runtime.IProgressMonitor monitor) throws
InvocationTargetException, InterruptedException
take revision of BuildPathAction
add following in run
IRunnableWithProgress runnable= new IRunnableWithProgress() {
};
observe: only the following method signature gets inserted.
No method body.
Additionally IProgressMonitor is fully qualified.
public void run(org.eclipse.core.runtime.IProgressMonitor monitor) throws
InvocationTargetException, InterruptedException","org.eclipse.jdt.internal.codeassist.CompletionEngine
org.eclipse.jdt.internal.ui.text.java.OverrideCompletionProposal"
FILE,eclipse-3.1,94201,2005-05-09T17:08:00.000-05:00,Applet Contextual Launch Action broken,"public class MyApplet extends Applet {
	private static final long serialVersionUID = 1L;

	public void paint(Graphics graphics) {
		graphics.drawString(""Hello World"", 50, 100);
	}
}
public void paint(Graphics graphics) {
		graphics.drawString(""Hello World"", 50, 100);
	}
}
When run from the context Menu an error message is display ""No Applet Found""
Manually creating a launch config via the lcd works fine.",org.eclipse.jdt.internal.debug.ui.launcher.AppletLaunchConfigurationUtils
FILE,eclipse-3.1,94216,2005-05-09T20:04:00.000-05:00,Open type does not work for generic types,"interface IGeneric<T> {
}
 public class Generic<T> implements IGeneric<T> {
    public static void main(String[] args) {
        IGeneric<String> gen= new Generic<String>();
        System.out.println();  // <-- breakpoint here
    }
}
interface IGeneric<T> {
} public class Generic<T> implements IGeneric<T> { public static void main(String[] args) {
IGeneric<String> gen= new Generic<String>();
System.out.println();  // <-- breakpoint here
}
}
Try to do 'open declaring type' or 'open concrete type' for 'gen' at the breakpoint, nothing happens.","org.eclipse.jdt.internal.debug.ui.actions.OpenVariableDeclaredTypeAction
org.eclipse.jdt.internal.debug.ui.actions.OpenVariableConcreteTypeAction"
FILE,eclipse-3.1,94465,2005-05-10T14:33:00.000-05:00,Java Core Dump where modifying value in the Variables View.,"String [] elms= { ""abc"", ""cde"", ""xyz"" };
String [] elms= { ""abc"", ""cde"", ""xyz"" };
I have a string array.
expand array in variables expand first element
value in Change primitive Value dialog
4. Click ok and it will result in a java dump.
Got the following error in the console:
JVMDG217: Dump Handler is Processing Signal 11 - Please Wait.
JVMDG303: JVM Requesting Java core file
JVMDG304: Java core file written to D:\eclipse3.1\I20050509
\eclipse\workspace\YetAnotherProj\javacore.20050510.142923.2576.txt
JVMDG215: Dump Handler has Processed Exception Signal 11.
Runnign IBM JVM 1.4.2","org.eclipse.jdt.internal.debug.ui.JDIModelPresentation
org.eclipse.jdt.internal.debug.ui.actions.JavaObjectValueEditor
org.eclipse.jdt.internal.debug.ui.actions.ActionMessages"
FILE,eclipse-3.1,95096,2005-05-13T06:16:00.000-05:00,[5.0][content assist] Content assist popup disappears while completing the statically imported method name,"import static java.lang.Math
I20050513-0010
Steps to reproduce:
import static java.lang.Math.
-> Instead of constraining the proposals to all members with prefix a, the popup closes","org.eclipse.jdt.internal.ui.text.java.JavaMethodCompletionProposal
org.eclipse.jdt.internal.ui.text.java.LazyJavaCompletionProposal"
FILE,eclipse-3.1,95152,2005-05-13T12:14:00.000-05:00,[search] F3 can't find synthetic constructor_,"InputReadJob readJob = new InputReadJob(streamsProxy);
Build: I20050513-0010
add org.eclipse.debug.ui by clicking add org.eclipse.debug.ui to search path ( i.e. click add to java
search "" in plugins view
open type on processconsole
go to line
InputReadJob readJob = new InputReadJob(streamsProxy);
highlight InputReadJob constructor _ hit f3
-> It opens a new class file editor, positioned at the top of the file.
5) The outline view in this editor has the constructor_
InputReadJob(ProcessConsole, IStreamsProxy).
Clicking this entry in the outline view does not jump to the constructor_ in the editor.
The mapping of class file to source is not handling the synthetic addition of the enclosing class by the compiler.
This breaks any kind of navigation to the corresponding constructor_ in the source attachment.","org.eclipse.ant.internal.ui.views.AntViewDropAdapter
org.eclipse.ant.internal.ui.launchConfigurations.AntLaunchShortcut
org.eclipse.ant.internal.ui.AntUtil
org.eclipse.jdt.internal.core.search.matching.ConstructorLocator
org.eclipse.jdt.internal.core.search.indexing.BinaryIndexer
org.eclipse.jdt.internal.core.index.DiskIndex
org.eclipse.jdt.internal.core.search.matching.ConstructorPattern"
FILE,eclipse-3.1,96440,2005-05-24T11:11:00.000-05:00,Tables laying out 3 times when trying to determine sizes,"table.getClientArea()
20050522
See Bug 93611
When we attempt to layout a table we are scaling columns with
table.getClientArea().
width.
In M6 this returned the width of the table - post
M6 it is returning a much smaller value and making all of our columns very small
in the Table Layout.
put breakpoint in jface TableLayout class
4 You will see a client area size of about 81
5 Do the same in M6 - it will be about 320 or so.",org.eclipse.jface.preference.PreferencePage
FILE,eclipse-3.1,96489,2005-05-24T14:40:00.000-05:00,[Presentations] (regression) Standalone view without title has no border,"layout.addStandaloneView(BrowserApp.BROWSER_VIEW_ID, false,
IPageLayout.RIGHT, .25f, IPageLayout.ID_EDITOR_AREA);
build N20050523
change BrowserPerspectiveFactory have following instead_of regular addView layout.addStandaloneView ( BrowserApp.BROWSER_VIEW_ID
IPageLayout.RIGHT, .25f, IPageLayout.ID_EDITOR_AREA);
show history view
- the history view (a regular view) has a border, but the standalone view does not
This is a regression from 3.0.2.","org.eclipse.ui.presentations.WorkbenchPresentationFactory
org.eclipse.ui.internal.presentations.defaultpresentation.EmptyTabFolder"
FILE,eclipse-3.1,96820,2005-05-26T12:27:00.000-05:00,JME during Source lookup,"enable()
N20050526-0010
work in full source workspace
set breakpoint in contentassisthandler #ce 19774
After opening the Find/Replace dialog and enabling ""Regular Expressions"", I got a ""Source not found."" editor and the JME below.
Since I imported all projects as source, a do have a project org.eclipse.core.boot, but it is not a Java project.
Error 2005-05-26 17:50:36.347 Error logged from Debug Core:
Java Model Exception: Java Model Status [org.eclipse.core.boot does not exist] at
org.eclipse.jdt.internal.core.JavaElement.newNotPresentException(JavaElement.java:468)
at
org.eclipse.jdt.internal.core.JavaModelManager.getPerProjectInfoCheckExistence(JavaModelManager.java:1200)
at
org.eclipse.jdt.internal.core.JavaProject.getPerProjectInfo(JavaProject.java:1794)
at org.eclipse.jdt.internal.core.JavaProject.getRawClasspath(JavaProject.java:1851)
at org.eclipse.jdt.internal.core.JavaProject.getRawClasspath(JavaProject.java:1837)
at
org.eclipse.jdt.launching.sourcelookup.containers.JavaProjectSourceContainer.createSourceContainers(JavaProjectSourceContainer.java:92)
at
org.eclipse.debug.core.sourcelookup.containers.CompositeSourceContainer.getSourceContainers(CompositeSourceContainer.java:126)
at
org.eclipse.jdt.launching.sourcelookup.containers.JavaProjectSourceContainer.findSourceElements(JavaProjectSourceContainer.java:133)
at
org.eclipse.debug.core.sourcelookup.AbstractSourceLookupParticipant.findSourceElements(AbstractSourceLookupParticipant.java:60)
at
org.eclipse.debug.core.sourcelookup.AbstractSourceLookupDirector$SourceLookupQuery.run(AbstractSourceLookupDirector.java:126)
at
org.eclipse.core.internal.runtime.InternalPlatform.run(InternalPlatform.java:1038)
at org.eclipse.core.runtime.Platform.run(Platform.java:775)
at
org.eclipse.debug.core.sourcelookup.AbstractSourceLookupDirector.doSourceLookup(AbstractSourceLookupDirector.java:465)
at
org.eclipse.debug.core.sourcelookup.AbstractSourceLookupDirector.getSourceElement(AbstractSourceLookupDirector.java:715)
at
org.eclipse.debug.internal.ui.sourcelookup.SourceLookupFacility.lookup(SourceLookupFacility.java:138)
at org.eclipse.debug.ui.DebugUITools.lookupSource(DebugUITools.java:658)
at
org.eclipse.debug.internal.ui.views.launch.LaunchView$SourceLookupJob.run(LaunchView.java:176)
at org.eclipse.core.internal.jobs.Worker.run(Worker.java:67)",org.eclipse.jdt.internal.launching.JavaSourceLookupUtil
FILE,eclipse-3.1,97722,2005-05-31T16:41:00.000-05:00,Pref Page Ant/Runtime/Tasks/Add Task dialog problems,"@

Dialog
The dialog's error message is cropped at the bottom.
The space between Name and Location seems unneccessary.
The background color of the error message is different from the dialog
background -- is this intended?
@@
Dialog font used: Trebuchet MS, size 11",org.eclipse.ant.internal.ui.preferences.AddCustomDialog
FILE,eclipse-3.1,98147,2005-06-02T13:09:00.000-05:00,Variables View does not show all children if same instance is expanded twice,"package xy;
public class Try {
	String fName;
	int fID;
	
	public Try(String name, int id) {
		fName= name;
		fID= id;
	}
	
	public static void main(String[] args) {
		Try t= new Try(""Hello"", 5);
		callee(t, t);
	}
	
	static void callee(Try t1, Try t2) {
		boolean same= t1.equals(t2); //breakpoint here
	}
	
}
N20050602-0010
show fName show fID
- Expand t2 -> only child fID is shown
package xy;
public class Try {
String fName;
int fID;
public Try(String name, int id) { fName= name;
fID= id;
} public static void main(String[] args) {
Try t= new Try(""Hello"", 5);
callee(t, t);
} static void callee(Try t1, Try t2) { boolean same= t1.equals(t2); //breakpoint here
}
}",org.eclipse.debug.internal.ui.views.RemoteTreeViewer
FILE,eclipse-3.1,98621,2005-06-06T22:04:00.000-05:00,[refactoring] [rename] Rename Type hangs,"class I18L  
 public class I18N {

	protected static void loadMessages(Class clazz, String name) {
		...
	}
}

 
 public class Messages extends I18L {
  public static String unexpectedException;
  ...
  static {
    loadMessages(Messages.class, ""messages.properties"");
  }
}
rename class i18l to i18n
public class I18N {
protected static void loadMessages(Class clazz, String name) {
		...
	}
}
extend class in subclasses
public class Messages extends I18L {
  public static String unexpectedException;
  ...
  static {
    loadMessages(Messages.class, ""messages.properties"");
  }
}
click OK in dialog
click cancel after minutes
The only
noticeable effect was the Cancel button was disabled.
Clicking the window exit
box had no effect.
I didn't have a Java console window so couldn't get a thread
dump.
I finally killed Eclipse with the Task Manager (WinXP SP2).
When I restarted Eclipse, 7 of the references had been changed to I18N and 3 had
not.
Open Type (after re-indexing its database) still shows the non-existant
I18L type, though if you try to open it, the path cannot be found.","org.eclipse.core.internal.jobs.ImplicitJobs
org.eclipse.core.internal.jobs.ThreadJob"
FILE,eclipse-3.1,98740,2005-06-07T13:25:00.000-05:00,Container attempts to refresh children on project that is not open,"String folder = ""/temp"";//$NON-NLS-1$
String projName = ""project"";//$NON-NLS-1$ 
IProjectDescription description = ResourcesPlugin.getWorkspace
().loadProjectDescription(projPath);
IProject project = ResourcesPlugin.getWorkspace().getRoot().getProject
(description.getName());
project.create(description, new NullProgressMonitor());

  project.open()  
 The members()  
 if (info.isSet(ICoreConstants.M_CHILDREN_UNKNOWN))
			workspace.refreshManager.refresh(this);
take existing simple project on disk import project into workspace import project by performing create with code
String folder = ""/temp"";//$NON-NLS-1$
String projName = ""project"";//$NON-NLS-1$
IProjectDescription description = ResourcesPlugin.getWorkspace
().
loadProjectDescription(projPath);
IProject project = ResourcesPlugin.getWorkspace().
getRoot().
getProject
(description.getName());
project.create(description, new NullProgressMonitor());
not open project with project.open() API
This is the key to the issue.
create project by API create project by UI
A background refresh job has now been started for the closed project, but it never finishes and is stuck in an infinite loop.
I believe the offending code is in the class org.eclipse.core.internal.resources.Container.
The members() method is excuting if (info.isSet(ICoreConstants.M_CHILDREN_UNKNOWN))
workspace.refreshManager.refresh(this);
because the projects members are not known.
Both the AliasManager and the Java
Perspective are calling members on the IProject.
If you override this method in Project and do not refresh for closed projects, the problem goes away.
load existing Java projects by performing load existing Java projects on disk perform create
On the next UI gesture, we get refresh infinite loops, one for each closed project.
We want the projects in the workspace, so we create them but do not open them, as open is very expensive.
This worked fine in Eclipse 3.0.","org.eclipse.core.internal.resources.Container
org.eclipse.core.internal.resources.Resource"
FILE,eclipse-3.1,99355,2005-06-10T09:48:00.000-05:00,extract method trips up with generics and final variables,"package p;

class Container<T>
{
   private final T m_t;

   public Container(T t)
   {
      m_t = t;
   }

   T get()
   {
      return m_t;
   }
}

class GenericContainer
{
   private final Container<?> m_c;

   public GenericContainer(Container<?> c) 
   {
      m_c = c;
   }

   public Container<?> getC()
   {
      return m_c;
   }
}

public class A
{
   GenericContainer createContainer()
   {
      final Container<String> innerContainer = new Container<String>(""hello"");
      final Container<Container<String>> outerContainer = new
Container<Container<String>>(innerContainer);
      return new GenericContainer(outerContainer);
   }
   
   void method()
   {
      final GenericContainer createContainer = createContainer();
      @SuppressWarnings(""unchecked"")
      final Container<Container<String>> c = (Container<Container<String>>)
createContainer.getC();
      //extract method from here
      final Container<String> container = c.get();
      final String string = container.get();
      //to here
   }
}
 
 

package p;

class Container<T>
{
   private final T m_t;

   public Container(T t)
   {
      m_t = t;
   }

   T get()
   {
      return m_t;
   }
}

class GenericContainer
{
   private final Container<?> m_c;

   public GenericContainer(Container<?> c) 
   {
      m_c = c;
   }

   public Container<?> getC()
   {
      return m_c;
   }
}

public class A
{
   GenericContainer createContainer()
   {
      final Container<String> innerContainer = new Container<String>(""hello"");
      final Container<Container<String>> outerContainer = new
Container<Container<String>>(innerContainer);
      return new GenericContainer(outerContainer);
   }
   
   void method()
   {
      final GenericContainer createContainer = createContainer();
      @SuppressWarnings(""unchecked"")
      final Container<Container<String>> c = (Container<Container<String>>)
createContainer.getC();
      //extract method from here
      extractedMethod(c);
      //to here
   }

   private void extractedMethod(final final final Container<Container<String>> c)
   {
      final Container<String> container = c.get();
      final String string = container.get();
   }
}
extract method
you will see that the extracted method declares its paramater with too many final modifiers:
-------------------------------------
package p;
class Container<T>
{ private final T m_t;
public Container(T t)
{ m_t = t;
}
T get()
{ return m_t;
}
}
class GenericContainer
{ private final Container<?> m_c;
public GenericContainer(Container<?> c)
{ m_c = c;
}
public Container<?> getC()
{ return m_c;
}
}
public class A
{
GenericContainer createContainer()
{ final Container<String> innerContainer = new Container<String>(""hello"");
final Container<Container<String>> outerContainer = new
Container<Container<String>>(innerContainer);
return new GenericContainer(outerContainer);
} void method()
{ final GenericContainer createContainer = createContainer();
@SuppressWarnings(""unchecked"")
final Container<Container<String>> c = (Container<Container<String>>)
createContainer.getC();
//extract method from here final Container<String> container = c.get();
final String string = container.get();
//to here
}
}
----------------------------------------------- results in
-----------------------------------------------
package p;
class Container<T>
{ private final T m_t;
public Container(T t)
{ m_t = t;
}
T get()
{ return m_t;
}
}
class GenericContainer
{ private final Container<?> m_c;
public GenericContainer(Container<?> c)
{ m_c = c;
}
public Container<?> getC()
{ return m_c;
}
}
public class A
{
GenericContainer createContainer()
{ final Container<String> innerContainer = new Container<String>(""hello"");
final Container<Container<String>> outerContainer = new
Container<Container<String>>(innerContainer);
return new GenericContainer(outerContainer);
} void method()
{ final GenericContainer createContainer = createContainer();
@SuppressWarnings(""unchecked"")
final Container<Container<String>> c = (Container<Container<String>>)
createContainer.getC();
//extract method from here extractedMethod(c);
//to here
}
private void extractedMethod(final final final Container<Container<String>> c)
{ final Container<String> container = c.get();
final String string = container.get();
}
}
-----------------------------------------------------------
notice the 3 final modifiers in the extractedMethod signature.",org.eclipse.jdt.core.dom.ASTConverter
FILE,eclipse-3.1,99693,2005-06-13T11:29:00.000-05:00,Invalid stack frames during display,"private static void doGenerics() {
		List<Integer> list = new ArrayList<Integer>();
		for (int i = 0; i < 1000; i++) {
			int num = rand.nextInt(10000) + 1;
			list.add(num);
		}
		
		int max = 0;
//start eval
		for (Integer integer : list) { // BREAKPOINT HERE
			max = Math.max(max, integer);
		}
		System.out.println(max);
//end eval
	}
debug following method to breakpoint
private static void doGenerics() {
List<Integer> list = new ArrayList<Integer>();
for (int i = 0; i < 1000; i++) { int num = rand.nextInt(10000) + 1;
list.add(num);
} int max = 0;
//start eval for (Integer integer : list) { // BREAKPOINT HERE max = Math.max(max, integer);
}
System.out.println(max);
//end eval
}
eval eval comments end eval comments
Watching the Variables View I see a lot of invalid stack frames.
They are not destructive (and nothing is logged).
Can we be smarter about not requesting and/or cancelling requests when the current stack frame is not valid?","org.eclipse.debug.internal.ui.views.variables.VariablesViewEventHandler
org.eclipse.debug.internal.ui.views.expression.ExpressionViewEventHandler"
CLASS,openjpa-2.2.0,OPENJPA-2163,2012-03-27T15:56:55.000-05:00,Lifecycle event callback occurs more often than expect,"final EntityManager em = factory.createEntityManager();
final EntityManager em2 = factory.createEntityManager();
 
 MyLifecycleListener l1 = new MyLifecycleListener();
MyLifecycleListener l2 = new MyLifecycleListener();
 
 ((OpenJPAEntityManagerSPI)em).addLifecycleListener(l1, null);
((OpenJPAEntityManagerSPI)em2).addLifecycleListener(l2, null);
uncover in scenario create scenario from same EntityManagerFactory initialize instance with new instance
final EntityManager em = factory.createEntityManager();
final EntityManager em2 = factory.createEntityManager();
...
MyLifecycleListener l1 = new MyLifecycleListener();
MyLifecycleListener l2 = new MyLifecycleListener();
...
((OpenJPAEntityManagerSPI)em).
addLifecycleListener(l1, null);
((OpenJPAEntityManagerSPI)em2).
addLifecycleListener(l2, null);
When life cycle event occurs for a specific entity manager, all the listeners created under the emf are being invoked.","openjpa-kernel.src.main.java.org.apache.openjpa.conf.OpenJPAConfigurationImpl
openjpa-persistence-jdbc.src.test.java.org.apache.openjpa.persistence.validation.TestValidationMode"
CLASS,openjpa-2.2.0,OPENJPA-428,2007-11-01T12:39:40.000-05:00,"Bad error message regarding ""openjpa.Id""","@Id 
 @Id  @Id 
 @Id 
 @Entity
@Table(name=""TAX"", schema=""JPA_SC"")
public class Tax  {
	
	// Class variables  
	protected double taxamount;
 
	public Tax(){
		
	}
	
	public Tax(double taxamount){
		this.taxamount = taxamount;
	}
//plus getter and setter for taxamount

}
Hi all, this bug is to report a confusing and misplaced error message.
Problem is described below.
Feel free to request more info from me.
When running my project with OpenJPA, I get the following error message:
140  INFO   [http-0.0.0.0-8080-Processor23] openjpa.Runtime - Starting OpenJPA 1.0.0
380  INFO   [http-0.0.0.0-8080-Processor23] openjpa.jdbc.JDBC - Using dictionary class ""org.apache.openjpa.jdbc.sql.DB2Dictionary"".
20  WARN   [http-0.0.0.0-8080-Processor25] openjpa.Runtime - The property named ""openjpa.Id"" was not recognized and will be ignored, although the name closely matches a valid property called ""openjpa.Id"".
100  INFO   [http-0.0.0.0-8080-Processor25] openjpa.Runtime - Starting OpenJPA 1.0.0
300  INFO   [http-0.0.0.0-8080-Processor25] openjpa.jdbc.JDBC - Using dictionary class ""org.apache.openjpa.jdbc.sql.DB2Dictionary"".
As you can see, the two property names printed are the same, not different or similar.
I retyped all my @Id annotations to make sure there was no special character in one of them coming from copy&paste.
Furthermore, I was able to identify that the error message was being printed only when I removed the @Id annotation from one of my classes (all the other classes still have @Id).
protect double taxamount getter for taxamount setter for taxamount
}
Regards,
Vitor Rodrigues","openjpa-lib.src.main.java.org.apache.openjpa.lib.conf.Configurations
openjpa-lib.src.main.java.org.apache.openjpa.lib.conf.ConfigurationImpl"
METHOD,atunes-1.10.0,231,2008-10-04T18:31:26.000-05:00,Can't add image if repository was read by older app version,"public boolean isSupportsInternalImage()
How to reproduce:
read by older version
add image
Result:
Adding image not possible.
Problem:
public boolean isSupportsInternalImage() returns false as was never set to true (as not supported in old versions).",net.sourceforge.atunes.kernel.modules.repository.audio.AudioFile:supportsInternalPicture()
CLASS,solr-4.4.0,SOLR-5295,2013-10-02T00:09:02.000-05:00,The createshard collection API creates maxShardsPerNode number of replicas if replicationFactor is not specified,"{quote}
 
  
  
  
 {quote}
As reported by Brett Hoerner on solr-user:
http://www.mail-archive.com/solr-user@lucene.apache.org/msg89545.html
{quote}
It seems that changes in 4.5 collection configuration now require users to set a maxShardsPerNode (or it defaults to 1).
Maybe this was the case before, but with the new CREATESHARD API it seems a very restrictive.
create simple test collection on machines set maxShardsPerNode at collection creation time set machines at collection creation time
make shards
Everything is good.
Now I want a 4th shard, it seems impossible to create because the cluster
""knows"" I should only have 1 shard per node.
Yet my problem doesn't require more hardware, I just my new shard to exist on one of the existing servers.
create collection with shards set maxShardsPerNode
Everything is good.
Now I add shard4 and it immediately tries to add 1000 replicas of shard4...
{quote}",solr.core.src.java.org.apache.solr.cloud.OverseerCollectionProcessor
CLASS,solr-4.4.0,SOLR-5296,2013-10-02T00:20:01.000-05:00,Creating a collection with implicit router adds shard ranges to each shard,"{quote}
 {quote}
Creating a collection with implicit router adds shard ranges to each shard.
use Example a from SolrCloud wiki
http://localhost:8983/solr/admin/collections?action=CREATE&name=myimplicitcollection3&numShards=2&maxShardsPerNode=5&router.name=implicit&shards=s1,s2&replicationFactor=2
The following clusterstate is created:
{quote}
""myimplicitcollection3"":{
""shards"":{
""s1"":{
""range"":""80000000-ffffffff"",
""state"":""active"",
""replicas"":{
""core_node1"":{
""state"":""active"",
""base_url"":""http://192.168.1.5:8983/solr"",
""core"":""myimplicitcollection3_s1_replica2"",
""node_name"":""192.168.1.5:8983_solr""},
""core_node3"":{
""state"":""active"",
""base_url"":""http://192.168.1.5:7574/solr"",
""core"":""myimplicitcollection3_s1_replica1"",
""node_name"":""192.168.1.5:7574_solr"",
""leader"":""true""}}},
""s2"":{
""range"":""0-7fffffff"",
""state"":""active"",
""replicas"":{
""core_node2"":{
""state"":""active"",
""base_url"":""http://192.168.1.5:8983/solr"",
""core"":""myimplicitcollection3_s2_replica2"",
""node_name"":""192.168.1.5:8983_solr""},
""core_node4"":{
""state"":""active"",
""base_url"":""http://192.168.1.5:7574/solr"",
""core"":""myimplicitcollection3_s2_replica1"",
""node_name"":""192.168.1.5:7574_solr"",
""leader"":""true""}}}},
""maxShardsPerNode"":""5"",
""router"":{""name"":""implicit""},
""replicationFactor"":""2""}
{quote}
Note that the createshard API does the right thing.",solr.core.src.java.org.apache.solr.cloud.Overseer
FILE,AMQP,AMQP-190,2011-09-10T20:24:17.000-05:00,CachingConnectionFactory leaks channels when synchronized with a TransactionManager,"convertAndSend()
It seems that when I use RabbitTemplate, channelTransacted=true, to convertAndSend() a message to an exchange within the context of a synchronized TransactionManager (e.g. an active transaction on the current thread), the channel is never closed, hence new publishes will always get their ""own"", shiny, new channel (that is never closed or released to the channel pool) until Rabbit can't handle any more channels.
See Forum Reference for more info.
The problem is not observed on the consumer side (e.g. MessageListenerContainer).
Its observed on the publishing side, (e.g. RabbitTemplate).
It is observed both if I use the RabbitTemplate, natively... or if I use spring-integration and the <int-amqp:outbound-channel-adapter...> tag.
BTW, the observed ""channel leak"" goes away when I choose channelTransacted=false.
I will look to supply a simple recreate, if I can scrounge the time.","org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer
org.springframework.amqp.rabbit.core.RabbitTemplatePerformanceIntegrationTests
org.springframework.amqp.rabbit.connection.ConnectionFactoryUtils
org.springframework.amqp.rabbit.connection.RabbitResourceHolder"
FILE,AMQP,AMQP-502,2015-06-19T03:02:33.000-05:00,Fanout binding is not created due to missing routing key,"@RabbitListener(




      bindings = @QueueBinding(




          value = @Queue(




              autoDelete = ""true""




          ),




          exchange = @Exchange(




              type = ""fanout"",




              value = ""mytest.broadcast"",




              autoDelete = ""true""




          ),




          key = ""#""




      )




  )




  public void processBroadcast(String data) {




    int i = 0;




  }






 
  
  
  
     
 
     
 
  
  
  
  
  
   {}   
     
 
     
 
     
 
  
     
 
     
 
     
 
     
 
     
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   {}   
  
     
 
      
   {}
use spring-cloud-starter-bus-amqp reference spring-amqp 1.4.3 in terms reference spring-cloud-starter-bus-amqp in terms
declare rabbitlistener
@RabbitListener(
bindings = @QueueBinding(
value = @Queue(
autoDelete = ""true""
),
exchange = @Exchange(
type = ""fanout"",
value = ""mytest.broadcast"",
autoDelete = ""true""
),
key = ""#""
)
)
public void processBroadcast(String data) {
int i = 0;
}
I will get an error, that the binding can not be created.
If i try another exchange type, the binding works.
Edit: It also does not work if omit the key.
The following is the debug logout and the stacktrace:
11:53:20.977 DEBUG   org.springframework.amqp.rabbit.core.RabbitAdmin - Initializing declarations
11:53:20.980  INFO   org.springframework.amqp.rabbit.core.RabbitAdmin - Auto-declaring a non-durable or auto-delete Exchange (mytest.broadcast) durable:false, auto-delete:true.
It will be deleted by the broker if it shuts down, and can be redeclared by closing and reopening the connection.
11:53:20.980  INFO   org.springframework.amqp.rabbit.core.RabbitAdmin - Auto-declaring a non-durable, auto-delete, or exclusive Queue (5df237ec-13d4-4aab-a0ff-772707bd7d03) durable:false, auto-delete:false, exclusive:true.
It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost.
11:53:20.982 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Creating cached Rabbit Channel from AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:20.982 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Executing callback on RabbitMQ Channel: Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:20.982 DEBUG   org.springframework.amqp.rabbit.core.RabbitAdmin - declaring Exchange 'mytest.broadcast'
11:53:20.984 DEBUG   org.springframework.amqp.rabbit.core.RabbitAdmin - declaring Queue '5df237ec-13d4-4aab-a0ff-772707bd7d03'
11:53:20.989 DEBUG   org.springframework.amqp.rabbit.core.RabbitAdmin - Binding destination [5df237ec-13d4-4aab-a0ff-772707bd7d03 (QUEUE)] to exchange [mytest.broadcast] with routing key [null]
11:53:20.991 DEBUG    o.s.a.r.listener.SimpleMessageListenerContainer - Recovering consumer in 5000 ms.
11:53:20.991 DEBUG    o.s.a.r.listener.SimpleMessageListenerContainer - Starting Rabbit listener container.
11:53:20.992 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Starting consumer Consumer: tags=[{}], channel=null, acknowledgeMode=AUTO local queue size=0
11:53:20.998 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Started on queue '5df237ec-13d4-4aab-a0ff-772707bd7d03' with tag amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA: Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:20.998 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - ConsumeOK : Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:20.999 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:21.093  INFO             mytest.server.Server - Started Server in 16.957 seconds (JVM running for 18.151)
11:53:22.003 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:23.004 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:24.009 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:25.013 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:26.017 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:26.071  WARN    o.s.a.r.listener.SimpleMessageListenerContainer - Consumer raised exception, processing can restart if the connection factory supports it
org.springframework.amqp.UncategorizedAmqpException: java.lang.IllegalStateException: Invalid configuration: 'routingKey' must be non-null.
at org.springframework.amqp.rabbit.support.RabbitExceptionTranslator.convertRabbitAccessException(RabbitExceptionTranslator.java:66) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.RabbitAccessor.convertRabbitAccessException(RabbitAccessor.java:110) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitTemplate.doExecute(RabbitTemplate.java:1124) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:1101) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:1077) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitAdmin.initialize(RabbitAdmin.java:381) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitAdmin$11.onCreate(RabbitAdmin.java:323) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.CompositeConnectionListener.onCreate(CompositeConnectionListener.java:32) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.createConnection(CachingConnectionFactory.java:446) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.ConnectionFactoryUtils$1.createConnection(ConnectionFactoryUtils.java:80) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.ConnectionFactoryUtils.doGetTransactionalResourceHolder(ConnectionFactoryUtils.java:130) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.ConnectionFactoryUtils.getTransactionalResourceHolder(ConnectionFactoryUtils.java:67) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.start(BlockingQueueConsumer.java:451) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1107) ~[spring-rabbit-1.5.0.M1.jar:na]
at java.lang.Thread.run(Thread.java:745) [na:1.8.0_20-ea]
Caused by: java.lang.IllegalStateException: Invalid configuration: 'routingKey' must be non-null.
at com.rabbitmq.client.impl.AMQImpl$Queue$Bind.<init>(AMQImpl.java:1577) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.AMQP$Queue$Bind$Builder.build(AMQP.java:870) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueBind(ChannelN.java:918) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueBind(ChannelN.java:61) ~[amqp-client-3.5.1.jar:na]
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_20-ea]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_20-ea]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_20-ea]
at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_20-ea]
at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:633) ~[spring-rabbit-1.5.0.M1.jar:na]
at com.sun.proxy.$Proxy0.queueBind(Unknown Source) ~[na:na]
at org.springframework.amqp.rabbit.core.RabbitAdmin.declareBindings(RabbitAdmin.java:480) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitAdmin.access$300(RabbitAdmin.java:54) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitAdmin$12.doInRabbit(RabbitAdmin.java:386) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitTemplate.doExecute(RabbitTemplate.java:1118) ~[spring-rabbit-1.5.0.M1.jar:na]
... 12 common frames omitted
11:53:26.071  INFO    o.s.a.r.listener.SimpleMessageListenerContainer - Restarting Consumer: tags=[{}], channel=null, acknowledgeMode=AUTO local queue size=0
11:53:26.071 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Closing Rabbit Channel: null
11:53:26.072 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Executing callback on RabbitMQ Channel: Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:26.072 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Publishing message on exchange [errors], routingKey = [org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.WARN]
11:53:26.072 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Starting consumer Consumer: tags=[{}], channel=null, acknowledgeMode=AUTO local queue size=0
11:53:26.075 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Creating cached Rabbit Channel from AMQChannel(amqp://stinger@10.0.10.34:5672/,2)
11:53:26.077 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
11:53:26.079 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Detected closed channel on exception.
Re-initializing: null
11:53:26.080  WARN     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Failed to declare queue:493eb6d6-8340-44a8-b73f-ab93446407dc
11:53:26.081 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Executing callback on RabbitMQ Channel: Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:26.081 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Publishing message on exchange [errors], routingKey = [org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.WARN]
11:53:26.081  WARN     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Queue declaration failed; retries left=3
org.springframework.amqp.rabbit.listener.BlockingQueueConsumer$DeclarationException: Failed to declare queue(s):[493eb6d6-8340-44a8-b73f-ab93446407dc]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:554) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.start(BlockingQueueConsumer.java:465) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1107) [spring-rabbit-1.5.0.M1.jar:na]
at java.lang.Thread.run(Thread.java:745) [na:1.8.0_20-ea]
Caused by: java.io.IOException: null
at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:106) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:102) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:124) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:873) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:61) ~[amqp-client-3.5.1.jar:na]
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_20-ea]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_20-ea]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_20-ea]
at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_20-ea]
at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:633) ~[spring-rabbit-1.5.0.M1.jar:na]
at com.sun.proxy.$Proxy0.queueDeclarePassive(Unknown Source) ~[na:na]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:544) ~[spring-rabbit-1.5.0.M1.jar:na]
... 3 common frames omitted
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:67) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:33) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:348) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.privateRpc(AMQChannel.java:221) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:118) ~[amqp-client-3.5.1.jar:na]
... 12 common frames omitted
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
at com.rabbitmq.client.impl.ChannelN.asyncShutdown(ChannelN.java:478) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.processAsync(ChannelN.java:315) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.handleCompleteInboundCommand(AMQChannel.java:144) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.handleFrame(AMQChannel.java:91) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:552) ~[amqp-client-3.5.1.jar:na]
... 1 common frames omitted
11:53:26.081 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Executing callback on RabbitMQ Channel: Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:26.081 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Publishing message on exchange [errors], routingKey = [org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.WARN]
11:53:27.018 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:28.022 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:29.025 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:30.030 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:31.034 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:31.086 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
11:53:31.086 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Detected closed channel on exception.
Re-initializing: null
11:53:31.088  WARN     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Failed to declare queue:493eb6d6-8340-44a8-b73f-ab93446407dc
11:53:31.089 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Executing callback on RabbitMQ Channel: Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:31.089 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Publishing message on exchange [errors], routingKey = [org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.WARN]
11:53:31.089  WARN     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Queue declaration failed; retries left=2
org.springframework.amqp.rabbit.listener.BlockingQueueConsumer$DeclarationException: Failed to declare queue(s):[493eb6d6-8340-44a8-b73f-ab93446407dc]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:554) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.start(BlockingQueueConsumer.java:465) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1107) [spring-rabbit-1.5.0.M1.jar:na]
at java.lang.Thread.run(Thread.java:745) [na:1.8.0_20-ea]
Caused by: java.io.IOException: null
at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:106) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:102) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:124) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:873) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:61) ~[amqp-client-3.5.1.jar:na]
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_20-ea]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_20-ea]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_20-ea]
at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_20-ea]
at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:633) ~[spring-rabbit-1.5.0.M1.jar:na]
at com.sun.proxy.$Proxy0.queueDeclarePassive(Unknown Source) ~[na:na]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:544) ~[spring-rabbit-1.5.0.M1.jar:na]
... 3 common frames omitted
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:67) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:33) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:348) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.privateRpc(AMQChannel.java:221) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:118) ~[amqp-client-3.5.1.jar:na]
... 12 common frames omitted
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
at com.rabbitmq.client.impl.ChannelN.asyncShutdown(ChannelN.java:478) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.processAsync(ChannelN.java:315) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.handleCompleteInboundCommand(AMQChannel.java:144) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.handleFrame(AMQChannel.java:91) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:552) ~[amqp-client-3.5.1.jar:na]
... 1 common frames omitted","org.springframework.amqp.rabbit.annotation.EnableRabbitIntegrationTests
org.springframework.amqp.rabbit.annotation.RabbitListenerAnnotationBeanPostProcessor"
FILE,AMQP,AMQP-516,2015-08-06T01:25:34.000-05:00,"Setting autoDelete or exclusive to anything, including ""true"" in @Queue without a queue name results in them being disabled","@RabbitListener(bindings = @QueueBinding(




    value = @Queue(autoDelete = ""true"", exclusive = ""true""),




    exchange = @Exchange(value = ""myFanout"", type = ExchangeTypes.FANOUT, durable = ""true"")




))






   
 if (!StringUtils.hasText(queueName)) {




    queueName = UUID.randomUUID().toString();




    if (!StringUtils.hasText(bindingQueue.exclusive())) {




        exclusive = true;




    }




    if (!StringUtils.hasText(bindingQueue.autoDelete())) {




        autoDelete = true;




    }




}




else {




    exclusive = resolveExpressionAsBoolean(bindingQueue.exclusive());




    autoDelete = resolveExpressionAsBoolean(bindingQueue.autoDelete());




}






 
 String e = bindingQueue.exclusive();




if (!StringUtils.hasText(e) || resolveExpressionAsBoolean(e)) {




    exclusive = true




}
The following queue declaration will result in a queue being declared with auto delete and exclusive set to false:
@RabbitListener(bindings = @QueueBinding(
value = @Queue(autoDelete = ""true"", exclusive = ""true""),
exchange = @Exchange(value = ""myFanout"", type = ExchangeTypes.FANOUT, durable = ""true"")
))
due to the following code in RabbitListenerAnnotationBeanProcessor:
if (!
StringUtils.hasText(queueName)) {
queueName = UUID.randomUUID().
toString();
if (!
StringUtils.hasText(bindingQueue.exclusive())) {
exclusive = true;
}
if (!
StringUtils.hasText(bindingQueue.autoDelete())) {
autoDelete = true;
}
}
else {
exclusive = resolveExpressionAsBoolean(bindingQueue.exclusive());
autoDelete = resolveExpressionAsBoolean(bindingQueue.autoDelete());
}
Making them exclusive and auto delete by default when using a random name seems like a good idea, but it should probably be changed to something like:
String e = bindingQueue.exclusive();
if (!
StringUtils.hasText(e) || resolveExpressionAsBoolean(e)) {
exclusive = true
}","org.springframework.amqp.rabbit.annotation.EnableRabbitIntegrationTests
org.springframework.amqp.rabbit.annotation.RabbitListenerAnnotationBeanPostProcessor"
FILE,AMQP,AMQP-653,2016-10-08T02:53:08.000-05:00,RabbitMessagingTemplate doesn't take advantage of RabbitTemplate's registered converters,"@Bean




Jackson2JsonMessageConverter jackson2JsonMessageConverter() {




	return new Jackson2JsonMessageConverter();




}
use RabbitTemplate in Spring boot application register Spring AMQP message converter
@Bean
Jackson2JsonMessageConverter jackson2JsonMessageConverter() {
return new Jackson2JsonMessageConverter();
}
However, if you switch to RabbitMessagingTemplate, that bean no longer works, because RabbitMessagingTemplate doesn't offer to look up RabbitTemplate's converters, and instead relies on its own.
Looking inside Spring Boot, there doesn't appear to be any wiring that offers to hook up message converters either.","org.springframework.amqp.rabbit.core.RabbitMessagingTemplateTests
org.springframework.amqp.rabbit.core.RabbitMessagingTemplate"
FILE,AMQP,AMQP-656,2016-10-15T00:25:46.000-05:00,Unable to refer to the default exchange using @Argument within a @RabbitListener,"@Argument 
 @RabbitListener(bindings =




        @QueueBinding(




            value = @Queue(




                value = ""app.events.myEvent"",




                durable = ""true"",




                exclusive = ""false"",




                autoDelete = ""false"",




                arguments = {




                        @Argument(name=""x-dead-letter-exchange"", value = """"),




                        @Argument(name=""x-dead-letter-routing-key"", value=""app.dlq"")




                }),




            exchange = @Exchange(value=""amq.topic"", durable = ""true"", type = ""topic""),




            key=""event.app.myEvent.v1""




        ))






 
 @Bean




    public Queue appMyEventQueue() {




        return QueueBuilder.durable(""app.events.myEvent"")




            .withArgument(""x-dead-letter-exchange"", """")




            .withArgument(""x-dead-letter-routing-key"", deadLetterQueue().getName())




            .build();




    }
It seems you are unable to use @Argument annotations that use empty strings to refer to the default exchange.
configure queue use default exchange as part
@RabbitListener(bindings =
@QueueBinding(
value = @Queue(
value = ""app.events.myEvent"",
durable = ""true"",
exclusive = ""false"",
autoDelete = ""false"",
arguments = {
@Argument(name=""x-dead-letter-exchange"", value = """"),
@Argument(name=""x-dead-letter-routing-key"", value=""app.dlq"")
}),
exchange = @Exchange(value=""amq.topic"", durable = ""true"", type = ""topic""),
key=""event.app.myEvent.v1""
))
This fails though as spring seems to not send the empty string.
I tried being creative with using things like SPEL that would evaluate to an empty string, but same result.
If I use bean configs I am able to get the configuration I want using something like the following, the issue is just with the annotation based config.
@Bean
public Queue appMyEventQueue() {
return QueueBuilder.durable(""app.events.myEvent"")
.
withArgument(""x-dead-letter-exchange"", """")
.
withArgument(""x-dead-letter-routing-key"", deadLetterQueue().
getName())
.
build();
}","org.springframework.amqp.rabbit.annotation.EnableRabbitIntegrationTests
org.springframework.amqp.rabbit.annotation.RabbitListenerAnnotationBeanPostProcessor"
METHOD,commons-math-3-3.0,MATH-841,2012-08-05T04:27:07.000-05:00,gcd speed up,"public void testApache(){
        Random rng=new Random(0);
        long checksum=0;
        long start=System.nanoTime();
        checksum+=gcd(0,Integer.MAX_VALUE);
        checksum+=gcd(Integer.MAX_VALUE,0);
        checksum+=gcd(Integer.MAX_VALUE,rng.nextInt());
        for(int i=0;i<10000;i++) checksum+=gcd(rng.nextInt(),Integer.MAX_VALUE);
        checksum+=gcd(Integer.MAX_VALUE,Integer.MAX_VALUE);
        checksum+=gcd(Integer.MIN_VALUE,1<<30);
        checksum+=gcd(1<<30,1<<30);
        checksum+=gcd(3 * (1<<20),9 * (1<<15));
        for(int i=0;i<30000000;i++) checksum+=gcd(rng.nextInt(),rng.nextInt());
        long end=System.nanoTime();
        long tns=end-start;
        long tms=(tns+500000)/1000000;
        long ts=(tms+500)/1000;
        System.out.println(""exec time=""+ts+""s, (""+tms+""ms), checksum=""+checksum);
        assertEquals(9023314441L,checksum);
    }
The gcd(int,int) method of ArithmeticUtils seems 2 times slower than the naive approach using modulo operator.
The following test code runs in 11s with current version and in 6s with the patch.
public void testApache(){
Random rng=new Random(0);
long checksum=0;
long start=System.nanoTime();
checksum+=gcd(0,Integer.MAX_VALUE);
checksum+=gcd(Integer.MAX_VALUE,0);
checksum+=gcd(Integer.MAX_VALUE,rng.nextInt());
for(int i=0;i<10000;i++) checksum+=gcd(rng.nextInt(),Integer.MAX_VALUE);
checksum+=gcd(Integer.MAX_VALUE,Integer.MAX_VALUE);
checksum+=gcd(Integer.MIN_VALUE,1<<30);
checksum+=gcd(1<<30,1<<30);
checksum+=gcd(3 * (1<<20),9 * (1<<15));
for(int i=0;i<30000000;i++) checksum+=gcd(rng.nextInt(),rng.nextInt());
long end=System.nanoTime();
long tns=end-start;
long tms=(tns+500000)/1000000;
long ts=(tms+500)/1000;
System.out.println(""exec time=""+ts+""s, (""+tms+""ms), checksum=""+checksum);
assertEquals(9023314441L,checksum);
}","org.apache.commons.math3.util.ArithmeticUtils:gcd(int, int)"
FILE,DATACMNS,DATACMNS-68,2011-08-26T08:05:09.000-05:00,NullPointerException in AbstractPersistentProperty::getComponentType(),"class TestClassSet extends TreeSet<Object> { }









 class TestClassComplex {




    private String id;




    private TestClassSet testClassSet;









    public String getId() {




        return id;




    }









    public TestClassSet getTestClassSet() {




        return testClassSet;




    }









    public void setTestClassSet(TestClassSet testClassSet) {




        this.testClassSet = testClassSet;




    }




}






 
 List<TestClassSet> o = mongoTemplate.findAll(TestClassSet.class);






 
 List<TestClassComplex> o = mongoTemplate.findAll(TestClassComplex.class);
class TestClassSet extends TreeSet<Object> { }
class TestClassComplex {
private String id;
private TestClassSet testClassSet;
public String getId() {
return id;
}
public TestClassSet getTestClassSet() {
return testClassSet;
}
public void setTestClassSet(TestClassSet testClassSet) {
this.testClassSet = testClassSet;
}
}
List<TestClassSet> o = mongoTemplate.findAll(TestClassSet.class);
But this fails with the NPE below:
List<TestClassComplex> o = mongoTemplate.findAll(TestClassComplex.class);
java.lang.NullPointerException: null
at org.springframework.data.mapping.model.AbstractPersistentProperty.getComponentType(AbstractPersistentProperty.java:147) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.model.AbstractPersistentProperty.isComplexType(AbstractPersistentProperty.java:136) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.model.AbstractPersistentProperty.isEntity(AbstractPersistentProperty.java:143) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.context.AbstractMappingContext.getNestedTypeToAdd(AbstractMappingContext.java:316) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.context.AbstractMappingContext.access$100(AbstractMappingContext.java:65) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.context.AbstractMappingContext$1.doWith(AbstractMappingContext.java:267) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.util.ReflectionUtils.doWithFields(ReflectionUtils.java:513) ~[spring-core-3.0.5.RELEASE.jar:3.0.5.RELEASE]
at org.springframework.data.mapping.context.AbstractMappingContext.addPersistentEntity(AbstractMappingContext.java:244) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.context.AbstractMappingContext.getPersistentEntity(AbstractMappingContext.java:165) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.context.AbstractMappingContext.getPersistentEntity(AbstractMappingContext.java:140) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mapping.context.AbstractMappingContext.getPersistentEntity(AbstractMappingContext.java:65) ~[spring-data-commons-core-1.2.0.BUILD-20110826.083456-44.jar:na]
at org.springframework.data.mongodb.core.MongoTemplate.determineCollectionName(MongoTemplate.java:1105) ~[spring-data-mongodb-1.0.0.BUILD-20110826.114729-388.jar:na]
at org.springframework.data.mongodb.core.MongoTemplate.findAll(MongoTemplate.java:786) ~[spring-data-mongodb-1.0.0.BUILD-20110826.114729-388.jar:na]
...",org.springframework.data.util.ClassTypeInformation
FILE,DATACMNS,DATACMNS-114,2011-12-19T03:21:41.000-06:00,Wrong custom implementation automatically detected,"AbstractRepositoryConfigDefinitionParser.detectCustomImplementation(...)  getImplementationClassName()
have repositories with similar name suffix
have custom interface have implementation end with similar name suffix
When automatically scanning the repositories, and their custom implementation, the wrong custom implementation is wired to our repository bean.
Resulting in the following exception:
Caused by: java.lang.IllegalArgumentException: No property find found for type class com.myproject.Contract
at org.springframework.data.repository.query.parser.Property.<init>(Property.java:76)
at org.springframework.data.repository.query.parser.Property.<init>(Property.java:97)
at org.springframework.data.repository.query.parser.Property.create(Property.java:312)
at org.springframework.data.repository.query.parser.Property.create(Property.java:326)
at org.springframework.data.repository.query.parser.Property.create(Property.java:326)
at org.springframework.data.repository.query.parser.Property.create(Property.java:326)
at org.springframework.data.repository.query.parser.Property.create(Property.java:292)
at org.springframework.data.repository.query.parser.Property.from(Property.java:251)
at org.springframework.data.repository.query.parser.Property.from(Property.java:232)
at org.springframework.data.repository.query.parser.Part.<init>(Part.java:48)
at org.springframework.data.repository.query.parser.PartTree$OrPart.<init>(PartTree.java:242)
at org.springframework.data.repository.query.parser.PartTree.buildTree(PartTree.java:101)
at org.springframework.data.repository.query.parser.PartTree.<init>(PartTree.java:77)
at org.springframework.data.jpa.repository.query.PartTreeJpaQuery.<init>(PartTreeJpaQuery.java:56)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:92)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateIfNotFoundQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:159)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$AbstractQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:71)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.<init>(RepositoryFactorySupport.java:303)
at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:157)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:120)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:39)
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:142)
... 67 more
have named ContractRepository with custom interface ContractRepositoryCustom have named ContractRepository with implementation ContractRepositoryImpl define inside same package
have repository in package have repository for entity type name AnotherContractRepository with custom interface AnotherContractRepositoryCustom name AnotherContractRepository with implementation AnotherContractRepositoryImpl
When starting the application context, the contractRepository bean is linked to our anotherContractRepositoryImpl rather than the contractRepositoryImpl.
This behavior seems to be operating system dependent, as it only occurs on our Linux CI server.
The cause of our problem can be found at AbstractRepositoryConfigDefinitionParser.detectCustomImplementation(...).",org.springframework.data.repository.config.AbstractRepositoryConfigDefinitionParser
FILE,DATACMNS,DATACMNS-157,2012-04-20T01:24:38.000-05:00,@Query in extending interface is not picked up correctly,"@Query 
 @NoRepositoryBean




public interface EntityRepository<T> extends JpaRepository<T, Long> {









	T findByDealer(Dealer dealer);




}









 public interface CarRepository extends EntityRepository<PersonalSiteVehicle> {









	@Override




	@Query(""select p from PersonalSiteVehicle p join p.detail d join d.enrichable e where e.dealer = ?1"")




	PersonalSiteVehicle findByDealer(Dealer dealer);




}






 
  @Query
define interface method in super repository interface implement in extending interface
This does not work.
@NoRepositoryBean
public interface EntityRepository<T> extends JpaRepository<T, Long> {
T findByDealer(Dealer dealer);
}
public interface CarRepository extends EntityRepository<PersonalSiteVehicle> {
@Override
@Query(""select p from PersonalSiteVehicle p join p.detail d join d.enrichable e where e.dealer = ?
1"")
PersonalSiteVehicle findByDealer(Dealer dealer);
}
Results in
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'carRepository': FactoryBean threw exception on object creation; nested exception is java.lang.IllegalArgumentException: Could not create query metamodel for method public abstract java.lang.Object nl.inmotiv.indi.repository.EntityRepository.findByDealer(nl.inmotiv.indi.domain.Dealer)!
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:149)
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:102)
at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1442)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:248)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:848)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:790)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:707)
at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:478)
... 32 more
Caused by: java.lang.IllegalArgumentException: Could not create query metamodel for method public abstract java.lang.Object nl.inmotiv.indi.repository.EntityRepository.findByDealer(nl.inmotiv.indi.domain.Dealer)!
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:95)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateIfNotFoundQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:164)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$AbstractQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:71)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.<init>(RepositoryFactorySupport.java:269)
at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:142)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:114)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:38)
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:142)
... 40 more
Caused by: java.lang.IllegalArgumentException: No property dealer found for type class nl.inmotiv.indi.domain.PersonalSiteVehicle
at org.springframework.data.mapping.PropertyPath.<init>(PropertyPath.java:73)
at org.springframework.data.mapping.PropertyPath.<init>(PropertyPath.java:92)
at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:319)
at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:301)
at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:265)
at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:239)
at org.springframework.data.repository.query.parser.Part.<init>(Part.java:70)
at org.springframework.data.repository.query.parser.PartTree$OrPart.<init>(PartTree.java:180)
at org.springframework.data.repository.query.parser.PartTree$Predicate.buildTree(PartTree.java:260)
at org.springframework.data.repository.query.parser.PartTree$Predicate.<init>(PartTree.java:240)
at org.springframework.data.repository.query.parser.PartTree.<init>(PartTree.java:71)
at org.springframework.data.jpa.repository.query.PartTreeJpaQuery.<init>(PartTreeJpaQuery.java:57)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:93)
It looks like Spring Data does not use the @Query annotation in the sub interface.","org.springframework.data.repository.core.support.DefaultRepositoryInformationUnitTests
org.springframework.data.repository.core.support.DefaultRepositoryInformation"
FILE,DATACMNS,DATACMNS-160,2012-04-21T08:47:35.000-05:00,Regression of Repository instances with only delete* methods,"public interface DeleteOnlyRepository<T, ID extends Serializable> extends Repository<T, ID>{









    public void delete(ID paramID);









    public void delete(T paramT);









    public void delete(Iterable<? extends T> paramIterable);









    public void deleteAll();









}
A repository which only defines delete methods is not created by the Spring Data code with the exception:
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'treeEntityDeleteRepository': FactoryBean threw exception on object creation; nested exception is java.lang.IllegalArgumentException: Could not create query metamodel for method public abstract void example.data.DeleteOnlyRepository.delete(java.lang.Object)!
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:149)
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:102)
at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1441)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:305)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:585)
at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:913)
at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:464)
at org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:139)
at org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:83)
at example.data.RepositoryTest.testExample(RepositoryTest.java:10)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:601)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
at org.junit.runners.BlockJUnit4ClassRunner.runNotIgnored(BlockJUnit4ClassRunner.java:79)
at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:71)
at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)
at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
Caused by: java.lang.IllegalArgumentException: Could not create query metamodel for method public abstract void example.data.DeleteOnlyRepository.delete(java.lang.Object)!
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:95)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateIfNotFoundQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:164)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$AbstractQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:71)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.<init>(RepositoryFactorySupport.java:269)
at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:142)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:114)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:38)
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:142)
... 33 more
Caused by: java.lang.IllegalArgumentException: No property delete found for type class example.data.TreeEntity
at org.springframework.data.mapping.PropertyPath.<init>(PropertyPath.java:73)
at org.springframework.data.mapping.PropertyPath.<init>(PropertyPath.java:92)
at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:319)
at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:301)
at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:265)
at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:239)
at org.springframework.data.repository.query.parser.Part.<init>(Part.java:70)
at org.springframework.data.repository.query.parser.PartTree$OrPart.<init>(PartTree.java:180)
at org.springframework.data.repository.query.parser.PartTree$Predicate.buildTree(PartTree.java:260)
at org.springframework.data.repository.query.parser.PartTree$Predicate.<init>(PartTree.java:240)
at org.springframework.data.repository.query.parser.PartTree.<init>(PartTree.java:68)
at org.springframework.data.jpa.repository.query.PartTreeJpaQuery.<init>(PartTreeJpaQuery.java:57)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:93)
... 40 more
caused by a repository which extends:
public interface DeleteOnlyRepository<T, ID extends Serializable> extends Repository<T, ID>{
public void delete(ID paramID);
public void delete(T paramT);
public void delete(Iterable<? extends T> paramIterable);
public void deleteAll();
}
This appears to be a regression following the upgrade to Spring Data Commons 1.3.0 RC1, as it's not present when using Spring Data JPA 1.1.0.
RC1, only when using the build snapshots.
I realise that the bug is most likely in the data commons package, but I wasn't sure how to reproduce it without using the JPA component, so I'm reporting here for the mo - hope that's OK.
reproduce issue
The reason for wanting such a repository is to prevent clients from performing CRU operations on a child object without the use of the parent, but I do need to offer the ability to delete it.","org.springframework.data.repository.core.support.DefaultRepositoryInformationUnitTests
org.springframework.data.repository.core.support.DefaultRepositoryInformation"
FILE,DATACMNS,DATACMNS-176,2012-05-21T11:47:05.000-05:00,StackOverflowError when inserted object is a CGLIB proxy,"@Scope(value=""session"", proxyMode = ScopedProxyMode.TARGET_CLASS)
persist object [ to MongoDB
M1)] that is in ""session"" scope and using a CGLIB proxy (ie: ""@Scope(value=""session"", proxyMode = ScopedProxyMode.TARGET_CLASS)"") I receive a StackOverflowError.
When removing the session scoping, it works correctly.java.lang.StackOverflowError
at java.util.HashMap$EntryIterator.<init>(HashMap.java:832)
at java.util.HashMap$EntryIterator.<init>(HashMap.java:832)
at java.util.HashMap.newEntryIterator(HashMap.java:846)
at java.util.HashMap$EntrySet.iterator(HashMap.java:950)
at java.util.AbstractMap.hashCode(AbstractMap.java:459)
at org.springframework.util.ObjectUtils.nullSafeHashCode(ObjectUtils.java:336)
at org.springframework.data.util.TypeDiscoverer.hashCode(TypeDiscoverer.java:365)
at org.springframework.data.util.ClassTypeInformation.hashCode(ClassTypeInformation.java:39)
at org.springframework.util.ObjectUtils.nullSafeHashCode(ObjectUtils.java:336)
at org.springframework.data.util.ParentTypeAwareTypeInformation.hashCode(ParentTypeAwareTypeInformation.java:79)
at org.springframework.util.ObjectUtils.nullSafeHashCode(ObjectUtils.java:336)
at org.springframework.data.util.ParentTypeAwareTypeInformation.hashCode(ParentTypeAwareTypeInformation.java:79)
at org.springframework.util.ObjectUtils.nullSafeHashCode(ObjectUtils.java:336)
at org.springframework.data.util.ParentTypeAwareTypeInformation.hashCode(ParentTypeAwareTypeInformation.java:79)
at org.springframework.util.ObjectUtils.nullSafeHashCode(ObjectUtils.java:336)
.... (Repeats)",org.springframework.data.util.ClassTypeInformation
FILE,DATACMNS,DATACMNS-233,2012-09-14T07:38:12.000-05:00,DomainClassConverter should gracefully return null for null sources or empty strings,"@javax.validation.constraints.NotNull  @javax.persistence.ManyToOne
I've noticed an important issue related to automatic web binding of String id to Domain class.
imagine use case have Order domain class have ManyToOne reference to customer have Order domain class to customer
When posting a new Order where Order.customer == """" then a converter exception is thrown:
Failed to convert property value of type java.lang.String to required type org.mycomp.domain.Customer for property customer; nested exception is org.springframework.core.convert.ConversionFailedException: Failed to convert from type java.lang.String to type @javax.
validation.constraints.NotNull @javax.
persistence.ManyToOne org.mycomp.domain.Customer for value '; nested exception is org.springframework.dao.InvalidDataAccessApiUsageException: The given id must not be null!
; nested exception is java.lang.IllegalArgumentException: The given id must not be null!
And note that for optional references this even might even cause a complete blocker?
<form:select path=""customer"">
<form:option value="""" label=""Select"" />
<form:options items=""${customers}"" itemValue=""id""></form:options>
</form:select>","org.springframework.data.repository.support.DomainClassConverterUnitTests
org.springframework.data.repository.support.DomainClassConverter"
FILE,DATACMNS,DATACMNS-257,2012-11-29T02:29:27.000-06:00,PropertyPath cannot deal with all uppercase fields,"@Id 
 class Foo{




  




  @Id




  private String UID;









  //code omitted




}
Cannot execute MongoOperations.findOne method if my model entity contains @Id field which name is uppercase, like UID.
class Foo{
@Id
private String UID;
//code omitted
}
Steps to reproduce:
create entity in example code snippet
call MongoOperations.findOne find by calling
3) at this step you will get an exception
java.lang.IllegalArgumentException: No property uID found on com.xxxxxxxxxxxxx.TemplateDefinitionObject!
at org.springframework.data.mapping.context.AbstractMappingContext.getPersistentPropertyPath(AbstractMappingContext.java:225)
at org.springframework.data.mongodb.core.convert.QueryMapper.getPath(QueryMapper.java:202)
at org.springframework.data.mongodb.core.convert.QueryMapper.determineKey(QueryMapper.java:221)
at org.springframework.data.mongodb.core.convert.QueryMapper.getMappedObject(QueryMapper.java:87)
at org.springframework.data.mongodb.core.MongoTemplate.doFindOne(MongoTemplate.java:1307)
at org.springframework.data.mongodb.core.MongoTemplate.findById(MongoTemplate.java:516)
at org.springframework.data.mongodb.core.MongoTemplate.findById(MongoTemplate.java:509)
at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.findOne(SimpleMongoRepository.java:99)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:616)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.executeMethodOn(RepositoryFactorySupport.java:334)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.invoke(RepositoryFactorySupport.java:319)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)
at $Proxy37.findOne(Unknown Source)
at com.xxxxxxxx.ShortTest.testFoo(ShortTest.java:65)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:616)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:74)
at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:83)
at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:72)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:231)
at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:174)
at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)","org.springframework.data.mapping.PropertyPath
org.springframework.data.mapping.PropertyPathUnitTests"
FILE,DATACMNS,DATACMNS-509,2014-05-08T08:39:02.000-05:00,NullableWrapper Breaks JSON Conversion,"{




    final Set<Pos> allPos = posService.findAll();




    return ImmutableSortedSet.copyOf(allPos);




}






 
 {""name: ""pos1""}  {""name: ""pos2""} 
  
     {""name: ""pos1""}  {""name: ""pos2""}
Since an upgrade to JPA 1.6 RC1, Spring MVC fails to properly address a NullableWrapper and this is returned, with the contents contained with the NullableWrapper.
have MVC method
public Callable<Set<Pos>> get(.....) {
final Set<Pos> allPos = posService.findAll();
return ImmutableSortedSet.copyOf(allPos);
}
With Spring Data JPA 1.5.
, I get on the wire a set of Pos's in JSON format, i.e.,
[{""name: ""pos1""}, {""name: ""pos2""}]
With Spring Data JPA 1.6 RC1, I now get the NullableWrapper with Contents:
[valueType: ""java.util.ArrayList"", value: [{""name: ""pos1""}, {""name: ""pos2""}]]","org.springframework.data.repository.core.support.DummyRepositoryFactory
org.springframework.data.repository.core.support.RepositoryFactorySupport
org.springframework.data.repository.core.support.RepositoryFactorySupportUnitTests"
FILE,DATACMNS,DATACMNS-511,2014-05-22T00:04:43.000-05:00,AbstractMappingContext.addPersistentEntity causes infinite loop,"public class User extends AbstractTenantUser<User, Role, Permission, Tenant> {




    ...




}




 public abstract class AbstractTenantUser<USER extends AbstractTenantUser<USER, ROLE, PERMISSION, TENANT>, ROLE extends AbstractRole<USER, PERMISSION>, PERMISSION extends AbstractPermission<USER>, TENANT extends AbstractTenant<USER>> extends AbstractUser<USER, ROLE, PERMISSION> implements TenantEntity<TENANT> {




    ...




}




 public abstract class AbstractUser<USER extends AbstractUser<USER, ROLE, PERMISSION>, ROLE extends AbstractRole<USER, PERMISSION>, PERMISSION extends AbstractPermission<USER>> extends AuditingDateBaseEntity<USER> {




    ...




}




 public abstract class AbstractPermission<USER extends AbstractUser<USER, ?, ?>> extends AuditingDateBaseEntity<USER> {




    ...




}




 public abstract class AuditingDateBaseEntity<USER extends AbstractUser<USER, ?, ?>> extends AbstractDateBaseEntity implements AuditingEntity<USER> {




    ...




}




 public abstract class AbstractDateBaseEntity extends AbstractBaseEntity implements DateEntity {




    ...




}




 public abstract class AbstractBaseEntity implements BaseEntity {




    ...




}
After updating from Codd SR2 to Dijkstra I could not run my tests.
After debugging the issue I found that the problem lies in AbstractMappingContext.addPersistentEntity.
This method is never called in Codd SR2 due to initialize not being triggered.
use few abstract MappedSuperclasses not work few abstract MappedSuperclasses have circular references have few abstract MappedSuperclasses
public class User extends AbstractTenantUser<User, Role, Permission, Tenant> {
...
}
public abstract class AbstractTenantUser<USER extends AbstractTenantUser<USER, ROLE, PERMISSION, TENANT>, ROLE extends AbstractRole<USER, PERMISSION>, PERMISSION extends AbstractPermission<USER>, TENANT extends AbstractTenant<USER>> extends AbstractUser<USER, ROLE, PERMISSION> implements TenantEntity<TENANT> {
...
}
public abstract class AbstractUser<USER extends AbstractUser<USER, ROLE, PERMISSION>, ROLE extends AbstractRole<USER, PERMISSION>, PERMISSION extends AbstractPermission<USER>> extends AuditingDateBaseEntity<USER> {
...
}
public abstract class AbstractPermission<USER extends AbstractUser<USER, ?
, ?
>> extends AuditingDateBaseEntity<USER> {
...
}
public abstract class AuditingDateBaseEntity<USER extends AbstractUser<USER, ?
, ?
>> extends AbstractDateBaseEntity implements AuditingEntity<USER> {
...
}
public abstract class AbstractDateBaseEntity extends AbstractBaseEntity implements DateEntity {
...
}
public abstract class AbstractBaseEntity implements BaseEntity {
...
}
I hope this gives enough insight into the problem and hopefully you can fix this soon.",org.springframework.data.util.TypeVariableTypeInformation
FILE,DATACMNS,DATACMNS-562,2014-08-19T01:25:20.000-05:00,MappingContext fails to resolve TreeMap as Map value type,"public class ClassC extends ClassA {




	private ClassB b;









	public ClassB getB() {




		return b;




	}









	public void setB(ClassB b) {




		this.b = b;




	}




}









 class ClassA {









	private String name;









	private ClassD dObject;









	public String getName() {




		return name;




	}









	public void setName(String name) {




		this.name = name;




	}









	public ClassD getdObject() {




		return dObject;




	}









	public void setdObject(ClassD dObject) {




		this.dObject = dObject;




	}




}









 class ClassB extends ClassA {




}









 class ClassD {









	private TreeMap<String, TreeMap<String, String>> map = new TreeMap<>();









	public TreeMap<String, TreeMap<String, String>> getMap() {




		return map;




	}









	public void setMap(TreeMap<String, TreeMap<String, String>> map) {




		this.map = map;




	}









}






 
 
 
 
 
 
 
 ClassC cObject = new ClassC();




cObject.setName(""Jon"");




try {




	mongoTemplate.save(cObject, ""c"");




} catch (Exception e) {




	e.printStackTrace();




}






 
 
     private transient EntrySet entrySet = null;
save to mongodb
ClassC.java
public class ClassC extends ClassA {
private ClassB b;
public ClassB getB() {
return b;
}
public void setB(ClassB b) {
this.b = b;
}
}
class ClassA {
private String name;
private ClassD dObject;
public String getName() {
return name;
}
public void setName(String name) {
this.name = name;
}
public ClassD getdObject() {
return dObject;
}
public void setdObject(ClassD dObject) {
this.dObject = dObject;
}
}
class ClassB extends ClassA {
}
class ClassD {
private TreeMap<String, TreeMap<String, String>> map = new TreeMap<>();
public TreeMap<String, TreeMap<String, String>> getMap() {
return map;
}
public void setMap(TreeMap<String, TreeMap<String, String>> map) {
this.map = map;
}
}
// handle this correctly somewhere
// @Autowired
// private MongoOperations	mongoTemplate;
ClassC cObject = new ClassC();
cObject.setName(""Jon"");
try {
mongoTemplate.save(cObject, ""c"");
} catch (Exception e) {
e.printStackTrace();
}
Exception caught as below:
java.lang.ArrayIndexOutOfBoundsException: 0
at org.springframework.data.util.ParameterizedTypeInformation.getComponentType(ParameterizedTypeInformation.java:147)
at org.springframework.data.util.TypeDiscoverer.getActualType(TypeDiscoverer.java:292)
at org.springframework.data.util.ParentTypeAwareTypeInformation.getActualType(ParentTypeAwareTypeInformation.java:29)
at org.springframework.data.mapping.model.AbstractPersistentProperty.getPersistentEntityType(AbstractPersistentProperty.java:125)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.createAndRegisterProperty(AbstractMappingContext.java:469)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.doWith(AbstractMappingContext.java:427)
at org.springframework.util.ReflectionUtils.doWithFields(ReflectionUtils.java:572)
at org.springframework.data.mapping.context.AbstractMappingContext.addPersistentEntity(AbstractMappingContext.java:295)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.createAndRegisterProperty(AbstractMappingContext.java:470)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.doWith(AbstractMappingContext.java:427)
at org.springframework.util.ReflectionUtils.doWithFields(ReflectionUtils.java:572)
at org.springframework.data.mapping.context.AbstractMappingContext.addPersistentEntity(AbstractMappingContext.java:295)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.createAndRegisterProperty(AbstractMappingContext.java:470)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.doWith(AbstractMappingContext.java:427)
at org.springframework.util.ReflectionUtils.doWithFields(ReflectionUtils.java:572)
at org.springframework.data.mapping.context.AbstractMappingContext.addPersistentEntity(AbstractMappingContext.java:295)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.createAndRegisterProperty(AbstractMappingContext.java:470)
at org.springframework.data.mapping.context.AbstractMappingContext$PersistentPropertyCreator.doWith(AbstractMappingContext.java:427)
at org.springframework.util.ReflectionUtils.doWithFields(ReflectionUtils.java:572)
at org.springframework.data.mapping.context.AbstractMappingContext.addPersistentEntity(AbstractMappingContext.java:295)
at org.springframework.data.mapping.context.AbstractMappingContext.getPersistentEntity(AbstractMappingContext.java:181)
at org.springframework.data.mapping.context.AbstractMappingContext.getPersistentEntity(AbstractMappingContext.java:141)
at org.springframework.data.mapping.context.AbstractMappingContext.getPersistentEntity(AbstractMappingContext.java:67)
at org.springframework.data.mongodb.core.MongoTemplate.getPersistentEntity(MongoTemplate.java:1831)
at org.springframework.data.mongodb.core.MongoTemplate.save(MongoTemplate.java:829)
I got the same issues on both spring-data-mongodb-1.5.0-RELEASE.jar and spring-data-mongodb-1.5.2-RELEASE.jar.
Below is some of my investigation, maybe helpful.
It seems something unsafe in spring-data-commons-1.8.0-RELEASE.jar and spring-data-commons-1.8.2-RELEASE.jar.
It seems that TreeMap has something different to HashMap, such as private transient EntrySet entrySet = null;, which causes returning empty Type array to emit ArrayIndexOutOfBoundsException.
May I know why the author treats Map as normal entity Type to traverse every field inside?
Normally Map and List only used as container.","org.springframework.data.mapping.model.AbstractPersistentPropertyUnitTests
org.springframework.data.mapping.model.AbstractPersistentProperty"
FILE,DATACMNS,DATACMNS-616,2014-12-17T02:25:54.000-06:00,AnnotationRevisionMetadata can't access private fields,"@Entity




@RevisionEntity(ExtendedRevisionListener.class)




@Table(name = ""revinfo"")




public class ExtendedRevision implements Serializable  
 @Id




	@GeneratedValue




	@Column(name = ""REV"")




	@RevisionNumber




	private Integer id;









	 @RevisionTimestamp




	@Temporal(TemporalType.TIMESTAMP)




	@Column(name = ""REVTSTMP"", nullable = false)




	private Date date;









	 @Column(nullable = false, length = 15)




	private String username;









	 public Integer getId() {




		return id;




	}









	 public Date getDate() {




		return date;




	}









	 public String getUsername() {




		return username;




	}









	 public void setUsername(String username) {




		this.username = username;




	}
use custom Envers revision class
@Entity
@RevisionEntity(ExtendedRevisionListener.class)
@Table(name = ""revinfo"")
public class ExtendedRevision implements Serializable {
@Id
@GeneratedValue
@Column(name = ""REV"")
@RevisionNumber
private Integer id;
@RevisionTimestamp
@Temporal(TemporalType.TIMESTAMP)
@Column(name = ""REVTSTMP"", nullable = false)
private Date date;
@Column(nullable = false, length = 15)
private String username;
public Integer getId() {
return id;
}
public Date getDate() {
return date;
}
public String getUsername() {
return username;
}
public void setUsername(String username) {
this.username = username;
}
triggers this error:
java.lang.IllegalStateException: Could not access method: Class org.springframework.util.ReflectionUtils can not access a member of class ExtendedRevision with modifiers ""private""
at org.springframework.util.ReflectionUtils.handleReflectionException(ReflectionUtils.java:262)
at org.springframework.util.ReflectionUtils.getField(ReflectionUtils.java:132)
at org.springframework.data.util.AnnotationDetectionFieldCallback.getValue(AnnotationDetectionFieldCallback.java:82)
at org.springframework.data.history.AnnotationRevisionMetadata.<init>(AnnotationRevisionMetadata.java:54)
I assume the fields have to be made accessible from the field callback.",org.springframework.data.util.AnnotationDetectionFieldCallback
FILE,DATACMNS,DATACMNS-683,2015-04-13T05:31:25.000-05:00,Enabling Spring Data web support breaks @ModelAttribute binding in Spring MVC,"package be.vdab.web;









import org.springframework.context.annotation.ComponentScan;




import org.springframework.context.annotation.Configuration;




import org.springframework.data.web.config.EnableSpringDataWebSupport;




import org.springframework.web.servlet.config.annotation.EnableWebMvc;




import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;









// enkele imports




@Configuration




@EnableWebMvc




@EnableSpringDataWebSupport




@ComponentScan




public class CreateControllerBeans extends WebMvcConfigurerAdapter {




}






  






package be.vdab.web;









import org.springframework.stereotype.Controller;




import org.springframework.web.bind.annotation.ModelAttribute;




import org.springframework.web.bind.annotation.RequestMapping;




import org.springframework.web.bind.annotation.RequestMethod;




import org.springframework.web.servlet.ModelAndView;









import be.vdab.entities.Person;









@Controller




@RequestMapping(value = ""/"")




public class PersonController {




	private static final String TOEVOEGEN_VIEW = ""/WEB-INF/JSP/index.jsp"";














	@RequestMapping(method=RequestMethod.GET)




	ModelAndView get() {




		return new ModelAndView(TOEVOEGEN_VIEW).addObject(new Person());




	}




	




	@RequestMapping(method = RequestMethod.POST)




	String post(@ModelAttribute Person person) {




	  if (person == null) {




		  throw new IllegalArgumentException(""person IS NULL"");




	  }




	  return ""redirect:/"";




	}



















}






 
    
 
 
 
    
 @EnableSpringDataWebSupport   
 @ModelAttribute
config class give following Java
package be.vdab.web;
import org.springframework.context.annotation.ComponentScan;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.web.config.EnableSpringDataWebSupport;
import org.springframework.web.servlet.config.annotation.EnableWebMvc;
import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;
// enkele imports
@Configuration
@EnableWebMvc
@EnableSpringDataWebSupport
@ComponentScan
public class CreateControllerBeans extends WebMvcConfigurerAdapter {
}
package be.vdab.web;
import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.ModelAttribute;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestMethod;
import org.springframework.web.servlet.ModelAndView;
import be.vdab.entities.Person;
@Controller
@RequestMapping(value = ""/"")
public class PersonController {
private static final String TOEVOEGEN_VIEW = ""/WEB-INF/JSP/index.jsp"";
@RequestMapping(method=RequestMethod.GET)
ModelAndView get() {
return new ModelAndView(TOEVOEGEN_VIEW).
addObject(new Person());
}
@RequestMapping(method = RequestMethod.POST)
String post(@ModelAttribute Person person) {
if (person == null) {
throw new IllegalArgumentException(""person IS NULL"");
}
return ""redirect:/"";
}
}
and following JSP
<%@page contentType=""text/html"" pageEncoding=""UTF-8"" session=""false""%>
<%@taglib prefix=""form"" uri=""http://www.springframework.org/tags/form"" %>
<!doctype html>
<html lang=""nl"">
<head>
<title>Add person</title>
</head>
<body>
<form:form action="""" method=""post"" commandName=""person"">
<form:label path=""name"">Name:</form:label>
<form:input path=""name"" autofocus=""true""/>
<input type=""submit"">
</form:form>
</body>
</html>
the method post in PersonController throws the InvalidArgumentException because the person parameter is null.
Observation 1:
This worked up to and including spring-data-jpa 1.7.2.
RELEASE
Observation 2:
The bug disappears when @EnableSpringDataWebSupport is put in comment in CreateControllerBeans.java
Observation 3:
The bug disappears when @ModelAttribute is put in comment in PersonController.java
You can clone a project that shows the bug from https://github.com/desmethans/springDataJpaError.git","org.springframework.data.repository.support.DomainClassConverterUnitTests
org.springframework.data.repository.support.DomainClassConverter"
FILE,DATACMNS,DATACMNS-695,2015-05-13T09:08:15.000-05:00,Potential NullPointerException in AbstractMappingContext,"public class External{




 ..




 private Optional<Internal> field = new Optional<Internal>();




 ..




}
We found the reported issue upgrading Spring Data MongoDB library from 1.3.5.
RELEASE to 1.5.5.
RELEASE.
query nested generic field qualified qualify with custom class
show for following snippet
public class External{
.
.
private Optional<Internal> field = new Optional<Internal>();
.
.
}
The call to mongoOperations throws a NullPointerException originating from AbstractMappingContext.
It is a Spring Data Commons class and we noticed that the issue starts from version 1.7.2.
RELEASE of this library, just after commit 02046da.","org.springframework.data.mapping.context.AbstractMappingContext
org.springframework.data.mapping.context.AbstractMappingContextUnitTests"
CLASS,derby-10.9.1.0,DERBY-3024,2007-08-23T05:24:31.000-05:00,Validation of shared plans hurts scalability,"GenericPreparedStatement.upToDate()   BaseActivation.checkStatementValidity()
To investigate whether there was anything in the SQL execution layer that prevented scaling on a multi-CPU machine, I wrote a multi-threaded test which continuously executed ""VALUES 1"" using a PreparedStatement. I ran the test on a machine with 8 CPUs and expected the throughput to be proportional to the number of concurrent clients up to 8 clients (the same as the number of CPUs). However, the throughput only had a small increase from 1 to 2 clients, and adding more clients did not increase the throughput. Looking at the test in a profiler, it seems like the threads are spending a lot of time waiting to enter synchronization blocks in GenericPreparedStatement.upToDate() and BaseActivation.checkStatementValidity() (both of which are synchronized on the a GenericPreparedStatement object).
change test append comment with unique thread id
That means the threads still did the same work, but each thread got its own plan (GenericPreparedStatement object) since the statement cache didn't regard the SQL text strings as identical.
When I made that change, the test scaled more or less perfectly up to 8 concurrent threads.","java.engine.org.apache.derby.impl.store.access.heap.HeapConglomerateFactory
java.engine.org.apache.derby.impl.store.raw.data.FileContainer
java.engine.org.apache.derby.impl.store.raw.data.RAFContainer
java.testing.org.apache.derbyTesting.functionTests.tests.lang.DBInJarTest
java.engine.org.apache.derby.impl.store.raw.data.TempRAFContainer
java.engine.org.apache.derby.impl.store.raw.data.InputStreamContainer
java.engine.org.apache.derby.impl.store.access.btree.index.B2IFactory"
CLASS,derby-10.9.1.0,DERBY-4647,2010-05-07T13:34:26.000-05:00,BaseTestCase.execJavaCmd() does not work with weme 6.2,"BaseTestCase.execJavaCmd()
Spawning a java process with BaseTestCase.execJavaCmd() does not work with weme 6.2, I think because the boot classpath does not get passed.
This issue came up in DERBY-4179.
After this issue is fixed, BootLockTest should be enabled for weme.
The error is actually
.
JVMJ9VM011W Unable to load jclfoun10_24: The specified module could not be foun
d.
JVMEXEX013E Internal VM error: Failed to create Java VM
JVMEXEX014I Run C:\cygwin\ibmsvn\ntsoftware\weme6.2\bin\j9.exe -help for usage
execJavaProcess does pick up the j9 executable but does not pass on the other settings.
invoke test
It probably has a lot of legacy system properties not needed, but I suppose execJavaCmd should just pass along all system properties, but I don't know how it would get the bootclasspath.
Perhaps -Dbootcp was a way to pass it on in the old harness.
c:/cygwin/ibmsvn/ntsoftware/weme6.2/bin/j9 -jcl:foun11 -DderbyTesting.serverho
st=localhost -DderbyTesting.clienthost=localhost -Demma.active= -Xbootclasspath/
a:c:/cygwin/ibmsvn/ntsoftware/weme6.2/lib/jdbc.
jar -Dbootcp=c:/cygwin/ibmsvn/nts
oftware/weme6.2/lib/jdbc.
jar junit.textui.TestRunner org.apache.derbyTesting.fun
ctionTests.tests.store.BootLockTest
Otherwise, currently I think the method is only used in replication and network server, but am not sure.","java.testing.org.apache.derbyTesting.functionTests.tests.store.BootLockMinion
java.testing.org.apache.derbyTesting.functionTests.tests.store.BootLockTest"
CLASS,derby-10.9.1.0,DERBY-4873,2010-10-28T18:45:13.000-05:00,NullPointerException in testBoundaries with ibm jvm 1.6,"testBoundaries(org.apache.derbyTesting.functionTests.tests.jdbcapi.InternationalConnectTest)
With the line skipping the testBoundaries fixture of the InternationalConnectTest commented out, I get the following stack when I run the test with ibm 1.6:
1 testBoundaries(org.apache.derbyTesting.functionTests.tests.jdbcapi.InternationalConnectTest)java.sql.SQLException: DERBY SQL error: SQLCODE: -1, SQLSTATE: XJ001, SQLERRMC: java.lang.NullPointerExceptionXJ001.U
at org.apache.derby.client.am.SQLExceptionFactory40.getSQLException(SQLExceptionFactory40.java:96)
at org.apache.derby.client.am.SqlException.getSQLException(SqlException.java:358)
at org.apache.derby.jdbc.ClientDriver.connect(ClientDriver.java:149)
at java.sql.DriverManager.getConnection(DriverManager.java:322)
at java.sql.DriverManager.getConnection(DriverManager.java:273)
at org.apache.derbyTesting.functionTests.tests.jdbcapi.InternationalConnectTest.testBoundaries(InternationalConnectTest.java:111)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:48)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:109)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)
at junit.extensions.TestSetup$1.protect(TestSetup.java:19)
at junit.extensions.TestSetup.run(TestSetup.java:23)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
Caused by: org.apache.derby.client.am.SqlException: DERBY SQL error: SQLCODE: -1, SQLSTATE: XJ001, SQLERRMC: java.lang.NullPointerExceptionXJ001.U
at org.apache.derby.client.am.Connection.completeSqlca(Connection.java:2117)
at org.apache.derby.client.net.NetConnectionReply.parseRdbAccessFailed(NetConnectionReply.java:541)
at org.apache.derby.client.net.NetConnectionReply.parseAccessRdbError(NetConnectionReply.java:434)
at org.apache.derby.client.net.NetConnectionReply.parseACCRDBreply(NetConnectionReply.java:297)
at org.apache.derby.client.net.NetConnectionReply.readAccessDatabase(NetConnectionReply.java:121)
at org.apache.derby.client.net.NetConnection.readSecurityCheckAndAccessRdb(NetConnection.java:846)
at org.apache.derby.client.net.NetConnection.flowSecurityCheckAndAccessRdb(NetConnection.java:769)
at org.apache.derby.client.net.NetConnection.flowUSRIDONLconnect(NetConnection.java:601)
at org.apache.derby.client.net.NetConnection.flowConnect(NetConnection.java:408)
at org.apache.derby.client.net.NetConnection.<init>(NetConnection.java:218)
at org.apache.derby.client.net.NetConnection40.<init>(NetConnection40.java:77)
at org.apache.derby.client.net.ClientJDBCObjectFactoryImpl40.newNetConnection(ClientJDBCObjectFactoryImpl40.java:269)
at org.apache.derby.jdbc.ClientDriver.connect(ClientDriver.java:140)
... 35 more
This is after the latest check in for DERBY-4836 (revision 1028035).
I'll attach derby.log.",java.engine.org.apache.derby.impl.store.raw.data.BaseDataFileFactory
CLASS,derby-10.9.1.0,DERBY-5407,2011-09-12T08:50:38.000-05:00,"When run across the network, dblook produces unusable DDL for VARCHAR FOR BIT DATA columns.","varchar( 20 )  
 
 
 VARCHAR ()
In private correspondence, Mani Afschar Yazdi reports that dblook omits the length specification for VARCHAR FOR BIT DATA columns when run across the network.
Embedded dblook runs fine.
bring up server
connect 'jdbc:derby://localhost:8246/memory:db;create=true';
create table t( a varchar( 20 ) for bit data );
run dblook across network
java -org.apache.derby.tools.dblook -d ""jdbc:derby://localhost:8246/memory:db""
This produces the following DDL for the table:
CREATE TABLE ""APP"".
""T"" (""A"" VARCHAR () FOR BIT DATA);
A similar experiment using an embedded database produces usable DDL which includes a length specification for the VARCHAR FOR BIT DATA column.","java.testing.org.apache.derbyTesting.functionTests.tests.lang.SystemCatalogTest
java.engine.org.apache.derby.catalog.types.BaseTypeIdImpl"
CLASS,derby-10.9.1.0,DERBY-5567,2012-01-05T07:35:04.000-06:00,AlterTableTest#testDropColumn fails: drop view cannot be performed due to dependency,"testDropColumn(org.apache.derbyTesting.functionTests.tests.lang.AlterTableTest)
Saw this when running suitesAll on 10.8.2.2:
1 testDropColumn(org.apache.derbyTesting.functionTests.tests.lang.AlterTableTest)java.sql.SQLException: Operation 'DROP VIEW' cannot be performed on object 'ATDC_VW_5A_1' because VIEW 'ATDC_VW_5A_2' is dependent on that object.
at org.apache.derby.client.am.SQLExceptionFactory40.getSQLException(Unknown Source)
at org.apache.derby.client.am.SqlException.getSQLException(Unknown Source)
at org.apache.derby.client.am.Statement.executeUpdate(Unknown Source)
at org.apache.derbyTesting.functionTests.tests.lang.AlterTableTest.testDropColumn(AlterTableTest.java:2465)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:113)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.extensions.TestSetup.run(TestSetup.java:25)
Caused by: org.apache.derby.client.am.SqlException: Operation 'DROP VIEW' cannot be performed on object 'ATDC_VW_5A_1' because VIEW 'ATDC_VW_5A_2' is dependent on that object.
at org.apache.derby.client.am.Statement.completeSqlca(Unknown Source)
at org.apache.derby.client.am.Statement.completeExecuteImmediate(Unknown Source)
at org.apache.derby.client.net.NetStatementReply.parseEXCSQLIMMreply(Unknown Source)
at org.apache.derby.client.net.NetStatementReply.readExecuteImmediate(Unknown Source)
at org.apache.derby.client.net.StatementReply.readExecuteImmediate(Unknown Source)
at org.apache.derby.client.net.NetStatement.readExecuteImmediate_(Unknown Source)
at org.apache.derby.client.am.Statement.readExecuteImmediate(Unknown Source)
at org.apache.derby.client.am.Statement.flowExecute(Unknown Source)
at org.apache.derby.client.am.Statement.executeUpdateX(Unknown Source)
... 55 more
Prior to this, though, I saw this on the console, but no error/failure.
Probably not related, I believe we have seen this before:
java.lang.Exception: DRDA_InvalidReplyTooShort.S:Invalid reply from network server: Insufficient data.
at org.apache.derby.impl.drda.NetworkServerControlImpl.consolePropertyMessageWork(Unknown Source)
at org.apache.derby.impl.drda.NetworkServerControlImpl.consolePropertyMessage(Unknown Source)
at org.apache.derby.impl.drda.NetworkServerControlImpl.fillReplyBuffer(Unknown Source)
at org.apache.derby.impl.drda.NetworkServerControlImpl.readResult(Unknown Source)
at org.apache.derby.impl.drda.NetworkServerControlImpl.pingWithNoOpen(Unknown Source)
at org.apache.derby.impl.drda.NetworkServerControlImpl.ping(Unknown Source)
at org.apache.derby.drda.NetworkServerControl.ping(Unknown Source)
at org.apache.derbyTesting.junit.NetworkServerTestSetup.pingForServerUp(NetworkServerTestSetup.java:567)
at org.apache.derbyTesting.functionTests.tests.derbynet.ServerPropertiesTest.canPingServer(ServerPropertiesTest.java:280)
at org.apache.derbyTesting.functionTests.tests.derbynet.ServerPropertiesTest.ttestSetPortPriority(ServerPropertiesTest.java:472)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:601)
at junit.framework.TestCase.runTest(TestCase.java:164)
at junit.framework.TestCase.runBare(TestCase.java:130)
at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:113)
at junit.framework.TestResult$1.protect(TestResult.java:106)
at junit.framework.TestResult.runProtected(TestResult.java:124)
at junit.framework.TestResult.run(TestResult.java:109)
at junit.framework.TestCase.run(TestCase.java:120)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.framework.TestResult.runProtected(TestResult.java:124)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at org.apache.derbyTesting.junit.BaseTestSetup.run(BaseTestSetup.java:57)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.framework.TestResult.runProtected(TestResult.java:124)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.framework.TestResult.runProtected(TestResult.java:124)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
at junit.extensions.TestSetup$1.protect(TestSetup.java:21)
at junit.framework.TestResult.runProtected(TestResult.java:124)
at junit.extensions.TestSetup.run(TestSetup.java:25)
at junit.framework.TestSuite.runTest(TestSuite.java:230)
at junit.framework.TestSuite.run(TestSuite.java:225)
at junit.framework.TestSuite.runTest(TestSuite.java:230)
at junit.framework.TestSuite.run(TestSuite.java:225)
at junit.framework.TestSuite.runTest(TestSuite.java:230)
at junit.framework.TestSuite.run(TestSuite.java:225)
at junit.framework.TestSuite.runTest(TestSuite.java:230)
at junit.framework.TestSuite.run(TestSuite.java:225)
at junit.textui.TestRunner.doRun(TestRunner.java:121)
at junit.textui.TestRunner.start(TestRunner.java:185)
at junit.textui.TestRunner.main(TestRunner.java:143)",java.engine.org.apache.derby.iapi.sql.dictionary.ViewDescriptor
CLASS,derby-10.9.1.0,DERBY-6053,2013-01-25T09:02:53.000-06:00,Client should use a prepared statement rather than regular statement for Connection.setTransactionIsolation,"client.am.Connection setTransactionIsolation()   setTransactionIsolation()   
 private Statement setTransactionIsolationStmt = null;
 
  
 createStatementX(java.sql.ResultSet.TYPE_FORWARD_ONLY,
                            java.sql.ResultSet.CONCUR_READ_ONLY,
                            holdability());
 
 private void setTransactionIsolationX(int level)
 
 setTransactionIsolationStmt.executeUpdate(
                ""SET CURRENT ISOLATION = "" + levelString);


 
   

import java.sql.*;
import java.net.*;
import java.io.*;
import org.apache.derby.drda.NetworkServerControl;

/**
 * Client template starts its own NetworkServer and runs some SQL against it.
 * The SQL or JDBC API calls can be modified to reproduce issues
 * 
 */public class SetTransactionIsolation {
    public static Statement s;
    
    public static void main(String[] args) throws Exception {
        try {
            // Load the driver. Not needed for network server.
            
            Class.forName(""org.apache.derby.jdbc.ClientDriver"");
            // Start Network Server
            startNetworkServer();
            // If connecting to a customer database. Change the URL
            Connection conn = DriverManager
                    .getConnection(""jdbc:derby://localhost:1527/wombat;create=true"");
            // clean up from a previous run
            s = conn.createStatement();
            try {
                s.executeUpdate(""DROP TABLE T"");
            } catch (SQLException se) {
                if (!se.getSQLState().equals(""42Y55""))
                    throw se;
            }

            for (int i = 0; i < 50000; i++) {
		conn.setTransactionIsolation(Connection.TRANSACTION_REPEATABLE_READ);
		conn.setTransactionIsolation(Connection.TRANSACTION_SERIALIZABLE);

	    }
            
            // rs.close();
            // ps.close();
            runtimeInfo();
            conn.close();
            // Shutdown the server
            shutdownServer();
        } catch (SQLException se) {
            while (se != null) {
                System.out.println(""SQLState="" + se.getSQLState()
                        + se.getMessage());
                se.printStackTrace();
                se = se.getNextException();
            }
        }
    }
    
    /**
     * starts the Network server
     * 
     */
    public static void startNetworkServer() throws SQLException {
        Exception failException = null;
        try {
            
            NetworkServerControl networkServer = new NetworkServerControl(
                    InetAddress.getByName(""localhost""), 1527);
            
            networkServer.start(new PrintWriter(System.out));
            
            // Wait for the network server to start
            boolean started = false;
            int retries = 10; // Max retries = max seconds to wait
            
            while (!started && retries > 0) {
                try {
                    // Sleep 1 second and then ping the network server
                    Thread.sleep(1000);
                    networkServer.ping();
                    
                    // If ping does not throw an exception the server has
                    // started
                    started = true;
                } catch (Exception e) {
                    retries--;
                    failException = e;
                }
                
            }
            
            // Check if we got a reply on ping
            if (!started) {
                throw failException;
            }
        } catch (Exception e) {
            SQLException se = new SQLException(""Error starting network  server"");
            se.initCause(failException);
            throw se;
        }
    }
    
    public static void shutdownServer() throws Exception {
        NetworkServerControl networkServer = new NetworkServerControl(
                InetAddress.getByName(""localhost""), 1527);
        networkServer.shutdown();
    }
    
    public static void runtimeInfo() throws Exception {
        NetworkServerControl networkServer = new NetworkServerControl(
                InetAddress.getByName(""localhost""), 1527);
        System.out.println(networkServer.getRuntimeInfo());
    }
    
}
o.a.d.client.am.Connection setTransactionIsolation() uses a Statement which  it builds up each time for setTransactionIsolation()  is called.
private Statement setTransactionIsolationStmt = null;
...
setTransactionIsolationStmt =
                    createStatementX(java.sql.ResultSet.TYPE_FORWARD_ONLY,
                            java.sql.ResultSet.CONCUR_READ_ONLY,
                            holdability());
....
private void setTransactionIsolationX(int level)
...
            setTransactionIsolationStmt.executeUpdate(
                ""SET CURRENT ISOLATION = "" + levelString);
show repeated calls to setTransactionIsolation
import java.sql.
*;
import java.net.
*;
import java.io.
*;
import org.apache.derby.drda.NetworkServerControl;
/**
* Client template starts its own NetworkServer and runs some SQL against it.
* The SQL or JDBC API calls can be modified to reproduce issues
*
*/public class SetTransactionIsolation {
public static Statement s;
public static void main(String[] args) throws Exception {
try {
// Load the driver.
Not needed for network server.
Class.forName(""org.apache.derby.jdbc.ClientDriver"");
// Start Network Server
startNetworkServer();
// If connecting to a customer database.
Change the URL
Connection conn = DriverManager
.
getConnection(""jdbc:derby://localhost:1527/wombat;create=true"");
// clean up from a previous run
s = conn.createStatement();
try {
s.executeUpdate(""DROP TABLE T"");
} catch (SQLException se) {
if (!
se.getSQLState().
equals(""42Y55""))
throw se;
}
for (int i = 0; i < 50000; i++) {
		conn.setTransactionIsolation(Connection.TRANSACTION_REPEATABLE_READ);
		conn.setTransactionIsolation(Connection.TRANSACTION_SERIALIZABLE);
}
// rs.close();
// ps.close();
runtimeInfo();
conn.close();
// Shutdown the server
shutdownServer();
} catch (SQLException se) {
while (se !
= null) {
System.out.println(""SQLState="" + se.getSQLState()
+ se.getMessage());
se.printStackTrace();
se = se.getNextException();
}
}
}
/**
* starts the Network server
*
*/
public static void startNetworkServer() throws SQLException {
Exception failException = null;
try {
NetworkServerControl networkServer = new NetworkServerControl(
InetAddress.getByName(""localhost""), 1527);
networkServer.start(new PrintWriter(System.out));
// Wait for the network server to start
boolean started = false;
int retries = 10; // Max retries = max seconds to wait
while (!
started && retries > 0) {
try {
// Sleep 1 second and then ping the network server
Thread.sleep(1000);
networkServer.ping();
// If ping does not throw an exception the server has
// started
started = true;
} catch (Exception e) {
retries--;
failException = e;
}
}
// Check if we got a reply on ping
if (!
started) {
throw failException;
}
} catch (Exception e) {
SQLException se = new SQLException(""Error starting network  server"");
se.initCause(failException);
throw se;
}
}
public static void shutdownServer() throws Exception {
NetworkServerControl networkServer = new NetworkServerControl(
InetAddress.getByName(""localhost""), 1527);
networkServer.shutdown();
}
public static void runtimeInfo() throws Exception {
NetworkServerControl networkServer = new NetworkServerControl(
InetAddress.getByName(""localhost""), 1527);
System.out.println(networkServer.getRuntimeInfo());
}
}",java.client.org.apache.derby.client.am.Connection
METHOD,time,21,2013-05-03T21:03:46.000-05:00,DateTimeFormat.parseInto sometimes miscalculates year (2.2),"public void testParseInto_monthDay_feb29_startOfYear() {
 DateTimeFormatter f = DateTimeFormat.forPattern(""M d"").withLocale(Locale.UK);
 MutableDateTime result = new MutableDateTime(2000, 1, 1, 0, 0, 0, 0, NEWYORK);
 assertEquals(4, f.parseInto(result, ""2 29"", 0));
 assertEquals(new MutableDateTime(2000, 2, 29, 0, 0, 0, 0, NEWYORK), result);
 }
There appears to be a bug in the fix to http://sourceforge.net/p/joda-time/bugs/148 (which I also reported).
The following code (which can be added to org.joda.time.format.TestDateTimeFormatter) breaks, because the input mutable date time's millis appear to be mishandled and the year for the parse is changed to 1999:
``` java
 public void testParseInto_monthDay_feb29_startOfYear() {
 DateTimeFormatter f = DateTimeFormat.forPattern(""M d"").
withLocale(Locale.UK);
 MutableDateTime result = new MutableDateTime(2000, 1, 1, 0, 0, 0, 0, NEWYORK);
 assertEquals(4, f.parseInto(result, ""2 29"", 0));
 assertEquals(new MutableDateTime(2000, 2, 29, 0, 0, 0, 0, NEWYORK), result);
 }
```","org.joda.time.format.DateTimeFormatter:parseInto(ReadWritableInstant, String, int)"
METHOD,time,28,2013-05-31T00:52:24.000-05:00,Questionable behaviour of GJChronology when dates pass 1BC,"Chronology chronology = GJChronology.getInstance();

LocalDate start = new LocalDate(2013, 5, 31, chronology);
LocalDate expectedEnd = new LocalDate(-1, 5, 31, chronology); // 1 BC
assertThat(start.minusYears(2013), is(equalTo(expectedEnd)));
assertThat(start.plus(Period.years(-2013)), is(equalTo(expectedEnd)));
expect following test
```
Chronology chronology = GJChronology.getInstance();
LocalDate start = new LocalDate(2013, 5, 31, chronology);
LocalDate expectedEnd = new LocalDate(-1, 5, 31, chronology); // 1 BC
assertThat(start.minusYears(2013), is(equalTo(expectedEnd)));
assertThat(start.plus(Period.years(-2013)), is(equalTo(expectedEnd)));
```
The error it gives is:
```
org.joda.time.IllegalFieldValueException: Value 0 for year is not supported
```
However, I never provided ""0"" for the year myself.","org.joda.time.chrono.GJChronology:getInstance(DateTimeZone, ReadableInstant, int)
org.joda.time.chrono.GJChronology:add(long, long)
org.joda.time.chrono.GJChronology:add(long, int)"
METHOD,time,79,2013-10-17T20:36:31.000-05:00,none standard PeriodType without year throws exception,"Period p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.forFields(new DurationFieldType[]{DurationFieldType.months(), DurationFieldType.weeks()})).normalizedStandard(PeriodType.forFields(new DurationFieldType[]{DurationFieldType.months(), DurationFieldType.weeks()}));
return p.getMonths();
 
    
      
   
 withYearsRemoved() throws the  
 Period p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.standard()).normalizedStandard(PeriodType.standard());
return p.getMonths();
 
 Period p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.standard().withYearsRemoved()).normalizedStandard(PeriodType.standard().withYearsRemoved());
return p.getMonths();
Hi.
get Period with following code get Period for months get Period for weeks
``` Java
Period p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.forFields(new DurationFieldType[]{DurationFieldType.months(), DurationFieldType.weeks()})).
normalizedStandard(PeriodType.forFields(new DurationFieldType[]{DurationFieldType.months(), DurationFieldType.weeks()}));
return p.getMonths();
```
This throws following exception:
```
10-17 14:35:50.999: E/AndroidRuntime(1350): java.lang.UnsupportedOperationException: Field is not supported
10-17 14:35:50.999: E/AndroidRuntime(1350): at org.joda.time.PeriodType.setIndexedField(PeriodType.java:690)
10-17 14:35:50.999: E/AndroidRuntime(1350): at org.joda.time.Period.withYears(Period.java:896) 10-17
14:35:50.999: E/AndroidRuntime(1350): at org.joda.time.Period.normalizedStandard(Period.java:1630)
```
Even removing the year component with .
withYearsRemoved() throws the same exception:
this works:
``` Java
Period p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.standard()).
normalizedStandard(PeriodType.standard());
return p.getMonths();
```
this fails:
``` Java
Period p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.standard().
withYearsRemoved()).
normalizedStandard(PeriodType.standard().
withYearsRemoved());
return p.getMonths();
```",org.joda.time.Period:normalizedStandard(PeriodType)
METHOD,time,88,2013-11-25T19:15:46.000-06:00,Constructing invalid Partials,"Partial a = new Partial(new DateTimeFieldType[] { year(), hourOfDay() }, new int[] { 1, 1});
Partial b = new Partial(year(), 1).with(hourOfDay(), 1);
assert(a == b);
 
 new Partial(new DateTimeFieldType[] { clockhourOfDay(), hourOfDay() }, new int[] { 1, 1}); // throws Types array must not contain duplicate
new Partial(clockhourOfDay(), 1).with(hourOfDay(), 1); // #<Partial [clockhourOfDay=1, hourOfDay=1]>
 
 new Partial(clockhourOfDay(), 1)  with(hourOfDay(), 1)  isEqual(new Partial(hourOfDay() ,1).with(clockhourOfDay(), 1)) // throws objects must have matching field types
Partials can be constructed by invoking a constructor `Partial(DateTimeFieldType[], int[])` or by merging together a set of partials using `with`, each constructed by calling `Partial(DateTimeFieldType, int)`, e.g.:
``` java
Partial a = new Partial(new DateTimeFieldType[] { year(), hourOfDay() }, new int[] { 1, 1});
Partial b = new Partial(year(), 1).
with(hourOfDay(), 1);
assert(a == b);
```
not work in cases
``` java
new Partial(new DateTimeFieldType[] { clockhourOfDay(), hourOfDay() }, new int[] { 1, 1}); // throws Types array must not contain duplicate
new Partial(clockhourOfDay(), 1).
with(hourOfDay(), 1); // #<Partial [clockhourOfDay=1, hourOfDay=1]>
```
Is that right?
There's also a related issue (probably stems from the fact that the Partial is invalid):
``` java
new Partial(clockhourOfDay(), 1).
with(hourOfDay(), 1).
isEqual(new Partial(hourOfDay() ,1).
with(clockhourOfDay(), 1)) // throws objects must have matching field types
```","org.joda.time.Partial:with(DateTimeFieldType, int)"
FILE,COMPRESS,COMPRESS-131,2011-06-03T16:25:45.000-05:00,ArrayOutOfBounds while decompressing bz2,"recvDecodingTables()
Decompressing a bz2 file generated by bzip2 utility throws an ArrayIndexOutOfBounds at method recvDecodingTables() line 469.
I believe it is related to encodings used to generate the original text file (the compressed file).",org.apache.commons.compress.compressors.BZip2TestCase
FILE,COMPRESS,COMPRESS-189,2012-06-26T21:30:39.000-05:00,ZipArchiveInputStream may read 0 bytes when reading from a nested Zip file,"ZipFile zipFile = new ZipFile(""C:/test.ZIP"");
    for (Enumeration<ZipArchiveEntry> iterator = zipFile.getEntries(); iterator.hasMoreElements(); ) {
      ZipArchiveEntry entry = iterator.nextElement();
      InputStream is = new BufferedInputStream(zipFile.getInputStream(entry));
      ZipArchiveInputStream zipInput = new ZipArchiveInputStream(is);
      ZipArchiveEntry innerEntry;
      while ((innerEntry = zipInput.getNextZipEntry()) != null){
        if (innerEntry.getName().endsWith(""XML""))
{

          //zipInput.read();

          System.out.println(IOUtils.toString(zipInput));

        }
      }
    }
When the following code is run an error ""Underlying input stream returned zero bytes"" is produced.
If the commented line is uncommented it can be seen that the ZipArchiveInputStream returned 0 bytes.
This only happens the first time read is called, subsequent calls work as expected i.e. the following code actually works correctly with that line uncommented!
produce behavious
If this is not the correct way of processing a zip file of zip files please let me know.
Also I believe whilst ZipFile can iterate over entries fast due to being able to look at the master table whilst ZipArchiveInputStream cannot.
Is there anyway of instantiating a ZipFile from a zip file inside another zip file without first extracting the nested zip file?
ZipFile zipFile = new ZipFile(""C:/test.ZIP"");
for (Enumeration<ZipArchiveEntry> iterator = zipFile.getEntries(); iterator.hasMoreElements(); ) {
ZipArchiveEntry entry = iterator.nextElement();
InputStream is = new BufferedInputStream(zipFile.getInputStream(entry));
ZipArchiveInputStream zipInput = new ZipArchiveInputStream(is);
ZipArchiveEntry innerEntry;
while ((innerEntry = zipInput.getNextZipEntry()) !
= null){ if (innerEntry.getName().
endsWith(""XML""))
{
//zipInput.read();
System.out.println(IOUtils.toString(zipInput));
}
}
}","org.apache.commons.compress.archivers.zip.ZipArchiveInputStreamTest
org.apache.commons.compress.archivers.zip.ZipArchiveInputStream"
FILE,COMPRESS,COMPRESS-273,2014-04-11T04:13:32.000-05:00,NullPointerException when creation fields/entries from scratch,"org.apache.commons.compress.archivers.zip.UnicodeCommentExtraField var0 = new org.apache.commons.compress.archivers.zip.UnicodeCommentExtraField();
    org.apache.commons.compress.archivers.zip.ZipShort var1 = var0.getLocalFileDataLength();
The API has public default constructors for many data types.
However, when these 0-argument constructors are used, certain internal references are null, resulting in a NullPointerException soon after.
This also applies to some 1-argument constructors where two references should be set before get... is used later.
In the latter case, there must be public set methods for the missing data.
contain number of similar test cases show same issue in couple show same issue of similar test cases show number in couple show number of similar test cases
org.apache.commons.compress.archivers.zip.UnicodeCommentExtraField var0 = new org.apache.commons.compress.archivers.zip.UnicodeCommentExtraField();
org.apache.commons.compress.archivers.zip.ZipShort var1 = var0.getLocalFileDataLength();","org.apache.commons.compress.archivers.zip.AbstractUnicodeExtraField
org.apache.commons.compress.archivers.cpio.CpioArchiveEntry
org.apache.commons.compress.archivers.zip.ExtraFieldUtils
org.apache.commons.compress.archivers.zip.UnrecognizedExtraField"
FILE,COMPRESS,COMPRESS-309,2015-02-18T17:22:16.000-06:00,BZip2CompressorInputStream return value wrong when told to read to a full buffer.,"BZip2CompressorInputStream.read(buffer, offset, length)  
 @Test

	public void testApacheCommonsBZipUncompression () throws Exception {

		// Create a big random piece of data

		byte[] rawData = new byte[1048576];

		for (int i=0; i<rawData.length; ++i) {

			rawData[i] = (byte) Math.floor(Math.random()*256);

		}



		// Compress it

		ByteArrayOutputStream baos = new ByteArrayOutputStream();

		BZip2CompressorOutputStream bzipOut = new BZip2CompressorOutputStream(baos);

		bzipOut.write(rawData);

		bzipOut.flush();

		bzipOut.close();

		baos.flush();

		baos.close();



		// Try to read it back in

		ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());

		BZip2CompressorInputStream bzipIn = new BZip2CompressorInputStream(bais);

		byte[] buffer = new byte[1024];

		// Works fine

		Assert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));

		// Fails, returns -1 (indicating the stream is complete rather than that the buffer 

		// was full)

		Assert.assertEquals(0, bzipIn.read(buffer, 1024, 0));

		// But if you change the above expected value to -1, the following line still works

		Assert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));

		bzipIn.close();

	}
BZip2CompressorInputStream.read(buffer, offset, length) returns -1 when given an offset equal to the length of the buffer.
This indicates, not that the buffer was full, but that the stream was finished.
use Kryo serialization have negative affects
@Test
public void testApacheCommonsBZipUncompression () throws Exception {
// Create a big random piece of data
byte[] rawData = new byte[1048576];
for (int i=0; i<rawData.length; ++i) {
rawData[i] = (byte) Math.floor(Math.random()*256);
}
// Compress it
ByteArrayOutputStream baos = new ByteArrayOutputStream();
BZip2CompressorOutputStream bzipOut = new BZip2CompressorOutputStream(baos);
bzipOut.write(rawData);
bzipOut.flush();
bzipOut.close();
baos.flush();
baos.close();
// Try to read it back in
ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());
BZip2CompressorInputStream bzipIn = new BZip2CompressorInputStream(bais);
byte[] buffer = new byte[1024];
// Works fine
Assert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));
// Fails, returns -1 (indicating the stream is complete rather than that the buffer
// was full)
Assert.assertEquals(0, bzipIn.read(buffer, 1024, 0));
// But if you change the above expected value to -1, the following line still works
Assert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));
bzipIn.close();
}",org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream
FILE,swt-3.1,104150,2005-07-16T19:58:00.000-05:00,[Patch] Table cursor separated from table selection when clicking on grid lines or empty space,"table.getLinesVisible()  
 table.setLinesVisible(true)
SWT-win32, v3138 (3.1-final)
When using a table cursor, there are two kinds of table regions that have the potential to separate the table cursor from the table selection when clicked on:
1) grid lines (table.getLinesVisible() == true)
2) empty space to the left of the first cell of each row (SWT.FULL_SELECTION)
Expected behaviour:
snippet with added table.setLinesVisible(true)",org.eclipse.swt.custom.TableCursor
FILE,swt-3.1,104545,2005-07-20T14:21:00.000-05:00,Make default size of empty composites smaller,"static final int DEFAULT_WIDTH	= 64;
 static final int DEFAULT_HEIGHT	= 64;
/* Default widths for widgets */ static final int DEFAULT_WIDTH	= 64;
static final int DEFAULT_HEIGHT	= 64;
I have run our tests (JFace, UI, RCP) and they run fine when the constants are 0.
Background: When you write an RCP app and enable the cool bar, the cool bar will initially be empty, but 64x64 pixels in size.
On Windows, you cannot see the border of the empty coolbar so the user gets a big empty space at the top of their window and might be confused.
See also Bug 70049, where the same problem occurs in an RCP application that starts off with no open perspective and thus no cool bar items.",org.eclipse.swt.widgets.CoolBar
FILE,swt-3.1,84609,2005-02-07T13:35:00.000-06:00,TableColumn has NPE while calling pack()  on last column,"lvtTable.getColumn(0).pack();
lvtTable.getColumn(1).pack();
lvtTable.getColumn(2).pack();

   
 parent.getColumns()
follow code have columns
// refresh table on new data lvtTable.getColumn(0).
pack();
lvtTable.getColumn(1).
pack();
lvtTable.getColumn(2).
pack();
On third call I get caught NPE (in debugger) in TableColumn (line 356), because parent.getColumns() (in TableColumn:354) returns array with 4 elements (always one more as existing in the table), and the last element is always null.
My system is WinXP, Eclipse Version: 3.1.0, Build id: I20050202-0800, JDK 1.5.0.
1","org.eclipse.swt.widgets.TableColumn
org.eclipse.swt.widgets.Table"
FILE,swt-3.1,86000,2005-02-21T14:47:00.000-06:00,ImageLoader Save - produces invalid JPEG images,"package com.ibm.test.image;

import org.eclipse.swt.*;
import org.eclipse.swt.graphics.*;

public class ImageLoaderTest {
		
	public static void main(String[] args) {
		ImageLoader loader;
		String dir=""c:\\image-problems\\"";
		String files[]={
				""s34i3p04"",
				""s34n3p04"",
				""s35i3p04"",
				""s35n3p04"",
				""s36i3p04"",
				""s36n3p04"",
				""s37i3p04"",
				""s37n3p04"",
				""s38i3p04"",
				""s38n3p04"",
				""s39i3p04"",
				""s39n3p04""
		};
		
		try {
			for (int i=0; i<files.length; i++) {
			String filein  = dir+files[i]+"".png"";
			String fileout = dir+files[i]+"".jpg"";
			
			loader = new ImageLoader();
			loader.load(filein);
			loader.save(fileout,SWT.IMAGE_JPEG);
			}
		} catch (SWTException e) {
		  e.printStackTrace();
		}
	}
}
The ImageLoader Save function appears to be producing bad JPG images.
I have only verified this with JPEG output.
test as JPEG
Many files were tested and the majority 
 did produced the proper JPG images as expected.
The attached Zip file contains
 only those files that did not save correctly to JPEG.
package com.ibm.test.image;
import org.eclipse.swt.
*;
import org.eclipse.swt.graphics.
*;
public class ImageLoaderTest {
		
	public static void main(String[] args) {
		ImageLoader loader;
		String dir=""c:\\image-problems\\"";
		String files[]={
				""s34i3p04"",
				""s34n3p04"",
				""s35i3p04"",
				""s35n3p04"",
				""s36i3p04"",
				""s36n3p04"",
				""s37i3p04"",
				""s37n3p04"",
				""s38i3p04"",
				""s38n3p04"",
				""s39i3p04"",
				""s39n3p04""
		};
		
		try {
			for (int i=0; i<files.length; i++) {
			String filein  = dir+files[i]+"".
png"";
			String fileout = dir+files[i]+"".
jpg"";
			
			loader = new ImageLoader();
			loader.load(filein);
			loader.save(fileout,SWT.IMAGE_JPEG);
			}
		} catch (SWTException e) {
		  e.printStackTrace();
		}
	}
}",org.eclipse.swt.internal.image.JPEGFileFormat
FILE,swt-3.1,87460,2005-03-08T21:22:00.000-06:00,StyledText: Caret location not updated when line style is used,"import org.eclipse.swt.*;
import org.eclipse.swt.custom.*;
import org.eclipse.swt.graphics.*;
import org.eclipse.swt.layout.*;
import org.eclipse.swt.widgets.*;

public class LineStyleCaretTest {
  public static void main(String[] args) {
    Display display = new Display();
    
    Shell shell = new Shell(display);
    shell.setLayout(new FillLayout());
    
    Font font = new Font(display, ""Arial"", 12, SWT.NORMAL);
      
    final StyledText text = new StyledText(shell, SWT.MULTI);
    text.setFont(font);
    text.setText(""Standard Widget Toolkit"");
    text.setCaretOffset(text.getText().length());
    
    text.addLineStyleListener(new LineStyleListener() {
      public void lineGetStyle(LineStyleEvent event) {
        StyleRange[] styles = new StyleRange[1];
        
        styles[0] = new StyleRange();
        styles[0].start  = 0;
        styles[0].length = text.getText().length();
        styles[0].fontStyle = SWT.BOLD;
        
        event.styles = styles;
      }
    });
    
    shell.setSize(300, 100);
    shell.open();
    
    while (!shell.isDisposed()) {
      if (!display.readAndDispatch()) {
        display.sleep();
      }
    }
    
    font.dispose();
    display.dispose();
  }
}
SWT-win32, v3124
In the line style listener, a bold font style is set, changing the width of the rendered text.
However, this does not happen.
For an italic style, it does not look right either.
Might be a bug?
---
import org.eclipse.swt.
*;
import org.eclipse.swt.custom.
*;
import org.eclipse.swt.graphics.
*;
import org.eclipse.swt.layout.
*;
import org.eclipse.swt.widgets.
*;
public class LineStyleCaretTest { public static void main(String[] args) {
Display display = new Display();
Shell shell = new Shell(display);
shell.setLayout(new FillLayout());
Font font = new Font(display, ""Arial"", 12, SWT.NORMAL);
final StyledText text = new StyledText(shell, SWT.MULTI);
text.setFont(font);
text.setText(""Standard Widget Toolkit"");
text.setCaretOffset(text.getText().
length());
text.addLineStyleListener(new LineStyleListener() { public void lineGetStyle(LineStyleEvent event) {
StyleRange[] styles = new StyleRange[1];
styles[0] = new StyleRange();
styles[0].
start  = 0;
styles[0].
length = text.getText().
length();
styles[0].
fontStyle = SWT.BOLD;
event.styles = styles;
}
});
shell.setSize(300, 100);
shell.open();
while (! shell.isDisposed()) { if (! display.readAndDispatch()) { display.sleep();
}
} font.dispose();
display.dispose();
}
}",org.eclipse.swt.custom.StyledText
FILE,swt-3.1,87997,2005-03-14T19:21:00.000-06:00,TableEditor.dispose( ) causes NPE if linked Table is being disposed,"TableEdtior.dispose( )  
  
   

import org.eclipse.swt.custom.TableEditor;
import org.eclipse.swt.events.*;
import org.eclipse.swt.widgets.*;

public class Test
{
    public static void main( String[ ] args )
    {
        Shell shell = new Shell( );
        Table table = new Table( shell, 0 );
        new TableColumn( table, 0 );
        TableItem item = new TableItem( table, 0 );
        final TableEditor editor = new TableEditor( table );
        final Text text = new Text( table, 0 );
        editor.setEditor( text, item, 0 );
        item.addDisposeListener( new DisposeListener( ) {
            public void widgetDisposed( DisposeEvent e )
            {
                text.dispose( );
                editor.dispose( ); // Triggers a NPE
            }
        } );
        shell.dispose( );
    }
}
Found in 3.1 I20050308-0835.
TableEdtior.dispose( ) calls methods on it's owning Table to remove some
listeners from the table's columns.
If the table is in the process of being
disposed, the columns will have already been disposed and this will result in a
NPE.
prevent from trying prevent from adding add dispose listener on Table add dispose listener on TableItem try dispose listener on Table try dispose listener on TableItem dispose of associated editor
Further if the dispose listener is set on the parent of the Table, a
""Widget is disposed"" exception will be thrown instead of the NPE.
This leaves
no place to hook to trigger the disposal of the TableEditor.
import org.eclipse.swt.custom.TableEditor;
import org.eclipse.swt.events.
*;
import org.eclipse.swt.widgets.
*;
public class Test
{
    public static void main( String[ ] args )
    {
        Shell shell = new Shell( );
        Table table = new Table( shell, 0 );
        new TableColumn( table, 0 );
        TableItem item = new TableItem( table, 0 );
        final TableEditor editor = new TableEditor( table );
        final Text text = new Text( table, 0 );
        editor.setEditor( text, item, 0 );
        item.addDisposeListener( new DisposeListener( ) {
            public void widgetDisposed( DisposeEvent e )
            {
                text.dispose( );
                editor.dispose( ); // Triggers a NPE
            }
        } );
        shell.dispose( );
    }
}","org.eclipse.swt.widgets.Tree
org.eclipse.swt.widgets.Table"
FILE,swt-3.1,97651,2005-05-31T14:43:00.000-05:00,tree insert mark cheese,"Tree.redraw() 
 public static void main(String[] args) {
	final Display display = new Display();
	final Shell shell = new Shell(display);
	shell.setBounds(10, 10, 300, 300);
	final Tree tree = new Tree(shell, SWT.NONE);
	tree.setBounds(10, 10, 200, 200);
	new TreeItem(tree, SWT.NONE).setText(""pre-root"");
	TreeItem root1 = new TreeItem(tree, SWT.NONE);
	root1.setText(""root"");
	TreeItem child = new TreeItem(root1, SWT.NONE);
	child.setText(""child"");
	Button button = new Button(shell, SWT.PUSH);
	button.setBounds(230,10,30,30);
	button.addSelectionListener(new SelectionAdapter() {
		public void widgetSelected(SelectionEvent e) {
			tree.redraw();
		}
	});
	root1.setExpanded(true);
	tree.setInsertMark(root1, false);
	shell.open();
	while (!shell.isDisposed()) {
		if (!display.readAndDispatch()) display.sleep();
	}
	display.dispose();
}
3.1RC1
run snippet
be under root item
collapse root item
-> problem 1: this makes most of the insert line go away, except for its pointy ends.
- press the button to the right of the Table: this does a Tree.redraw(), and note that the insert line reappears, so I guess it never really meant to go away
-> problem 2: now expand the root item again and its insert mark gets copied to below the child item in addition to its initial location.
This is cheese, as can be seen by damaging part of this line with another window
public static void main(String[] args) { final Display display = new Display();
final Shell shell = new Shell(display);
shell.setBounds(10, 10, 300, 300);
final Tree tree = new Tree(shell, SWT.NONE);
tree.setBounds(10, 10, 200, 200);
new TreeItem(tree, SWT.NONE).
setText(""pre-root"");
TreeItem root1 = new TreeItem(tree, SWT.NONE);
root1.setText(""root"");
TreeItem child = new TreeItem(root1, SWT.NONE);
child.setText(""child"");
Button button = new Button(shell, SWT.PUSH);
button.setBounds(230,10,30,30);
button.addSelectionListener(new SelectionAdapter() { public void widgetSelected(SelectionEvent e) { tree.redraw();
}
});
root1.setExpanded(true);
tree.setInsertMark(root1, false);
shell.open();
while (! shell.isDisposed()) { if (! display.readAndDispatch()) display.sleep();
} display.dispose();
}","org.eclipse.swt.dnd.TreeDragUnderEffect
org.eclipse.swt.widgets.Tree"
CLASS,pig-0.8.0,PIG-1776,2010-12-17T16:28:09.000-06:00,"changing statement corresponding to alias after explain , then doing dump gives incorrect result","{code}
 
  
 {code}
{code}
grunt> a = load '/tmp/t2.
txt' as (str:chararray, num1:int, alph : chararray);
grunt> dump a;
(ABC,1,a)
(ABC,1,b)
(ABC,1,a)
(ABC,2,b)
(DEF,1,d)
(XYZ,1,x)
grunt> c = foreach b  generate group.str, group.
$1, COUNT(a.alph) ;          
grunt> dump c; -- gives correct results
(ABC,1,3)
(ABC,2,1)
(DEF,1,1)
(XYZ,1,1)
/* but dumping c after following steps gives incorrect results */
grunt> c = foreach b  generate group.
$0 , (CHARARRAY)group.
$1;                                                                                 
grunt> explain c;
...
...
grunt> c = foreach b  generate group.str, group.
$1, COUNT(a.alph) ;
grunt> dump c;             
(ABC,1,0)
(ABC,2,0)
(DEF,1,0)
(XYZ,1,0)
{code}","src.org.apache.pig.PigServer
src.org.apache.pig.newplan.logical.relational.LOLoad
test.org.apache.pig.test.TestUDFContext"
CLASS,pig-0.8.0,PIG-1785,2011-01-04T17:20:28.000-06:00,New logical plan: uid conflict in flattened fields,"{code}
 
 b0>b2;
dump c;
{code}

 
 {(1,2),(2,3)}
produce wrong result
txt' as (a0:bag{t:tuple(i0:int, i1:int)});
b = foreach a generate flatten(a0) as (b0, b1), flatten(a0) as (b2, b3);
c = filter b by b0>b2;
dump c;
{code}
{(1 2),(2,3)}
(2 3,1,2)
We get nothing.","src.org.apache.pig.newplan.logical.rules.ImplicitSplitInserter
test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.newplan.logical.rules.DuplicateForEachColumnRewrite
src.org.apache.pig.newplan.optimizer.PlanOptimizer
src.org.apache.pig.newplan.optimizer.Rule"
CLASS,pig-0.8.0,PIG-1808,2011-01-17T08:50:48.000-06:00,Error message in 0.8 not much helpful as compared to 0.7,"null;
DUMP D;
A = LOAD 'i1' ;
B = LOAD 'i2' ;
C = JOIN A by $92 left outer,B by $92  ;
D =  filter C by $100 is null;
DUMP D;
The below script fails both in 0.7 and 0.8 since A requires a valid schema to be defined.
But the error message in 0.8 is not helpful.
Error message in 0.8
-----------------------------
ERROR 2000: Error processing rule PushUpFilter.
Try -t PushUpFilter org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1066: Unable to open iterator for alias D
....
Caused by: org.apache.pig.impl.logicalLayer.FrontendException: ERROR 2042: Error in new logical plan. Try -Dpig.usenewlogicalplan=false.
....
Caused by: org.apache.pig.impl.logicalLayer.FrontendException: ERROR 2000: Error processing rule PushUpFilter. Try -t PushUpFilter
....
Caused by: java.lang.NullPointerException
at org.apache.pig.newplan.logical.rules.PushUpFilter$PushUpFilterTransformer.hasAll(PushUpFilter.java:308)
at org.apache.pig.newplan.logical.rules.PushUpFilter$PushUpFilterTransformer.check(PushUpFilter.java:141)
at org.apache.pig.newplan.optimizer.PlanOptimizer.optimize(PlanOptimizer.java:108)
... 13 more
Error message in 0.7
----------------------------- org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1066: Unable to open iterator for alias D
....
....
Caused by: org.apache.pig.backend.hadoop.executionengine.physicalLayer.LogicalToPhysicalTranslatorException:
ERROR 1109: Input (B) on which outer join is desired should have a valid schema","test.org.apache.pig.test.TestPushUpFilter
src.org.apache.pig.newplan.logical.rules.PushUpFilter"
CLASS,pig-0.8.0,PIG-1812,2011-01-19T20:06:36.000-06:00,Problem with DID_NOT_FIND_LOAD_ONLY_MAP_PLAN,"{t:(id:chararray, wht:float)} 
    
 flatten(cat_bag.id)    
    
 {
        I = order M by ts;
        J = order B by ts;
        generate flatten(group) as (pkg:chararray, cat_id:chararray), J.ts as tsorig, I.ts as tsmap;
}
Hi,
have following input files
pkg.txt
a       3       {(123,1.0),(236,2.0)} a       3       {(236,1.0)}
model.txt
a       123     2       0.33 a       236     2       0.5
My script is listed below:
A = load 'pkg.txt' using PigStorage('\t') as (pkg:chararray, ts:int, cat_bag:{t:(id:chararray, wht:float)});
M = load 'model.txt' using PigStorage('\t') as (pkg:chararray, cat_id:chararray, ts:int, score:double);
B = foreach A generate ts, pkg, flatten(cat_bag.
id) as (cat_id:chararray);
B = distinct B;
H1 = cogroup M by (pkg, cat_id) inner, B by (pkg, cat_id);
H2 = foreach H1 {
I = order M by ts;
J = order B by ts;
generate flatten(group) as (pkg:chararray, cat_id:chararray), J.ts as tsorig, I.ts as tsmap;
}
dump H2;
When running this script, I got a warning about ""Encountered Warning DID_NOT_FIND_LOAD_ONLY_MAP_PLAN 1 time(s)"" and pig error log as below:
Pig Stack Trace
---------------
ERROR 2043: Unexpected error during execution.
org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1066: Unable to open iterator for alias H2
at org.apache.pig.PigServer.openIterator(PigServer.java:764)
at org.apache.pig.tools.grunt.GruntParser.processDump(GruntParser.java:612)
at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:303)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:165)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:141)
at org.apache.pig.tools.grunt.Grunt.exec(Grunt.java:90)
at org.apache.pig.Main.run(Main.java:500)
at org.apache.pig.Main.main(Main.java:107)
Caused by: org.apache.pig.PigException: ERROR 1002: Unable to store alias H2
at org.apache.pig.PigServer.storeEx(PigServer.java:888)
at org.apache.pig.PigServer.store(PigServer.java:826)
at org.apache.pig.PigServer.openIterator(PigServer.java:738)
... 7 more
Caused by: org.apache.pig.backend.executionengine.ExecException: ERROR 2043: Unexpected error during execution.
at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.execute(HExecutionEngine.java:403)
at org.apache.pig.PigServer.executeCompiledLogicalPlan(PigServer.java:1208)
at org.apache.pig.PigServer.storeEx(PigServer.java:884)
... 9 more
Caused by: java.lang.ClassCastException: org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLoad cannot be cast to org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLocalRearrange
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizer.visitMROp(SecondaryKeyOptimizer.java:352)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceOper.visit(MapReduceOper.java:246)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceOper.visit(MapReduceOper.java:41)
at org.apache.pig.impl.plan.DepthFirstWalker.depthFirst(DepthFirstWalker.java:69)
at org.apache.pig.impl.plan.DepthFirstWalker.depthFirst(DepthFirstWalker.java:71)
at org.apache.pig.impl.plan.DepthFirstWalker.walk(DepthFirstWalker.java:52)
at org.apache.pig.impl.plan.PlanVisitor.visit(PlanVisitor.java:51)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.compile(MapReduceLauncher.java:498)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.launchPig(MapReduceLauncher.java:117)
at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.execute(HExecutionEngine.java:378)
... 11 more
But, when I removed the DISTINCT statement before COGROUP, i.e. ""B = distinct B;""  this script can run smoothly.
I have also tried other reducer side operations like ORDER, it seems that they will also trigger above error.
This is really very confusing.","src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler.LimitAdjuster
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.KeyTypeDiscoveryVisitor
test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler.RearrangeAdjuster
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler
test.org.apache.pig.test.TestMRCompiler"
CLASS,pig-0.8.0,PIG-1813,2011-01-20T10:25:01.000-06:00,Pig 0.8 throws ERROR 1075 while trying to refer a map in the result of  eval udf.Works with 0.7,"flatten(org.myudf.GETFIRST(value))  
 PigStorage()
register myudf.jar;
A = load 'input' MyZippedStorage('\u0001') as ($inputSchema);
B = foreach A generate id , value  ;
C = foreach B generate id , org.myudf.ExplodeHashList( (chararray)value, '\u0002', '\u0004', '\u0003') as value;
D = FILTER C by value is not null;
E = foreach D generate id , flatten(org.myudf.GETFIRST(value)) as hop;
F = foreach E generate id , hop#'rmli' as rmli:bytearray ;
store F into 'output.bz2' using PigStorage();
The above script fails when run with Pig 0.8 but runs fine with Pig 0.7 or if pig.usenewlogicalplan=false.
The below is the exception thrown in 0.8 :
org.apache.pig.backend.executionengine.ExecException: ERROR 1075: Received a bytearray from the UDF. Cannot determine how to convert the bytearray to map.
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POCast.getNext(POCast.java:952)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POMapLookUp.processInput(POMapLookUp.java:87)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POMapLookUp.getNext(POMapLookUp.java:98)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POMapLookUp.getNext(POMapLookUp.java:117)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.processPlan(POForEach.java:346)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.getNext(POForEach.java:291)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.runPipeline(PigMapBase.java:236)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.map(PigMapBase.java:231)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.map(PigMapBase.java:53)
at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)
at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:638)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:314)
at org.apache.hadoop.mapred.Child$4.run(Child.java:217)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1062)
at org.apache.hadoop.mapred.Child.main(Child.java:211)","src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc
test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.newplan.logical.relational.LOGenerate"
CLASS,pig-0.8.0,PIG-1831,2011-01-28T04:02:31.000-06:00,Indeterministic behavior in local mode due to static variable PigMapReduce.sJobConf,"PigStorage()
The below script when run in local mode gives me a different output.
It looks like in local mode I have to store a relation obtained through streaming in order to use it afterwards.
consider script
DEFINE MySTREAMUDF `test.sh`;
A  = LOAD 'myinput' USING PigStorage() AS (myId:chararray, data2, data3,data4 );
B = STREAM A THROUGH MySTREAMUDF AS (wId:chararray, num:int);
--STORE B into 'output.B';
C = JOIN B by wId LEFT OUTER, A by myId;
D = FOREACH C GENERATE B::wId,B::num,data4 ;
D = STREAM D THROUGH MySTREAMUDF AS (f1:chararray,f2:int);
--STORE D into 'output.D';
E = foreach B GENERATE wId,num;
F = DISTINCT E;
G = GROUP F ALL;
H = FOREACH G GENERATE COUNT_STAR(F) as TotalCount;
I = CROSS D,H;
STORE I  into 'output.I';
test.sh
---------
#/bin/bash
cut -f1,3
Here if I store relation B and D then everytime i get the result  :
acbd            3
abcd            3
adbc            3
But if i dont store relations B and D then I get an empty output.
Here again I have observed that this behaviour is random ie sometimes like 1out of 5 runs there will be output.","src.org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POMergeCogroup
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POPackage
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POPartitionRearrange
src.org.apache.pig.builtin.Distinct
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.PODistinct
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POJoinPackage
src.org.apache.pig.data.InternalSortedBag
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POMergeJoin
src.org.apache.pig.impl.builtin.DefaultIndexableLoader
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce.Map
src.org.apache.pig.impl.io.FileLocalizer
test.org.apache.pig.test.TestFinish
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.partitioners.SkewedPartitioner
src.org.apache.pig.backend.hadoop.streaming.HadoopExecutableManager
src.org.apache.pig.data.InternalCachedBag
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce
test.org.apache.pig.test.TestPruneColumn
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POCombinerPackage
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase
test.org.apache.pig.test.TestFRJoin
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POSort
src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POCollectedGroup
test.org.apache.pig.test.utils.FILTERFROMFILE
src.org.apache.pig.data.InternalDistinctBag"
CLASS,pig-0.8.0,PIG-1858,2011-02-17T02:27:48.000-06:00,UDF in nested plan results frontend exception,"{code}
 
 PigStorage()  
 {
        Pvs = order B by pvs;
        Const = org.vivek.MyAnotherUDF(Pvs.pvs).(count,sum);
        generate Const.sum as sum;
        } 
   ;
{code}
register myinput use PigStorage() generate pvs as avg foreach by pvs
(count,sum);
        generate Const.sum as sum;
        };
store D into 'out_D';
{code}
The script is failing during compilation of the plan.
The usage of the udf inside the foreach is causing the problem.
The udf implements algebraic and the 
output schema is also defined.
The below is the exception that I get :
ERROR 2042: Error in new logical plan.
Try -Dpig.usenewlogicalplan=false.
org.apache.pig.impl.logicalLayer.FrontendException: ERROR 2042: Error in new logical plan. Try -Dpig.usenewlogicalplan=false.
at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.compile(HExecutionEngine.java:309)
at org.apache.pig.PigServer.compilePp(PigServer.java:1364)
at org.apache.pig.PigServer.executeCompiledLogicalPlan(PigServer.java:1206)
at org.apache.pig.PigServer.execute(PigServer.java:1200)
at org.apache.pig.PigServer.access$100(PigServer.java:128)
at org.apache.pig.PigServer$Graph.execute(PigServer.java:1527)
at org.apache.pig.PigServer.executeBatchEx(PigServer.java:372)
at org.apache.pig.PigServer.executeBatch(PigServer.java:339)
at org.apache.pig.tools.grunt.GruntParser.executeBatch(GruntParser.java:112)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:169)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:141)
at org.apache.pig.tools.grunt.Grunt.exec(Grunt.java:90)
at org.apache.pig.Main.run(Main.java:500)
at org.apache.pig.Main.main(Main.java:107)
Caused by: java.lang.NullPointerException
at org.apache.pig.newplan.ReverseDependencyOrderWalker.walk(ReverseDependencyOrderWalker.java:70)
at org.apache.pig.newplan.PlanVisitor.visit(PlanVisitor.java:50)
at org.apache.pig.newplan.logical.optimizer.SchemaResetter.visit(SchemaResetter.java:105)
at org.apache.pig.newplan.logical.relational.LOGenerate.accept(LOGenerate.java:229)
at org.apache.pig.newplan.DependencyOrderWalker.walk(DependencyOrderWalker.java:75)
at org.apache.pig.newplan.logical.optimizer.SchemaResetter.visit(SchemaResetter.java:94)
at org.apache.pig.newplan.logical.relational.LOForEach.accept(LOForEach.java:71)
at org.apache.pig.newplan.DependencyOrderWalker.walk(DependencyOrderWalker.java:75)
at org.apache.pig.newplan.PlanVisitor.visit(PlanVisitor.java:50)
at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.compile(HExecutionEngine.java:261)
... 13 more
When i trun off new logical plan the script executes successfully.
The issue is observed in both 0.8 and 0.9",test.org.apache.pig.test.TestEvalPipeline2
CLASS,pig-0.8.0,PIG-1868,2011-02-24T00:42:05.000-06:00,New logical plan fails when I have complex data types from udf,"{code}
 
 {
 Tuples = order B1 by ts;
 generate Tuples;
} 
   { t: ( previous, current, next ) } 
 as id;
dump C3;
{code}

 
 {code}
 
 {code}

  on C1 ;
{code}
C1: {seq: {t: (previous: (id: chararray,ts: int,url: chararray),current: (id: chararray,ts: int,url: chararray),next: (id: chararray,ts: int,url: chararray))}}
{code}
The new logical plan fails when I have complex data types returning from my eval function.
{code}
register myudf.jar;   
B1 = load 'myinput' as (id:chararray,ts:int,url:chararray);
B2 = group B1 by id;
B = foreach B2 {
 Tuples = order B1 by ts;
 generate Tuples;
};
C1 = foreach B generate TransformToMyDataType(Tuples,-1,0,1) as seq: { t: ( previous, current, next ) };
C2 = foreach C1 generate FLATTEN(seq);
C3 = foreach C2 generate  current.id as id;
dump C3;
{code}
On C3 it fails with below message :
{code}
Couldn't find matching uid -1 for project (Name: Project Type: bytearray Uid: 45 Input: 0 Column: 1)
{code}
The script works if I turn off new logical plan or use Pig 0.7.","src.org.apache.pig.newplan.logical.relational.LogicalSchema
test.org.apache.pig.test.TestSchema"
CLASS,pig-0.8.0,PIG-1892,2011-03-10T02:44:12.000-06:00,Bug in new logical plan : No output generated even though there are valid records,"Maploader()
I have the below script which provides me no output even though there are valid records in relation B which is used for the left out join.
A0 = load 'input' using Maploader()  as ( map1, map2, map3 );
A = filter A0 by ( (map2#'params'#'prop' == 464)   and (map2#'params'#'query' is not null) );
B0 = filter A by (map1#'type' == 'c');
B = filter B0 by ( map2#'info'#'s' matches 'aaaa|bbb|cccc');
C =  filter A by (map1#'type' == 'p');
D = join B by map2#'params'#'query' LEFT OUTER , C by map2#'params'#'query';
store D into 'output';
This is a bug with the newlogical plan.
From the plan i can see that  map1#'type'  and map2#'info'#'s' is not marked as RequiredKeys ,
but where as all the fields reffered in the firts filter statement is marked as required.
turn off coloumn prune optimizer t ColumnMapKeyPrune rearrange script by and rearrange script by ) have for script","test.org.apache.pig.test.TestPruneColumn.PigStorageWithTrace
src.org.apache.pig.newplan.logical.rules.MapKeysPruneHelper
test.org.apache.pig.test.TestPruneColumn"
CLASS,pig-0.8.0,PIG-1963,2011-04-04T17:18:24.000-05:00,"in nested foreach, accumutive udf taking input from order-by does not get results in order","{code}
 
 explain d;
dump d;
{code}
not use secondary sort for order-by
b = cogroup a1 by f1, a2 by f1;
d = foreach b {
   sort1 = order a1 by f2;
   sort2 = order a2 by f2; -- secondary sort not getting used here, MYCONCATBAG gets results in wrong order
   generate group, MYCONCATBAG(sort1.f1), MYCONCATBAG(sort2.f2);
}
-- explain d;
dump d;
{code}","test.org.apache.pig.test.TestAccumulator
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.AccumulatorOptimizer"
CLASS,pig-0.8.0,PIG-1979,2011-04-08T02:24:01.000-05:00,New logical plan failing with ERROR 2229: Couldn't find matching uid -1,"{code}
 
  
    
    
      
     PigStorage() 
  
  
  
   PigStorage() ;
{code}

   
  
    
 {code}

 import java.io.IOException;
import org.apache.pig.EvalFunc;
import org.apache.pig.data.*;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.logicalLayer.schema.Schema.FieldSchema;

public class MyExtractor extends EvalFunc<DataBag>
{
  @Override
	public Schema outputSchema(Schema arg0) {
	  try {
			return Schema.generateNestedSchema(DataType.BAG, DataType.CHARARRAY);
		} catch (FrontendException e) {
			System.err.println(""Error while generating schema. ""+e);
			return new Schema(new FieldSchema(null, DataType.BAG));
		}
	}

  @Override
  public DataBag exec(Tuple inputTuple)
    throws IOException
  {
    try {
      Tuple tp2 = TupleFactory.getInstance().newTuple(1);
      tp2.set(0, (inputTuple.get(0).toString()+inputTuple.hashCode()));
      DataBag retBag = BagFactory.getInstance().newDefaultBag();
      retBag.add(tp2);
      return retBag;
    }
    catch (Exception e) {
      throw new IOException("" Caught exception"", e);
    }
  }
}

 {code}
format IS NOT NULL AND format c02 = FILTER BY result
= '' ;
c03 = FOREACH c02 GENERATE url, formatted, FLATTEN(usage);
c04 = FOREACH c03 GENERATE usage::domain AS domain, url, formatted;
doc_001 = FOREACH c04 GENERATE domain,url, FLATTEN(MyExtractor(formatted)) AS category;
doc_004_1 = GROUP doc_001 BY (domain,url);
doc_005 = FOREACH doc_004_1 GENERATE group.domain as domain, group.url as url, doc_001.
category as category;
STORE doc_005 INTO 'out_final' USING PigStorage();
review1 = FOREACH c04 GENERATE domain,url, MyExtractor(formatted) AS rev;
review2 = FILTER review1 BY SIZE(rev)>0;
joinresult = JOIN review2 by (domain,url), doc_005 by (domain,url);
finalresult = FOREACH joinresult GENERATE  doc_005::category;
STORE finalresult INTO 'out_final' using PigStorage();
{code}
The script is failing in building the plan, while applying for logical optimization rule for AddForEach.
ERROR org.apache.pig.tools.grunt.Grunt - ERROR 2229: Couldn't find matching uid -1 for project (Name: Project Type: bytearray Uid: 106 Input: 0 Column: 5)
include doc_005
This is field is orginated from the udf org.vivek.udfs.MyExtractor (source given below).
{code}
import java.io.IOException;
import org.apache.pig.EvalFunc;
import org.apache.pig.data.
*;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.logicalLayer.schema.Schema.FieldSchema;
public class MyExtractor extends EvalFunc<DataBag>
{
  @Override
	public Schema outputSchema(Schema arg0) {
	  try {
			return Schema.generateNestedSchema(DataType.BAG, DataType.CHARARRAY);
		} catch (FrontendException e) {
			System.err.println(""Error while generating schema. ""
+e);
			return new Schema(new FieldSchema(null, DataType.BAG));
		}
	}
@Override
  public DataBag exec(Tuple inputTuple)
    throws IOException
  {
    try {
      Tuple tp2 = TupleFactory.getInstance().
newTuple(1);
      tp2.set(0, (inputTuple.get(0).
toString()+inputTuple.hashCode()));
      DataBag retBag = BagFactory.getInstance().
newDefaultBag();
      retBag.add(tp2);
      return retBag;
    }
    catch (Exception e) {
      throw new IOException("" Caught exception"", e);
    }
  }
}
{code}
The script goes through fine if I disable AddForEach rule by -t AddForEach","test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.newplan.logical.expression.DereferenceExpression"
CLASS,pig-0.8.0,PIG-730,2009-03-24T14:36:45.000-05:00,"problem combining schema from a union of several LOAD expressions, with a nested bag inside the schema.","flatten(outlinks.target);
  flatten(outlinks.target);
grunt> a = load 'foo' using BinStorage as (url:chararray,outlinks:{t:(target:chararray,text:chararray)});
grunt> b = union (load 'foo' using BinStorage as (url:chararray,outlinks:{t:(target:chararray,text:chararray)})), (load 'bar' using BinStorage as (url:chararray,outlinks:{t:(target:chararray,text:chararray)}));
grunt> c = foreach a generate flatten(outlinks.target);
grunt> d = foreach b generate flatten(outlinks.target);
---> Would expect both C and D to work, but only C works.
D gives the error shown below.
---> Turns out using outlinks.t.target (instead of outlinks.target) works for D but not for C.
2009-03-24 13:15:05,376 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1000: Error during parsing.
Invalid alias: target in {t: (target: chararray,text: chararray)}
Details at logfile: /echo/olston/data/pig_1237925683748.
log
grunt> quit
$ cat pig_1237925683748.log
ERROR 1000: Error during parsing. Invalid alias: target in {t: (target: chararray,text: chararray)}
org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1000: Error during parsing. Invalid alias: target in {t: (target: chararray,text: chararray)}
at org.apache.pig.PigServer.parseQuery(PigServer.java:317)
at org.apache.pig.PigServer.registerQuery(PigServer.java:276)
at org.apache.pig.tools.grunt.GruntParser.processPig(GruntParser.java:529)
at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:280)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:99)
at org.apache.pig.tools.grunt.Grunt.run(Grunt.java:69)
at org.apache.pig.Main.main(Main.java:321)
Caused by: org.apache.pig.impl.logicalLayer.parser.ParseException: Invalid alias: target in {t: (target: chararray,text: chararray)}
at org.apache.pig.impl.logicalLayer.parser.QueryParser.AliasFieldOrSpec(QueryParser.java:6042)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.ColOrSpec(QueryParser.java:5898)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.BracketedSimpleProj(QueryParser.java:5423)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.BaseEvalSpec(QueryParser.java:4100)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.UnaryExpr(QueryParser.java:3967)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.CastExpr(QueryParser.java:3920)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.MultiplicativeExpr(QueryParser.java:3829)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.AdditiveExpr(QueryParser.java:3755)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.InfixExpr(QueryParser.java:3721)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.FlattenedGenerateItem(QueryParser.java:3617)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.FlattenedGenerateItemList(QueryParser.java:3557)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.GenerateStatement(QueryParser.java:3514)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.NestedBlock(QueryParser.java:2985)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.ForEachClause(QueryParser.java:2395)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.BaseExpr(QueryParser.java:1028)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.Expr(QueryParser.java:804)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.Parse(QueryParser.java:595)
at org.apache.pig.impl.logicalLayer.LogicalPlanBuilder.parse(LogicalPlanBuilder.java:60)
at org.apache.pig.PigServer.parseQuery(PigServer.java:310)
... 6 more","src.org.apache.pig.impl.logicalLayer.schema.Schema
src.org.apache.pig.newplan.logical.expression.DereferenceExpression
src.org.apache.pig.newplan.logical.relational.LogicalSchema
test.org.apache.pig.test.TestSchema"
CLASS,hibernate-3.5.0b2,HHH-4617,2009-11-28T11:42:08.000-06:00,Using materialized blobs with Postgresql causes error,"@Lob
I have entity with byte[] property annotated as @Lob and lazy fetch type, when table is createad the created column is of type oid, but when the column is read in application, the Hibernate reads the OID value instead of bytes under given oid.
It's behavior like to read / write bytea.
If i remember well, auto-creating table with Hibernate creates oid column.","org.hibernate.type.CharacterArrayClobType
org.hibernate.type.MaterializedClobType
org.hibernate.type.PrimitiveCharacterArrayClobType
org.hibernate.type.WrappedMaterializedBlobType
org.hibernate.type.MaterializedBlobType
org.hibernate.test.lob.MaterializedBlobTest
org.hibernate.type.BlobType
org.hibernate.type.ClobType
org.hibernate.test.lob.ClobLocatorTest
org.hibernate.dialect.Dialect
org.hibernate.cfg.annotations.SimpleValueBinder
org.hibernate.dialect.PostgreSQLDialect
org.hibernate.Hibernate"
CLASS,hibernate-3.5.0b2,HHH-5042,2010-03-26T05:06:09.000-05:00,TableGenerator does not increment hibernate_sequences.next_hi_value anymore after having exhausted the current lo-range,"class MultipleHiLoPerTableGenerator 
 IntegralDataTypeHolder value;
 
 int lo;

 
  
  
 IntegralDataTypeHolder hiVal = (IntegralDataTypeHolder) doWorkInNewTransaction( session );

   
  
 varchar(255) 
     varchar(255)
This bug is new in 3.5
In version 3.5 class MultipleHiLoPerTableGenerator.java was modified introducing a new increment variable
IntegralDataTypeHolder value;
along with int lo;
The problem in the new code is that only value get's incremented whilst variable lo is still used to check when a new hiVal must be obtained.
if ( lo > maxLo ) {
IntegralDataTypeHolder hiVal = (IntegralDataTypeHolder) doWorkInNewTransaction( session );
as lo is never incremented, MultipleHiLoPerTableGenerator continues to deliver numbers without ever update hibernate_sequences.
next_hi_value on the database (only one unique update is propagates at the first insert)
This lead to duplicate keys as soon another session from another sessionfactory tries to insert new objects on the concerning table.
IMPORTANT ADVICE TO RUN THE TESTCASE:
run without hbm2ddl.auto property
create table A (oid bigint not null, name varchar(255), version integer not null, primary key (oid), unique (name))
create table hibernate_sequences ( sequence_name varchar(255),  sequence_next_hi_value integer )","org.hibernate.id.SequenceHiLoGenerator
org.hibernate.id.enhanced.OptimizerFactory
org.hibernate.id.SequenceGenerator
org.hibernate.id.MultipleHiLoPerTableGenerator"
METHOD,openjpa-2.0.1,OPENJPA-1627,2010-04-12T05:21:13.000-05:00,ORderBy with @ElementJoinColumn and EmbeddedId uses wrong columns in SQL,"@OneToMany(fetch = FetchType.LAZY, cascade = {CascadeType.PERSIST})
	@ElementJoinColumn(name=""maccno"", referencedColumnName=""maccno"")
	@OrderBy(value = ""_id._processDate ASC, _id._tranSequenceNumber ASC"")
	private LinkedList<Transaction> _transactions;



      
 @EmbeddedId
	private TransactionId _id;
	
	 @Column(name = ""mtrancde"")
	private int _transactionCode;
	
	 @Column(name = ""mamount"")
	private BigDecimal _amount;
	
	 @Column(name = ""mdesc"")
	private String _description;
	


	 @Column(name = ""mactdate"")
	private Date _actualDate;
	
	 @Column(name = ""mbranch"")
	private int _branch;



   
 @Embeddable
public class TransactionId  
 @Column(name = ""maccno"")
	private String _accountNumber;
	
	 @Column(name = ""mprocdate"")
	private Date _processDate;
	
	 @Column(name = ""mtranseqno"")
	private int _tranSequenceNumber;
Typical bank example, Account with Transactions.
It is a legacy db so Transaction has compound key - represented by TransactionId class.
The problem is that the order by in the generated SQL is for columns mapped in the transaction entity NOT the TransacionId as expected.
have following fragment ....
@OneToMany(fetch = FetchType.LAZY, cascade = {CascadeType.PERSIST})
	@ElementJoinColumn(name=""maccno"", referencedColumnName=""maccno"")
	@OrderBy(value = ""_id.
_processDate ASC, _id.
_tranSequenceNumber ASC"")
	private LinkedList<Transaction> _transactions;
_processDate and _tranSequenceNumber are defined in the TransactionId class.
Transaction has the following fragment....
@EmbeddedId
	private TransactionId _id;
	
	@Column(name = ""mtrancde"")
	private int _transactionCode;
	
	@Column(name = ""mamount"")
	private BigDecimal _amount;
	
	@Column(name = ""mdesc"")
	private String _description;
@Column(name = ""mactdate"")
	private Date _actualDate;
	
	@Column(name = ""mbranch"")
	private int _branch;
And TransactionId defines the primary key columns....
@Embeddable
public class TransactionId {
	
	@Column(name = ""maccno"")
	private String _accountNumber;
	
	@Column(name = ""mprocdate"")
	private Date _processDate;
	
	@Column(name = ""mtranseqno"")
	private int _tranSequenceNumber;
However the generated SQL is doing order by on columns mapped in Transaction:
executing prepstmnt 23188098 SELECT t0.maccno, t0.mprocdate, t0.mtranseqno, t0.mactdate, t0.mamount, t0.mbranch, t0.mchqcash, t0.mdesc,
 t0.mtmnlno, t0.mtrancde, t0.mtrnfeed 
FROM transaction t0 
WHERE t0.maccno = ?
ORDER BY t0.mamount ASC, t0.mbranch ASC [params=(String) 000734123]
ORDER BY t0.mprocdate ASC, t0.mtranseqno ASC [params=(String) 000734123]
Thanks
Michael","org.apache.openjpa.jdbc.meta.JDBCRelatedFieldOrder:order(Select, ClassMapping, Joins)"
METHOD,openjpa-2.0.1,OPENJPA-1784,2010-09-08T08:31:29.000-05:00,Map value updates not flushed,"@Embeddable
public class LocalizedString {


    private String language;
    private String string;


    // getters and setters omitted
}


 


 @Entity
public class MultilingualString {


    @Id
    private long id;


    @ElementCollection(fetch=FetchType.EAGER)
    private Map<String, LocalizedString> map = new HashMap<String, LocalizedString>();
}



 
   ;
    em.getTransaction().begin();
    m.getMap().get(""en"").setString(""foo"");
     em.merge(m)
     em.getTransaction()  commit();
   
 
   ;
    em.getTransaction().begin();
     m.getMap()  put(""en"")  new LocalizedString(""en"", ""foo"") 
 em.merge(m)
     em.getTransaction()  commit();


 
 hashCode()   equals()   equal()
have entity with map element collection
@Embeddable
public class LocalizedString {
private String language;
    private String string;
// getters and setters omitted
}
@Entity
public class MultilingualString {
@Id
    private long id;
@ElementCollection(fetch=FetchType.EAGER)
    private Map<String, LocalizedString> map = new HashMap<String, LocalizedString>();
}
update member of given map value merge modified entity
EntityManager em = ...;
    em.getTransaction().
begin();
    m.getMap().
get(""en"").
setString(""foo"");
    em.merge(m)
    em.getTransaction().
commit();
   
The problem is, the state change of the map does not get saved to the database.
With DEBUG logging on, I can see that the flush on commit does not trigger any SQL UPDATE.
To force the update, I have to put a new value into the map instead of just changing the existing one.
EntityManager em = ...;
    em.getTransaction().
begin();
    m.getMap().
put(""en""), new LocalizedString(""en"", ""foo""));
    em.merge(m)
    em.getTransaction().
commit();
After this change, I do see the expected UPDATE.
My Embeddable does have hashCode() and equals() implemented such that the changed map is not equal() to the former version in either case.
This looks like a bug in the dirty-checking logic in OpenJPA.","org.apache.openjpa.util.ProxyMaps:beforePut(ProxyMap, Object, Object)"
METHOD,openjpa-2.0.1,OPENJPA-526,2008-02-27T13:28:05.000-06:00,Insert text more than 4K bytes to Clob column causes SQLException: Exhausted Resultset,"public class Exam 
 @Lob 
 @Column(name = ""text"", nullable = false)  
 private String text;
 
 With nullable = false
lead to bug
Here are the differences with nullable = true:
INSERT INTO exam (id, text) VALUES (?
, ?)
[params=(long) 1, (Clob) oracle.sql.CLOB@d402dd]
SELECT t0.text FROM exam t0 WHERE t0.id = ?
FOR UPDATE [params=(long) 1]
With nullable = false:
INSERT INTO exam (id, text) VALUES (?
, ?)
[params=(long) 1, (Reader) java.io.StringReader@1603522]
SELECT t0.text FROM exam t0 WHERE t0.id = ?
FOR UPDATE [params=(long) 1] [code=1400, state=23000]
Here's the full stack trace:
[2008-02-27 10:43:51,232][main][org.apache.openjpa.lib.log.Log4JLogFactory$LogAdapter:72][DEBUG] <t 11050211, conn 32112901> executing prepstmnt 15029693 INSERT INTO exam (id, last_updated_by, comments, sustained_on, text, version, course_id, professor_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?) [params=(long) 11, (String) test, (null) null, (Date) 2008-02-27, (Reader) java.io.StringReader@da9ea4, (int) 1, (long) 1, (long) 8]
[2008-02-27 10:43:51,248][main][org.apache.openjpa.lib.log.Log4JLogFactory$LogAdapter:72][DEBUG] <t 11050211, conn 32112901> [16 ms] spent
[2008-02-27 10:43:51,248][main][org.apache.openjpa.lib.log.Log4JLogFactory$LogAdapter:72][DEBUG] <t 11050211, conn 32112901> executing prepstmnt 24422114 SELECT t0.text FROM exam t0 WHERE t0.id = ? FOR UPDATE [params=(long) 11]
[2008-02-27 10:43:51,279][main][org.apache.openjpa.lib.log.Log4JLogFactory$LogAdapter:72][DEBUG] <t 11050211, conn 32112901> [31 ms] spent
[2008-02-27 10:43:51,279][main][org.apache.openjpa.lib.log.Log4JLogFactory$LogAdapter:76][DEBUG] An exception occurred while ending the transaction.  This exception will be re-thrown.
<openjpa-1.0.2-r420667:627158 fatal store error> org.apache.openjpa.util.StoreException: The transaction has been rolled back.  See the nested exceptions for details on the errors that occurred.
at org.apache.openjpa.kernel.BrokerImpl.newFlushException(BrokerImpl.java:2108)
at org.apache.openjpa.kernel.BrokerImpl.flush(BrokerImpl.java:1955)
at org.apache.openjpa.kernel.BrokerImpl.flushSafe(BrokerImpl.java:1853)
at org.apache.openjpa.kernel.BrokerImpl.beforeCompletion(BrokerImpl.java:1771)
at org.apache.openjpa.kernel.LocalManagedRuntime.commit(LocalManagedRuntime.java:81)
at org.apache.openjpa.kernel.BrokerImpl.commit(BrokerImpl.java:1293)
at org.apache.openjpa.kernel.DelegatingBroker.commit(DelegatingBroker.java:861)
at org.apache.openjpa.persistence.EntityManagerImpl.commit(EntityManagerImpl.java:408)
at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:438)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:662)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:632)
at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:319)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:116)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:631)
at com.intellapps.university.service.impl.ServiceDahImpl$$EnhancerByCGLIB$$81ecf35d.insertExam(<generated>)
at com.intellapps.university.service.impl.ServiceImpl.insertExam(ServiceImpl.java:98)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:585)
at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:301)
at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:182)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:149)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:106)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:204)
at $Proxy17.insertExam(Unknown Source)
at com.intellapps.university.app.Main.testInsertExamWithLongText(Main.java:103)
at com.intellapps.university.app.Main.main(Main.java:203)
Caused by: <openjpa-1.0.2-r420667:627158 nonfatal store error> org.apache.openjpa.util.StoreException: Exhausted Resultset
at org.apache.openjpa.jdbc.sql.DBDictionary.newStoreException(DBDictionary.java:3946)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:97)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:83)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:59)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:96)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:72)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager.flush(JDBCStoreManager.java:514)
at org.apache.openjpa.kernel.DelegatingStoreManager.flush(DelegatingStoreManager.java:130)
... 29 more
Caused by: java.sql.SQLException: Exhausted Resultset
at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:112)
at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:146)
at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:208)
at oracle.jdbc.driver.ScrollableResultSet.getOracleObject(ScrollableResultSet.java:510)
at oracle.jdbc.driver.ScrollableResultSet.getCLOB(ScrollableResultSet.java:1446)
at oracle.jdbc.driver.UpdatableResultSet.getCLOB(UpdatableResultSet.java:1639)
at oracle.jdbc.driver.UpdatableResultSet.getClob(UpdatableResultSet.java:982)
at org.apache.commons.dbcp.DelegatingResultSet.getClob(DelegatingResultSet.java:515)
at org.apache.openjpa.lib.jdbc.DelegatingResultSet.getClob(DelegatingResultSet.java:576)
at org.apache.openjpa.jdbc.meta.strats.MaxEmbeddedClobFieldStrategy.putData(MaxEmbeddedClobFieldStrategy.java:69)
at org.apache.openjpa.jdbc.meta.strats.MaxEmbeddedLobFieldStrategy.customUpdate(MaxEmbeddedLobFieldStrategy.java:162)
at org.apache.openjpa.jdbc.meta.strats.MaxEmbeddedLobFieldStrategy.customInsert(MaxEmbeddedLobFieldStrategy.java:140)
at org.apache.openjpa.jdbc.meta.FieldMapping.customInsert(FieldMapping.java:684)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager$CustomMapping.execute(AbstractUpdateManager.java:358)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:94)
... 32 more
NestedThrowables:
<openjpa-1.0.2-r420667:627158 nonfatal store error> org.apache.openjpa.util.ReferentialIntegrityException: ORA-01400: cannot insert NULL into (""TEST"".""EXAM"".""TEXT"")
{prepstmnt 15029693 INSERT INTO exam (id, last_updated_by, comments, sustained_on, text, version, course_id, professor_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?) [params=(long) 11, (String) test, (null) null, (Date) 2008-02-27, (Reader) java.io.StringReader@da9ea4, (int) 1, (long) 1, (long) 8]} [code=1400, state=23000]
FailedObject: com.intellapps.university.core.model.Exam@1417690
at org.apache.openjpa.jdbc.sql.DBDictionary.newStoreException(DBDictionary.java:3944)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:97)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:67)
at org.apache.openjpa.jdbc.kernel.PreparedStatementManagerImpl.flushInternal(PreparedStatementManagerImpl.java:108)
at org.apache.openjpa.jdbc.kernel.PreparedStatementManagerImpl.flush(PreparedStatementManagerImpl.java:73)
at org.apache.openjpa.jdbc.kernel.OperationOrderUpdateManager.flushPrimaryRow(OperationOrderUpdateManager.java:203)
at org.apache.openjpa.jdbc.kernel.OperationOrderUpdateManager.flush(OperationOrderUpdateManager.java:89)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:89)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:72)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager.flush(JDBCStoreManager.java:514)
at org.apache.openjpa.kernel.DelegatingStoreManager.flush(DelegatingStoreManager.java:130)
at org.apache.openjpa.kernel.BrokerImpl.flush(BrokerImpl.java:1955)
at org.apache.openjpa.kernel.BrokerImpl.flushSafe(BrokerImpl.java:1853)
at org.apache.openjpa.kernel.BrokerImpl.beforeCompletion(BrokerImpl.java:1771)
at org.apache.openjpa.kernel.LocalManagedRuntime.commit(LocalManagedRuntime.java:81)
at org.apache.openjpa.kernel.BrokerImpl.commit(BrokerImpl.java:1293)
at org.apache.openjpa.kernel.DelegatingBroker.commit(DelegatingBroker.java:861)
at org.apache.openjpa.persistence.EntityManagerImpl.commit(EntityManagerImpl.java:408)
at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:438)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:662)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:632)
at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:319)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:116)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:631)
at com.intellapps.university.service.impl.ServiceDahImpl$$EnhancerByCGLIB$$81ecf35d.insertExam(<generated>)
at com.intellapps.university.service.impl.ServiceImpl.insertExam(ServiceImpl.java:98)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:585)
at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:301)
at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:182)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:149)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:106)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:204)
at $Proxy17.insertExam(Unknown Source)
at com.intellapps.university.app.Main.testInsertExamWithLongText(Main.java:103)
at com.intellapps.university.app.Main.main(Main.java:203)
Caused by: org.apache.openjpa.lib.jdbc.ReportingSQLException: ORA-01400: cannot insert NULL into (""TEST"".""EXAM"".""TEXT"")
{prepstmnt 15029693 INSERT INTO exam (id, last_updated_by, comments, sustained_on, text, version, course_id, professor_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?) [params=(long) 11, (String) test, (null) null, (Date) 2008-02-27, (Reader) java.io.StringReader@da9ea4, (int) 1, (long) 1, (long) 8]} [code=1400, state=23000]
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator.wrap(LoggingConnectionDecorator.java:192)
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator.access$800(LoggingConnectionDecorator.java:57)
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator$LoggingConnection$LoggingPreparedStatement.executeUpdate(LoggingConnectionDecorator.java:858)
at org.apache.openjpa.lib.jdbc.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:269)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager$CancelPreparedStatement.executeUpdate(JDBCStoreManager.java:1363)
at org.apache.openjpa.jdbc.kernel.PreparedStatementManagerImpl.flushInternal(PreparedStatementManagerImpl.java:97)
... 36 more
NestedThrowables:
java.sql.SQLException: ORA-01400: cannot insert NULL into (""TEST"".""EXAM"".""TEXT"")
at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:112)
at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:331)
at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:288)
at oracle.jdbc.driver.T4C8Oall.receive(T4C8Oall.java:745)
at oracle.jdbc.driver.T4CPreparedStatement.doOall8(T4CPreparedStatement.java:216)
at oracle.jdbc.driver.T4CPreparedStatement.executeForRows(T4CPreparedStatement.java:966)
at oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1170)
at oracle.jdbc.driver.OraclePreparedStatement.executeInternal(OraclePreparedStatement.java:3339)
at oracle.jdbc.driver.OraclePreparedStatement.executeUpdate(OraclePreparedStatement.java:3423)
at org.apache.commons.dbcp.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:102)
at org.apache.openjpa.lib.jdbc.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:269)
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator$LoggingConnection$LoggingPreparedStatement.executeUpdate(LoggingConnectionDecorator.java:856)
at org.apache.openjpa.lib.jdbc.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:269)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager$CancelPreparedStatement.executeUpdate(JDBCStoreManager.java:1363)
at org.apache.openjpa.jdbc.kernel.PreparedStatementManagerImpl.flushInternal(PreparedStatementManagerImpl.java:97)
at org.apache.openjpa.jdbc.kernel.PreparedStatementManagerImpl.flush(PreparedStatementManagerImpl.java:73)
at org.apache.openjpa.jdbc.kernel.OperationOrderUpdateManager.flushPrimaryRow(OperationOrderUpdateManager.java:203)
at org.apache.openjpa.jdbc.kernel.OperationOrderUpdateManager.flush(OperationOrderUpdateManager.java:89)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:89)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:72)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager.flush(JDBCStoreManager.java:514)
at org.apache.openjpa.kernel.DelegatingStoreManager.flush(DelegatingStoreManager.java:130)
at org.apache.openjpa.kernel.BrokerImpl.flush(BrokerImpl.java:1955)
at org.apache.openjpa.kernel.BrokerImpl.flushSafe(BrokerImpl.java:1853)
at org.apache.openjpa.kernel.BrokerImpl.beforeCompletion(BrokerImpl.java:1771)
at org.apache.openjpa.kernel.LocalManagedRuntime.commit(LocalManagedRuntime.java:81)
at org.apache.openjpa.kernel.BrokerImpl.commit(BrokerImpl.java:1293)
at org.apache.openjpa.kernel.DelegatingBroker.commit(DelegatingBroker.java:861)
at org.apache.openjpa.persistence.EntityManagerImpl.commit(EntityManagerImpl.java:408)
at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:438)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:662)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:632)
at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:319)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:116)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:631)
at com.intellapps.university.service.impl.ServiceDahImpl$$EnhancerByCGLIB$$81ecf35d.insertExam(<generated>)
at com.intellapps.university.service.impl.ServiceImpl.insertExam(ServiceImpl.java:98)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:585)
at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:301)
at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:182)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:149)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:106)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:204)
at $Proxy17.insertExam(Unknown Source)
at com.intellapps.university.app.Main.testInsertExamWithLongText(Main.java:103)
at com.intellapps.university.app.Main.main(Main.java:203)","org.apache.openjpa.persistence.kernel.common.apps.Lobs:getId()
org.apache.openjpa.persistence.kernel.common.apps.Lobs:getLob()
org.apache.openjpa.persistence.kernel.common.apps.Lobs:Lobs(String, int)
org.apache.openjpa.persistence.kernel.common.apps.Lobs:setLob(String)
org.apache.openjpa.jdbc.sql.OracleDictionary:setNull(PreparedStatement, int, int, Column)"
METHOD,adempiere-3.1.0,1240,2008-05-16T03:03:55.000-05:00,Posting not balanced when is producing more than 1 produc,"Production Quantity= 2
The accounting is not balanced  when more that 1 product BOM is produced.
when is necesary serialize, then the line must be put 1 each line.
in this case the production  cant  apply.
Step reproduce
create row in tab Production header create row for production patio
create row in tab Production plan create row for Patio
3. Then click on  ""Create/post Production"" button in the Production header tab, this create the production line.
verify in the production line tab.
give serial in attribute set instance field create other row similar in Patio furniture set product set in movement quantity
click on create/post production button
6. click on ""Not Postet"" Button, then there the botton label is changed to ""Dont Balanced""
Regards,
Layda Salas - globalqss http://globalqss.com",org.compiere.acct.Doc_Production:createFacts(MAcctSchema)
FILE,CONFIGURATION,CONFIGURATION-241,2006-12-02T00:03:48.000-06:00,clearProperty() does not generate events,"clearProperty() 
 ConfigurationFactory configurationFactory = new ConfigurationFactory();
   
 configurationFactory.setConfigurationURL(configFileURL);
Configuration configuration = ConfigurationFactory.getConfiguration();
configuration.addConfigurationListener(new ConfigurationListener() {
    public void configurationChanged(ConfigurationEvent e) 
{
        System.out.println(e.getPropertyName() + "": "" + e.getPropertyValue());
    }
});
System.out.println(configuration.getProperty(""name.first"")); // prints ""Mike""
 configuration.claerProperty(""name.first"")  ; // no output whatsoever
System.out.println(configuration.getProperty(""name.first"")); // prints ""null""
load configuration information from multiple sources register listener with resulting configuration object
Unfortunately the listener does not receive ""clear property"" events.
I've confirmed that it can properly receive other events (like ""set property""), and that calls to ""clearProperty()"" do actually clear the property, so I believe this may be a bug in commons-configuration.
I've tried setting ""details"" to true, which had no effect.
ConfigurationFactory configurationFactory = new ConfigurationFactory();
URL configFileURL = ... get the config file ...
configurationFactory.setConfigurationURL(configFileURL);
Configuration configuration = ConfigurationFactory.getConfiguration();
configuration.addConfigurationListener(new ConfigurationListener() { public void configurationChanged(ConfigurationEvent e)
{
System.out.println(e.getPropertyName() + "": "" + e.getPropertyValue());
}
});
System.out.println(configuration.getProperty(""name.first"")); // prints ""Mike"" configuration.claerProperty(""name.first"")); // no output whatsoever
System.out.println(configuration.getProperty(""name.first"")); // prints ""null""","org.apache.commons.configuration.TestCompositeConfiguration
org.apache.commons.configuration.CompositeConfiguration"
FILE,CONFIGURATION,CONFIGURATION-259,2007-03-28T08:47:56.000-05:00,ConfigurationFactory Merge is broken,"URL configURL = getClass().getResource(configFile);
ConfigurationFactory factory = new ConfigurationFactory();
factory.setConfigurationURL(configURL);
myConfig = factory.getConfiguration();
 
 
 DefaultConfigurationBuilder builder = new DefaultConfigurationBuilder();
            builder.setURL(configURL);
            myConfig = builder.getConfiguration();
merge configuration use ConfigurationFactory use additional tag
It turns out that subsequent operations on the merged data provide wrong results.
In particular, after creating a particular subset from a loaded configuration, the subset is empty.
Strangely enough, when using DefaultConfigurationBuilder to load exactly the same configurations this works properly.
So when initializing the configuration as follows, I get the following error:
URL configURL = getClass().
getResource(configFile);
ConfigurationFactory factory = new ConfigurationFactory();
factory.setConfigurationURL(configURL);
myConfig = factory.getConfiguration();
60043 java.util.NoSuchElementException: 'HvNr' doesn't map to an existing object
at org.apache.commons.configuration.AbstractConfiguration.getLong(AbstractConfiguration.java:743)
at de.awd.vertriebsportal.portal.person.TestConfiguration.main(TestConfiguration.java:84)
Exception in thread ""main""
But when initializing it like this everything works properly
DefaultConfigurationBuilder builder = new DefaultConfigurationBuilder();
builder.setURL(configURL);
myConfig = builder.getConfiguration();
60043
54564
I will attach full source code and xml files",org.apache.commons.configuration.ConfigurationFactory
FILE,CONFIGURATION,CONFIGURATION-332,2008-07-04T15:54:10.000-05:00,PropertiesConfiguration.save() doesn't persist properties added through a DataConfiguration,"public void testSaveWithDataConfiguration() throws ConfigurationException
{
    File file = new File(""target/testsave.properties"");
    if (file.exists()) {
        assertTrue(file.delete());
    }

    PropertiesConfiguration config = new PropertiesConfiguration(file);

    DataConfiguration dataConfig = new DataConfiguration(config);

    dataConfig.setProperty(""foo"", ""bar"");
    assertEquals(""bar"", config.getProperty(""foo""));
    config.save();

    // reload the file
    PropertiesConfiguration config2 = new PropertiesConfiguration(file);
    assertFalse(""empty configuration"", config2.isEmpty());
}
There is a regression in Commons Configuration with PropertiesConfiguration wrapped into a DataConfiguration.
The properties added through a DataConfiguration aren't persisted when the configuration is saved, but they can be queried normally.
Commons Configuration 1.4 wasn't affected by this issue.
fail on last assertion
public void testSaveWithDataConfiguration() throws ConfigurationException
{
File file = new File(""target/testsave.
properties"");
if (file.exists()) { assertTrue(file.delete());
}
PropertiesConfiguration config = new PropertiesConfiguration(file);
DataConfiguration dataConfig = new DataConfiguration(config);
dataConfig.setProperty(""foo"", ""bar"");
assertEquals(""bar"", config.getProperty(""foo""));
config.save();
// reload the file
PropertiesConfiguration config2 = new PropertiesConfiguration(file);
assertFalse(""empty configuration"", config2.isEmpty());
}","org.apache.commons.configuration.TestPropertiesConfiguration
org.apache.commons.configuration.DataConfiguration"
FILE,CONFIGURATION,CONFIGURATION-347,2008-11-05T21:06:22.000-06:00,Iterating over the keys of a file-based configuration can cause a ConcurrentModificationException,"getKeys()
Some implementations of FileConfiguration return an iterator in their getKeys() method that is directly connected to the underlying data store.
When now a reload is performed (which can happen at any time) the data store is modified, and the iterator becomes invalid.
This behavior is very confusing because ConcurrentModificationExceptions are typically related to multi-threading access.
But even if the code performing the iteration is the only instance that accesses the configuration, the exception can be thrown.","org.apache.commons.configuration.TestFileConfiguration
org.apache.commons.configuration.AbstractFileConfiguration"
FILE,CONFIGURATION,CONFIGURATION-408,2010-02-11T01:01:05.000-06:00,"When I save a URL as a property value, the forward slashes are getting escaped","public static void main(String[] args)
  {
    try
    {

      PropertiesConfiguration config = new PropertiesConfiguration();     

      File newProps = new File(""foo.properties"");

      config.setProperty(""foo"", ""http://www.google.com/"");     

      config.save(newProps);

      

    }
    catch (Exception e){}
  }
When I save a URL as a property value, the forward slashes are getting escaped.
ie:
foo = http:\/\/www.google.com\/
public static void main(String[] args)
{ try
{
PropertiesConfiguration config = new PropertiesConfiguration();
File newProps = new File(""foo.properties"");
config.setProperty(""foo"", ""http://www.google.com/"");
config.save(newProps);
} catch (Exception e){}
}",org.apache.commons.configuration.TestPropertiesConfiguration
FILE,CONFIGURATION,CONFIGURATION-481,2012-02-26T20:27:46.000-06:00,Variable interpolation across files broken in 1.7 & 1.8,"{myvar}  
 
 
 
 combinedConfig.getConfiguration(""test"")  configurationAt(""products/product[@name='abc']"", true)  getString(""desc"")

  {myvar}
declare variable in properties file reference in XML file use } syntax
global.properties:
myvar=abc
test.xml:
<products>
<product name=""abc"">
<desc>${myvar}-product</desc>
</product>
</products>
config.xml:
<properties fileName=""global.properties""/>
<xml fileName=""test.xml"" config-name=""test"">
<expressionEngine config-class=""org.apache.commons.configuration.tree.xpath.XPathExpressionEngine""/>
</xml>
retrieve value
combinedConfig.getConfiguration(""test"").
configurationAt(""products/product[@name='abc']"", true).
getString(""desc"")
I get ""${myvar}-product"" instead of ""abc-product"".
This was working in Commons Configuration 1.6, but seems to be broken in 1.7 and 1.8.","org.apache.commons.configuration.DefaultConfigurationBuilder
org.apache.commons.configuration.interpol.ConfigurationInterpolator
org.apache.commons.configuration.TestDefaultConfigurationBuilder"
FILE,CONFIGURATION,CONFIGURATION-627,2016-05-04T22:54:12.000-05:00,BeanHelper exception on XMLConfiguration builder.getConfiguration(),"builder =

        new FileBasedConfigurationBuilder<XMLConfiguration>(

                XMLConfiguration.class)

                        .configure(params.xml()

                                .setFileName(

                                        propsFile.getCanonicalPath())

                                .setValidating(false));



config = builder.getConfiguration();



   
 private static boolean isPropertyWriteable(Object bean, String propName)    
  
   org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)
create XMLConfiguration from file
builder =
new FileBasedConfigurationBuilder<XMLConfiguration>(
XMLConfiguration.class)
.
configure(params.xml()
.
setFileName(
propsFile.getCanonicalPath())
.
setValidating(false));
config = builder.getConfiguration();
Causes a non-halting exception originating in org.apache.commons.configuration2.beanutils.BeanHelper, method private static boolean isPropertyWriteable(Object bean, String propName) with parameters XMLConfiguration, ""validating"".
The exception:
May 04, 2016 3:29:26 PM org.apache.commons.beanutils.FluentPropertyBeanIntrospector introspect
WARNING: Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)!
Ignoring this property.
java.beans.IntrospectionException: bad write method arg count: public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)
at java.beans.PropertyDescriptor.findPropertyType(PropertyDescriptor.java:657)
at java.beans.PropertyDescriptor.setWriteMethod(PropertyDescriptor.java:327)
at java.beans.PropertyDescriptor.<init>(PropertyDescriptor.java:139)
at org.apache.commons.beanutils.FluentPropertyBeanIntrospector.createFluentPropertyDescritor(FluentPropertyBeanIntrospector.java:177)
at org.apache.commons.beanutils.FluentPropertyBeanIntrospector.introspect(FluentPropertyBeanIntrospector.java:140)
at org.apache.commons.beanutils.PropertyUtilsBean.fetchIntrospectionData(PropertyUtilsBean.java:2234)
at org.apache.commons.beanutils.PropertyUtilsBean.getIntrospectionData(PropertyUtilsBean.java:2215)
at org.apache.commons.beanutils.PropertyUtilsBean.getPropertyDescriptor(PropertyUtilsBean.java:950)
at org.apache.commons.beanutils.PropertyUtilsBean.isWriteable(PropertyUtilsBean.java:1466)
at org.apache.commons.configuration2.beanutils.BeanHelper.isPropertyWriteable(BeanHelper.java:521)
at org.apache.commons.configuration2.beanutils.BeanHelper.initProperty(BeanHelper.java:357)
at org.apache.commons.configuration2.beanutils.BeanHelper.initBeanProperties(BeanHelper.java:273)
at org.apache.commons.configuration2.beanutils.BeanHelper.initBean(BeanHelper.java:192)
at org.apache.commons.configuration2.beanutils.BeanHelper$BeanCreationContextImpl.initBean(BeanHelper.java:669)
at org.apache.commons.configuration2.beanutils.DefaultBeanFactory.initBeanInstance(DefaultBeanFactory.java:162)
at org.apache.commons.configuration2.beanutils.DefaultBeanFactory.createBean(DefaultBeanFactory.java:116)
at org.apache.commons.configuration2.beanutils.BeanHelper.createBean(BeanHelper.java:459)
at org.apache.commons.configuration2.beanutils.BeanHelper.createBean(BeanHelper.java:479)
at org.apache.commons.configuration2.beanutils.BeanHelper.createBean(BeanHelper.java:492)
at org.apache.commons.configuration2.builder.BasicConfigurationBuilder.createResultInstance(BasicConfigurationBuilder.java:447)
at org.apache.commons.configuration2.builder.BasicConfigurationBuilder.createResult(BasicConfigurationBuilder.java:417)
at org.apache.commons.configuration2.builder.BasicConfigurationBuilder.getConfiguration(BasicConfigurationBuilder.java:285)",org.apache.commons.configuration2.builder.TestPropertiesBuilderParametersImpl
METHOD,math,MATH-1021,2013-08-10T00:00:22.000-05:00,HypergeometricDistribution.sample suffers from integer overflow,"HypergeometricDistribution.sample()  
 {code}
 import org.apache.commons.math3.distribution.HypergeometricDistribution;

public class Foo {
  public static void main(String[] args) {
    HypergeometricDistribution a = new HypergeometricDistribution(
        43130568, 42976365, 50);
    System.out.printf(""%d %d%n"", a.getSupportLowerBound(), a.getSupportUpperBound()); // Prints ""0 50""
    System.out.printf(""%d%n"",a.sample());                                             // Prints ""-50""
  }
}
 {code}

  HypergeometricDistribution.getNumericalMean()  
 {code}
 return (double) (getSampleSize() * getNumberOfSuccesses()) / (double) getPopulationSize();
{code}
 
 {code}
 return getSampleSize() * ((double) getNumberOfSuccesses() / (double) getPopulationSize());
{code}
Hi, I have an application which broke when ported from commons math 2.2 to 3.2.
It looks like the HypergeometricDistribution.sample() method doesn't work as well as it used to with large integer values -- the example code below should return a sample between 0 and 50, but usually returns -50.
{code}
import org.apache.commons.math3.distribution.HypergeometricDistribution;
public class Foo {
  public static void main(String[] args) {
    HypergeometricDistribution a = new HypergeometricDistribution(
        43130568, 42976365, 50);
    System.out.printf(""%d %d%n"", a.getSupportLowerBound(), a.getSupportUpperBound()); // Prints ""0 50""
    System.out.printf(""%d%n"",a.sample());                                             // Prints ""-50""
  }
}
{code}
In the debugger, I traced it as far as an integer overflow in HypergeometricDistribution.getNumericalMean() -- instead of doing
{code}
return (double) (getSampleSize() * getNumberOfSuccesses()) / (double) getPopulationSize();
{code}
it could do:
{code}
return getSampleSize() * ((double) getNumberOfSuccesses() / (double) getPopulationSize());
{code}
This seemed to fix it, based on a quick test.",org.apache.commons.math3.distribution.HypergeometricDistribution:getNumericalMean()
METHOD,math,MATH-221,2008-08-29T13:31:56.000-05:00,Result of multiplying and equals for complex numbers is wrong,"class Complex  
 {code}
 import org.apache.commons.math.complex.*;
public class TestProg {
        public static void main(String[] args) {

                ComplexFormat f = new ComplexFormat();
                Complex c1 = new Complex(0,1);
                Complex c2 = new Complex(-1,0);

                Complex res = c1.multiply(c2);
                Complex comp = new Complex(0,-1);

                System.out.println(""res:  ""+f.format(res));
                System.out.println(""comp: ""+f.format(comp));

                System.out.println(""res=comp: ""+res.equals(comp));
        }
}
 {code}
Hi.
The bug relates on complex numbers.
The methods ""multiply"" and ""equals"" of the class Complex are involved.
mathematic background:  (0,i) * (-1,0i) = (0,-i).
show bug show java program + output
-----------------------------------------------------------------------
{code}
import org.apache.commons.math.complex.
*;
public class TestProg {
public static void main(String[] args) {
ComplexFormat f = new ComplexFormat();
                Complex c1 = new Complex(0,1);
                Complex c2 = new Complex(-1,0);
Complex res = c1.multiply(c2);
                Complex comp = new Complex(0,-1);
System.out.println(""res:  ""+f.format(res));
                System.out.println(""comp: ""+f.format(comp));
System.out.println(""res=comp: ""+res.equals(comp));
}
}
{code}
-----------------------------------------------------------------------
res:  -0 - 1i
comp: 0 - 1i
res=comp: false
-----------------------------------------------------------------------
The problem could either be the ""multiply"" method that gives (-0,-1i) instead of (0,-1i),
or if you think thats right, the equals method has to be modified.
Good Luck
Dieter",org.apache.commons.math.complex.Complex:equals(Object)
METHOD,math,MATH-318,2009-11-06T15:09:36.000-06:00,wrong result in eigen decomposition,"{code}
     public void testMathpbx02() {

        double[] mainTridiagonal = {
        	  7484.860960227216, 18405.28129035345, 13855.225609560746,
        	 10016.708722343366, 559.8117399576674, 6750.190788301587, 
        	    71.21428769782159
        };
        double[] secondaryTridiagonal = {
        	 -4175.088570476366,1975.7955858241994,5193.178422374075, 
        	  1995.286659169179,75.34535882933804,-234.0808002076056
        };

        // the reference values have been computed using routine DSTEMR
        // from the fortran library LAPACK version 3.2.1
        double[] refEigenValues = {
        		20654.744890306974412,16828.208208485466457,
        		6893.155912634994820,6757.083016675340332,
        		5887.799885688558788,64.309089923240379,
        		57.992628792736340
        };
        RealVector[] refEigenVectors = {
        		new ArrayRealVector(new double[] {-0.270356342026904, 0.852811091326997, 0.399639490702077, 0.198794657813990, 0.019739323307666, 0.000106983022327, -0.000001216636321}),
        		new ArrayRealVector(new double[] {0.179995273578326,-0.402807848153042,0.701870993525734,0.555058211014888,0.068079148898236,0.000509139115227,-0.000007112235617}),
        		new ArrayRealVector(new double[] {-0.399582721284727,-0.056629954519333,-0.514406488522827,0.711168164518580,0.225548081276367,0.125943999652923,-0.004321507456014}),
        		new ArrayRealVector(new double[] {0.058515721572821,0.010200130057739,0.063516274916536,-0.090696087449378,-0.017148420432597,0.991318870265707,-0.034707338554096}),
        		new ArrayRealVector(new double[] {0.855205995537564,0.327134656629775,-0.265382397060548,0.282690729026706,0.105736068025572,-0.009138126622039,0.000367751821196}),
        		new ArrayRealVector(new double[] {-0.002913069901144,-0.005177515777101,0.041906334478672,-0.109315918416258,0.436192305456741,0.026307315639535,0.891797507436344}),
        		new ArrayRealVector(new double[] {-0.005738311176435,-0.010207611670378,0.082662420517928,-0.215733886094368,0.861606487840411,-0.025478530652759,-0.451080697503958})
        };

        // the following line triggers the exception
        EigenDecomposition decomposition =
            new EigenDecompositionImpl(mainTridiagonal, secondaryTridiagonal, MathUtils.SAFE_MIN);

        double[] eigenValues = decomposition.getRealEigenvalues();
        for (int i = 0; i < refEigenValues.length; ++i) {
            assertEquals(refEigenValues[i], eigenValues[i], 1.0e-3);
            if (refEigenVectors[i].dotProduct(decomposition.getEigenvector(i)) < 0) {
                assertEquals(0, refEigenVectors[i].add(decomposition.getEigenvector(i)).getNorm(), 1.0e-5);
            } else {
                assertEquals(0, refEigenVectors[i].subtract(decomposition.getEigenvector(i)).getNorm(), 1.0e-5);
            }
        }

    }
 {code}
Some results computed by EigenDecompositionImpl are wrong.
The following case computed by Fortran Lapack fails with version 2.0
{code}
    public void testMathpbx02() {
double[] mainTridiagonal = {
7484.860960227216, 18405.28129035345, 13855.225609560746,
10016.708722343366, 559.8117399576674, 6750.190788301587,
71.21428769782159
};
double[] secondaryTridiagonal = {
-4175.088570476366,1975.7955858241994,5193.178422374075,
1995.286659169179,75.34535882933804,-234.0808002076056
};
// the reference values have been computed using routine DSTEMR
// from the fortran library LAPACK version 3.2.1
double[] refEigenValues = {
20654.744890306974412,16828.208208485466457,
6893.155912634994820,6757.083016675340332,
5887.799885688558788,64.309089923240379,
57.992628792736340
};
RealVector[] refEigenVectors = {
new ArrayRealVector(new double[] {-0.270356342026904, 0.852811091326997, 0.399639490702077, 0.198794657813990, 0.019739323307666, 0.000106983022327, -0.000001216636321}),
new ArrayRealVector(new double[] {0.179995273578326,-0.402807848153042,0.701870993525734,0.555058211014888,0.068079148898236,0.000509139115227,-0.000007112235617}),
new ArrayRealVector(new double[] {-0.399582721284727,-0.056629954519333,-0.514406488522827,0.711168164518580,0.225548081276367,0.125943999652923,-0.004321507456014}),
new ArrayRealVector(new double[] {0.058515721572821,0.010200130057739,0.063516274916536,-0.090696087449378,-0.017148420432597,0.991318870265707,-0.034707338554096}),
new ArrayRealVector(new double[] {0.855205995537564,0.327134656629775,-0.265382397060548,0.282690729026706,0.105736068025572,-0.009138126622039,0.000367751821196}),
new ArrayRealVector(new double[] {-0.002913069901144,-0.005177515777101,0.041906334478672,-0.109315918416258,0.436192305456741,0.026307315639535,0.891797507436344}),
new ArrayRealVector(new double[] {-0.005738311176435,-0.010207611670378,0.082662420517928,-0.215733886094368,0.861606487840411,-0.025478530652759,-0.451080697503958})
};
// the following line triggers the exception
        EigenDecomposition decomposition =
            new EigenDecompositionImpl(mainTridiagonal, secondaryTridiagonal, MathUtils.SAFE_MIN);
double[] eigenValues = decomposition.getRealEigenvalues();
        for (int i = 0; i < refEigenValues.length; ++i) {
            assertEquals(refEigenValues[i], eigenValues[i], 1.0e-3);
            if (refEigenVectors[i].
dotProduct(decomposition.getEigenvector(i)) < 0) {
                assertEquals(0, refEigenVectors[i].
add(decomposition.getEigenvector(i)).
getNorm(), 1.0e-5);
            } else {
                assertEquals(0, refEigenVectors[i].
subtract(decomposition.getEigenvector(i)).
getNorm(), 1.0e-5);
            }
        }
}
{code}","org.apache.commons.math.linear.EigenDecompositionImpl:flipIfWarranted(int, int)"
METHOD,math,MATH-358,2010-03-24T17:25:37.000-05:00,ODE integrator goes past specified end of integration range,"{code}
   public void testMissedEvent() throws IntegratorException, DerivativeException {
          final double t0 = 1878250320.0000029;
          final double t =  1878250379.9999986;
          FirstOrderDifferentialEquations ode = new FirstOrderDifferentialEquations() {
            
            public int getDimension() {
                return 1;
            }
            
            public void computeDerivatives(double t, double[] y, double[] yDot)
                throws DerivativeException {
                yDot[0] = y[0] * 1.0e-6;
            }
        };

        DormandPrince853Integrator integrator = new DormandPrince853Integrator(0.0, 100.0,
                                                                               1.0e-10, 1.0e-10);

        double[] y = { 1.0 };
        integrator.setInitialStepSize(60.0);
        double finalT = integrator.integrate(ode, t0, y, t, y);
        Assert.assertEquals(t, finalT, 1.0e-6);
    }

 {code}
End of integration range in ODE solving is handled as an event.
In some cases, numerical accuracy in events detection leads to error in events location.
The following test case shows the end event is not handled properly and an integration that should cover a 60s range in fact covers a 160s range, more than twice the specified range.
{code}
public void testMissedEvent() throws IntegratorException, DerivativeException {
final double t0 = 1878250320.0000029;
final double t =  1878250379.9999986;
FirstOrderDifferentialEquations ode = new FirstOrderDifferentialEquations() {
public int getDimension() {
return 1;
}
public void computeDerivatives(double t, double[] y, double[] yDot)
throws DerivativeException {
yDot[0] = y[0] * 1.0e-6;
}
};
DormandPrince853Integrator integrator = new DormandPrince853Integrator(0.0, 100.0,
1 0e-10, 1.0e-10);
double[] y = { 1.0 };
        integrator.setInitialStepSize(60.0);
        double finalT = integrator.integrate(ode, t0, y, t, y);
        Assert.assertEquals(t, finalT, 1.0e-6);
    }
{code}","org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator:integrate(FirstOrderDifferentialEquations, double, double[], double, double[])
org.apache.commons.math.ode.nonstiff.RungeKuttaIntegrator:integrate(FirstOrderDifferentialEquations, double, double[], double, double[])"
METHOD,math,MATH-60,2006-05-14T04:20:21.000-05:00,"[math] Function math.fraction.ProperFractionFormat.parse(String, ParsePosition) return illogical result","Fraction parse(String source, 
ParsePostion pos)  class ProperFractionFormat  
 ProperFractionFormat properFormat = new ProperFractionFormat();
result = null;
String source = ""1 -1 / 2"";
ParsePosition pos = new ParsePosition(0);

//Test 1 : fail 
 public void testParseNegative(){
 
   String source = ""-1 -2 / 3"";
   ParsePosition pos = new ParsePosition(0);

   Fraction actual = properFormat.parse(source, pos);
   assertNull(actual);
}

// Test2: success
 public void testParseNegative(){
 
   String source = ""-1 -2 / 3"";
   ParsePosition pos = new ParsePosition(0);

   Fraction actual = properFormat.parse(source, pos);  // return Fraction 1/3
   assertEquals(1, source.getNumerator());
   assertEquals(3, source.getDenominator());
}

 
 parse(String, ParsePosition)
Hello,
I find illogical returned result from function ""Fraction parse(String source,
ParsePostion pos)"" (in class ProperFractionFormat of the Fraction Package) of the Commons Math library.
see following code segment for more details
""
ProperFractionFormat properFormat = new ProperFractionFormat();
result = null;
String source = ""1 -1 / 2"";
ParsePosition pos = new ParsePosition(0);
//Test 1 : fail public void testParseNegative(){
String source = ""-1 -2 / 3"";
ParsePosition pos = new ParsePosition(0);
Fraction actual = properFormat.parse(source, pos);
assertNull(actual);
}
// Test2: success public void testParseNegative(){
String source = ""-1 -2 / 3"";
ParsePosition pos = new ParsePosition(0);
Fraction actual = properFormat.parse(source, pos);  // return Fraction 1/3 assertEquals(1, source.getNumerator());
assertEquals(3, source.getDenominator());
}
""
pass in following inputs
Function ""Fraction parse(String, ParsePosition)"" returned Fraction 1/3 (means the result Fraction had numerator = 1 and  denominator = 3)for all 3 inputs above.
I think the function does not handle parsing the numberator/ denominator properly incase input string provide invalid numerator/denominator.
Thank you!","org.apache.commons.math.fraction.ProperFractionFormat:parse(String, ParsePosition)"
METHOD,math,MATH-836,2012-07-31T17:04:25.000-05:00,"Fraction(double, int) constructor_ strange behaviour","public Fraction(double value, int maxDenominator)
        throws FractionConversionException
    {
       this(value, 0, maxDenominator, 100);
    }
The Fraction constructor_ Fraction(double, int) takes a double value and a int maximal denominator, and approximates a fraction.
1: the constructor_ returns a positive Fraction.
Calling Fraction(-33655.1677817278, 371880) returns the fraction 410517235/243036, which both has the wrong sign, and is far away from the absolute value of the given value
2: the constructor_ does not manage to reduce the Fraction properly.
Calling Fraction(-43979.60679604749, 366081) returns the fraction -1651878166/256677, which should have* been reduced to -24654898/3831.
I have, as of yet, not found a solution.
The constructor_ looks like this:
public Fraction(double value, int maxDenominator)
throws FractionConversionException
{ this(value, 0, maxDenominator, 100);
}
Increasing the 100 value (max iterations) does not fix the problem for all cases.
Changing the 0-value (the epsilon, maximum allowed error) to something small does not work either, as this breaks the tests in FractionTest.
The problem is not neccissarily that the algorithm is unable to approximate a fraction correctly.
A solution where a FractionConversionException had been thrown in each of these examples would probably be the best solution if an improvement on the approximation algorithm turns out to be hard to find.
This bug has been found when trying to explore the idea of axiom-based testing (http://bldl.ii.uib.no/testing.html).
Attached is a java test class FractionTestByAxiom (junit, goes into org.apache.commons.math3.fraction) which shows these bugs through a simplified approach to this kind of testing, and a text file describing some of the value/maxDenominator combinations which causes one of these failures.
* It is never specified in the documentation that the Fraction class guarantees that completely reduced rational numbers are constructed, but a comment inside the equals method claims that ""since fractions are always in lowest terms, numerators and can be compared directly for equality"", so it seems like this is the intention.","org.apache.commons.math3.fraction.Fraction:Fraction(double, double, int, int)"
METHOD,math,MATH-949,2013-03-15T18:11:56.000-05:00,LevenbergMarquardtOptimizer reports 0 iterations,"LevenbergMarquardtOptimizer.getIterations()     BaseOptimizer.incrementEvaluationsCount()

 
 {noformat}
     @Test
    public void testGetIterations() {
        // setup
        LevenbergMarquardtOptimizer otim = new LevenbergMarquardtOptimizer();

        // action
        otim.optimize(new MaxEval(100), new Target(new double[] { 1 }),
                new Weight(new double[] { 1 }), new InitialGuess(
                        new double[] { 3 }), new ModelFunction(
                        new MultivariateVectorFunction() {
                            @Override
                            public double[] value(double[] point)
                                    throws IllegalArgumentException {
                                return new double[] { FastMath.pow(point[0], 4) };
                            }
                        }), new ModelFunctionJacobian(
                        new MultivariateMatrixFunction() {
                            @Override
                            public double[][] value(double[] point)
                                    throws IllegalArgumentException {
                                return new double[][] { { 0.25 * FastMath.pow(
                                        point[0], 3) } };
                            }
                        }));

        // verify
        assertThat(otim.getEvaluations(), greaterThan(1));
        assertThat(otim.getIterations(), greaterThan(1));
    }

 {noformat}
The method LevenbergMarquardtOptimizer.getIterations() does not report the correct number of iterations; It always returns 0.
A quick look at the code shows that only SimplexOptimizer calls BaseOptimizer.incrementEvaluationsCount()
put test case
Notice how the evaluations count is correctly incremented, but the iterations count is not.
{noformat}
    @Test
    public void testGetIterations() {
        // setup
        LevenbergMarquardtOptimizer otim = new LevenbergMarquardtOptimizer();
// action
otim.optimize(new MaxEval(100), new Target(new double[] { 1 }),
new Weight(new double[] { 1 }), new InitialGuess(
new double[] { 3 }), new ModelFunction(
new MultivariateVectorFunction() {
@Override
public double[] value(double[] point)
throws IllegalArgumentException {
return new double[] { FastMath.pow(point[0], 4) };
}
}), new ModelFunctionJacobian(
new MultivariateMatrixFunction() {
@Override
public double[][] value(double[] point)
throws IllegalArgumentException {
return new double[][] { { 0.25 * FastMath.pow(
point[0], 3) } };
}
}));
// verify
        assertThat(otim.getEvaluations(), greaterThan(1));
        assertThat(otim.getIterations(), greaterThan(1));
    }
{noformat}","org.apache.commons.math3.optim.nonlinear.scalar.gradient.NonLinearConjugateGradientOptimizer:doOptimize()
org.apache.commons.math3.optim.nonlinear.scalar.noderiv.CMAESOptimizer:doOptimize()
org.apache.commons.math3.optim.nonlinear.vector.jacobian.GaussNewtonOptimizer:doOptimize()
org.apache.commons.math3.optim.nonlinear.scalar.noderiv.SimplexOptimizer:doOptimize()
org.apache.commons.math3.optim.BaseOptimizer:BaseOptimizer(ConvergenceChecker<PAIR>)
org.apache.commons.math3.optim.nonlinear.scalar.noderiv.PowellOptimizer:doOptimize()
org.apache.commons.math3.optim.nonlinear.vector.jacobian.LevenbergMarquardtOptimizer:doOptimize()"
FILE,WFCORE,WFCORE-267,2014-11-19T19:47:31.000-06:00,CLI prints output twice if using cli client jar,"INFO: {




    ""outcome"" => ""success"",




    ""result"" => [




        ""core-service"",




        ""deployment"",




        ""deployment-overlay"",




        ""extension"",




        ""interface"",




        ""path"",




        ""socket-binding-group"",




        ""subsystem"",




        ""system-property""




    ]




}




{




    ""outcome"" => ""success"",




    ""result"" => [




        ""core-service"",




        ""deployment"",




        ""deployment-overlay"",




        ""extension"",




        ""interface"",




        ""path"",




        ""socket-binding-group"",




        ""subsystem"",




        ""system-property""




    ]




}
If you are using the CLI client jar, all output is printed twice.
This is because JBoss logging is not set up and by default CommandContextImpl is printing log messages to standard out.
The output will look something like this:
[standalone@localhost:9999 /] :read-children-types
Nov 19, 2014 8:57:19 AM org.jboss.as.cli.impl.CommandContextImpl printLine
INFO: {
""outcome"" => ""success"",
""result"" => [
""core-service"",
""deployment"",
""deployment-overlay"",
""extension"",
""interface"",
""path"",
""socket-binding-group"",
""subsystem"",
""system-property""
]
}
{
""outcome"" => ""success"",
""result"" => [
""core-service"",
""deployment"",
""deployment-overlay"",
""extension"",
""interface"",
""path"",
""socket-binding-group"",
""subsystem"",
""system-property""
]
}",org.jboss.as.cli.CommandLineMain
FILE,WFCORE,WFCORE-495,2015-01-12T08:48:29.000-06:00,"WFLY won't startup due to ""WFLYCTL0212: Duplicate resource [(\""deployment\"" => \""xxx.war\"")]""","file(standalone.xml)  file(standalone.xml)
WFLY won't startup due to ""WFLYCTL0212: Duplicate resource [(\""deployment\"" => \""xxx.war\"")]""
firstly deploy
deploy 2nd time
After server restart, it shows:
15:26:26,913 INFO  [org.jboss.as] (MSC service thread 1-8) WFLYSRV0049: WildFly Full 9.0.0.Alpha2-SNAPSHOT (WildFly Core 1.0.0.
Alpha15) starting
15:26:27,133 ERROR [org.jboss.as.controller.management-operation] (Controller Boot Thread) WFLYCTL0013: Operation (""add"") failed - address: ([(""deployment"" => ""xxx.war"")]) - failure description: ""WFLYCTL0212: Duplicate resource [(\""deployment\"" => \""xxx.war\"")]""
15:26:27,136 FATAL [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0056: Server boot has failed in an unrecoverable manner; exiting.
See previous messages for details.
15:26:27,138 INFO  [org.jboss.as.server] (Thread-2) WFLYSRV0220: Server shutdown has been requested.
15:26:27,153 INFO  [org.jboss.as] (MSC service thread 1-1) WFLYSRV0050: WildFly Full 9.0.0.Alpha2-SNAPSHOT (WildFly Core 1.0.0.
Alpha15) stopped in 4ms
steps to reproduce:
start wildfly
3. restart wildfly to see the error message.
This happens because step 2 does a ""full-replace-deployment"" operation which does not remove content from standalone/data/content/aa/2d0425dd53572294d591b56efdee2680539eaf/content and deployment info from configuration file(standalone.xml).
Therefore, you will have xxx.war in standalone/data/content and configuration file(standalone.xml), also a xxx.war and xxx.war.deployed file inside /standalone/deployments.
A second time server restart will cause a duplicate resource error.",org.jboss.as.server.deployment.DeploymentFullReplaceHandler
FILE,WFCORE,WFCORE-604,2015-03-18T09:19:35.000-05:00,"After failed to deploy, remain deployment information in JBOSS_HOME/{standalone|domaine}/data/content directory","{standalone|domaine} 
 {standalone|domaine}  
 {standalone|domaine} 
 {standalone|domaine} 
 {standalone|domaine}
Description of problem:
===
- After failed to deploy, remain deployment information in JBOSS_HOME/{standalone|domaine}/data/content directory
- Please see following reproduce steps.
How reproducible:
===
Steps to Reproduce:
fix deployment to deploy fix success to deploy
4. Find ""new"" deployment info in JBOSS_HOME/{standalone|domaine}/data/content, and the old deployment info will be still there.
- I know that as we changed application in step-3, its hash value was changed.
And then, old info is remained in JBOSS_HOME/{standalone|domaine}/data/content.
But I think it always happens and should be fixed.
Actual results:
- The deployment information which created when deploy was failed remains in JBOSS_HOME/{standalone|domaine}/data/content.
Expected results:","org.jboss.as.host.controller.mgmt.MasterDomainControllerOperationHandlerImpl
org.jboss.as.server.controller.resources.ServerRootResourceDefinition
org.jboss.as.host.controller.ManagedServerOperationsFactory
org.jboss.as.host.controller.DomainModelControllerService
org.jboss.as.host.controller.RemoteDomainConnectionService
org.jboss.as.test.shared.ModelParserUtils
org.jboss.as.server.deployment.DeploymentAddHandler
org.jboss.as.domain.controller.operations.deployment.ServerGroupDeploymentAddHandler
org.jboss.as.server.logging.ServerLogger
org.jboss.as.server.deployment.DeploymentRemoveHandler
org.jboss.as.domain.controller.resources.ServerGroupResourceDefinition
org.jboss.as.repository.LocalDeploymentFileRepository
org.jboss.as.domain.controller.operations.ApplyRemoteMasterDomainModelHandler
org.jboss.as.server.deployment.DeploymentReplaceHandler
org.jboss.as.domain.controller.resources.DomainRootDefinition
org.jboss.as.server.deploymentoverlay.DeploymentOverlayContentDefinition
org.jboss.as.repository.logging.DeploymentRepositoryLogger
org.jboss.as.domain.controller.operations.deployment.DeploymentFullReplaceHandler
org.jboss.as.core.model.test.LegacyKernelServicesImpl
org.jboss.as.subsystem.test.TestModelControllerService
org.jboss.as.host.controller.HostControllerService
org.jboss.as.domain.controller.resources.DomainDeploymentResourceDefinition
org.jboss.as.core.model.test.TestModelControllerService
org.jboss.as.server.mgmt.domain.RemoteFileRepositoryService
org.jboss.as.server.deploymentoverlay.DeploymentOverlayContentAdd
org.jboss.as.server.ApplicationServerService
org.jboss.as.repository.LocalFileRepository
org.jboss.as.domain.controller.operations.deployment.ServerGroupDeploymentRemoveHandler
org.jboss.as.management.client.content.ManagedDMRContentTypeAddHandler
org.jboss.as.server.test.InterfaceManagementUnitTestCase
org.jboss.as.host.controller.model.host.HostResourceDefinition
org.jboss.as.server.deployment.DeploymentAddHandlerTestCase
org.jboss.as.repository.DeploymentFileRepository
org.jboss.as.domain.controller.operations.deployment.ServerGroupDeploymentReplaceHandler
org.jboss.as.repository.ContentRepository
org.jboss.as.domain.controller.operations.deployment.DeploymentAddHandler
org.jboss.as.domain.controller.operations.deployment.DeploymentRemoveHandler
org.jboss.as.management.client.content.ManagedDMRContentTypeResource
org.jboss.as.host.controller.mgmt.ServerToHostProtocolHandler
org.jboss.as.server.deployment.DeploymentFullReplaceHandler"
FILE,WFCORE,WFCORE-626,2015-04-06T15:53:19.000-05:00,Global list-get operation can inadvertently create list elements,"clear(name=attribute)
  get(name=attribute, index=0)
  add(name=attribute, value=test)
  get(name=attribute, index=0)
consider following sequence of operations
:list-clear(name=attribute)
:list-get(name=attribute, index=0)
:list-add(name=attribute, value=test)
:list-get(name=attribute, index=0)
#2 will return <undefined> as expected.
However, it returns <undefined>.
This is because #2 will create the missing element at index 0 causing #3 to operate on index 1.","org.jboss.as.controller.operations.global.ListOperations
org.jboss.as.controller.operations.global.MapOperations"
FILE,WFCORE,WFCORE-716,2015-05-27T10:21:36.000-05:00,Once server in reload-required state capabilities no longer checked at stage Model.,"attribute(name=security-realm)




 {




    ""outcome"" => ""success"",




    ""response-headers"" => {




        ""operation-requires-reload"" => true,




        ""process-state"" => ""reload-required""




    }




 
 attribute(name=security-domain, value=MgMtDom)




 {




    ""outcome"" => ""success"",




    ""response-headers"" => {




        ""operation-requires-reload"" => true,




        ""process-state"" => ""reload-required""




    }
Once a server is in the state reload-required capabilities and requirements are no longer checked e.g.: -
[standalone@localhost:9990 /] .
/core-service=management/management-interface=http-interface:undefine-attribute(name=security-realm)
{
""outcome"" => ""success"",
""response-headers"" => {
""operation-requires-reload"" => true,
""process-state"" => ""reload-required""
}
}
reference non-existent capability
[standalone@localhost:9990 /] .
/core-service=management/management-interface=http-interface:write-attribute(name=security-domain, value=MgMtDom)
{
""outcome"" => ""success"",
""response-headers"" => {
""operation-requires-reload"" => true,
""process-state"" => ""reload-required""
}
}
When I execute :reload it will fail: -
11:21:18,567 ERROR [org.jboss.as.controller.management-operation] (Controller Boot Thread) WFLYCTL0013: Operation (""add"") failed - address: ([
(""core-service"" => ""management""),
(""management-interface"" => ""http-interface"")
]): java.lang.IllegalStateException: WFLYCTL0364: Capability 'org.wildfly.security.security-domain.
MgMtDom' is unknown.
at org.jboss.as.controller.ModelControllerImpl$CapabilityRegistryImpl.getCapabilityRegistration(ModelControllerImpl.java:1388)",org.jboss.as.controller.CapabilityReferenceRecorder
FILE,WFCORE,WFCORE-815,2015-07-13T07:57:45.000-05:00,One profile can have more ancestors with same submodules,"add(name=includes, value=mail-01)
  add(name=includes, value=mail-02)

 
 {




    ""outcome"" => ""failed"",




    ""failure-description"" => {""domain-failure-description"" => ""WFLYCTL0401: Profile 'mail-01' defines subsystem 'mail' which is also defined in its ancestor profile 'mail-02'. Overriding subsystems is not supported""} 
 add(name=includes, value=mail-01)
  add(name=includes, value=mail-02)
Description of problem:
One profile can have more ancestors with same submodules.
It leads to WFLYCTL0212: Duplicate resource [(""subsystem"" => ""subsystem_name"")] .
Hierarchical composition of profiles was added to AS with EAP7-281 and WFCORE-382
How reproducible:
Always
Steps to Reproduce:
get fresh EAP
.
/domain.sh
.
/jboss-cli.sh -c
/profile=mail-01:add
/profile=mail-02:add
/profile=mail-01/subsystem=mail:add
/profile=mail-02/subsystem=mail:add
/profile=default-new:add
/profile=default-new:list-add(name=includes, value=mail-01)
/profile=default-new:list-add(name=includes, value=mail-02)
Actual results:
Expected results:
{
""outcome"" => ""failed"",
""failure-description"" => {""domain-failure-description"" => ""WFLYCTL0401: Profile 'mail-01' defines subsystem 'mail' which is also defined in its ancestor profile 'mail-02'.
Overriding subsystems is not supported""},
""rolled-back"" => true
}
Workaround:
Add any subsystem to default-new profile:
/profile=mail-01:add
/profile=mail-02:add
/profile=mail-01/subsystem=mail:add
/profile=mail-02/subsystem=mail:add
/profile=default-new:add
/profile=default-new/subsystem=jdr:add
/profile=default-new:list-add(name=includes, value=mail-01)
/profile=default-new:list-add(name=includes, value=mail-02)","org.jboss.as.domain.controller.operations.ProfileIncludesHandlerTestCase
org.jboss.as.domain.controller.operations.SocketBindingGroupIncludesHandlerTestCase
org.jboss.as.host.controller.logging.HostControllerLogger"
FILE,WFCORE,WFCORE-955,2015-08-27T14:34:07.000-05:00,Server is not responding after attempt to set parent of profile to non-existent profile,"add()
 
 {




    ""outcome"" => ""failed"",




    ""failure-description"" => ""java.lang.NullPointerException:null""




}




 
 add()
Description of problem:
Server is not responding after attempt to set parent of profile to non-existent profile.
Server is not responding also after attempt to set parent of socket-binding-group to non-existent socket-binding-group.
This works correctly on wildfly-core (2.0.0.
Beta4).
But this occurs on wildfly (master branch) and on EAP 7.0.0.
DR9. It may be some integration issue.
Priority of this jira tends to be critical.
How reproducible:
Always
Steps to Reproduce (profile):
get fresh EAP
.
/domain.sh
.
/jboss-cli.sh
/profile=new:add()
/profile=new:write-attribute(name=includes,value=[nonsence])
/profile=new:remove
Actual results:
[domain@localhost:9990 /] /profile=new:write-attribute(name=includes,value=[nonsence])
{
""outcome"" => ""failed"",
""failure-description"" => ""java.lang.NullPointerException:null""
}
[domain@localhost:9990 /] /profile=new:remove
server needs to be restarted
Expected results:
[domain@localhost:9990 /] /profile=new:write-attribute(name=includes,value=[nonsence])
{
""outcome"" => ""failed"",
""failure-description"" => {""domain-failure-description"" => ""WFLYCTL0369: Required capabilities are not available:
org.wildfly.domain.profile.nonsence in context 'profiles'""},
""rolled-back"" => true
}
[domain@localhost:9990 /] /profile=new:remove
{
""outcome"" => ""success"",
""result"" => undefined,
""server-groups"" => undefined
}
Steps to reproduce (socket-binding-group):
get fresh EAP
.
/domain.sh
.
/jboss-cli.sh
/profile=new:add()
/socket-binding-group=testt:add(default-interface=public,includes=[nonsence])
/profile=new:remove","org.jboss.as.controller.OperationContextImpl
org.jboss.as.controller.AbstractOperationContext
org.jboss.as.controller.logging.ControllerLogger
org.jboss.as.controller.SocketCapabilityResolutionUnitTestCase
org.jboss.as.controller.capability.registry.IncludingResourceCapabilityScope
org.jboss.as.controller.AbstractCapabilityResolutionTestCase"
FILE,WFCORE,WFCORE-876,2015-08-12T07:52:43.000-05:00,Reload or Shutdown inside IF statement is performed before the if/else block batch is executed,"resource()
Executing a reload or shutdown inside an if/else block results in the reload or restart occurring before the other commands in the batch are executed.
if (outcome == success) of /subsystem=logging/logger=org.jboss.as.cli:read-resource()
/subsystem=logging:write-attribute(name=use-deployment-logging-config
shutdown --restart=true
end-if
This command will actually leave the server in a reload-required state.
The shutdown, or reload, will occur before the write-attribute is executed.","org.jboss.as.cli.handlers.trycatch.TryCatchFinallyControlFlow
org.jboss.as.test.integration.management.cli.ifelse.NonExistingPathComparisonTestCase
org.jboss.as.test.integration.management.cli.TryCatchFinallyTestCase
org.jboss.as.cli.handlers.ifelse.IfElseControlFlow
org.jboss.as.test.integration.management.cli.ifelse.BasicIfElseTestCase"
FILE,WFCORE,WFCORE-1007,2015-09-24T06:45:11.000-05:00,Warnings about missing notification descriptions when an operation removes an extension,"migrate()




 {




    ""outcome"" => ""success"",




    ""result"" => {""migration-warnings"" => []}




 
 migrate()




 {




    ""outcome"" => ""success"",




    ""result"" => {""migration-warnings"" => []}




 
 migrate()




 {




    ""outcome"" => ""success"",




    ""result"" => {""migration-warnings"" => []}
When I use migration operation the console log is filled with warning messages of type
WARN  [org.jboss.as.controller] (management-handler-thread - 1) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [(""subsystem"" => ""jacorb"")]
This is the same either for jacorb or web or messaging subsystem.
do sequence of operation
[standalone@localhost:9999 /] /subsystem=jacorb:migrate()
{
""outcome"" => ""success"",
""result"" => {""migration-warnings"" => []}
}
[standalone@localhost:9999 /] /subsystem=messaging:migrate()
{
""outcome"" => ""success"",
""result"" => {""migration-warnings"" => []}
}
[standalone@localhost:9999 /] /subsystem=we
web  webservices  weld
[standalone@localhost:9999 /] /subsystem=web
web  webservices
[standalone@localhost:9999 /] /subsystem=web:migrate()
{
""outcome"" => ""success"",
""result"" => {""migration-warnings"" => []}
}
then I the log looks like
2015-09-24 08:41:09,729 WARN  [org.jboss.as.controller] (management-handler-thread - 1) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [(""subsystem"" => ""jacorb"")]
2015-09-24 08:43:13,229 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""jms-queue"" => ""DLQ"")
]
2015-09-24 08:43:13,230 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""jms-queue"" => ""ExpiryQueue"")
]
2015-09-24 08:43:13,230 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""pooled-connection-factory"" => ""hornetq-ra"")
]
2015-09-24 08:43:13,230 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""connection-factory"" => ""RemoteConnectionFactory"")
]
2015-09-24 08:43:13,231 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""connection-factory"" => ""InVmConnectionFactory"")
]
2015-09-24 08:43:13,231 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""address-setting"" => ""#"")
]
2015-09-24 08:43:13,231 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""security-setting"" => ""#""),
(""role"" => ""guest"")
]
2015-09-24 08:43:13,232 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""security-setting"" => ""#"")
]
2015-09-24 08:43:13,232 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""in-vm-acceptor"" => ""in-vm"")
]
2015-09-24 08:43:13,232 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-acceptor"" => ""netty-throughput""),
(""param"" => ""direct-deliver"")
]
2015-09-24 08:43:13,233 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-acceptor"" => ""netty-throughput""),
(""param"" => ""batch-delay"")
]
2015-09-24 08:43:13,233 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-acceptor"" => ""netty-throughput"")
]
2015-09-24 08:43:13,233 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-acceptor"" => ""netty"")
]
2015-09-24 08:43:13,234 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""in-vm-connector"" => ""in-vm"")
]
2015-09-24 08:43:13,234 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-connector"" => ""netty-throughput""),
(""param"" => ""batch-delay"")
]
2015-09-24 08:43:13,234 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-connector"" => ""netty-throughput"")
]
2015-09-24 08:43:13,235 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-connector"" => ""netty"")
]
2015-09-24 08:43:13,235 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default"")
]
2015-09-24 08:43:13,235 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [(""subsystem"" => ""messaging"")]
2015-09-24 08:43:20,957 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""web""),
(""configuration"" => ""jsp-configuration"")
]
2015-09-24 08:43:20,957 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""web""),
(""configuration"" => ""static-resources"")
]
2015-09-24 08:43:20,958 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""web""),
(""configuration"" => ""container"")
]
2015-09-24 08:43:20,958 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""web""),
(""virtual-server"" => ""default-host"")
]
2015-09-24 08:43:20,958 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""web""),
(""connector"" => ""http"")
]
2015-09-24 08:43:20,959 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [(""subsystem"" => ""web"")]","org.jboss.as.controller.AbstractOperationContext
org.jboss.as.controller.logging.ControllerLogger"
FILE,WFCORE,WFCORE-1027,2015-10-01T18:16:10.000-05:00,Inconsistent read-resource results with host scoped roles,"{roles=master-monitor}




 
 {




                ""directory-grouping"" => ""by-server"",




                ""domain-controller"" => {""local"" => {} 
  
 {""org.jboss.as.jmx"" => undefined} 
 {




                    ""management"" => undefined,




                    ""public"" => undefined,




                    ""unsecure"" => undefined




                } 
 {""default"" => undefined} 
 {""jmx"" => undefined} 
 {roles=slave-maintainer}




 
 {roles=slave-maintainer}




 
  
 {""org.jboss.as.jmx"" => undefined} 
 {




                ""management"" => undefined,




                ""public"" => undefined,




                ""unsecure"" => undefined




            } 
 {""default"" => undefined} 
 {""jmx"" => undefined}
set up host scop roles follow https://gist.github.com/heiko-braun/0dc810ed04db8739defd
When using a role which only selects the master there is no access-control response header showing the filtered resources, and the slave wrongly appears in the results:
[domain@localhost:9990 /] /host=*:read-resource{roles=master-monitor}
{
""outcome"" => ""success"",
""result"" => [
{
""address"" => [(""host"" => ""master"")],
""outcome"" => ""success"",
""result"" => {
""directory-grouping"" => ""by-server"",
""domain-controller"" => {""local"" => {}},
""management-major-version"" => 4,
""management-micro-version"" => 0,
""management-minor-version"" => 0,
""master"" => true,
""name"" => ""master"",
""namespaces"" => [],
""organization"" => undefined,
""product-name"" => ""WildFly Core"",
""product-version"" => ""2.0.0.CR6-SNAPSHOT"",
""release-codename"" => ""Kenny"",
""release-version"" => ""2.0.0.CR6-SNAPSHOT"",
""schema-locations"" => [],
""core-service"" => {
""host-environment"" => undefined,
""platform-mbean"" => undefined,
""management"" => undefined,
""discovery-options"" => undefined,
""ignored-resources"" => undefined,
""patching"" => undefined,
""module-loading"" => undefined
},
""extension"" => {""org.jboss.as.jmx"" => undefined},
""interface"" => {
""management"" => undefined,
""public"" => undefined,
""unsecure"" => undefined
},
""jvm"" => {""default"" => undefined},
""path"" => undefined,
""server"" => {
""server-one"" => undefined,
""server-two"" => undefined,
""server-three"" => undefined
},
""server-config"" => {
""server-one"" => undefined,
""server-two"" => undefined,
""server-three"" => undefined
},
""socket-binding-group"" => undefined,
""subsystem"" => {""jmx"" => undefined},
""system-property"" => undefined
}
},
{
""address"" => [(""host"" => ""localhost"")],
""outcome"" => ""success"",
""result"" => undefined
}
]
}
When using a role that only selects the slave we get a proper access-control header
[domain@localhost:9990 /] /host=*:read-resource{roles=slave-maintainer}
{
""outcome"" => ""success"",
""result"" => [{
""address"" => [(""host"" => ""localhost"")],
""outcome"" => ""success"",
""result"" => undefined
}],
""response-headers"" => {""access-control"" => [{
""absolute-address"" => [],
""relative-address"" => [],
""filtered-children-types"" => [""host""]
}]}
The same output on master with WFCORE-994 applied:
[domain@localhost:9990 /] /host=*:read-resource{roles=slave-maintainer}
{
""outcome"" => ""success"",
""result"" => [{
""address"" => [(""host"" => ""slave"")],
""outcome"" => ""success"",
""result"" => {
""directory-grouping"" => ""by-server"",
""domain-controller"" => {""remote"" => {
""protocol"" => undefined,
""port"" => undefined,
""host"" => undefined,
""username"" => undefined,
""ignore-unused-configuration"" => undefined,
""admin-only-policy"" => undefined,
""security-realm"" => ""ManagementRealm""
}},
""management-major-version"" => 4,
""management-micro-version"" => 0,
""management-minor-version"" => 0,
""master"" => false,
""name"" => ""slave"",
""namespaces"" => [],
""organization"" => undefined,
""product-name"" => undefined,
""product-version"" => undefined,
""release-codename"" => ""Kenny"",
""release-version"" => ""2.0.0.CR6-SNAPSHOT"",
""schema-locations"" => [],
""core-service"" => {
""host-environment"" => undefined,
""platform-mbean"" => undefined,
""management"" => undefined,
""discovery-options"" => undefined,
""ignored-resources"" => undefined,
""patching"" => undefined,
""module-loading"" => undefined
},
""extension"" => {""org.jboss.as.jmx"" => undefined},
""interface"" => {
""management"" => undefined,
""public"" => undefined,
""unsecure"" => undefined
},
""jvm"" => {""default"" => undefined},
""path"" => undefined,
""server"" => {
""server-one"" => undefined,
""server-two"" => undefined
},
""server-config"" => {
""server-one"" => undefined,
""server-two"" => undefined
},
""socket-binding-group"" => undefined,
""subsystem"" => {""jmx"" => undefined},
""system-property"" => undefined
}
}],
""response-headers"" => {""access-control"" => [{
""absolute-address"" => [],
""relative-address"" => [],
""filtered-children-types"" => [""host""]
}]}
}","org.jboss.as.test.integration.domain.rbac.RBACProviderHostScopedRolesTestCase
org.jboss.as.test.integration.domain.rbac.AbstractHostScopedRolesTestCase
org.jboss.as.controller.operations.global.GlobalOperationHandlers
org.jboss.as.test.integration.domain.rbac.JmxRBACProviderHostScopedRolesTestCase
org.jboss.as.test.integration.domain.rbac.ListRoleNamesTestCase
org.jboss.as.test.integration.domain.rbac.WildcardReadsTestCase"
FILE,WFCORE,WFCORE-989,2015-09-19T03:11:07.000-05:00,Premature registration of reconnecting server,"{""server-group"" => {




        ""main-server-group"" => {""host"" => {""slave"" => {""main-three"" => ""WFLYHC0153: Channel closed""}
ServerInventoryImpl.reconnectServer is registering the ProxyController for the reconnecting server with the DomainModelControllerService.
The problem is that ProxyController is not yet in a state where it can forward requests to the server.
That won't happen until the server calls back with a DomainServerProtocol.SERVER_RECONNECT_REQUEST and the ServerToHostProtocolHandler.ServerReconnectRequestHandler handles it.
The effect is if a request for the server comes in during this window, it will fail.
If that request is part of a domain operation rollout (because during the window the HC regarded the server as 'live' and instructed the DC to send rollout ops to it), then the domain rollout will be affected.
This happened in the testsuite failure I just saw.
Most significant logging is as follows:
2015-09-18 17:59:32,229 INFO  [org.jboss.as] (Controller Boot Thread) WFLYSRV0025: WildFly Core 2.0.0.CR2-SNAPSHOT ""Kenny"" (Host Controller) started in 93ms - Started 48 of 51 services (15 services are lazy, passive or on-demand)
2015-09-18 17:59:32,247 INFO  [org.jboss.as.controller.management-operation] (Remoting ""slave:MANAGEMENT"" task-16) Initialized for 1849055188
2015-09-18 17:59:32,247 INFO  [org.jboss.as.host.controller] (Remoting ""slave:MANAGEMENT"" task-14) WFLYHC0021: Server [Server:main-three] connected using connection [Channel ID 08aa200b (inbound) of Remoting connection 27e3d90d to /127.0.0.1:49272]
2015-09-18 17:59:32,247 INFO  [org.jboss.as.host.controller] (Remoting ""slave:MANAGEMENT"" task-15) WFLYHC0021: Server [Server:other-two] connected using connection [Channel ID 02bd2646 (inbound) of Remoting connection 64a8b7f2 to /127.0.0.1:49273]
2015-09-18 17:59:32,247 INFO  [org.jboss.as.controller.management-operation] (Host Controller Service Threads - 34) Initialized for 1849055188
2015-09-18 17:59:32,252 INFO  [org.jboss.as.controller.management-operation] (Host Controller Service Threads - 34) sending prepared response for 1849055188  --- interrupted: false
2015-09-18 17:59:32,254 INFO  [org.jboss.as.controller.management-operation] (Remoting ""slave:MANAGEMENT"" task-1) Initialized for 1933145457
2015-09-18 17:59:32,254 INFO  [org.jboss.as.controller.management-operation] (Remoting ""slave:MANAGEMENT"" task-1) Initialized for 481103151
2015-09-18 17:59:32,254 INFO  [org.jboss.as.controller.management-operation] (Host Controller Service Threads - 36) Initialized for 1933145457
2015-09-18 17:59:32,254 INFO  [org.jboss.as.controller.management-operation] (Host Controller Service Threads - 37) Initialized for 481103151
2015-09-18 17:59:32,255 INFO  [org.jboss.as.controller.management-operation] (Host Controller Service Threads - 36) sending pre-prepare failed response for 1933145457  --- interrupted: false
2015-09-18 17:59:32,256 INFO  [org.jboss.as.controller.management-operation] (Host Controller Service Threads - 37) sending pre-prepare failed response for 481103151  --- interrupted: false
The HC completes boot.
Then servers main-three and other-two register.
The HC sends a prepared response to a request.
This is the host rollout request to the slave from the DC with the response being the ops to invoke on the servers.
The HC reports sending a ""pre-prepare failed response"" to two requests.
These are the requests the DC has asked it to proxy to the servers.
The result of all this for the client is the following failure of a management op:
Failed operation:
{
""operation"" => ""add"",
""address"" => [(""extension"" => ""org.jboss.as.test.hc.extension"")]
}
Response:
{
""outcome"" => ""failed"",
""result"" => undefined,
""failure-description"" => {""WFLYDC0074: Operation failed or was rolled back on all servers.
Server failures:"" => {""server-group"" => {
""main-server-group"" => {""host"" => {""slave"" => {""main-three"" => ""WFLYHC0153: Channel closed""}}},
""other-server-group"" => {""host"" => {""slave"" => {""other-two"" => ""WFLYHC0153: Channel closed""}}}
}}},
""rolled-back"" => true,
""server-groups"" => {
""main-server-group"" => {""host"" => {
""master"" => {""main-one"" => {""response"" => {
""outcome"" => ""failed"",
""result"" => [(""HC"" => ""1.1.1"")],
""rolled-back"" => true
}}},
""slave"" => {""main-three"" => {""response"" => {
""outcome"" => ""failed"",
""result"" => undefined,
""failure-description"" => ""WFLYHC0153: Channel closed"",
""rolled-back"" => true
}}}
}},
""other-server-group"" => {""host"" => {""slave"" => {""other-two"" => {""response"" => {
""outcome"" => ""failed"",
""result"" => undefined,
""failure-description"" => ""WFLYHC0153: Channel closed"",
""rolled-back"" => true
}}}}}
}
}
The ""WFLYHC0153: Channel closed"" failure is what is produced when an attempt is made to invoke on a disconnected proxy controller.","org.jboss.as.host.controller.ServerInventoryImpl
org.jboss.as.host.controller.mgmt.ServerToHostProtocolHandler"
FILE,WFCORE,WFCORE-1214,2015-12-11T23:17:45.000-06:00,Operation headers not propagated to domain servers when 'composite' op is used,"{blocking-timeout=5;rollback-on-runtime-failure=false}  
 {

[Host Controller] 10:53:40,697 INFO  [stdout] (management-handler-thread - 3)     ""blocking-timeout"" => ""5"",

[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""rollback-on-runtime-failure"" => ""false"",

[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""caller-type"" => ""user"",

[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""access-mechanism"" => ""NATIVE""

[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3) }
When the user adds request headers to an op, they are not propagated to the servers during domain rollout if the 'composite' op is involved.
add stdout printing be on various processes
[domain@localhost:9990 /] deploy ~/tmp/helloworld.
war --headers={blocking-timeout=5;rollback-on-runtime-failure=false} --all-server-groups
Then on a HC with two servers, this is logged:
[Host Controller] 10:53:40,697 INFO  [stdout] (management-handler-thread - 3) ""composite"" headers:
{
[Host Controller] 10:53:40,697 INFO  [stdout] (management-handler-thread - 3)     ""blocking-timeout"" => ""5"",
[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""rollback-on-runtime-failure"" => ""false"",
[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""caller-type"" => ""user"",
[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""access-mechanism"" => ""NATIVE""
[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3) }
[Host Controller] 10:53:40,727 INFO  [org.jboss.as.repository] (management-handler-thread - 3) WFLYDR0001: Content added at location /Users/bstansberry/dev/wildfly/wildfly-core/dist/target/wildfly-core-2.0.5.
Final-SNAPSHOT/domain/data/content/6f/cd9eae343ed6d5aa9fffa83012d155b1ef911c/content
[Server:server-one] 10:53:40,772 INFO  [stdout] (ServerService Thread Pool  11) ""composite"" headers: null
[Server:server-two] 10:53:40,772 INFO  [stdout] (ServerService Thread Pool  11) ""composite"" headers: null
The HC logs, then the servers report.
The user-specified headers are not included.
Invoke the same op without the batch and this is logged:
[Host Controller] 10:43:50,400 INFO  [stdout] (management-handler-thread - 4) ""composite"" headers: {
[Host Controller] 10:43:50,401 INFO  [stdout] (management-handler-thread - 4)     ""blocking-timeout"" => ""5"",
[Host Controller] 10:43:50,401 INFO  [stdout] (management-handler-thread - 4)     ""rollback-on-runtime-failure"" => ""false"",
[Host Controller] 10:43:50,401 INFO  [stdout] (management-handler-thread - 4)     ""caller-type"" => ""user"",
[Host Controller] 10:43:50,401 INFO  [stdout] (management-handler-thread - 4)     ""access-mechanism"" => ""NATIVE""
[Host Controller] 10:43:50,401 INFO  [stdout] (management-handler-thread - 4) }
[Host Controller] 10:43:50,425 INFO  [org.jboss.as.repository] (management-handler-thread - 4) WFLYDR0001: Content added at location /Users/bstansberry/dev/wildfly/wildfly-core/dist/target/wildfly-core-2.0.5.
Final-SNAPSHOT/domain/data/content/6f/cd9eae343ed6d5aa9fffa83012d155b1ef911c/content
[Server:server-two] 10:43:50,464 INFO  [stdout] (ServerService Thread Pool -- 11) ""composite"" headers: {
[Server:server-two] 10:43:50,464 INFO  [stdout] (ServerService Thread Pool -- 11)     ""blocking-timeout"" => ""5"",
[Server:server-two] 10:43:50,464 INFO  [stdout] (ServerService Thread Pool -- 11)     ""rollback-on-runtime-failure"" => ""false"",
[Server:server-one] 10:43:50,464 INFO  [stdout] (ServerService Thread Pool -- 11) ""composite"" headers: {
[Server:server-two] 10:43:50,464 INFO  [stdout] (ServerService Thread Pool -- 11)     ""access-mechanism"" => ""NATIVE"",
[Server:server-one] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11)     ""blocking-timeout"" => ""5"",
[Server:server-two] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11)     ""domain-uuid"" => ""216d2e99-dba5-4c89-8020-b0c16bd553c5""
[Server:server-one] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11)     ""rollback-on-runtime-failure"" => ""false"",
[Server:server-two] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11) }
[Server:server-one] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11)     ""access-mechanism"" => ""NATIVE"",
[Server:server-one] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11)     ""domain-uuid"" => ""216d2e99-dba5-4c89-8020-b0c16bd553c5""
[Server:server-one] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11) }
Expected headers are present.
Note the CLI 'deploy' is far from the only time the 'composite' op is used.
Among other places, the high level CLI 'batch' command in a domain involves use of 'composite'.","org.jboss.as.domain.controller.operations.coordination.DomainRolloutStepHandler
org.jboss.as.domain.controller.operations.coordination.OperationCoordinatorStepHandler"
FILE,WFCORE,WFCORE-701,2015-05-19T15:06:17.000-05:00,Inconsistent domain server status reports between server-config resource and server resource,"attribute(name=status)




 {




    ""outcome"" => ""success"",




    ""result"" => ""FAILED""




}




  attribute(name=server-state)




 {




    ""outcome"" => ""success"",




    ""result"" => ""STOPPED""




}
When a managed server fails in some way, the server status reporting is inconsistent between the /host=<host>/server-config=<server> resources and the /host=<host>/server=<server> resource.
run domain.sh find pid of server process kill <thepid>
[domain@localhost:9990 /] /host=master/server-config=server-two:read-attribute(name=status)
{
""outcome"" => ""success"",
""result"" => ""FAILED""
}
[domain@localhost:9990 /] /host=master/server=server-two:read-attribute(name=server-state)
{
""outcome"" => ""success"",
""result"" => ""STOPPED""
}",org.jboss.as.host.controller.ManagedServer
FILE,WFCORE,WFCORE-1570,2016-05-27T12:51:56.000-05:00,Saved rollout-plan 'name' or 'id' attribute discrepancy,"group(rolling-to-servers=false,max-failed-servers=1)  group(rolling-to-servers=true,max-failure-percentage=20)  
 {rollout id=my-rollout-plan}
When using rollout plans for EAP deployment scenarios I can create my own named rollout-plan for ease of use.
apply rollout command refer with name
There is minor discrepancy in the way I create and use such rollout plan though.
use command
rollout-plan add --name=my-rollout-plan --content={rollout main-server-group(rolling-to-servers=false,max-failed-servers=1),other-server-group(rolling-to-servers=true,max-failure-percentage=20) rollback-across-groups=true}
see --name attribute given to name my rollout plan
use following command
deploy /path/to/test-application.
war --all-server-groups --headers={rollout id=my-rollout-plan}
see id attribute given to rollout header operation
Note: examples are used from our documentation.
Note: I do not know whether I am missing something but I was not able to retrieve more info how to use rollout header operation in deploy command directly in CLI.","org.jboss.as.cli.parsing.operation.header.RolloutPlanState
org.jboss.as.cli.parsing.operation.header.RolloutPlanHeaderCallbackHandler
org.jboss.as.cli.operation.impl.RolloutPlanCompleter"
FILE,WFCORE,WFCORE-1578,2016-06-07T05:13:13.000-05:00,Better check of names of existing resources when adding '{local|remote-destination-outbound-socket-binding',"{remote|local} 
   add()




    add(host=localhost,port=8765)




 
   add(socket-binding-ref=http)




 
  
  
     
  
 
  
 {remote|local}
have with particular name
Then when I create some /socket-binding-group=standard-sockets/remote-destination-outbound-socket-binding or /socket-binding-group=standard-sockets/local-destination-outbound-socket-binding using same name as of already existing socket-binding resource, add operation is successful but when I perform server reload, it crashes as it is not able to parse configuration.
See:
create own socket-binding resource perform own socket-binding resource
/socket-binding-group=standard-sockets/socket-binding=myBinding:add()
/socket-binding-group=standard-sockets/remote-destination-outbound-socket-binding=myBinding:add(host=localhost,port=8765)
or
/socket-binding-group=standard-sockets/local-destination-outbound-socket-binding=myBinding:add(socket-binding-ref=http)
reload
server crashes with following stacktrace in console log:
17:31:40,447 INFO  [org.jboss.as.connector.deployers.jdbc] (MSC service thread 1-7) WFLYJCA0019: Stopped Driver service with driver-name = h2
17:31:40,453 INFO  [org.wildfly.extension.undertow] (MSC service thread 1-8) WFLYUT0008: Undertow HTTP listener default suspending
17:31:40,454 INFO  [org.wildfly.extension.undertow] (MSC service thread 1-8) WFLYUT0007: Undertow HTTP listener default stopped, was bound to 127.0.0.1:8080
17:31:40,454 INFO  [org.wildfly.extension.undertow] (MSC service thread 1-3) WFLYUT0004: Undertow 1.3.21.Final-redhat-1 stopping
17:31:40,458 INFO  [org.jboss.as.mail.extension] (MSC service thread 1-7) WFLYMAIL0002: Unbound mail session [java:jboss/mail/Default]
17:31:40,461 INFO  [org.jboss.as] (MSC service thread 1-5) WFLYSRV0050: JBoss EAP 7.0.0.
GA (WildFly Core 2.1.2.Final-redhat-1) stopped in 22ms
17:31:40,461 INFO  [org.jboss.as] (MSC service thread 1-5) WFLYSRV0049: JBoss EAP 7.0.0.
GA (WildFly Core 2.1.2.Final-redhat-1) starting
17:31:40,489 ERROR [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0055: Caught exception during boot: org.jboss.as.controller.persistence.ConfigurationPersistenceException: WFLYCTL0085: Failed to parse configuration
at org.jboss.as.controller.persistence.XmlConfigurationPersister.load(XmlConfigurationPersister.java:131)
at org.jboss.as.server.ServerService.boot(ServerService.java:356)
at org.jboss.as.controller.AbstractControllerService$1.run(AbstractControllerService.java:299)
at java.lang.Thread.run(Thread.java:745)
Caused by: javax.xml.stream.XMLStreamException: ParseError at [row,col]:[410,9]
Message: WFLYCTL0042: A socket-binding or a outbound-socket-binding myBinding already declared has already been declared in socket-binding-group standard-sockets
at org.jboss.as.server.parsing.StandaloneXml_4.
parseSocketBindingGroup(StandaloneXml_4.java:518)
at org.jboss.as.server.parsing.StandaloneXml_4.
readServerElement(StandaloneXml_4.java:254)
at org.jboss.as.server.parsing.StandaloneXml_4.
readElement(StandaloneXml_4.java:141)
at org.jboss.as.server.parsing.StandaloneXml.readElement(StandaloneXml.java:103)
at org.jboss.as.server.parsing.StandaloneXml.readElement(StandaloneXml.java:49)
at org.jboss.staxmapper.XMLMapperImpl.processNested(XMLMapperImpl.java:110)
at org.jboss.staxmapper.XMLMapperImpl.parseDocument(XMLMapperImpl.java:69)
at org.jboss.as.controller.persistence.XmlConfigurationPersister.load(XmlConfigurationPersister.java:123)
... 3 more
17:31:40,490 FATAL [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0056: Server boot has failed in an unrecoverable manner; exiting.
See previous messages for details.
17:31:40,491 INFO  [org.jboss.as.server] (Thread-2) WFLYSRV0220: Server shutdown has been requested.
17:31:40,496 INFO  [org.jboss.as] (MSC service thread 1-2) WFLYSRV0050: JBoss EAP 7.0.0.
GA (WildFly Core 2.1.2.Final-redhat-1) stopped in 3ms
After this occurs, one needs to fix .
/standalone/configuration/standalone.xml manually by removing duplicate resources.
Note: not sure whether CLI component is appropriate, please change if there is better component for this.","org.jboss.as.controller.logging.ControllerLogger
org.jboss.as.server.services.net.LocalDestinationOutboundSocketBindingAddHandler
org.jboss.as.server.services.net.SocketBindingAddHandler
org.jboss.as.server.services.net.RemoteDestinationOutboundSocketBindingAddHandler"
FILE,WFCORE,WFCORE-1635,2016-07-05T07:04:51.000-05:00,Write attribute on a new deployment scanner fails in batch,"add(path=log, relative-to=""jboss.server.base.dir"", auto-deploy-exploded=false, scan-enabled=false)




  attribute(name=scan-interval, value=6000)




 
 
 add(path=log, relative-to=""jboss.server.base.dir"", auto-deploy-exploded=false, scan-enabled=false)




  attribute(name=scan-interval, value=6000)
Creating a new deployment-scanner and altering it's attribute fails if done in single batch.
Running the commands without batch or running batch on CLI embed-server works fine.
reproduce
batch
/subsystem=deployment-scanner/scanner=scan:add(path=log, relative-to=""jboss.server.base.dir"", auto-deploy-exploded=false, scan-enabled=false)
/subsystem=deployment-scanner/scanner=scan:write-attribute(name=scan-interval, value=6000)
run-batch
fails with
08:09:19,076 ERROR [org.jboss.as.controller.management-operation] (management-handler-thread - 4) WFLYCTL0013: Operation (""write-attribute"") failed - address: ([
(""subsystem"" => ""deployment-scanner""),
(""scanner"" => ""scan"")
]): java.lang.IllegalStateException
at org.jboss.as.server.deployment.scanner.DeploymentScannerService.getValue(DeploymentScannerService.java:234)
at org.jboss.as.server.deployment.scanner.DeploymentScannerService.getValue(DeploymentScannerService.java:62)
at org.jboss.msc.service.ServiceControllerImpl.getValue(ServiceControllerImpl.java:1158)
at org.jboss.as.controller.OperationContextImpl$OperationContextServiceController.getValue(OperationContextImpl.java:2282)
at org.jboss.as.server.deployment.scanner.AbstractWriteAttributeHandler.applyUpdateToRuntime(AbstractWriteAttributeHandler.java:58)
at org.jboss.as.controller.AbstractWriteAttributeHandler$1.execute(AbstractWriteAttributeHandler.java:104)
at org.jboss.as.controller.AbstractOperationContext.executeStep(AbstractOperationContext.java:890)
at org.jboss.as.controller.AbstractOperationContext.processStages(AbstractOperationContext.java:659)
at org.jboss.as.controller.AbstractOperationContext.executeOperation(AbstractOperationContext.java:370)
at org.jboss.as.controller.OperationContextImpl.executeOperation(OperationContextImpl.java:1344)
at org.jboss.as.controller.ModelControllerImpl.internalExecute(ModelControllerImpl.java:392)
at org.jboss.as.controller.ModelControllerImpl.execute(ModelControllerImpl.java:217)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler.doExecute(ModelControllerClientOperationHandler.java:208)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler.access$300(ModelControllerClientOperationHandler.java:130)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler$1$1.run(ModelControllerClientOperationHandler.java:152)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler$1$1.run(ModelControllerClientOperationHandler.java:148)
at java.security.AccessController.doPrivileged(AccessController.java:686)
at javax.security.auth.Subject.doAs(Subject.java:569)
at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:92)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler$1.execute(ModelControllerClientOperationHandler.java:148)
at org.jboss.as.protocol.mgmt.AbstractMessageHandler$ManagementRequestContextImpl$1.doExecute(AbstractMessageHandler.java:363)
at org.jboss.as.protocol.mgmt.AbstractMessageHandler$AsyncTaskRunner.run(AbstractMessageHandler.java:472)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at java.lang.Thread.run(Thread.java:785)
at org.jboss.threads.JBossThread.run(JBossThread.java:320)
using the embed server works
embed-server
batch
/subsystem=deployment-scanner/scanner=scan:add(path=log, relative-to=""jboss.server.base.dir"", auto-deploy-exploded=false, scan-enabled=false)
/subsystem=deployment-scanner/scanner=scan:write-attribute(name=scan-interval, value=6000)
run-batch
Setting only as minor as there is no real use case behind this (scan-interval can be set while adding a new scanner) - run into it quite accidentally.
No regression against previous release.",org.jboss.as.server.deployment.scanner.AbstractWriteAttributeHandler
FILE,WFCORE,WFCORE-1590,2016-06-12T14:18:43.000-05:00,Default parameter length validating ignores setMinSize(0),"static final SimpleAttributeDefinition REPLACEMENT = new SimpleAttributeDefinitionBuilder(ElytronDescriptionConstants.REPLACEMENT, ModelType.STRING, false)




        .setAllowExpression(true)




        .setMinSize(0)




        .setFlags(AttributeAccess.Flag.RESTART_RESOURCE_SERVICES)




        .build();






 
 add(pattern=""@ELYTRON.ORG"", replacement="""", replace-all=true)
static final SimpleAttributeDefinition REPLACEMENT = new SimpleAttributeDefinitionBuilder(ElytronDescriptionConstants.REPLACEMENT, ModelType.STRING, false)
.
setAllowExpression(true)
.
setMinSize(0)
.
setFlags(AttributeAccess.Flag.RESTART_RESOURCE_SERVICES)
.
build();
The following error is reported if an empty string is used as a parameter: -
[standalone@localhost:9990 /] .
/subsystem=elytron/regex-name-rewriter=strip-realm:add(pattern=""@ELYTRON.
ORG"", replacement="""", replace-all=true)
{
""outcome"" => ""failed"",
""failure-description"" => ""WFLYCTL0113: '' is an invalid value for parameter replacement.
Values must have a minimum length of 1 characters"",
""rolled-back"" => true
}","org.jboss.as.controller.operations.validation.BytesValidator
org.jboss.as.controller.SimpleAttributeDefinitionUnitTestCase
org.jboss.as.controller.test.WriteAttributeOperationTestCase
org.jboss.as.controller.AbstractAttributeDefinitionBuilder
org.jboss.as.controller.AttributeDefinition"
FILE,WFCORE,WFCORE-1718,2016-08-16T09:49:11.000-05:00,Handlers within Audit Logger are not removed properly when Audit Logger is removed,"remove()
  remove()
 
 {




    ""outcome"" => ""failed"",




    ""failure-description"" => ""WFLYCTL0158: Operation handler failed: java.lang.NullPointerException"",




    ""rolled-back"" => true




}






   
 attribute(name=level,value=DEBUG)
If Audit Logger is removed, destination handlers (i.e. its child nodes) are not removed properly.
They are not present in the config file.
They seem to be not removed ""internally"" though.
This leads to a couple of issues:
1. It is not possible to remove referenced File/Syslog handlers.
If user tries to remove them the NullPointerException is given as a result.
try following commands
/core-service=management/access=audit/file-handler=file:remove()
/core-service=management/access=audit/syslog-handler=my-syslog-handler:remove()
Their output is:
{
""outcome"" => ""failed"",
""failure-description"" => ""WFLYCTL0158: Operation handler failed: java.lang.NullPointerException"",
""rolled-back"" => true
}
2. AuditLog continues to send auditable events to previously referenced File/Syslog handlers.
create auditable event )
See log in the file (WILDFLY_HOME/standalone/data/audit-log.log)
See log in the syslog (/var/log/messages)","org.jboss.as.domain.management.audit.AuditLogLoggerResourceDefinition
org.jboss.as.domain.management.audit.AccessAuditResourceDefinition
org.jboss.as.domain.management.audit.AuditLogHandlerReferenceResourceDefinition"
FILE,WFCORE,WFCORE-1765,2016-09-05T16:22:02.000-05:00,unclear NullPointerException if the deployment-scanner element is removed from the configuration,"{xml}
         {xml}
If the deployment scanner element is removed from the configuration of the standalone server a NullPointerException is logged which is unclear and difficult to find as the stack does not show any hint.
Config:
{xml}
<subsystem xmlns=""urn:jboss:domain:deployment-scanner:2.0"">
<!-- deployment-scanner path=""deployments"" relative-to=""jboss.server.base.dir"" scan-interval=""5000"" runtime-failure-causes-rollback=""${jboss.deployment.scanner.rollback.on.failure:false}""/ -->
</subsystem>{xml}
Log message:
ERROR [org.jboss.as.controller.management-operation] (ServerService Thread Pool  34) WFLYCTL0403: Unexpected failure during execution of the following operation(s): []: java.lang.NullPointerException
at org.jboss.as.controller.AbstractOperationContext$Step.access$300(AbstractOperationContext.java:1185)
at org.jboss.as.controller.AbstractOperationContext.executeResultHandlerPhase(AbstractOperationContext.java:767)
at org.jboss.as.controller.AbstractOperationContext.executeDoneStage(AbstractOperationContext.java:753)
at org.jboss.as.controller.AbstractOperationContext.processStages(AbstractOperationContext.java:680)
at org.jboss.as.controller.AbstractOperationContext.executeOperation(AbstractOperationContext.java:370)
at org.jboss.as.controller.ParallelBootOperationStepHandler$ParallelBootTask.run(ParallelBootOperationStepHandler.java:359)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at java.lang.Thread.run(Thread.java:745)
at org.jboss.threads.JBossThread.run(JBossThread.java:320)",org.jboss.as.controller.ParallelBootOperationStepHandler
FILE,WFCORE,WFCORE-1793,2016-09-14T08:08:21.000-05:00,add-content operation fails to overwrite existing content with overwrite=true set when passing content by file path,"{""outcome"" => ""success""}




 
 {""outcome"" => ""success""}




 
 {""outcome"" => ""success""}




  {path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt} 
  
 {path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt} 
  
 {path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt}
Upon overwriting content in managed exploded deployments on wildfly-core, the following errors are produced:
CLI
[standalone@localhost:9990 /] deploy /home/mjurc/testing/eap7-204/jboss-kitchensink-ear.
ear
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:undeploy
{""outcome"" => ""success""}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:explode
{""outcome"" => ""success""}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:deploy
{""outcome"" => ""success""}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:add-content(content=[{path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt}], overwrite=true)
{
""outcome"" => ""failed"",
""failure-description"" => ""org.jboss.as.repository.ExplodedContentException: WFLYDR0021: Error updating content of exploded deployment"",
""rolled-back"" => true
}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:add-content(content=[{path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt}], overwrite=false)
{
""outcome"" => ""failed"",
""failure-description"" => ""org.jboss.as.repository.ExplodedContentException: WFLYDR0021: Error updating content of exploded deployment"",
""rolled-back"" => true
}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:add-content(content=[{path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt}])
{
""outcome"" => ""failed"",
""failure-description"" => ""org.jboss.as.repository.ExplodedContentException: WFLYDR0021: Error updating content of exploded deployment"",
""rolled-back"" => true
}
Server
09:41:36,029 WARN  [org.jboss.as.repository] (management-handler-thread - 5) java.nio.file.FileAlreadyExistsException: /home/mjurc/testing/wildfly-core/build/target/wildfly-core-3.0.0.
Alpha8-SNAPSHOT/standalone/data/content/content7797527203290314566/content/test.txt
09:45:27,505 WARN  [org.jboss.as.repository] (management-handler-thread - 12) java.nio.file.FileAlreadyExistsException: /home/mjurc/testing/wildfly-core/build/target/wildfly-core-3.0.0.
Alpha8-SNAPSHOT/standalone/data/content/content721393778736298367/content/test.txt
09:45:36,352 WARN  [org.jboss.as.repository] (management-handler-thread - 10) java.nio.file.FileAlreadyExistsException: /home/mjurc/testing/wildfly-core/build/target/wildfly-core-3.0.0.
Alpha8-SNAPSHOT/standalone/data/content/content344811471223714239/content/test.txt
This issue does not seem to arise when the content is passed to the server by input stream index.","org.jboss.as.server.controller.resources.DeploymentAttributes
org.jboss.as.server.deployment.ExplodedDeploymentAddContentHandler"
FILE,WFCORE,WFCORE-1864,2016-10-13T09:12:31.000-05:00,Whitespaces are not removed from dependencies in module add command,"{{
...
    <dependencies>
        <module name=""org.a""/>
        <module name="" org.b ""/>
    </dependencies>
...
}}
Running module add --name=foo.bar --resources=foo.jar --dependencies=[org.a, org.b ] will result in following dependencies in module.xml
{{
...
<dependencies>
<module name=""org.a""/>
<module name="" org.b ""/>
</dependencies>
...
}}","org.jboss.as.cli.handlers.module.ASModuleHandler
org.jboss.as.test.integration.management.cli.ModuleTestCase"
FILE,WFCORE,WFCORE-1908,2016-10-31T08:13:57.000-05:00,Tab completion suggest writing attribute which has access type metric and is not writable,"attribute(name=message-count, value=5)




 {




    ""outcome"" => ""failed"",




    ""failure-description"" => ""WFLYCTL0048: Attribute message-count is not writable"",




    ""rolled-back"" => true




}
CLI tab completion suggests attributes that are not writable and their access-type is metric
/subsystem=messaging-activemq/server=default/jms-queue=DLQ:write-attribute(name=<TAB>
consumer-count  delivering-count  entries  legacy-entries  message-count  messages-added  scheduled-count
From executing :read-resource-description we can see, attributes consumer-count, delivering-count, message-count, messages-added, scheduled-count are of type metric.
On attempt to write metric attribute, for example message-count, non writable error is printed
[standalone@localhost:9990 jms-queue=q] :write-attribute(name=message-count, value=5)
{
""outcome"" => ""failed"",
""failure-description"" => ""WFLYCTL0048: Attribute message-count is not writable"",
""rolled-back"" => true
}","org.jboss.as.cli.impl.AttributeNamePathCompleter
org.jboss.as.cli.parsing.test.AttributeNamePathCompletionTestCase
org.jboss.as.cli.Util"
FILE,WFCORE,WFCORE-1936,2016-11-04T10:57:06.000-05:00,"Value of parameters ""restart-required"" for fixed-*port attributes does not match reality for socket-binding and *-destination-outbound-socket-binding in CLI","description(recursive=true)
But reality is different.
If you tries to change such attributes you are informed that reload is necessary.
The attributes are defined as ""restart-required"" => ""no-services"", see /socket-binding-group=standard-sockets:read-resource-description(recursive=true)","org.jboss.as.server.services.net.OutboundSocketBindingResourceDefinition
org.jboss.as.controller.resource.AbstractSocketBindingResourceDefinition"
FILE,WFCORE,WFCORE-1959,2016-11-08T16:28:30.000-06:00,Deploying an empty managed exploded deployment to server group in domain fails,"{empty=true} 
 add()
Deploying an empty exploded deployment created on domain controller fails with the following:
[domain@localhost:9990 /] /deployment=empty-deployment.jar:add(content=[{empty=true}])
{
""outcome"" => ""success"",
""result"" => undefined,
""server-groups"" => undefined
}
[domain@localhost:9990 /] /server-group=main-server-group/deployment=empty-deployment.jar:add()
{
""outcome"" => ""failed"",
""result"" => undefined,
""failure-description"" => {""WFLYDC0074: Operation failed or was rolled back on all servers.
Server failures:"" => {""server-group"" => {""main-server-group"" => {""host"" => {""master"" => {
""server-one"" => ""WFLYSRV0201: Cannot have more than one of [bytes, input-stream-index, hash, url, empty]"",
""server-two"" => ""WFLYSRV0201: Cannot have more than one of [bytes, input-stream-index, hash, url, empty]""
}}}}}},
""rolled-back"" => true,
""server-groups"" => {""main-server-group"" => {""host"" => {""master"" => {
""server-one"" => {""response"" => {
""outcome"" => ""failed"",
""failure-description"" => ""WFLYSRV0201: Cannot have more than one of [bytes, input-stream-index, hash, url, empty]"",
""rolled-back"" => true
}},
""server-two"" => {""response"" => {
""outcome"" => ""failed"",
""failure-description"" => ""WFLYSRV0201: Cannot have more than one of [bytes, input-stream-index, hash, url, empty]"",
""rolled-back"" => true
}}
}}}}
}",org.jboss.as.domain.controller.operations.coordination.ServerOperationResolver
CLASS,jedit-4.3,1193683,2005-05-02T09:22:25.000-05:00,"folding bug, text is in a black hole","{\{\{ test
aaaa
bbbb
cccc
\}
have folded text \
\{\{\{ test aaaa bbbb cccc
\}\}\}
Close it you'll get
\{\{\{ test \[4 lines\]
You'll have
\{\{ test
and no text fold anymore.
It seems really dangerous isn't it ?
But the weird thing is that the text is not completely lost because you can type another \{ \(no need to undo\)
and the fold will reappear magically.
So the text was still here but hidden by jEdit's text area",org.gjt.sp.jedit.textarea.BufferHandler
CLASS,jedit-4.3,1571752,2006-10-05T21:26:12.000-05:00,'Add Explicit Fold'  in PHP mode - wrong comments,"{

\} 
 {\{\{  --&gt;
function foo\(\) \{

\} //\}\}\}
jEdit version: 4.3pre7
Java version: 1.6.0-beta2
Before 'Add Explicit fold' the content of buffer looks like this \('X' means selection boundaries\):
&lt;? php
Xfunction foo\(\) \{
\}X
/\* :folding=explicit:\*/
?&gt;
After:
&lt;? php
&lt;\!
--\{\{\{  --&gt;
function foo\(\) \{
\} //\}\}\}
/\* :folding=explicit:\*/
?&gt;
If is between '&lt;? php' and 'function' empty line, then it works OK.",org.gjt.sp.jedit.textarea.TextArea
CLASS,jedit-4.3,1599709,2006-11-20T13:17:56.000-06:00,NPE with JEditBuffer and new indenting,"lt;ENTER&gt;
The indenting refactoring introduced some NullPointerExceptions.
I've ""catched"" one in r8096, but as stated in the commit message, it's probably an error further up.
r8096 should be reverted.
The problem seems to be that ctx.rules.getModeName\(\) returns null, while it should return the main rule name.
save empty buffer as test.php.
When pressing ENTER, after the ""'"", the following exception gets thrown:
java.lang.NullPointerException
at org.gjt.sp.jedit.buffer.JEditBuffer.getIdealIndentForLine\(JEditBuffer.java:991\)
at org.gjt.sp.jedit.buffer.JEditBuffer.indentLine\(JEditBuffer.java:907\)
at org.gjt.sp.jedit.textarea.TextArea.insertEnterAndIndent\(TextArea.java:4327\)
at sun.reflect.GeneratedMethodAccessor23.invoke\(Unknown Source\)
at sun.reflect.DelegatingMethodAccessorImpl.invoke\(Unknown Source\)
at java.lang.reflect.Method.invoke\(Unknown Source\)
at bsh.Reflect.invokeMethod\(Reflect.java:134\)
at bsh.Reflect.invokeObjectMethod\(Reflect.java:80\)
at bsh.Name.invokeMethod\(Name.java:858\)
at bsh.BSHMethodInvocation.eval\(BSHMethodInvocation.java:75\)
at bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:102\)
at bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:47\)
at bsh.BSHBlock.evalBlock\(BSHBlock.java:130\)
at bsh.BSHBlock.eval\(BSHBlock.java:80\)
at bsh.BshMethod.invokeImpl\(BshMethod.java:362\)
at bsh.BshMethod.invoke\(BshMethod.java:258\)
at bsh.BshMethod.invoke\(BshMethod.java:186\)
at org.gjt.sp.jedit.BeanShell.runCachedBlock\(BeanShell.java:509\)
at org.gjt.sp.jedit.BeanShellAction.invoke\(BeanShellAction.java:76\)
at org.gjt.sp.jedit.gui.InputHandler.invokeAction\(InputHandler.java:415\)
at org.gjt.sp.jedit.gui.InputHandler.invokeAction\(InputHandler.java:381\)
at org.gjt.sp.jedit.gui.DefaultInputHandler.handleKey\(DefaultInputHandler.java:373\)
at org.gjt.sp.jedit.input.AbstractInputHandler.processKeyEventKeyStrokeHandling\(AbstractInputHandler.java:116\)
at org.gjt.sp.jedit.gui.InputHandler.processKeyEvent\(InputHandler.java:184\)
at org.gjt.sp.jedit.textarea.TextArea.processKeyEvent\(TextArea.java:4572\)
at java.awt.Component.processEvent\(Unknown Source\)
at java.awt.Container.processEvent\(Unknown Source\)
at java.awt.Component.dispatchEventImpl\(Unknown Source\)
at java.awt.Container.dispatchEventImpl\(Unknown Source\)
at java.awt.Component.dispatchEvent\(Unknown Source\)
at java.awt.KeyboardFocusManager.redispatchEvent\(Unknown Source\)
at java.awt.DefaultKeyboardFocusManager.dispatchKeyEvent\(Unknown Source\)
at java.awt.DefaultKeyboardFocusManager.preDispatchKeyEvent\(Unknown Source\)
at java.awt.DefaultKeyboardFocusManager.typeAheadAssertions\(Unknown Source\)
at java.awt.DefaultKeyboardFocusManager.dispatchEvent\(Unknown Source\)
at java.awt.Component.dispatchEventImpl\(Unknown Source\)
at java.awt.Container.dispatchEventImpl\(Unknown Source\)
at java.awt.Window.dispatchEventImpl\(Unknown Source\)
at java.awt.Component.dispatchEvent\(Unknown Source\)
at java.awt.EventQueue.dispatchEvent\(Unknown Source\)
at java.awt.EventDispatchThread.pumpOneEventForFilters\(Unknown Source\)
at java.awt.EventDispatchThread.pumpEventsForFilter\(Unknown Source\)
at java.awt.EventDispatchThread.pumpEventsForHierarchy\(Unknown Source\)
at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
at java.awt.EventDispatchThread.run\(Unknown Source\)",org.gjt.sp.jedit.buffer.JEditBuffer
CLASS,jedit-4.3,1600401,2006-11-21T13:16:31.000-06:00,StringIndexOutOfBoundsException in TokenMarker,"lt;init&gt; 
    
    
    
    
    
    
    
    
    
    
    
  
  
  
  
  
  
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
   {12,39\} 
    
     lt;init&gt; 
      
      
      
      
      
      
      
      
    
    
    
      
    
    
    
    
    
    
    
    
    
    
    
    
    
   {12,39\} 
    
     lt;init&gt; 
      
      
      
      
      
      
      
    
  
    
    
    
      
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
     lt;init&gt; 
      
      
      
      
      
      
    
    
  
    
    
    
      
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
     lt;init&gt;
After pressing ENTER in a rather long line in a .
php file, I got the following exception.
The line appeared wrong highlighted in the first place, that why I wanted to see if splitting it would resolve the highlight issue.
After this the buffer window is not usable anymore \(e.g. I cannot enter it, nor does it get repainted\).
\[error\] Buffer: Exception while sending buffer event to org.gjt.sp.jedit.textarea.BufferHandler@1484a8a :
\[error\] Buffer: java.lang.StringIndexOutOfBoundsException: String index out of range: 103
\[error\] Buffer:  at java.lang.String.&lt;init&gt;\(Unknown Source\)
\[error\] Buffer:  at org.gjt.sp.jedit.syntax.TokenMarker.handleRule\(TokenMarker.java:343\)
\[error\] Buffer:  at org.gjt.sp.jedit.syntax.TokenMarker.markTokens\(TokenMarker.java:155\)
\[error\] Buffer:  at org.gjt.sp.jedit.buffer.JEditBuffer.markTokens\(JEditBuffer.java:1234\)
\[error\] Buffer:  at org.gjt.sp.jedit.textarea.ChunkCache.lineToChunkList\(ChunkCache.java:771\)
\[error\] Buffer:  at org.gjt.sp.jedit.textarea.ChunkCache.getLineSubregionCount\(ChunkCache.java:266\)
\[error\] Buffer:  at org.gjt.sp.jedit.textarea.DisplayManager.updateScreenLineCount\(DisplayManager.java:661\)
\[error\] Buffer:  at org.gjt.sp.jedit.textarea.BufferHandler.doDelayedUpdate\(BufferHandler.java:327\)
\[error\] Buffer:  at org.gjt.sp.jedit.textarea.BufferHandler.transactionComplete\(BufferHandler.java:287\)
\[error\] Buffer:  at org.gjt.sp.jedit.buffer.JEditBuffer.fireTransactionComplete\(JEditBuffer.java:2173\)
\[error\] Buffer:  at org.gjt.sp.jedit.buffer.JEditBuffer.endCompoundEdit\(JEditBuffer.java:1966\)
\[error\] Buffer:  at org.gjt.sp.jedit.textarea.TextArea.insertEnterAndIndent\(TextArea.java:4331\)
\[error\] Buffer:  at sun.reflect.NativeMethodAccessorImpl.invoke0\(Native Method\)
\[error\] Buffer:  at sun.reflect.NativeMethodAccessorImpl.invoke\(Unknown Source\)
\[error\] Buffer:  at sun.reflect.DelegatingMethodAccessorImpl.invoke\(Unknown Source\)
\[error\] Buffer:  at java.lang.reflect.Method.invoke\(Unknown Source\)
\[error\] Buffer:  at bsh.Reflect.invokeMethod\(Reflect.java:134\)
\[error\] Buffer:  at bsh.Reflect.invokeObjectMethod\(Reflect.java:80\)
\[error\] Buffer:  at bsh.Name.invokeMethod\(Name.java:858\)
\[error\] Buffer:  at bsh.BSHMethodInvocation.eval\(BSHMethodInvocation.java:75\)
\[error\] Buffer:  at bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:102\)
\[error\] Buffer:  at bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:47\)
\[error\] Buffer:  at bsh.BSHBlock.evalBlock\(BSHBlock.java:130\)
\[error\] Buffer:  at bsh.BSHBlock.eval\(BSHBlock.java:80\)
\[error\] Buffer:  at bsh.BshMethod.invokeImpl\(BshMethod.java:362\)
\[error\] Buffer:  at bsh.BshMethod.invoke\(BshMethod.java:258\)
\[error\] Buffer:  at bsh.BshMethod.invoke\(BshMethod.java:186\)
\[error\] Buffer:  at org.gjt.sp.jedit.BeanShell.runCachedBlock\(BeanShell.java:509\)
\[error\] Buffer:  at org.gjt.sp.jedit.BeanShellAction.invoke\(BeanShellAction.java:76\)
\[error\] Buffer:  at org.gjt.sp.jedit.gui.InputHandler.invokeAction\(InputHandler.java:415\)
\[error\] Buffer:  at org.gjt.sp.jedit.gui.InputHandler.invokeAction\(InputHandler.java:381\)
\[error\] Buffer:  at org.gjt.sp.jedit.gui.DefaultInputHandler.handleKey\(DefaultInputHandler.java:373\)
\[error\] Buffer:  at org.gjt.sp.jedit.input.AbstractInputHandler.processKeyEventKeyStrokeHandling\(AbstractInputHandler.java:116\)
\[error\] Buffer:  at org.gjt.sp.jedit.gui.InputHandler.processKeyEvent\(InputHandler.java:184\)
\[error\] Buffer:  at org.gjt.sp.jedit.textarea.TextArea.processKeyEvent\(TextArea.java:4572\)
\[error\] Buffer:  at java.awt.Component.processEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.Container.processEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.Component.dispatchEventImpl\(Unknown Source\)
\[error\] Buffer:  at java.awt.Container.dispatchEventImpl\(Unknown Source\)
\[error\] Buffer:  at java.awt.Component.dispatchEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.KeyboardFocusManager.redispatchEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.DefaultKeyboardFocusManager.dispatchKeyEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.DefaultKeyboardFocusManager.preDispatchKeyEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.DefaultKeyboardFocusManager.typeAheadAssertions\(Unknown Source\)
\[error\] Buffer:  at java.awt.DefaultKeyboardFocusManager.dispatchEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.Component.dispatchEventImpl\(Unknown Source\)
\[error\] Buffer:  at java.awt.Container.dispatchEventImpl\(Unknown Source\)
\[error\] Buffer:  at java.awt.Window.dispatchEventImpl\(Unknown Source\)
\[error\] Buffer:  at java.awt.Component.dispatchEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.EventQueue.dispatchEvent\(Unknown Source\)
\[error\] Buffer:  at java.awt.EventDispatchThread.pumpOneEventForFilters\(Unknown Source\)
\[error\] Buffer:  at java.awt.EventDispatchThread.pumpEventsForFilter\(Unknown Source\)
\[error\] Buffer:  at java.awt.EventDispatchThread.pumpEventsForHierarchy\(Unknown Source\)
\[error\] Buffer:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] Buffer:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] Buffer:  at java.awt.EventDispatchThread.run\(Unknown Source\)
\[error\] ExtensionManager: Error repainting line range \{12,39\}:
\[error\] ExtensionManager: java.lang.StringIndexOutOfBoundsException: String index out of range: 103
\[error\] ExtensionManager:  at java.lang.String.&lt;init&gt;\(Unknown Source\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.syntax.TokenMarker.handleRule\(TokenMarker.java:343\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.syntax.TokenMarker.markTokens\(TokenMarker.java:155\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.buffer.JEditBuffer.markTokens\(JEditBuffer.java:1234\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ChunkCache.lineToChunkList\(ChunkCache.java:771\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ChunkCache.updateChunksUpTo\(ChunkCache.java:646\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ChunkCache.getLineInfo\(ChunkCache.java:255\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ExtensionManager.paintScreenLineRange\(ExtensionManager.java:102\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.TextAreaPainter.paint\(TextAreaPainter.java:726\)
\[error\] ExtensionManager:  at javax.swing.JComponent.paintToOffscreen\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.BufferStrategyPaintManager.paint\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.paint\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.JComponent.\_paintImmediately\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.JComponent.paintImmediately\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.paintDirtyRegions\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.paintDirtyRegions\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.seqPaintDirtyRegions\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.SystemEventQueueUtilities$ComponentWorkRequest.run\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.event.InvocationEvent.dispatch\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventQueue.dispatchEvent\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpOneEventForFilters\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEventsForFilter\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEventsForHierarchy\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.run\(Unknown Source\)
\[error\] ExtensionManager: Error repainting line range \{12,39\}:
\[error\] ExtensionManager: java.lang.StringIndexOutOfBoundsException: String index out of range: 103
\[error\] ExtensionManager:  at java.lang.String.&lt;init&gt;\(Unknown Source\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.syntax.TokenMarker.handleRule\(TokenMarker.java:343\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.syntax.TokenMarker.markTokens\(TokenMarker.java:155\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.buffer.JEditBuffer.markTokens\(JEditBuffer.java:1234\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ChunkCache.lineToChunkList\(ChunkCache.java:771\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ChunkCache.updateChunksUpTo\(ChunkCache.java:646\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ChunkCache.getLineInfo\(ChunkCache.java:255\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.ExtensionManager.paintScreenLineRange\(ExtensionManager.java:102\)
\[error\] ExtensionManager:  at org.gjt.sp.jedit.textarea.Gutter.paintComponent\(Gutter.java:131\)
\[error\] ExtensionManager:  at javax.swing.JComponent.paint\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.JComponent.paintToOffscreen\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.BufferStrategyPaintManager.paint\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.paint\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.JComponent.\_paintImmediately\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.JComponent.paintImmediately\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.paintDirtyRegions\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.paintDirtyRegions\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.RepaintManager.seqPaintDirtyRegions\(Unknown Source\)
\[error\] ExtensionManager:  at javax.swing.SystemEventQueueUtilities$ComponentWorkRequest.run\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.event.InvocationEvent.dispatch\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventQueue.dispatchEvent\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpOneEventForFilters\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEventsForFilter\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEventsForHierarchy\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] ExtensionManager:  at java.awt.EventDispatchThread.run\(Unknown Source\)
\[error\] AWT-EventQueue-0: Exception in thread ""AWT-EventQueue-0""
\[error\] AWT-EventQueue-0: java.lang.StringIndexOutOfBoundsException: String index out of range: 103
\[error\] AWT-EventQueue-0:  at java.lang.String.&lt;init&gt;\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.syntax.TokenMarker.handleRule\(TokenMarker.java:343\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.syntax.TokenMarker.markTokens\(TokenMarker.java:155\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.buffer.JEditBuffer.markTokens\(JEditBuffer.java:1234\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.ChunkCache.lineToChunkList\(ChunkCache.java:771\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.ChunkCache.updateChunksUpTo\(ChunkCache.java:646\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.ChunkCache.getLineInfo\(ChunkCache.java:255\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.Gutter.paintLine\(Gutter.java:544\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.Gutter.paintComponent\(Gutter.java:137\)
\[error\] AWT-EventQueue-0:  at javax.swing.JComponent.paint\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.JComponent.paintToOffscreen\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.BufferStrategyPaintManager.paint\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.RepaintManager.paint\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.JComponent.\_paintImmediately\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.JComponent.paintImmediately\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.RepaintManager.paintDirtyRegions\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.RepaintManager.paintDirtyRegions\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.RepaintManager.seqPaintDirtyRegions\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.SystemEventQueueUtilities$ComponentWorkRequest.run\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.event.InvocationEvent.dispatch\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventQueue.dispatchEvent\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpOneEventForFilters\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEventsForFilter\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEventsForHierarchy\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.run\(Unknown Source\)
\[error\] AWT-EventQueue-0: Exception in thread ""AWT-EventQueue-0""
\[error\] AWT-EventQueue-0: java.lang.StringIndexOutOfBoundsException: String index out of range: 103
\[error\] AWT-EventQueue-0:  at java.lang.String.&lt;init&gt;\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.syntax.TokenMarker.handleRule\(TokenMarker.java:343\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.syntax.TokenMarker.markTokens\(TokenMarker.java:155\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.buffer.JEditBuffer.markTokens\(JEditBuffer.java:1234\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.ChunkCache.lineToChunkList\(ChunkCache.java:771\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.ChunkCache.updateChunksUpTo\(ChunkCache.java:646\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.ChunkCache.getLineInfo\(ChunkCache.java:255\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.TextArea.invalidateLine\(TextArea.java:1145\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.TextArea.blinkCaret\(TextArea.java:2118\)
\[error\] AWT-EventQueue-0:  at org.gjt.sp.jedit.textarea.TextArea$CaretBlinker.actionPerformed\(TextArea.java:5907\)
\[error\] AWT-EventQueue-0:  at javax.swing.Timer.fireActionPerformed\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at javax.swing.Timer$DoPostEvent.run\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.event.InvocationEvent.dispatch\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventQueue.dispatchEvent\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpOneEventForFilters\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEventsForFilter\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEventsForHierarchy\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.pumpEvents\(Unknown Source\)
\[error\] AWT-EventQueue-0:  at java.awt.EventDispatchThread.run\(Unknown Source\)
\[debug\] PHPSideKickParser: Requesting sidekick complete
\[debug\] WorkThread: Running in work thread: \[id=265,run=org.gjt.sp.jedit.bufferio.BufferAutosaveRequest\[Y.php \(X\\\)\]\]
\[debug\] DockableWindowManager: Loading dockables from jeditresource:/ErrorList.jar\!/dockables.xml
\[debug\] EditBus: DockableWindowUpdate\[what=ACTIVATED,dockable=error-list,source=org.gjt.sp.jedit.gui.DockableWindowManager\[,0,0,1600x1081,invalid,layout=org.gjt.sp.jedit.gui.DockableLayout,alignmentX=0.0,alignmentY=0.0,border=,flags=9,maximumSize=,minimumSize=,preferredSize=\]\]",org.gjt.sp.jedit.syntax.TokenMarker
CLASS,jedit-4.3,1658252,2007-02-12T17:48:03.000-06:00,C mode: incorrect bracket matching in multi-line defines,"{ \
code;                         \
more code;                    \
even more code;               \
\}
try define
\#define LONG\_MULTI\_LINE\_DEFINE \{ \
code;                         \
more code;                    \
even more code;               \
\}
The brackets don't match.","org.gjt.sp.jedit.syntax.ParserRule
org.gjt.sp.jedit.syntax.XModeHandler
org.gjt.sp.jedit.syntax.XModeHandler.TagDecl
org.gjt.sp.jedit.syntax.TokenMarker"
CLASS,jedit-4.3,1724940,2007-05-24T15:02:18.000-05:00,typing in multiple select,"lt;body&gt;
  lt;p&gt;
 
 the &lt;p&gt;  
 lt;body&gt;
  lt;d&gt;
If I highlight multiple selections of text in the text area and then begin typing, only the first character of what I type is inserted in the selected areas \(except for where the cursor ended up after making the selection\).
have text
&lt;body&gt;
&lt;p&gt;
Some Text
&lt;/p&gt;
&lt;/body&gt;
and I highlight both p's in the &lt;p&gt; tags and then type ""div"" I end up with:
&lt;body&gt;
&lt;d&gt;
Some Text
&lt;/div&gt;
&lt;/body&gt;
I've attached a screenshot.",org.gjt.sp.jedit.textarea.BufferHandler
CLASS,jedit-4.3,1999448,2008-08-23T10:28:24.000-05:00,Unnecesarry fold expantion when folded lines are edited,"{\{\{ hello

something

\}
While testing the patch \#1999448, a problem was found.
But the patch was applied in r13404 to avoid more
serious black hole bugs.
This problem has now became a
bug.
fold with buffer
\{\{\{ hello
something
\}\}\}
all folds are folded.
remove l","org.gjt.sp.jedit.textarea.BufferHandler
org.gjt.sp.jedit.textarea.DisplayManager
org.gjt.sp.jedit.textarea.TextArea"
CLASS,jedit-4.3,2129419,2008-09-25T23:53:11.000-05:00,NPE in EditPane.setBuffer when quitting jEdit,"lt;init&gt;
When trying to quit jEdit, I get the following Null-Pointer-Exception, which is probably related to some files being changed/deleted \(due to a ""cvs up"" in the background\).
Previously to trying to quit jEdit, the ""Files have changed.
Reload?""
dialog already failed, so that ""Close"" was the only option that worked.
The NPE:
java.lang.NullPointerException
at org.gjt.sp.jedit.EditPane.setBuffer\(EditPane.java:136\)
at org.gjt.sp.jedit.View.setBuffer\(View.java:1009\)
at org.gjt.sp.jedit.View.showBuffer\(View.java:1484\)
at org.gjt.sp.jedit.View.showBuffer\(View.java:1042\)
at org.gjt.sp.jedit.gui.CloseDialog$ListHandler.valueChanged\(CloseDialog.java:233\)
at javax.swing.JList.fireSelectionValueChanged\(JList.java:1765\)
at javax.swing.JList$ListSelectionHandler.valueChanged\(JList.java:1779\)
at javax.swing.DefaultListSelectionModel.fireValueChanged\(DefaultListSelectionModel.java:167\)
at javax.swing.DefaultListSelectionModel.fireValueChanged\(DefaultListSelectionModel.java:147\)
at javax.swing.DefaultListSelectionModel.fireValueChanged\(DefaultListSelectionModel.java:194\)
at javax.swing.DefaultListSelectionModel.changeSelection\(DefaultListSelectionModel.java:388\)
at javax.swing.DefaultListSelectionModel.changeSelection\(DefaultListSelectionModel.java:398\)
at javax.swing.DefaultListSelectionModel.setSelectionInterval\(DefaultListSelectionModel.java:442\)
at javax.swing.JList.setSelectedIndex\(JList.java:2179\)
at org.gjt.sp.jedit.gui.CloseDialog.&lt;init&gt;\(CloseDialog.java:96\)
at org.gjt.sp.jedit.jEdit.closeAllBuffers\(jEdit.java:1871\)
at org.gjt.sp.jedit.jEdit.exit\(jEdit.java:2621\)
at sun.reflect.NativeMethodAccessorImpl.invoke0\(Native Method\)
at sun.reflect.NativeMethodAccessorImpl.invoke\(NativeMethodAccessorImpl.java:39\)
at sun.reflect.DelegatingMethodAccessorImpl.invoke\(DelegatingMethodAccessorImpl.java:25\)
at java.lang.reflect.Method.invoke\(Method.java:597\)
at org.gjt.sp.jedit.bsh.Reflect.invokeMethod\(Reflect.java:134\)
at org.gjt.sp.jedit.bsh.Reflect.invokeStaticMethod\(Reflect.java:98\)
at org.gjt.sp.jedit.bsh.Name.invokeMethod\(Name.java:871\)
at org.gjt.sp.jedit.bsh.BSHMethodInvocation.eval\(BSHMethodInvocation.java:75\)
at org.gjt.sp.jedit.bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:102\)
at org.gjt.sp.jedit.bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:47\)
at org.gjt.sp.jedit.bsh.BSHBlock.evalBlock\(BSHBlock.java:130\)
at org.gjt.sp.jedit.bsh.BSHBlock.eval\(BSHBlock.java:80\)
at org.gjt.sp.jedit.bsh.BshMethod.invokeImpl\(BshMethod.java:362\)
at org.gjt.sp.jedit.bsh.BshMethod.invoke\(BshMethod.java:258\)
at org.gjt.sp.jedit.bsh.BshMethod.invoke\(BshMethod.java:186\)
at org.gjt.sp.jedit.BeanShellFacade.runCachedBlock\(BeanShellFacade.java:225\)
at org.gjt.sp.jedit.BeanShell.runCachedBlock\(BeanShell.java:441\)
at org.gjt.sp.jedit.BeanShellAction.invoke\(BeanShellAction.java:73\)
at org.gjt.sp.jedit.gui.InputHandler.invokeAction\(InputHandler.java:352\)
at org.gjt.sp.jedit.jEdit$4.invokeAction\(jEdit.java:3080\)
at org.gjt.sp.jedit.jEdit$4.invokeAction\(jEdit.java:3062\)
at org.gjt.sp.jedit.EditAction$Wrapper.actionPerformed\(EditAction.java:220\)
at javax.swing.AbstractButton.fireActionPerformed\(AbstractButton.java:1995\)
at javax.swing.AbstractButton$Handler.actionPerformed\(AbstractButton.java:2318\)
at javax.swing.DefaultButtonModel.fireActionPerformed\(DefaultButtonModel.java:387\)
at javax.swing.DefaultButtonModel.setPressed\(DefaultButtonModel.java:242\)
at javax.swing.AbstractButton.doClick\(AbstractButton.java:357\)
at javax.swing.plaf.basic.BasicMenuItemUI.doClick\(BasicMenuItemUI.java:1220\)
at javax.swing.plaf.basic.BasicMenuItemUI$Handler.mouseReleased\(BasicMenuItemUI.java:1261\)
at java.awt.AWTEventMulticaster.mouseReleased\(AWTEventMulticaster.java:272\)
at java.awt.Component.processMouseEvent\(Component.java:6041\)
at javax.swing.JComponent.processMouseEvent\(JComponent.java:3265\)
at java.awt.Component.processEvent\(Component.java:5806\)
at java.awt.Container.processEvent\(Container.java:2058\)
at java.awt.Component.dispatchEventImpl\(Component.java:4413\)
at java.awt.Container.dispatchEventImpl\(Container.java:2116\)
at java.awt.Component.dispatchEvent\(Component.java:4243\)
at java.awt.LightweightDispatcher.retargetMouseEvent\(Container.java:4322\)
at java.awt.LightweightDispatcher.processMouseEvent\(Container.java:3986\)
at java.awt.LightweightDispatcher.dispatchEvent\(Container.java:3916\)
at java.awt.Container.dispatchEventImpl\(Container.java:2102\)
at java.awt.Window.dispatchEventImpl\(Window.java:2440\)
at java.awt.Component.dispatchEvent\(Component.java:4243\)
at java.awt.EventQueue.dispatchEvent\(EventQueue.java:599\)
at java.awt.EventDispatchThread.pumpOneEventForFilters\(EventDispatchThread.java:273\)
at java.awt.EventDispatchThread.pumpEventsForFilter\(EventDispatchThread.java:183\)
at java.awt.EventDispatchThread.pumpEventsForHierarchy\(EventDispatchThread.java:173\)
at java.awt.EventDispatchThread.pumpEvents\(EventDispatchThread.java:168\)
at java.awt.EventDispatchThread.pumpEvents\(EventDispatchThread.java:160\)
at java.awt.EventDispatchThread.run\(EventDispatchThread.java:121\)",org.gjt.sp.jedit.gui.CloseDialog.ListHandler
