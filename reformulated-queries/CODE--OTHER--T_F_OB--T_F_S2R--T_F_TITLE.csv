Dataset,System,Bug ID,Creation Date,Title,Description,Ground Truth
CLASS,lucene-4.0,LUCENE-4461,2012-10-05T10:21:38.000-05:00,create inconsistent results,"FacetSearchParams facetSearchParams = new FacetSearchParams();
		facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(""author""), 10));
		facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(""author""), 10));
create wrong results in case
FacetSearchParams facetSearchParams = new FacetSearchParams();
		facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(""author""), 10));
		facetSearchParams.addFacetRequest(new CountFacetRequest(new CategoryPath(""author""), 10));
Problem can be fixed by defining hashcode and equals in certain way that Lucene recognize we are talking about different requests.
Attached test case.",org.apache.lucene.facet.search.StandardFacetsAccumulator
CLASS,tika-1.3,TIKA-1152,2013-07-23T08:45:11.000-05:00,process loops on parsing parse of CHM file,"{code}
 
    
     
    
    
    
    
    
    
    
    
 {code}
stick by parsing
{code}
Thread[main,5,main]
org.apache.tika.parser.chm.lzx.ChmLzxBlock.extractContent(ChmLzxBlock.java:203)
org.apache.tika.parser.chm.lzx.ChmLzxBlock.<init>(ChmLzxBlock.java:77)
org.apache.tika.parser.chm.core.ChmExtractor.extractChmEntry(ChmExtractor.java:338)
org.apache.tika.parser.chm.CHMDocumentInformation.getContent(CHMDocumentInformation.java:72)
org.apache.tika.parser.chm.CHMDocumentInformation.getText(CHMDocumentInformation.java:141)
org.apache.tika.parser.chm.CHM2XHTML.process(CHM2XHTML.java:34)
org.apache.tika.parser.chm.ChmParser.parse(ChmParser.java:51)
org.apache.tika.parser.ParserDecorator.parse(ParserDecorator.java:91)
org.apache.tika.parser.CompositeParser.parse(CompositeParser.java:242)
org.apache.tika.parser.AbstractParser.parse(AbstractParser.java:53)
com.polyspot.document.converter.DocumentConverter.realizeConversion(DocumentConverter.java:192)
...
{code}",tika-parsers.src.main.java.org.apache.tika.parser.chm.lzx.ChmLzxBlock
FILE,DATAMONGO,DATAMONGO-467,2012-06-24T08:58:49.000-05:00,use QueryDSL,"@Document 
 @Id String id;






 
 QUser.id.eq(""4f43b6a384aea4e77d403709"")
use entity definition with String
User.class
...
@Id String id;
and following query
QUser.id.eq(""4f43b6a384aea4e77d403709"")
not translate String 4f43b6a384aea4e77d403709 to ObjectId(""4f43b6a384aea4e77d403709"") look at mongoDb query do in mongo shell",org.springframework.data.mongodb.repository.support.SpringDataMongodbSerializerUnitTests
FILE,DATAMONGO,DATAMONGO-505,2012-08-14T03:07:56.000-05:00,not work for collection values,"class Entity {









  Long id;




  @DBRef




  Property property;




}









 class Property {




  Long id;




}









 interface EntityRepository extends Repository<Entity, Long> {









  Entity findByPropertyIn(Property... property);




}






  findByProperty()
have following scenario
class Entity {
Long id;
@DBRef
Property property;
}
class Property {
Long id;
}
interface EntityRepository extends Repository<Entity, Long> {
Entity findByPropertyIn(Property... property);
}
not translate given array into collection
treat value create DBRef","org.springframework.data.mongodb.repository.query.ConvertingParameterAccessor
org.springframework.data.mongodb.repository.query.ConvertingParameterAccessorUnitTests"
FILE,DATAMONGO,DATAMONGO-523,2012-09-01T03:39:51.000-05:00,not use with AbstractMongoConfiguration,"@TypeAlias      @Document  @TypeAlias
use AbstractMongoConfiguration without further modifications write _ class property
use SimpleTypeInformationMapper
The documentation suggests that you just annotate your @Document classes with the @TypeAlias annotations and everything should be fine.",org.springframework.data.mongodb.core.convert.MappingMongoConverterUnitTests
FILE,DATAMONGO,DATAMONGO-585,2012-12-01T08:28:43.000-06:00,exception during authentication,"class which implements Runnable.  
Those
Bug & further details are here:
http://forum.springsource.org/showthread.php?132878-can-t-authenticate-twice-on-same-database
use ThreadPoolExecutor set minpool maxpool value add objects use specifically for test case
implement runnable implement class
perform bunch into mongoDB perform bunch of inserts use DocumentDao call mongoOperations.insert. call DocumentDao
thanks",org.springframework.data.mongodb.core.MongoDbUtils
FILE,DATAMONGO,DATAMONGO-629,2013-03-22T04:08:25.000-05:00,count with field find with field,"Query q = query 
    
  
 
 
 {




		""id"" : /zzz/




	} 
 
 
 
 
 
  
  
 
 
 {




		""count"" : ""test"",




		""query"" : {




			""_id"" : /zzz/




		}




	 
 
 
 
 
 
     find()     count()
have following query
Query q = query(where('id').
regex('zzz'))
{ ""ts"" : ISODate(""2013-03-22T10:00:51.685Z""),
""op"" : ""query"",
""ns"" : ""test.test"",
""query"" : {
""id"" : /zzz/
},
""nscanned"" : 1,
""responseLength"" : 20,
""millis"" : 0,
""client"" : ""127.0.0.1"",
""user"" : """"
}
use in count )
{
""ts"" : ISODate(""2013-03-22T10:00:36.299Z""),
""op"" : ""command"",
""ns"" : ""test.
$cmd"",
""command"" : {
""count"" : ""test"",
""query"" : {
""_id"" : /zzz/
}
},
""ntoreturn"" : 1,
""responseLength"" : 48,
""millis"" : 0,
""client"" : ""127.0.0.1"",
""user"" : """"
}
have records with field id retrieve from db
give bad results use _ id field
In org.springframework.data.mongodb.core.convert.QueryMapper the method determineKey, for some reason treats id and _id as the same field.
not use QueryMapper not use count()","org.springframework.data.mongodb.core.mapping.MongoMappingContext
org.springframework.data.mongodb.core.MongoTemplateTests
org.springframework.data.mongodb.core.convert.QueryMapper
org.springframework.data.mongodb.core.convert.QueryMapperUnitTests"
FILE,DATAMONGO,DATAMONGO-571,2012-11-09T08:00:10.000-06:00,not save null values add @Version to domain class,"Scenario 
 CrudRepository.findOne()  
 @Version 
 CrudRepository.save()  
 @Version
Scenario:
use CrudRepository.findOne() method load domain class from mongodb
set loaded instances to null
use CrudRepository.save() method save loaded instance to same mongodb
set field to null doesnt write to database
Important: The problem doesnt occur when @Version annotation is not used in the domain class definition.","org.springframework.data.mongodb.core.MongoTemplateTests
org.springframework.data.mongodb.core.query.Update"
FILE,DATAMONGO,DATAMONGO-392,2012-02-07T04:28:15.000-06:00,update object not write type information for objects,"MappingMongoConverter.writeInternal(...)   addCustomTypeIfNecessary(...)     convertToMongoType(...)   removeTypeInfoRecursively(...)
use complex domain model consist complex domain model of instantiable domain classes
use 1.0.0
read from database store m5 version with object store type information with object
That worked perfectly for me till my upgrade to 1.0.0.
break application break RELEASE version save objects without type information read back to java model
call addCustomTypeIfNecessary(...) in turn call MappingMongoConverter.writeInternal(...) method in turn put type information into DBObject put addCustomTypeIfNecessary(...) into DBObject
call removeTypeInfoRecursively(...) during execution save under _ class key
I had to comment out this call in order to
The first point is that there is a contradiction: why to save type information to DBObject if it is later removed by other method?","org.springframework.data.mongodb.core.MongoTemplateTests
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-721,2013-07-11T11:36:06.000-05:00,persist on update operations,"@Document
public class ParentClass {
   private List<ChildClass> list;
}
    @Document   
        
  
 mongoTemplate.updateFirst(Query.query(criteria), 
  new Update().push(""list"", child));
We found a problem with Spring Data for Mongo DB.
have entity have attribute have entity
@Document public class ParentClass { private List<ChildClass> list;
} the ChildClass is annotated with @Document too, but we want to store it's content as an embed document of ParentClass.
use MongoTemplate class with code face instantiation problems not insert _ class attribute on embedded document
mongoTemplate.updateFirst(Query.query(criteria), new Update().
push(""list"", child));
not add _ class attribute to embedded document",org.springframework.data.mongodb.core.convert.QueryMapper
FILE,DATAMONGO,DATAMONGO-602,2013-01-30T02:22:53.000-06:00,return results query with $in operator query on id field,"List<BigInteger> profileIds = findProfileIds();




Predicate predicate = QProfileDocument.profileDocument.id.in(profileIds);




Iterable<ProfileDocument> profiles = profileRepository.findAll(predicate);
query for documents be in given list
Id field is mapped as a BigInteger.
contain item
List<BigInteger> profileIds = findProfileIds();
Predicate predicate = QProfileDocument.profileDocument.id.in(profileIds);
Iterable<ProfileDocument> profiles = profileRepository.findAll(predicate);
The underlying MongodbQuery is different if there is only one item in profileIds.
{ ""_id"" : { ""$in"" : [ ""25069473312490162649510603609"" , ""25045916045544535958655878835""]}}
{ ""_id"" : { ""$oid"" : ""5100fb776c67e7e092be6b59""}}
return results in first case return results in first case work Iterable with item work Iterable in second return Iterable with item return Iterable in second
As you can see, the problem is with the representation of the BigInteger.
using decimal format will not work with MongoDB.",org.springframework.data.mongodb.core.MongoTemplateTests
FILE,DATAMONGO,DATAMONGO-805,2013-12-02T06:34:36.000-06:00,exclude DBRef field in query cause MappingException,"Query query = new Query(Criteria.where(""parentField"").is(""test""));
        query.fields().exclude(""children"");
        ParentClass parentClass = mongoOperations.findOne(query, ParentClass.class);
exclude field in query throw MappingException
Query query = new Query(Criteria.where(""parentField"").
is(""test""));
query.fields().
exclude(""children"");
ParentClass parentClass = mongoOperations.findOne(query, ParentClass.class);
org.springframework.data.mapping.model.MappingException: No mapping metadata found for class java.lang.Integer
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.createDBRef(MappingMongoConverter.java:729)
at com.digitalshadows.collation.persistence.impl.CollectionNameProvidedMongoConverter.createDBRef(CollectionNameProvidedMongoConverter.java:28)
at org.springframework.data.mongodb.core.convert.MappingMongoConverter.toDBRef(MappingMongoConverter.java:288)
at org.springframework.data.mongodb.core.convert.QueryMapper.convertAssociation(QueryMapper.java:273)
at org.springframework.data.mongodb.core.convert.QueryMapper.getMappedValue(QueryMapper.java:204)
at org.springframework.data.mongodb.core.convert.QueryMapper.getMappedObject(QueryMapper.java:113)
at org.springframework.data.mongodb.core.MongoTemplate.doFindOne(MongoTemplate.java:1439)
at org.springframework.data.mongodb.core.MongoTemplate.findOne(MongoTemplate.java:489)
at org.springframework.data.mongodb.core.MongoTemplate.findOne(MongoTemplate.java:484)
at ExcludeDBRefFieldTest.testExcludeChildren(ExcludeDBRefFieldTest.java:28)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
at java.lang.reflect.Method.invoke(Unknown Source)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:74)
at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:83)
at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:72)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:231)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:88)
at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:174)
at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
attach simple test case throw MappingException throw simple test case
The workaround for this I can currently see is to use include for all the other fields instead.","org.springframework.data.mongodb.core.convert.QueryMapper
org.springframework.data.mongodb.core.mapping.MappingTests
org.springframework.data.mongodb.core.convert.QueryMapperUnitTests"
FILE,DATAMONGO,DATAMONGO-897,2014-04-01T04:38:51.000-05:00,use @DbRef as target use interface as target,"MongoTemplate.findAndModify(...)   @DbRef  @DbRef
use MongoTemplate.findAndModify(...) with @DbRef use MongoTemplate.findAndModify(...) with interface use MongoTemplate.findAndModify(...) as @DbRef target
See attached project for more details.
Probably regression issue since same test is passing with Spring Data Commons 1.6.3.
RELEASE and Spring Data MongoDB 1.3.3.
RELEASE.","org.springframework.data.mongodb.core.convert.UpdateMapperUnitTests
org.springframework.data.mongodb.core.convert.QueryMapper"
FILE,DATAMONGO,DATAMONGO-892,2014-03-28T09:08:03.000-05:00,not configure as nested bean definition,"parserContext.isNested()
work sample config in 1.1.1 version
<beans:bean id=""messageStore"" class=""org.springframework.integration.mongodb.store.ConfigurableMongoDbMessageStore"">
<beans:constructor-arg ref=""mongoDbFactory""/>
<beans:constructor-arg>
<mongo:mapping-converter>
<mongo:custom-converters>
<mongo:converter>
<beans:bean class=""org.springframework.integration.mongodb.store.ConfigurableMongoDbMessageGroupStoreTests$MessageReadConverter""/>
</mongo:converter>
</mongo:custom-converters>
</mongo:mapping-converter>
</beans:constructor-arg>
<beans:constructor-arg value=""testConfigurableMongoDbMessageStore""/>
</beans:bean>
not check if returns null not check if parserContext.isNested() BeanDefinition","org.springframework.data.mongodb.config.MappingMongoConverterParser
org.springframework.data.mongodb.config.MappingMongoConverterParserIntegrationTests"
FILE,DATAMONGO,DATAMONGO-647,2013-04-09T17:29:02.000-05:00,ignore @Field annotation for field alias,"@Field(""sr"")
 
 List<Answer> findByQuestionIdOrderByScoreDesc(String questionId)
create method use query approach
have field inside Answer object call score annotate score
@Field(""sr"")
int Score
List<Answer> findByQuestionIdOrderByScoreDesc(String questionId)
sort results by score sort results by sr field name",org.springframework.data.mongodb.core.convert.QueryMapperUnitTests
FILE,DATAMONGO,DATAMONGO-938,2014-05-21T06:09:48.000-05:00,create geo within Criteria use MapReduce,"Criteria.where(""location"")  within(new Box(lowerLeft, upperRight));
get IllegalArgumentException query MongoDB collection use Criteria.within use box
Criteria.where(""location"").
within(new Box(lowerLeft, upperRight));
java.lang.IllegalArgumentException: can't serialize class org.springframework.data.mongodb.core.query.GeoCommand","org.springframework.data.mongodb.core.mapreduce.MapReduceTests
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-952,2014-06-10T22:45:47.000-05:00,not work with only field restrictions,"@Query 
 @Query(fields = ""{ 'email' : 1 }"")




User findByEmail(String email)






  @Query
use based queries try based queries use @Query annotation limit fetched fields have effect
@Query(fields = ""{ 'email' : 1 }"")
User findByEmail(String email)
return fields of User have effect
use @Query with value define query",org.springframework.data.mongodb.repository.query.PartTreeMongoQuery
FILE,DATAMONGO,DATAMONGO-987,2014-07-14T12:01:52.000-05:00,get data use MongoTemplate problem with lazy loading,"@Document 
 @Document




class Parent {




     @Id




     private String id;




     private String name;




     @DBref(lazy=true)




     private Child child;









    // getters and setters ommited




}






 
 @Document




class Child {




      @Id




       private String id;




       private String name;




      //getters and setters ommited




}






 
 Parent parent = new Parent();




parent.setName(""Daddy"");




mongoTemplate.save(parent); //ok, it is persisted like we expected.




// Than we try to load this same entity from the database




Criteria criteria = Criteria.where(""_id"").is(parent.getId());




Parent persisted = mongoTemplate.findOne(new Query(criteria), Parent.class);




// The child attribute should be null, right?




assertNull(persisted.getChild()); // it fails
call Parent call child reference on entity class
@Document
class Parent {
@Id
private String id;
private String name;
@DBref(lazy=true)
private Child child;
// getters and setters ommited
}
and the Child class
@Document
class Child {
@Id
private String id;
private String name;
//getters and setters ommited
}
Parent parent = new Parent();
parent.setName(""Daddy"");
load same entity from database
Criteria criteria = Criteria.where(""_id"").
is(parent.getId());
Parent persisted = mongoTemplate.findOne(new Query(criteria), Parent.class);
The null attribute is actually an enhanced class generated by CGLib.
It should not be.
This brings a lot of problems when you, by accident, persist the same entity.
attach project with junit test reproduce project with junit test","org.springframework.data.mongodb.core.convert.MappingMongoConverter
org.springframework.data.mongodb.core.convert.DbRefMappingMongoConverterUnitTests"
FILE,DATAMONGO,DATAMONGO-1068,2014-10-08T19:43:32.000-05:00,build special cirteria,"public class Room {




		private String name;




		private List<Date> occupied;




	}






 
 {




		occupied : {




			$not : {




				$elemMatch : {




					$gte : start,




					$lte : end




				}




			}




		}




	}






 
 Criteria c1 = new Criteria().gte(start).lte(end);




	Criteria c = Criteria.where(""occupied"").not().elemMatch(c1);






 
 {




	occupied : {




		$not : {




			$elemMatch : {




			}




		}




	}




}






  elemMatch(Criteria)
public class Room {
private String name;
private List<Date> occupied;
}
fetch documents fall documents into specified date range
{
occupied : {
$not : {
$elemMatch : {
$gte : start,
$lte : end
}
}
}
}
Criteria c1 = new Criteria().
gte(start).
lte(end);
Criteria c = Criteria.where(""occupied"").
not().
elemMatch(c1);
{
occupied : {
$not : {
$elemMatch : {
}
}
}
}
empty map by invoking invoke elemMatch(Criteria) not assign key
But really no key I can assign to it.","org.springframework.data.mongodb.core.query.CriteriaTests
org.springframework.data.mongodb.core.query.Criteria"
FILE,DATAMONGO,DATAMONGO-1088,2014-11-07T03:08:58.000-06:00,not remove _ class property on collection,"@Query(value = ""{ embedded : { $in : ?0} }"")




	List<Foo> findByEmbeddedIn2(Collection<EmbeddedObject> c)
@Query(value = ""{ embedded : { $in : ?
0} }"")
List<Foo> findByEmbeddedIn2(Collection<EmbeddedObject> c);
generate incorrect query
{ ""embedded"" : { ""$in"" : [ {  ""_class"" : ""demo.EmbeddedObject"" , ""s"" : ""hello""}]}}
{ ""embedded"" : { ""$in"" : [ { ""s"" : ""hello""}]}}
attach test project demonstrate bug
This bug is related to https://jira.spring.io/browse/DATAMONGO-893","org.springframework.data.mongodb.core.convert.MappingMongoConverter
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-1123,2014-12-17T09:39:36.000-06:00,not return matching elements return max of documents,"public GeoResults<MyObject> findByTypeAndLocationNear(MyObjectType type, Point p, Distance distance) {




   final NearQuery nearQuery = NearQuery.near(p).maxDistance(distance);




   log.info(""{}"",nearQuery.toDBObject());




   return mongoTemplate.geoNear(nearQuery, MyObject.class);




}






   
 {@link GeoResults}   {@link NearQuery}
Aloha,
have following query
public GeoResults<MyObject> findByTypeAndLocationNear(MyObjectType type, Point p, Distance distance) {
final NearQuery nearQuery = NearQuery.near(p).
maxDistance(distance);
log.info(""{}"",nearQuery.toDBObject());
return mongoTemplate.geoNear(nearQuery, MyObject.class);
}
The geoNear method is documented like this:
Returns {@link GeoResults} for all entities matching the given {@link NearQuery}.
expect matching documents
restrict result
That should be stated in the method.
And another method having a pageable should be added.
What do you think?",org.springframework.data.mongodb.core.MongoOperations
FILE,DATAMONGO,DATAMONGO-1126,2014-12-21T06:03:21.000-06:00,keyword query findByInId with pageable,"getTotalElements()   getTotalPages()  
 @Document




public class Item {









    @Id




    private String id;




    private String type;




}












 public interface ItemRepository extends MongoRepository<Item, String> {









    Page<Item> findByIdIn(Collection ids, Pageable pageable);




    Page<Item> findByTypeIn(Collection types, Pageable pageable);




}












 @RunWith(SpringJUnit4ClassRunner.class)




@ContextConfiguration(classes = {MongoDbConfig.class})




@TransactionConfiguration(defaultRollback = false)




public class TestPageableIdIn {









    @Autowired




    private ItemRepository itemRepository;




    




    private List<String> allIds = new LinkedList<>();









    @Before




    public void setUp() {




        itemRepository.deleteAll();




        String[] types = {""SWORD"", ""SHIELD"", ""ARMOUR""};









        // 10 items per type




        for (String type : types) {




            for (int i = 0; i < 10; i++) {




                String id = UUID.randomUUID().toString();




                allIds.add(id);




                itemRepository.save(new Item(id, type));




            }




        }




    }









    @Test




    public void testPageableIdIn() {




        




        Pageable pageable = new PageRequest(0, 5);




        




        // expect 5 Items returned, total of 10 Items(SWORDS) in 2 Pages




        Page<Item> results = itemRepository.findByTypeIn(Arrays.asList(""SWORD""), pageable);




        Assert.assertEquals(5, results.getContent().size());




        Assert.assertEquals(10, results.getTotalElements());




        Assert.assertEquals(2, results.getTotalPages());




        




        // expect 5 Items returned, total of 30 Items in 6 Pages




        results = itemRepository.findByIdIn(allIds, pageable);




        Assert.assertEquals(5, results.getContent().size());




        Assert.assertEquals(30, results.getTotalElements()); // this is returning 0




        Assert.assertEquals(6, results.getTotalPages());     // this is returning 0




    }




}
use with identifiers make query pageable
get other page
I've tried using In with another member other than id and it works as expected.
use for testing
create types in total create types per types create items in total create items per types
@Document
public class Item {
@Id
private String id;
private String type;
}
public interface ItemRepository extends MongoRepository<Item, String> {
Page<Item> findByIdIn(Collection ids, Pageable pageable);
Page<Item> findByTypeIn(Collection types, Pageable pageable);
}
@RunWith(SpringJUnit4ClassRunner.class)
@ContextConfiguration(classes = {MongoDbConfig.class})
@TransactionConfiguration(defaultRollback = false)
public class TestPageableIdIn {
@Autowired
private ItemRepository itemRepository;
private List<String> allIds = new LinkedList<>();
@Before
public void setUp() {
itemRepository.deleteAll();
String[] types = {""SWORD"", ""SHIELD"", ""ARMOUR""};
// 10 items per type
for (String type : types) {
for (int i = 0; i < 10; i++) {
String id = UUID.randomUUID().
toString();
allIds.add(id);
itemRepository.save(new Item(id, type));
}
}
}
@Test
public void testPageableIdIn() {
Pageable pageable = new PageRequest(0, 5);
Page<Item> results = itemRepository.findByTypeIn(Arrays.asList(""SWORD""), pageable);
Assert.assertEquals(5, results.getContent().
size());
Assert.assertEquals(10, results.getTotalElements());
Assert.assertEquals(2, results.getTotalPages());
results = itemRepository.findByIdIn(allIds, pageable);
Assert.assertEquals(5, results.getContent().
size());
return //
return //
}
}","org.springframework.data.mongodb.repository.Person
org.springframework.data.mongodb.repository.query.AbstractMongoQueryUnitTests
org.springframework.data.mongodb.core.MongoOperations
org.springframework.data.mongodb.core.MongoTemplate
org.springframework.data.mongodb.repository.query.AbstractMongoQuery"
FILE,DATAMONGO,DATAMONGO-1250,2015-07-03T21:07:44.000-05:00,not use in updates,"@Document 
 
 
 @Document




public class MyPersistantObject  
 public Allocation allocation;




     public BigDecimal value;









     
 private final String code;









         Allocation(String code) {




            this.code = code;




        }









         public static Converter<Allocation, String> writer() {




            return new Converter<Allocation, String>() {




                public String convert(Allocation allocation) {




                    return allocation.getCode();




                }




            };




        }









         public static Converter<String, Allocation> reader() {




            return new Converter<String, Allocation>() {




                public Allocation convert(String source) {




                    return Allocation.getByCode(source);




                }




            };




        }









         public static Allocation getByCode(String code)  
 return AVAILABLE;




                 
 return ALLOCATED;




             
 throw new IllegalArgumentException(""Unable to get Allocation from: "" + code);




         
 public String getCode() {




            return code;




        }




     
 @Bean




    public CustomConversions customConversions() {




        return new CustomConversions(Arrays.asList(




                MyPersistantObject.Allocation.reader(),




                MyPersistantObject.Allocation.writer()




        ));




    }






 
 @Test




    public void testConversion() {




        Update update;




        Query query;




        MyPersistantObject returned;




        MyPersistantObject myPersistantObject = new MyPersistantObject();




        myPersistantObject.allocation = AVAILABLE;




        myPersistantObject.value = new BigDecimal(1234567);









        mongoTemplate.save(myPersistantObject);









        // Check it was saved correctly - first with invalid allocation to confirm conversion in query




        query = query(where(""allocation"").is(ALLOCATED));




        assertThat(mongoTemplate.findOne(query, MyPersistantObject.class), is(nullValue()));









        // Check it was saved correctly - now with valid allocation to confirm conversion in query




        query = query(where(""allocation"").is(AVAILABLE));




        returned = mongoTemplate.findOne(query, MyPersistantObject.class);




        assertThat(returned.allocation, is(AVAILABLE));




        assertThat(returned.value.longValue(), is(1234567L));









        try {




            // Update allocation from constant - will fail




            update = update(""allocation"", ALLOCATED);




            mongoTemplate.updateMulti(query, update, MyPersistantObject.class);




        } catch (Exception e) {




            System.err.println(""failed to convert allocation: java.lang.IllegalArgumentException: can't serialize class converter_test.MyPersistantObject$Allocation"");




        }









        // Update allocation from string value - succeeds




        update = update(""allocation"", ALLOCATED.getCode());




        mongoTemplate.updateMulti(query, update, MyPersistantObject.class);




        // Check allocation update




        query = query(where(""allocation"").is(ALLOCATED));




        returned = mongoTemplate.findOne(query, MyPersistantObject.class);




        assertThat(returned.allocation, is(ALLOCATED));









        // Update value only - will fail: Caused by: java.lang.IllegalArgumentException: Unable to get MyPersistantObject.Allocation from: 54321




        // Tries to use MyPersistantObject.Allocation converter to String




        update = update(""value"", new BigDecimal(54321));




        mongoTemplate.updateMulti(query, update, MyPersistantObject.class);




        // Check value update




        returned = mongoTemplate.findAll(MyPersistantObject.class).get(0);




        assertThat(returned.value.longValue(), is(54321L));




    }
There does seem to be an issue with the use of customer converters when used in mongoTemplate.update* via an Update object.
have custom serialiser for enumerated type work custom serialiser for enumerated type save @Document annotated POJO load @Document annotated POJO
build Query execute Query
use in update call in situations
clone https://github.com/patrickherrera/converter_test.git for full test application
have static enum with desired converters be in brief
@Document
public class MyPersistantObject {
public Allocation allocation;
public BigDecimal value;
public enum Allocation {
AVAILABLE(""V""),
ALLOCATED(""A"");
private final String code;
Allocation(String code) {
this.code = code;
}
public static Converter<Allocation, String> writer() {
return new Converter<Allocation, String>() {
public String convert(Allocation allocation) {
return allocation.getCode();
}
};
}
public static Converter<String, Allocation> reader() {
return new Converter<String, Allocation>() {
public Allocation convert(String source) {
return Allocation.getByCode(source);
}
};
}
public static Allocation getByCode(String code) {
switch (code) {
case ""V"":
return AVAILABLE;
case ""A"":
return ALLOCATED;
}
throw new IllegalArgumentException(""Unable to get Allocation from: "" + code);
}
public String getCode() {
return code;
}
}
}
It simply converts back and forward using a short code rather than the full Enum name.
These are registered in the Spring Boot application entry point:
@Bean
public CustomConversions customConversions() {
return new CustomConversions(Arrays.asList(
MyPersistantObject.Allocation.reader(),
MyPersistantObject.Allocation.writer()
));
}
drive few scenarios drive unit test
@Test
public void testConversion() {
Update update;
Query query;
MyPersistantObject returned;
MyPersistantObject myPersistantObject = new MyPersistantObject();
myPersistantObject.allocation = AVAILABLE;
myPersistantObject.value = new BigDecimal(1234567);
mongoTemplate.save(myPersistantObject);
// Check it was saved correctly - first with invalid allocation to confirm conversion in query
query = query(where(""allocation"").
is(ALLOCATED));
assertThat(mongoTemplate.findOne(query, MyPersistantObject.class), is(nullValue()));
// Check it was saved correctly - now with valid allocation to confirm conversion in query
query = query(where(""allocation"").
is(AVAILABLE));
returned = mongoTemplate.findOne(query, MyPersistantObject.class);
assertThat(returned.allocation, is(AVAILABLE));
assertThat(returned.value.longValue(), is(1234567L));
try {
// Update allocation from constant - will fail
update = update(""allocation"", ALLOCATED);
mongoTemplate.updateMulti(query, update, MyPersistantObject.class);
} catch (Exception e) {
System.err.println(""failed to convert allocation: java.lang.IllegalArgumentException: can't serialize class converter_test.
MyPersistantObject$Allocation"");
}
// Update allocation from string value - succeeds
update = update(""allocation"", ALLOCATED.getCode());
mongoTemplate.updateMulti(query, update, MyPersistantObject.class);
// Check allocation update
query = query(where(""allocation"").
is(ALLOCATED));
returned = mongoTemplate.findOne(query, MyPersistantObject.class);
assertThat(returned.allocation, is(ALLOCATED));
// Update value only - will fail: Caused by: java.lang.IllegalArgumentException: Unable to get MyPersistantObject.Allocation from: 54321
// Tries to use MyPersistantObject.Allocation converter to String
update = update(""value"", new BigDecimal(54321));
mongoTemplate.updateMulti(query, update, MyPersistantObject.class);
// Check value update
returned = mongoTemplate.findAll(MyPersistantObject.class).
get(0);
assertThat(returned.value.longValue(), is(54321L));
}
Hopefully that makes sense.
Firstly it saves and queries for the object to demonstrate that the converters are called correctly on the document.
I have confirmed that the document in the database correctly stores the Enum code rather than the name.
appear by use use in Query builder
come to update throw exception to effect
If I change it to use the code (a String), it works and we confirm that by Querying it back from the DB.
convert from Enum not call customer converter in situation not call customer converter for converting
Next I try and update the other value in the Document.
try numeric String into Allocation enum convert numeric String into Allocation enum convert BigDecimal to String fail Allocation enum of course
I tried to debug the code and it seems that there is an overloaded method in CustomConversions: getCustomWriteTarget that takes one or two arguments, the second being a requestedTargetType.
not use Allocation converter call in MappingMongoConverter
use first converter handle input type handle first converter seem without type information be in case
It is my custom one which is picked up first but can't actually handle it.
Please advise if there is something I am missing, as I can't find a workaround either - I have resorted to the Mongo Driver itself to do the update.","org.springframework.data.mongodb.core.convert.UpdateMapperUnitTests
org.springframework.data.mongodb.core.convert.UpdateMapper"
FILE,DATAMONGO,DATAMONGO-1263,2015-07-30T09:03:41.000-05:00,involve generic types,"class Book  
 class AbstractProduct  
 class ProductWrapper    
 class Catalog
involve generic types not infer type information at startup time result in missing indexes
Please, see https://github.com/agustisanchez/SpringDataMongoDBBug, for code samples.
class Book with index on ""ISBN"" attribute super class AbstractProduct with index on ""name"" attribute class ProductWrapper holding attribute ""content"" of generic type ""T extends AbstractProduct""
define class Catalog with list
List<ProductWrapper<Book>> books2 = new ArrayList<>
infer type infromation from ProductWrapper class definition inherit from AbstractProduct create index name inside catalog define on Book class not create Book class as Spring data Mongo
define wrapper class as ProductWrapper<T> create indexes on Catalog.books2.content.","org.springframework.data.mongodb.core.index.MongoPersistentEntityIndexResolver
org.springframework.data.mongodb.core.index.MongoPersistentEntityIndexResolverUnitTests"
FILE,DATAMONGO,DATAMONGO-1360,2016-01-16T07:47:34.000-06:00,not query with JSR310,"query.addCriteria(where(""createdDate"").lte(LocalDateTime.now()));
have MongoDb document use Spring data MongoDb
{
""_id"" : ""1"",
""_class"" : ""SomeClass"",
""createdDate"" : ISODate(""2016-01-16T07:05:45.656Z""),
""lastUpdate"" : ISODate(""2016-01-16T07:05:45.656Z"")
}
create custom Criteria query look custom Criteria query
query.addCriteria(where(""createdDate"").
lte(LocalDateTime.now()));
{ ""createdDate"" : { ""$lte"" : { $java : 2016-01-16T14:36:50.656 } } }
fail with message
java.lang.IllegalArgumentException: can't serialize class java.time.LocalDateTime at org.bson.BasicBSONEncoder.
_putObjectField(BasicBSONEncoder.java:299)
use java.util.Date in query persist document with java.time.LocalDateTime object
{ ""createdDate"" : { ""$lte"" : { ""$date"" : ""2016-01-16T07:35:19.985Z""}}}
I'm hoping there is a way to not have to convert my LocalDateTime objects to Date objects for querying.
Please advise.
Cheers,
Bjorn","org.springframework.data.mongodb.core.Venue
org.springframework.data.mongodb.core.geo.AbstractGeoSpatialTests
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-1438,2016-05-26T14:01:14.000-05:00,get warning in logs switch in Spring boot 1.3.5 switch to Spring,"@Document
start Spring boot 1.3.5 application with custom conversions get Train hopper-sr1 following warning
Registering converter from class java.lang.Number to class java.lang.Number as writing converter although it doesn't convert to a Mongo supported type!
You might wanna check you annotation setup at the converter implementation.
With the in Spring Boot 1.3.5 integrated version the warning is not exists.
.
alle Domain classes save with @Document save in MongoDB annotated","org.springframework.data.mongodb.core.convert.MongoConvertersUnitTests
org.springframework.data.mongodb.core.convert.MongoConverters"
FILE,DATAMONGO,DATAMONGO-1406,2016-04-04T18:59:49.000-05:00,not use @Field field name nest fields with nested keywords nest fields in combination,";






@Document(collection = ""Computer"")




public class Computer




{




   @Id




   private String _id;









   private String batchId;









  @Field(""stat"")




   private String status;









   @Field(""disp"")




   private List<Monitor> displays;









   //setters and getters




}









public class Monitor {




   @Field(""res"")




   private String resolution;









  // setters/getters




}






   
 protected <S, T> List<T> doFind(String collectionName, DBObject query, DBObject fields, Class<S> entityClass,




			CursorPreparer preparer, DbObjectCallback<T> objectCallback)









 DBObject mappedQuery = queryMapper.getMappedObject(query, entity);






  @Field   
  
  
 
  
  @Field
have document class
@Document(collection = ""Computer"")
public class Computer
{
@Id
private String _id;
private String batchId;
@Field(""stat"")
private String status;
@Field(""disp"")
private List<Monitor> displays;
//setters and getters
}
public class Monitor {
@Field(""res"")
private String resolution;
// setters/getters
}
call in MongoTemplate.java
protected <S, T> List<T> doFind(String collectionName, DBObject query, DBObject fields, Class<S> entityClass,
CursorPreparer preparer, DbObjectCallback<T> objectCallback)
DBObject mappedQuery = queryMapper.getMappedObject(query, entity);
resolve to stat
Note the queries in the inner list, are setup as elemMatch.
submit to mongo
{ ""$and"" : [ { ""stat"" : ""A""} , { ""disp"" : { ""$elemMatch"" : { ""$and"" : [ { ""resolution"" : { ""$ne"" :  null }} , { ""resolution"" : { ""$ne"" : """"}}]}}}] , ""batchId"" : ""5d0f1c53-92a2-48cb-8c84-1061769962c1""}
not get data call resolution
note query input to getMappedObject
{ ""$and"" : [ { ""status"" : ""A""} , { ""displays"" : { ""$elemMatch"" : { ""$and"" : [ { ""resolution"" : { ""$ne"" :  null }} , { ""resolution"" : { ""$ne"" : """"}}]}}}] , ""batchId"" : ""5d0f1c53-92a2-48cb-8c84-1061769962c1""}
convert to value
{ ""$and"" : [ { ""stat"" : ""A""} , { ""disp"" : { ""$elemMatch"" : { ""$and"" : [ { ""res"" : { ""$ne"" :  null }} , { ""res"" : { ""$ne"" : """"}}]}}}] , ""batchId"" : ""5d0f1c53-92a2-48cb-8c84-1061769962c1""}
operate queries on fields","org.springframework.data.mongodb.core.convert.QueryMapper
org.springframework.data.mongodb.core.convert.QueryMapperUnitTests"
CLASS,derby-10.7.1.1,DERBY-4835,2010-10-06T11:05:13.000-05:00,cause java.lang.NoSuchMethodError not recompile with upgrade not recompile from 10.5.3.0 not recompile to 10.6.1.0,"tidlggls(blt_number,create_date,update_date,propagation_date,glossary_status,
     time_stamp,min_max_size )
    
      
 
  
 tidlrblt(BLT,BLT_SIZE,MIN_MAX_SIZE)  
 
     
  
   GeneratedMe
thod;    
  
  
 if (fromVersion.majorVersionNumber >= DataDictionary.DD_VERSION_DERBY_10_5)
				bootingDictionary.updateMetadataSPSes(tc);
			else
				bootingDictionary.clearSPSPlans();

  clearSPSPlans()
cause following exception not recompile to 10.6.1.0 not recompile on upgrade fire trigger after upgrade fire first time after upgrade
ATABASE = wombat), (DRDAID = null), Failed Statement is: INSERT INTO tidlggls(blt_number,create_date,update_date,propagation_date,glossary_status,
     time_stamp,min_max_size )
 VALUES ( (select max(blt_number) from tidlrblt), CURRENT_DATE,
CURRENT_DATE, CURRENT_DATE, '00' , CURRENT_TIMESTAMP, (select min_max_size from tidlrblt where blt_number = (select max(blt_number) from tidlrblt)))
java.lang.NoSuchMethodError: org/apache/derby/iapi/sql/execute/ResultSetFactory.getProjectRestrictResultSet(Lorg/apache/derby/iapi/sql/execute/NoPutResultSet;Lorg/apache/derby/iapi/services/loader/GeneratedMethod;Lorg/apache/derby/iapi/services/loader/GeneratedMethod;ILorg/apache/derby/iapi/services/loader/GeneratedMethod;IZZDD)Lorg/apache/derby/iapi/sql/execute/NoPutResultSet;
at org.apache.derby.exe.acf81e0010x012bx823cxd0d3x00000026c4a00.g0(Unknown Source)
at org.apache.derby.exe.acf81e0010x012bx823cxd0d3x00000026c4a00.execute(Unknown Source)
at org.apache.derby.impl.sql.GenericActivationHolder.execute(Unknown Source)
at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
at org.apache.derby.impl.sql.GenericPreparedStatement.executeSubStatement(Unknown Source)
at org.apache.derby.impl.sql.execute.GenericTriggerExecutor.executeSPS(Unknown Source)
at org.apache.derby.impl.sql.execute.StatementTriggerExecutor.fireTrigger(Unknown Source)
at org.apache.derby.impl.sql.execute.TriggerEventActivator.notifyEvent(Unknown Source)
at org.apache.derby.impl.sql.execute.InsertResultSet.normalInsertCore(Unknown Source)
at org.apache.derby.impl.sql.execute.InsertResultSet.open(Unknown Source)
at org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)
at org.apache.derby.impl.jdbc.EmbedStatement.execute(Unknown Source)
at org.apache.derby.impl.tools.ij.ij.executeImmediate(Unknown Source)
at org.apache.derby.impl.tools.ij.utilMain.doCatch(Unknown Source)
at org.apache.derby.impl.tools.ij.utilMain.runScriptGuts(Unknown Source)
at org.apache.derby.impl.tools.ij.utilMain.go(Unknown Source)
at org.apache.derby.impl.tools.ij.Main.go(Unknown Source)
at org.apache.derby.impl.tools.ij.Main.mainCore(Unknown Source)
at org.apache.derby.impl.tools.ij.Main.main(Unknown Source)
at org.apache.derby.tools.ij.main(Unknown Source)
Cleanup action completed
run attached script 10_5_3_work.sql with 10.5.3.0 release connect with 10.6.1.0 insert into table
connect 'jdbc:derby:wombat;upgrade=true';
 
INSERT INTO tidlrblt(BLT,BLT_SIZE,MIN_MAX_SIZE) VALUES('Mamatha Testing2', 15, 20);
ERROR XJ001: Java exception: 'org/apache/derby/iapi/sql/execute/ResultSetFactory
.
getProjectRestrictResultSet(Lorg/apache/derby/iapi/sql/execute/NoPutResultSet;L
org/apache/derby/iapi/services/loader/GeneratedMethod;Lorg/apache/derby/iapi/ser
vices/loader/GeneratedMethod;ILorg/apache/derby/iapi/services/loader/GeneratedMe
thod;IZZDD)Lorg/apache/derby/iapi/sql/execute/NoPutResultSet;: java.lang.NoSuchM
ethodError'.
I think this may be related to the DERBY-1107 change in handleMinorRevisionChange which has the code:
if (fromVersion.majorVersionNumber >= DataDictionary.DD_VERSION_DERBY_10_5)
				bootingDictionary.updateMetadataSPSes(tc);
			else
				bootingDictionary.clearSPSPlans();
Likely, clearSPSPlans() should not be in the else clause but rather executed unconditionally.
To work around the issue, after connecting with 10.6.1, drop and recreate the trigger as in workaround.sql","org.apache.derby.impl.sql.catalog.DD_Version
org.apache.derbyTesting.functionTests.tests.upgradeTests.BasicSetup"
CLASS,derby-10.7.1.1,DERBY-4889,2010-11-05T20:06:56.000-05:00,boolean conversion on embedded boolean conversion on client,"PreparedStatement ps = c.prepareStatement(""values cast(? as boolean)"");
        ps.setByte(1, (byte) 32);
        ResultSet rs = ps.executeQuery();
        rs.next();
        System.out.println(rs.getBoolean(1));

 If setByte()   setInt()
print true with client driver print true with embedded driver print true with false
PreparedStatement ps = c.prepareStatement(""values cast(?
as boolean)"");
        ps.setByte(1, (byte) 32);
        ResultSet rs = ps.executeQuery();
        rs.next();
        System.out.println(rs.getBoolean(1));
print true replace setByte() with setInt()","org.apache.derbyTesting.functionTests.tests.jdbcapi.ParameterMappingTest
org.apache.derby.impl.drda.DRDAConnThread"
CLASS,pig-0.11.1,PIG-2828,2012-07-19T05:03:16.000-05:00,null in DataType.compare,"Object field1 = o1.get(fieldNum);
                Object field2 = o2.get(fieldNum);
                if (!typeFound) {
                    datatype = DataType.findType(field1);
                    typeFound = true;
                }
                return DataType.compare(field1, field2, datatype, datatype);
use TOP contain null value generate following exception
Caused by: java.lang.NullPointerException
at org.apache.pig.data.DataType.compare(DataType.java:427)
at org.apache.pig.builtin.TOP$TupleComparator.compare(TOP.java:97)
at org.apache.pig.builtin.TOP$TupleComparator.compare(TOP.java:1)
at java.util.PriorityQueue.siftUpUsingComparator(PriorityQueue.java:649)
at java.util.PriorityQueue.siftUp(PriorityQueue.java:627)
at java.util.PriorityQueue.offer(PriorityQueue.java:329)
at java.util.PriorityQueue.add(PriorityQueue.java:306)
at org.apache.pig.builtin.TOP.updateTop(TOP.java:141)
at org.apache.pig.builtin.TOP.exec(TOP.java:116)
code: (TOP.java, starts with line 91)
Object field1 = o1.get(fieldNum);
Object field2 = o2.get(fieldNum);
if (! typeFound) { datatype = DataType.findType(field1);
typeFound = true;
} return DataType.compare(field1, field2, datatype, datatype);","src.org.apache.pig.data.DataType
src.org.apache.pig.builtin.TOP
test.org.apache.pig.test.TestNull"
CLASS,pig-0.11.1,PIG-3114,2013-01-03T19:49:42.000-06:00,duplicate macro name error use pigunit,"{code:title=test.pig|borderStyle=solid}
    {
    $C = ORDER $QUERY BY total DESC, $A;
}  
  
     AS total;

queries_ordered = my_macro_1(queries_count, query);

    
   ;
{code}
use PigUnit test pig script define macro
get parsing error with pigunit
So I tried very basic pig script with macro and getting similar error.
org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1000: Error during parsing.
<line 9> null.
Reason: Duplicated macro name 'my_macro_1'
at org.apache.pig.PigServer$Graph.parseQuery(PigServer.java:1607)
at org.apache.pig.PigServer$Graph.registerQuery(PigServer.java:1546)
at org.apache.pig.PigServer.registerQuery(PigServer.java:516)
at org.apache.pig.tools.grunt.GruntParser.processPig(GruntParser.java:988)
at org.apache.pig.pigunit.pig.GruntParser.processPig(GruntParser.java:61)
at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:412)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:194)
at org.apache.pig.pigunit.pig.PigServer.registerScript(PigServer.java:56)
at org.apache.pig.pigunit.PigTest.registerScript(PigTest.java:160)
at org.apache.pig.pigunit.PigTest.assertOutput(PigTest.java:231)
at org.apache.pig.pigunit.PigTest.assertOutput(PigTest.java:261)
at FirstPigTest.MyPigTest.testTop2Queries(MyPigTest.java:32)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at junit.framework.TestCase.runTest(TestCase.java:176)
at junit.framework.TestCase.runBare(TestCase.java:141)
at junit.framework.TestResult$1.protect(TestResult.java:122)
at junit.framework.TestResult.runProtected(TestResult.java:142)
at junit.framework.TestResult.run(TestResult.java:125)
at junit.framework.TestCase.run(TestCase.java:129)
at junit.framework.TestSuite.runTest(TestSuite.java:255)
at junit.framework.TestSuite.run(TestSuite.java:250)
at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:84)
at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
Caused by: Failed to parse: <line 9> null.
Reason: Duplicated macro name 'my_macro_1'
at org.apache.pig.parser.QueryParserDriver.makeMacroDef(QueryParserDriver.java:406)
at org.apache.pig.parser.QueryParserDriver.expandMacro(QueryParserDriver.java:277)
at org.apache.pig.parser.QueryParserDriver.parse(QueryParserDriver.java:178)
at org.apache.pig.PigServer$Graph.parseQuery(PigServer.java:1599)
... 30 more
{code:title=test.pig|borderStyle=solid}
DEFINE my_macro_1 (QUERY, A) RETURNS C {
$C = ORDER $QUERY BY total DESC, $A;
} ;
data =  LOAD 'input' AS (query:CHARARRAY);
queries_group = GROUP data BY query;
queries_count = FOREACH queries_group GENERATE group AS query, COUNT(data) AS total;
queries_ordered = my_macro_1(queries_count, query);
queries_limit = LIMIT queries_ordered 2;
STORE queries_limit INTO 'output';
{code}
If I remove macro pigunit works fine.
Even just defining macro without using it results in parsing error.","src.org.apache.pig.PigServer
test.org.apache.pig.test.pigunit.TestPigTest
test.org.apache.pig.pigunit.PigTest
test.org.apache.pig.pigunit.pig.PigServer"
CLASS,pig-0.11.1,PIG-3292,2013-04-24T03:06:41.000-05:00,get cross product,"{code}
 
  
   {
  y = a.x;
  pair = cross a.x, y;
  generate flatten(pair);
}

 dump b;
{code}

 
 {code}
   
 {code}

 
 {code}
 
  
   {
  y = foreach a generate -(-x);
  pair = cross a.x, y;
  generate flatten(pair);
}

 dump b;
{code}
Hi.
Looks like PIG-3020
but works in a different way.
Our pig version is: 
Apache Pig version 0.10.0-cdh4.2.0 (rexported) 
compiled Feb 15 2013, 12:20:54
Accoring to release note, PIG-3020 is included into CDH 4.2 dist
http://archive.cloudera.com/cdh4/cdh/4/pig-0.10.0-cdh4.2.0.CHANGES.txt
get cross-product { code
a_group = group a by key;
b = foreach a_group {
  y = a.x;
  pair = cross a.x, y;
  generate flatten(pair);
}
dump b;
{code}
Here is workaround :)
{code}
a = load '/input' as (key, x:int);
a_group = group a by key;
b = foreach a_group {
  y = foreach a generate -(-x);
  pair = cross a.x, y;
  generate flatten(pair);
}
dump b;
{code}","test.org.apache.pig.test.TestEvalPipelineLocal
src.org.apache.pig.newplan.logical.relational.LOCross"
CLASS,pig-0.11.1,PIG-3310,2013-05-03T02:59:57.000-05:00,not generate new uids for nested schema fields lead to miscomputations,"{code}
     
    
        
        
    
           as shop;

EXPLAIN K;
DUMP K;
{code}

 
 {code}
 
 {code}

 
 {code}
 
 {code}
 
        
      
  
 {code}
                  
              
              
              
              
              
 {code}

 
 {code}
                   
  
  
 {code}

     
 LOSplitOutput.getSchema()
Hi,
consider following example
{code}
inp = LOAD '$INPUT' AS (memberId:long, shopId:long, score:int);
tuplified = FOREACH inp GENERATE (memberId, shopId) AS tuplify, score;
D1 = FOREACH tuplified GENERATE tuplify.memberId as memberId, tuplify.shopId as shopId, score AS score;
D2 = FOREACH tuplified GENERATE tuplify.memberId as memberId, tuplify.shopId as shopId, score AS score;
J = JOIN D1 By shopId, D2 by shopId;
K = FOREACH J GENERATE D1::memberId AS member_id1, D2::memberId AS member_id2, D1::shopId as shop;
EXPLAIN K;
DUMP K;
{code}
It is a bit weird written like that, but it provides a minimal reproduction case (in the real case, the ""tuplified"" phase came from a multi-key grouping).
give wrongful output
In the initial case, there was a FILTER (member_id1 < member_id2) after K, and computation failed because of PushUpFilter optimization mistakenly moving the LOFilter operation before the join, at a place where it tried to work on a tuple and failed.
My understanding of the issue is that when the ImplicitSplitInserter creates the LOSplitOutputs, it will correctly reset the schema, and the LOSplitOutput will regenerate uids for the fields of D1 and D2 ... but will not do that on the tuple members.
The logical plan after the ImplicitSplitINserter will look like (simplified)
{code}
|---D1: (Name: LOForEach Schema: memberId#124:long,shopId#125:long)ColumnPrune:InputUids=[127]ColumnPrune:OutputUids=[125, 124]
|---tuplified: (Name: LOSplitOutput Schema: tuplify#127:tuple(memberId#124:long,shopId#125:long))ColumnPrune:InputUids=[123]ColumnPrune:OutputUids=[127]
|---tuplified: (Name: LOSplit Schema: tuplify#123:tuple(memberId#124:long,shopId#125:long))ColumnPrune:InputUids=[123]ColumnPrune:OutputUids=[123]
|---D2: (Name: LOForEach Schema: memberId#124:long,shopId#125:long)ColumnPrune:InputUids=[130]ColumnPrune:OutputUids=[125, 124]
|---tuplified: (Name: LOSplitOutput Schema: tuplify#130:tuple(memberId#124:long,shopId#125:long))ColumnPrune:InputUids=[123]ColumnPrune:OutputUids=[130]
|---tuplified: (Name: LOSplit Schema: tuplify#123:tuple(memberId#124:long,shopId#125:long))ColumnPrune:InputUids=[123]ColumnPrune:OutputUids=[123]
{code}
tuplified correctly gets a new uid (127 and 130) but the members of the tuple don't.
When they get reprojected, both branches have the same uid and the join looks like:
{code}
|---J: (Name: LOJoin(HASH) Schema: D1::memberId#124:long,D1::shopId#125:long,D2::memberId#139:long,D2::shopId#132:long)ColumnPrune:InputUids=[125, 124, 132]ColumnPrune:OutputUids=[125, 124, 132]
|   |
|   shopId:(Name: Project Type: long Uid: 125 Input: 0 Column: 1)
|   |
|   shopId:(Name: Project Type: long Uid: 125 Input: 1 Column: 1)
{code}
If for example instead of reprojecting ""memberId"", we project ""memberId+0"", a new node is created, and ultimately the two branches of the join will correctly get separate uids.
My understanding is that LOSplitOutput.getSchema() should recurse on nested schema fields.
However, I only have a light understanding of all of the logical plan handling, so I may be completely wrong.
Attached is a draft of patch and a test reproducing the issue.
Unfortunately, I haven't been able to run all unit tests with the ""fix"" (I have some weird hangs)
I'd be happy if you could indicate if that looks like completely the wrong way to fix the issue.",src.org.apache.pig.newplan.logical.relational.LOSplitOutput
CLASS,pig-0.11.1,PIG-3329,2013-05-16T22:44:41.000-05:00,work with SPLIT,"RANK b;
dump d;
dump d use PigStorage(' ') as SPLIT
fail with error message
java.lang.RuntimeException: Unable to read counter pig.counters.counter_4929375455335572575_-1
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.PORank.addRank(PORank.java:161)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.PORank.getNext(PORank.java:134)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator.processInput(PhysicalOperator.java:308)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POSplit.getNext(POSplit.java:214)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.runPipeline(PigGenericMapBase.java:283)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.map(PigGenericMapBase.java:278)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapBase.map(PigGenericMapBase.java:64)
at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:157)
at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:324)
at org.apache.hadoop.mapred.Child$4.run(Child.java:275)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1340)
at org.apache.hadoop.mapred.Child.main(Child.java:269)","src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceOper
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler"
CLASS,zookeeper-3.4.5,ZOOKEEPER-1781,2013-10-03T20:19:27.000-05:00,set snapCount,"int randRoll = r.nextInt(snapCount/2);
{code}
set snapCount
2013-10-02 18:09:07,600 [myid:1] - ERROR [SyncThread:1:SyncRequestProcessor@151] - Severe unrecoverable error, exiting java.lang.IllegalArgumentException: n must be positive
at java.util.Random.nextInt(Random.java:300)
at org.apache.zookeeper.server.SyncRequestProcessor.run(SyncRequestProcessor.java:93)
{code:title=org.apache.zookeeper.server.SyncRequestProcessor.java|borderStyle=solid}
91             // we do this in an attempt to ensure that not all ofthe servers
92             // in the ensemble take a snapshot at the same time
93             int randRoll = r.nextInt(snapCount/2);
{code}
I think this supposition is not bad because snapCount = 1 is not realistic setting...
But, it may be better to mention this restriction in documentation or add a validation in the source code.",src.java.main.org.apache.zookeeper.server.ZooKeeperServer
CLASS,jedit-4.3,1193683,2005-05-02T09:22:25.000-05:00,be in black hole,"{\{\{ test
aaaa
bbbb
cccc
\}
have folded text \
\{\{\{ test aaaa bbbb cccc
\}\}\}
\{\{\{ test \[4 lines\]
\{\{ test
It seems really dangerous isn't it ?
type \ { \
hide text",org.gjt.sp.jedit.textarea.BufferHandler
CLASS,jedit-4.3,1571752,2006-10-05T21:26:12.000-05:00,fold wrong comments in PHP mode,"{

\} 
 {\{\{  --&gt;
function foo\(\) \{

\} //\}\}\}
jEdit version: 4.3pre7
Java version: 1.6.0-beta2
fold content of buffer looks
&lt;? php
Xfunction foo\(\) \{
\}X
/\* :folding=explicit:\*/
?&gt;
&lt;? php
&lt;\!
--\{\{\{  --&gt;
function foo\(\) \{
\} //\}\}\}
/\* :folding=explicit:\*/
?&gt;
If is between '&lt;? php' and 'function' empty line, then it works OK.",org.gjt.sp.jedit.textarea.TextArea
CLASS,jedit-4.3,1658252,2007-02-12T17:48:03.000-06:00,match in multi-line defines,"{ \
code;                         \
more code;                    \
even more code;               \
\}
try define
\#define LONG\_MULTI\_LINE\_DEFINE \{ \
code;                         \
more code;                    \
even more code;               \
\}","org.gjt.sp.jedit.syntax.ParserRule
org.gjt.sp.jedit.syntax.XModeHandler
org.gjt.sp.jedit.syntax.XModeHandler.TagDecl
org.gjt.sp.jedit.syntax.TokenMarker"
CLASS,jedit-4.3,1724940,2007-05-24T15:02:18.000-05:00,type in multiple,"lt;body&gt;
  lt;p&gt;
 
 the &lt;p&gt;  
 lt;body&gt;
  lt;d&gt;
highlight multiple selections in text area highlight multiple selections of text begin typing insert first character in selected areas \ insert first character of i type
have text
&lt;body&gt;
&lt;p&gt;
Some Text
&lt;/p&gt;
&lt;/body&gt;
&lt;body&gt;
&lt;d&gt;
Some Text
&lt;/div&gt;
&lt;/body&gt;
I've attached a screenshot.",org.gjt.sp.jedit.textarea.BufferHandler
CLASS,jedit-4.3,1999448,2008-08-23T10:28:24.000-05:00,fold expantion,"{\{\{ hello

something

\}
While testing the patch \#1999448, a problem was found.
But the patch was applied in r13404 to avoid more
serious black hole bugs.
This problem has now became a
bug.
fold with buffer
\{\{\{ hello
something
\}\}\}
remove l","org.gjt.sp.jedit.textarea.BufferHandler
org.gjt.sp.jedit.textarea.DisplayManager
org.gjt.sp.jedit.textarea.TextArea"
CLASS,jedit-4.3,2129419,2008-09-25T23:53:11.000-05:00,quit jEdit,"lt;init&gt;
quit jEdit get following null-pointer-exception relate following null-pointer-exception to files
Previously to trying to quit jEdit, the ""Files have changed.
Reload?""
java.lang.NullPointerException
at org.gjt.sp.jedit.EditPane.setBuffer\(EditPane.java:136\)
at org.gjt.sp.jedit.View.setBuffer\(View.java:1009\)
at org.gjt.sp.jedit.View.showBuffer\(View.java:1484\)
at org.gjt.sp.jedit.View.showBuffer\(View.java:1042\)
at org.gjt.sp.jedit.gui.CloseDialog$ListHandler.valueChanged\(CloseDialog.java:233\)
at javax.swing.JList.fireSelectionValueChanged\(JList.java:1765\)
at javax.swing.JList$ListSelectionHandler.valueChanged\(JList.java:1779\)
at javax.swing.DefaultListSelectionModel.fireValueChanged\(DefaultListSelectionModel.java:167\)
at javax.swing.DefaultListSelectionModel.fireValueChanged\(DefaultListSelectionModel.java:147\)
at javax.swing.DefaultListSelectionModel.fireValueChanged\(DefaultListSelectionModel.java:194\)
at javax.swing.DefaultListSelectionModel.changeSelection\(DefaultListSelectionModel.java:388\)
at javax.swing.DefaultListSelectionModel.changeSelection\(DefaultListSelectionModel.java:398\)
at javax.swing.DefaultListSelectionModel.setSelectionInterval\(DefaultListSelectionModel.java:442\)
at javax.swing.JList.setSelectedIndex\(JList.java:2179\)
at org.gjt.sp.jedit.gui.CloseDialog.&lt;init&gt;\(CloseDialog.java:96\)
at org.gjt.sp.jedit.jEdit.closeAllBuffers\(jEdit.java:1871\)
at org.gjt.sp.jedit.jEdit.exit\(jEdit.java:2621\)
at sun.reflect.NativeMethodAccessorImpl.invoke0\(Native Method\)
at sun.reflect.NativeMethodAccessorImpl.invoke\(NativeMethodAccessorImpl.java:39\)
at sun.reflect.DelegatingMethodAccessorImpl.invoke\(DelegatingMethodAccessorImpl.java:25\)
at java.lang.reflect.Method.invoke\(Method.java:597\)
at org.gjt.sp.jedit.bsh.Reflect.invokeMethod\(Reflect.java:134\)
at org.gjt.sp.jedit.bsh.Reflect.invokeStaticMethod\(Reflect.java:98\)
at org.gjt.sp.jedit.bsh.Name.invokeMethod\(Name.java:871\)
at org.gjt.sp.jedit.bsh.BSHMethodInvocation.eval\(BSHMethodInvocation.java:75\)
at org.gjt.sp.jedit.bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:102\)
at org.gjt.sp.jedit.bsh.BSHPrimaryExpression.eval\(BSHPrimaryExpression.java:47\)
at org.gjt.sp.jedit.bsh.BSHBlock.evalBlock\(BSHBlock.java:130\)
at org.gjt.sp.jedit.bsh.BSHBlock.eval\(BSHBlock.java:80\)
at org.gjt.sp.jedit.bsh.BshMethod.invokeImpl\(BshMethod.java:362\)
at org.gjt.sp.jedit.bsh.BshMethod.invoke\(BshMethod.java:258\)
at org.gjt.sp.jedit.bsh.BshMethod.invoke\(BshMethod.java:186\)
at org.gjt.sp.jedit.BeanShellFacade.runCachedBlock\(BeanShellFacade.java:225\)
at org.gjt.sp.jedit.BeanShell.runCachedBlock\(BeanShell.java:441\)
at org.gjt.sp.jedit.BeanShellAction.invoke\(BeanShellAction.java:73\)
at org.gjt.sp.jedit.gui.InputHandler.invokeAction\(InputHandler.java:352\)
at org.gjt.sp.jedit.jEdit$4.invokeAction\(jEdit.java:3080\)
at org.gjt.sp.jedit.jEdit$4.invokeAction\(jEdit.java:3062\)
at org.gjt.sp.jedit.EditAction$Wrapper.actionPerformed\(EditAction.java:220\)
at javax.swing.AbstractButton.fireActionPerformed\(AbstractButton.java:1995\)
at javax.swing.AbstractButton$Handler.actionPerformed\(AbstractButton.java:2318\)
at javax.swing.DefaultButtonModel.fireActionPerformed\(DefaultButtonModel.java:387\)
at javax.swing.DefaultButtonModel.setPressed\(DefaultButtonModel.java:242\)
at javax.swing.AbstractButton.doClick\(AbstractButton.java:357\)
at javax.swing.plaf.basic.BasicMenuItemUI.doClick\(BasicMenuItemUI.java:1220\)
at javax.swing.plaf.basic.BasicMenuItemUI$Handler.mouseReleased\(BasicMenuItemUI.java:1261\)
at java.awt.AWTEventMulticaster.mouseReleased\(AWTEventMulticaster.java:272\)
at java.awt.Component.processMouseEvent\(Component.java:6041\)
at javax.swing.JComponent.processMouseEvent\(JComponent.java:3265\)
at java.awt.Component.processEvent\(Component.java:5806\)
at java.awt.Container.processEvent\(Container.java:2058\)
at java.awt.Component.dispatchEventImpl\(Component.java:4413\)
at java.awt.Container.dispatchEventImpl\(Container.java:2116\)
at java.awt.Component.dispatchEvent\(Component.java:4243\)
at java.awt.LightweightDispatcher.retargetMouseEvent\(Container.java:4322\)
at java.awt.LightweightDispatcher.processMouseEvent\(Container.java:3986\)
at java.awt.LightweightDispatcher.dispatchEvent\(Container.java:3916\)
at java.awt.Container.dispatchEventImpl\(Container.java:2102\)
at java.awt.Window.dispatchEventImpl\(Window.java:2440\)
at java.awt.Component.dispatchEvent\(Component.java:4243\)
at java.awt.EventQueue.dispatchEvent\(EventQueue.java:599\)
at java.awt.EventDispatchThread.pumpOneEventForFilters\(EventDispatchThread.java:273\)
at java.awt.EventDispatchThread.pumpEventsForFilter\(EventDispatchThread.java:183\)
at java.awt.EventDispatchThread.pumpEventsForHierarchy\(EventDispatchThread.java:173\)
at java.awt.EventDispatchThread.pumpEvents\(EventDispatchThread.java:168\)
at java.awt.EventDispatchThread.pumpEvents\(EventDispatchThread.java:160\)
at java.awt.EventDispatchThread.run\(EventDispatchThread.java:121\)",org.gjt.sp.jedit.gui.CloseDialog.ListHandler
CLASS,argouml-0.22,3923,2006-02-07T13:17:48.000-06:00,import Poseidon activity diagrams from XMI,"Collection actionStates = getModel().getAllActionStates();
  Iterator iterActionState = actionStates.iterator();
iterActionState.hasNext(); 
 ActionStateFacade actionState =
(ActionStateFacade) iterActionState.next();
There is a bug in Beta 3 which prevents you using the activity diagram for AndroMDA.
Here is what I've done:
import XMI from poseidon work poseidon with AndroMDA ( the
Everything went fine.
add activity diagram under use case diagram get new activity graph have activity graphs alltogether
not add activity diagram under imported activity graph
see screenshot
See: http://argouml.tigris.org/servlets/ReadMsg?list=dev&msgNo=19267
http://argouml.tigris.org/servlets/GetAttachment?list=dev&msgId=770688&attachId=1
work code with poseidon not work ) with argouml
Collection actionStates = getModel().
getAllActionStates();
for (Iterator iterActionState = actionStates.iterator();
iterActionState.hasNext();) {
ActionStateFacade actionState =
(ActionStateFacade) iterActionState.next();
import activity diagram from Poseidon works import activity diagram from result make activity diagram from beginning process )
(nr.
3).
So, it seems that ArgoUML still has a problem with activity diagram...
Thanks,
Lofi.",org.argouml.persistence.XMIParser
METHOD,eclipse-2.0,31779,2003-02-13T09:55:00.000-06:00,ensure [ resources,"getStat()
Build: I20030211 using natives (Linux/Windows)
find new file from file system
not exist for different reasons
execute refresh operations appear to user
find file at first moment find file in file system assume file at first moment assume file in file system create corresponding resource in workspace
not find folder corresponding at second refresh not find folder corresponding in file system not find folder corresponding to resource remove from workspace
Bugs that revealed this problem: bug 21217 and bug 13463.","org.eclipse.core.internal.localstore.UnifiedTree:addChildrenFromFileSystem(UnifiedTreeNode, String, Object[], int)
org.eclipse.core.internal.localstore.UnifiedTree:createChildNodeFromFileSystem(UnifiedTreeNode, String, String)"
CLASS,openjpa-2.0.1,OPENJPA-1787,2010-09-10T11:23:51.000-05:00,merge new entity,"EntityManager em = entityManagerFactory.createEntityManager();
        Person person = new Person();
        person.setName(""Oliver"");                               // Employee.name is annotated @NotNull 
        person = em.merge(person);
The bean validation is not working correctly
merge new entity
EntityManager em = entityManagerFactory.createEntityManager();
        Person person = new Person();
        person.setName(""Oliver"");                               // Employee.name is annotated @NotNull 
        person = em.merge(person);
get ConstraintValidationException","org.apache.openjpa.kernel.BrokerImpl
org.apache.openjpa.kernel.AttachStrategy
org.apache.openjpa.integration.validation.TestValidationGroups"
CLASS,openjpa-2.0.1,OPENJPA-1903,2010-12-06T13:05:34.000-06:00,work first time,"@Entity
@IdClass(MandantAndNameIdentity.class)
public class Website {
    @Id
    private String mandant;
   
    @Id
    private String name;
...
}

 @Entity
@IdClass(WebsiteProduktDatumIdentity.class)
public class Preis {
    @Id
    @ManyToOne(cascade = CascadeType.MERGE)
    private Website website;

    @Id
    @Basic
    private String datum;
...
}

 
 em.getTransaction().begin();

        Website website = em.merge(new Website(""Mandant"", ""Website""));

        em.merge(new Preis(website, DATUM));
       
        em.getTransaction().commit();

 
 TypedQuery<Preis> q = em.createQuery(
                ""select m from Preis m "" +
                ""where m.website.name = :website "", Preis.class);
       q.setParameter(""website"", website.getName());

 
 TypedQuery<Preis> q = em.createQuery(
                ""select m from Preis m "" +
                ""where m.website = :website "", Preis.class);
        q.setParameter(""website"", website);
return data
I have reduced it to the code as much as I could into an Eclipse project available at http://ubuntuone.com/p/S9n/
This happens with OpenJPA 2.0.1 as well as the daily snapshot from 2010-12-05 and an out-of-process Derby database.
have Entities use multiple ids use Entities produce Primary key contain foreign key on website
@Entity
@IdClass(MandantAndNameIdentity.class)
public class Website {
    @Id
    private String mandant;
   
    @Id
    private String name;
...
}
@Entity
@IdClass(WebsiteProduktDatumIdentity.class)
public class Preis {
    @Id
    @ManyToOne(cascade = CascadeType.MERGE)
    private Website website;
@Id
    @Basic
    private String datum;
...
}
set up website set up preis
em.getTransaction().
begin();
Website website = em.merge(new Website(""Mandant"", ""Website""));
em.merge(new Preis(website, DATUM));
       
        em.getTransaction().
commit();
TypedQuery<Preis> q = em.createQuery(
                ""select m from Preis m "" +
                ""where m.website.name = :website "", Preis.class);
       q.setParameter(""website"", website.getName());
work time
put query
TypedQuery<Preis> q = em.createQuery(
                ""select m from Preis m "" +
                ""where m.website = :website "", Preis.class);
        q.setParameter(""website"", website);
work ONCE not return ONCE
See testcase DataAccessVerifyTest for details.
Discussion on the mailinglist seems to indicate that this is a bug.",org.apache.openjpa.jdbc.kernel.PreparedQueryImpl
CLASS,openjpa-2.0.1,OPENJPA-1912,2011-01-03T13:48:09.000-06:00,generate invalid code,"@Entity
public abstract class AbstractGroup {
   ...
    @Temporal(TemporalType.TIMESTAMP)
    @TrackChanges
    private Date applicationBegin;
 ...
}

 
 @Entity
public class Group extends AbstractGroup {
...
}

 
 public void writeExternal(ObjectOutput objectoutput)
        throws IOException
     
 pcWriteUnmanaged(objectoutput);
        if(pcStateManager != null)
        {
            if(pcStateManager.writeDetached(objectoutput))
                return;
        } else
        {
            objectoutput.writeObject(pcGetDetachedState());
            objectoutput.writeObject(null);
        }
        objectoutput.writeObject(applicationBegin);
        objectoutput.writeObject(applicationEnd);
        objectoutput.writeObject(applicationLocked);
        objectoutput.writeObject(approvalRequired);
add implements + writeExternal + readExternal
externalize private members of given superclass
get runtime Exception access fields
@Entity public abstract class AbstractGroup {
...
@Temporal(TemporalType.TIMESTAMP)
@TrackChanges private Date applicationBegin;
...
}
and
@Entity public class Group extends AbstractGroup {
...
}
public void writeExternal(ObjectOutput objectoutput)
throws IOException
{ pcWriteUnmanaged(objectoutput);
if(pcStateManager !
= null)
{ if(pcStateManager.writeDetached(objectoutput))
return;
} else
{ objectoutput.writeObject(pcGetDetachedState());
objectoutput.writeObject(null);
} objectoutput.writeObject(applicationBegin);
objectoutput.writeObject(applicationEnd);
objectoutput.writeObject(applicationLocked);
objectoutput.writeObject(approvalRequired);
...",org.apache.openjpa.enhance.PCEnhancer
CLASS,openjpa-2.0.1,OPENJPA-1918,2011-01-06T08:11:24.000-06:00,ignore class loader,"PersistenceUnitInfo.getClassLoader() 
 MetaDataRepository.preload()      
 PersistenceUnitInfo.getClassLoader()    
  
   PersistenceProvider.createContainerEntityManagerFactory()  MetaDatRepository.preload()
We are using openjpa inside an OSGi container together with
openjpa.MetaDataRepository"" value=""Preload=true""
pass appliation class loeader as part pass appliation class loeader by returning return from PersistenceUnitInfo.getClassLoader()
use context class loader from PersistenceUnitInfo leade PersistenceUnitInfo to ClassNotFoundExpcetions mention at end
A fix might be quite easily establihed by appending the return value of PersistenceUnitInfo.getClassLoader() to the list of claas loaders participating in the MultiClassLoader set up in
  
  MetaDataRepository.java:310ff
In the meanwhile, we are additionally setting our classloader as context loader during the creation of the EntityManagerFactory by PersistenceProvider.createContainerEntityManagerFactory(), but a fix in MetaDatRepository.preload() is highly appreciated.
TIA for fixing this,
Wolfgang
Stack trace:
org.osgi.service.blueprint.container.ComponentDefinitionException: Error when instantiating bean entityManagerFactory of class null
at org.apache.aries.blueprint.container.BeanRecipe.getInstance(BeanRecipe.java:233)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BeanRecipe.internalCreate(BeanRecipe.java:726)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.di.AbstractRecipe.create(AbstractRecipe.java:64)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintRepository.createInstances(BlueprintRepository.java:219)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintRepository.createAll(BlueprintRepository.java:147)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintContainerImpl.instantiateEagerComponents(BlueprintContainerImpl.java:624)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintContainerImpl.doRun(BlueprintContainerImpl.java:315)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BlueprintContainerImpl.run(BlueprintContainerImpl.java:213)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)[:1.6.0_20]
at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)[:1.6.0_20]
at java.util.concurrent.FutureTask.run(FutureTask.java:166)[:1.6.0_20]
at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$101(ScheduledThreadPoolExecutor.java:165)[:1.6.0_20]
at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:266)[:1.6.0_20]
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)[:1.6.0_20]
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)[:1.6.0_20]
at java.lang.Thread.run(Thread.java:636)[:1.6.0_20]
Caused by: <openjpa-2.0.1-r422266:989424 fatal user error> org.apache.openjpa.persistence.ArgumentException: Unexpected error during early loading of entity metadata during initialization. See nested stacktrace for details.
at org.apache.openjpa.meta.MetaDataRepository.preload(MetaDataRepository.java:331)
at org.apache.openjpa.persistence.PersistenceProviderImpl.preloadMetaDataRepository(PersistenceProviderImpl.java:280)
at org.apache.openjpa.persistence.PersistenceProviderImpl.createContainerEntityManagerFactory(PersistenceProviderImpl.java:211)
at org.apache.openjpa.persistence.PersistenceProviderImpl.createContainerEntityManagerFactory(PersistenceProviderImpl.java:65)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[:1.6.0_20]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)[:1.6.0_20]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[:1.6.0_20]
at java.lang.reflect.Method.invoke(Method.java:616)[:1.6.0_20]
at org.apache.aries.blueprint.container.AbstractServiceReferenceRecipe$JdkProxyFactory$1.invoke(AbstractServiceReferenceRecipe.java:632)
at $Proxy67.createContainerEntityManagerFactory(Unknown Source)
at org.clazzes.util.jpa.provider.EntityManagerFactoryFactory.newEntityManagerFactory(EntityManagerFactoryFactory.java:108)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[:1.6.0_20]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)[:1.6.0_20]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[:1.6.0_20]
at java.lang.reflect.Method.invoke(Method.java:616)[:1.6.0_20]
at org.apache.aries.blueprint.utils.ReflectionUtils.invoke(ReflectionUtils.java:221)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BeanRecipe.invoke(BeanRecipe.java:844)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
at org.apache.aries.blueprint.container.BeanRecipe.getInstance(BeanRecipe.java:231)[7:org.apache.aries.blueprint:0.3.0.incubating-SNAPSHOT]
... 15 more
Caused by: java.security.PrivilegedActionException: java.lang.ClassNotFoundException: org.clazzes.fancymail.server.entities.EMail
at java.security.AccessController.doPrivileged(Native Method)[:1.6.0_20]
at org.apache.openjpa.meta.MetaDataRepository.preload(MetaDataRepository.java:326)
... 32 more
Caused by: java.lang.ClassNotFoundException: org.clazzes.fancymail.server.entities.EMail
at org.apache.openjpa.lib.util.MultiClassLoader.findClass(MultiClassLoader.java:216)
at java.lang.ClassLoader.loadClass(ClassLoader.java:321)[:1.6.0_20]
at java.lang.ClassLoader.loadClass(ClassLoader.java:266)[:1.6.0_20]
at java.lang.Class.forName0(Native Method)[:1.6.0_20]
at java.lang.Class.forName(Class.java:264)[:1.6.0_20]
at org.apache.openjpa.lib.util.J2DoPrivHelper$4.run(J2DoPrivHelper.java:233)
at org.apache.openjpa.lib.util.J2DoPrivHelper$4.run(J2DoPrivHelper.java:231)
... 34 more","org.apache.openjpa.meta.FieldMetaData
org.apache.openjpa.meta.MetaDataRepository
org.apache.openjpa.persistence.detach.NoVersionEntity"
CLASS,openjpa-2.0.1,OPENJPA-1986,2011-04-27T11:44:53.000-05:00,cascade persist,"@Entity
public class CascadePersistEntity implements Serializable {
    private static final long serialVersionUID = -8290604110046006897L;

    @Id
    long id;

    @OneToOne(cascade = CascadeType.ALL)
    CascadePersistEntity other;
...
}

 
 CascadePersistEntity cpe1 = new CascadePersistEntity(1);
CascadePersistEntity cpe2 = new CascadePersistEntity(2);
cpe1.setOther(cpe2);
em.persist(cpe1);
find scenario cascade persist to new entity generate extra queries while cascading
see following example
@Entity
public class CascadePersistEntity implements Serializable {
    private static final long serialVersionUID = -8290604110046006897L;
@Id
    long id;
@OneToOne(cascade = CascadeType.ALL)
    CascadePersistEntity other;
...
}
and following scenario
The extra select is what I'm going to get rid of with this JIRA.","org.apache.openjpa.kernel.BrokerImpl
org.apache.openjpa.conf.Compatibility
org.apache.openjpa.kernel.SingleFieldManager"
METHOD,mahout-0.8,MAHOUT-1301,2013-08-01T09:31:21.000-05:00,have excess comma at end,"SequentialAccessSparseVector toString()   toString()  
 {code:java}
 Vector v = new SequentialAccessSparseVector(capacity);
v.set(1, 0.1);
v.set(3, 0.3);
{code}
  v.toString()  
 {code:java}
 {1:0.1,3:0.3}
 {code}
 
 {code:java}
 {1:0.1,3:0.3,}
 {code}
Realization of SequentialAccessSparseVector toString() method had changed in MAHOUT-1259 patch.
introduce new bug add at end
return { code:java","org.apache.mahout.math.SequentialAccessSparseVector:toString()
org.apache.mahout.math.RandomAccessSparseVector:toString()"
METHOD,mahout-0.8,MAHOUT-1314,2013-08-18T09:07:48.000-05:00,throw NullPointerException set REDUCE_STREAMING_KMEANS to true,"return input.getCentroid();  
 input.getCentroid()  clone();
set REDUCE_STREAMING_KMEANS option to true fail with NullPointerException
the problem is in the reduce method itself: on line 60 ( return input.getCentroid(); )
it should be input.getCentroid().
clone();
similar to line 81.
full stack trace:
java.lang.NullPointerException
at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:191)
at org.apache.mahout.math.random.WeightedThing.<init>(WeightedThing.java:31)
at org.apache.mahout.math.neighborhood.BruteSearch.searchFirst(BruteSearch.java:133)
at org.apache.mahout.clustering.ClusteringUtils.estimateDistanceCutoff(ClusteringUtils.java:100)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansThread.call(StreamingKMeansThread.java:64)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:66)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:1)
at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:176)
at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:650)
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:418)
at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:260)
happen time set REDUCE_STREAMING_KMEANS to true set time to true","org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer:reduce(IntWritable, Iterable<CentroidWritable>, Context)
org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer:getBestCentroids(List<Centroid>, Configuration)"
METHOD,mahout-0.8,MAHOUT-1358,2013-11-18T01:58:22.000-06:00,throw IllegalArgumentException set REDUCE_STREAMING_KMEANS to true,"{Code}


 {Code}


  StreamingKMeansThread.call()


 {Code}
     Iterator<Centroid> datapointsIterator = datapoints.iterator();
    if (estimateDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
      List<Centroid> estimatePoints = Lists.newArrayListWithExpectedSize(NUM_ESTIMATE_POINTS);
      while (datapointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) {
        estimatePoints.add(datapointsIterator.next());
      }
      estimateDistanceCutoff = ClusteringUtils.estimateDistanceCutoff(estimatePoints, searcher.getDistanceMeasure());
    }


    StreamingKMeans clusterer = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);
    while (datapointsIterator.hasNext()) {
      clusterer.cluster(datapointsIterator.next());
    }
{Code}
throw following error for running cluster with REDUCE_STREAMING_KMEANS
{Code}
java.lang.IllegalArgumentException: Must have nonzero number of training and test vectors. Asked for %.1f %% of %d vectors for test [10.000000149011612, 0]
at com.google.common.base.Preconditions.checkArgument(Preconditions.java:120)
at org.apache.mahout.clustering.streaming.cluster.BallKMeans.splitTrainTest(BallKMeans.java:176)
at org.apache.mahout.clustering.streaming.cluster.BallKMeans.cluster(BallKMeans.java:192)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.getBestCentroids(StreamingKMeansReducer.java:107)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:73)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:37)
at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:177)
at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:649)
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:418)
at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:398)
{Code}
The issue is caused by the following code in StreamingKMeansThread.call()
{Code}
    Iterator<Centroid> datapointsIterator = datapoints.iterator();
    if (estimateDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
      List<Centroid> estimatePoints = Lists.newArrayListWithExpectedSize(NUM_ESTIMATE_POINTS);
      while (datapointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) {
        estimatePoints.add(datapointsIterator.next());
      }
      estimateDistanceCutoff = ClusteringUtils.estimateDistanceCutoff(estimatePoints, searcher.getDistanceMeasure());
    }
StreamingKMeans clusterer = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);
    while (datapointsIterator.hasNext()) {
      clusterer.cluster(datapointsIterator.next());
    }
{Code}
The code is using the same iterator twice, and it fails on the second use for obvious reasons.","org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansThread:StreamingKMeansThread(Path, Configuration)
org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansThread:StreamingKMeansThread(Iterable<Centroid>, Configuration)"
METHOD,lang,LANG-363,2007-10-23T07:12:48.000-05:00,not escape /' into '\/ make IE render page,"document.getElementById(""test"")   document.getElementById(""test"") 
  
 String s = ""<script>alert('aaa');</script>"";
  String str = org.springframework.web.util.JavaScriptUtils.javaScriptEscape(s);
  System.out.println(""Spring JS Escape : ""+str);
  str = org.apache.commons.lang.StringEscapeUtils.escapeJavaScript(s);
  System.out.println(""Apache Common Lang JS Escape : ""+ str);
make IE render page uncorrect
value = '<script>alert(\'aaa\');<\/script>';
Btw, Spring's JavascriptEscape behavor is correct.
find difference run below codes","org.apache.commons.lang.StringEscapeUtils:escapeJavaStyleString(Writer, String, boolean)"
METHOD,lang,LANG-477,2009-01-09T10:05:53.000-06:00,contain single quotes,"{code:title=ExtendedMessageFormatTest.java|borderStyle=solid}

 private static Map<String, Object> formatRegistry = new HashMap<String, Object>();    
     static {
        formatRegistry.put(DummyFormatFactory.DUMMY_FORMAT, new DummyFormatFactory());
    }
    
     public static void main(String[] args) {
        ExtendedMessageFormat mf = new ExtendedMessageFormat(""it''s a {dummy} 'test'!"", formatRegistry);
        String formattedPattern = mf.format(new String[] {""great""});
        System.out.println(formattedPattern);
    }
 
 {code}

 
 {code:title=ExtendedMessageFormat.java|borderStyle=solid}
 
 if (escapingOn && c[start] == QUOTE) {
        return appendTo == null ? null : appendTo.append(QUOTE);
}

WORKING:
if (escapingOn && c[start] == QUOTE) {
        next(pos);
        return appendTo == null ? null : appendTo.append(QUOTE);
}
{code}
use ExtendedMessageFormat with custom format registry conatine single quotes
cause error
{code:title=ExtendedMessageFormatTest.java|borderStyle=solid}
private static Map<String, Object> formatRegistry = new HashMap<String, Object>();    
    static {
        formatRegistry.put(DummyFormatFactory.DUMMY_FORMAT, new DummyFormatFactory());
    }
    
    public static void main(String[] args) {
        ExtendedMessageFormat mf = new ExtendedMessageFormat(""it''s a {dummy} 'test'!""
, formatRegistry);
        String formattedPattern = mf.format(new String[] {""great""});
        System.out.println(formattedPattern);
    }
}
{code}
The following change starting at line 421 on the 2.4 release seems to fix the problem:
{code:title=ExtendedMessageFormat.java|borderStyle=solid}
CURRENT (Broken):
if (escapingOn && c[start] == QUOTE) {
        return appendTo == null ?
null : appendTo.append(QUOTE);
}
WORKING:
if (escapingOn && c[start] == QUOTE) {
        next(pos);
        return appendTo == null ?
null : appendTo.append(QUOTE);
}
{code}","org.apache.commons.lang.text.ExtendedMessageFormat:appendQuotedString(String, ParsePosition, StringBuffer, boolean)"
METHOD,lang,LANG-710,2011-07-01T20:57:30.000-05:00,"call unescapeHtml4(""&#03"")","unescapeHtml4()
call unescapeHtml4() on String
Exception in thread ""main"" java.lang.StringIndexOutOfBoundsException: String index out of range: 4
at java.lang.String.charAt(String.java:686)
at org.apache.commons.lang3.text.translate.NumericEntityUnescaper.translate(NumericEntityUnescaper.java:49)
at org.apache.commons.lang3.text.translate.AggregateTranslator.translate(AggregateTranslator.java:53)
at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:88)
at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:60)
at org.apache.commons.lang3.StringEscapeUtils.unescapeHtml4(StringEscapeUtils.java:351)","org.apache.commons.lang3.text.translate.NumericEntityUnescaper:translate(CharSequence, int, Writer)"
METHOD,lang,LANG-879,2013-03-18T21:46:29.000-05:00,fail with new Locale,"import static org.hamcrest.MatcherAssert.assertThat;
import static org.hamcrest.Matchers.equalTo;

import java.util.Locale;

import org.testng.annotations.Test;

import com.scispike.foundation.i18n.StringToLocaleConverter;

public class LocaleStringConverterTest {

	StringToLocaleConverter converter = new StringToLocaleConverter();

	public void testStringToLocale(Locale l) {
		String s = l.toString();

		assertThat(converter.convert(s), equalTo(l));
	}

	@Test
	public void testAllLocales() {

		Locale[] locales = Locale.getAvailableLocales();
		for (Locale l : locales) {
			testStringToLocale(l);
		}
	}
}


  
 import java.util.Locale;

import org.apache.commons.lang3.LocaleUtils;
import org.springframework.core.convert.converter.Converter;

public class StringToLocaleConverter implements Converter<String, Locale> {

	@Override
	public Locale convert(String source) {
		if (source == null) {
			return LocaleToStringConverter.DEFAULT;
		}
		return LocaleUtils.toLocale(source);
	}
}
fail with following error succeed on jdk6
testAllLocales
""java.lang.AssertionError:
Expected: <ja_JP_JP_#u-ca-japanese>
but: was <ja_JP_JP_#u-ca-japanese>
at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)
at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:8)
at com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testStringToLocale(LocaleStringConverterTest.java:20)
at com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testAllLocales(LocaleStringConverterTest.java:28)
at org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:76)
at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeMulti(TestNGDirectoryTestSuite.java:161)
at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.execute(TestNGDirectoryTestSuite.java:101)
at org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:115)
at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:103)
at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:74)
... Removed 25 stack frames
java.lang.AssertionError:
Expected: <ja_JP_JP_#u-ca-japanese>
but: was <ja_JP_JP_#u-ca-japanese>
at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)
at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:8)
at com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testStringToLocale(LocaleStringConverterTest.java:20)
at com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testAllLocales(LocaleStringConverterTest.java:28)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:601)
at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:80)
at org.testng.internal.Invoker.invokeMethod(Invoker.java:715)
at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:907)
at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1237)
at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:127)
at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:111)
at org.testng.TestRunner.privateRun(TestRunner.java:767)
at org.testng.TestRunner.run(TestRunner.java:617)
at org.testng.SuiteRunner.runTest(SuiteRunner.java:334)
at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:329)
at org.testng.SuiteRunner.privateRun(SuiteRunner.java:291)
at org.testng.SuiteRunner.run(SuiteRunner.java:240)
at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:51)
at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:85)
at org.testng.TestNG.runSuitesSequentially(TestNG.java:1197)
at org.testng.TestNG.runSuitesLocally(TestNG.java:1122)
at org.testng.TestNG.run(TestNG.java:1030)
at org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:76)
at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeMulti(TestNGDirectoryTestSuite.java:161)
at org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.execute(TestNGDirectoryTestSuite.java:101)
at org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:115)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:601)
at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:103)
at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:74)
""
org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)
org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:8)
com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testStringToLocale(LocaleStringConverterTest.java:20)
com.scispike.foundation.test.unit.i18n.LocaleStringConverterTest.testAllLocales(LocaleStringConverterTest.java:28)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:601)
org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:80)
org.testng.internal.Invoker.invokeMethod(Invoker.java:715)
org.testng.internal.Invoker.invokeTestMethod(Invoker.java:907)
org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1237)
org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:127)
org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:111)
org.testng.TestRunner.privateRun(TestRunner.java:767)
org.testng.TestRunner.run(TestRunner.java:617)
org.testng.SuiteRunner.runTest(SuiteRunner.java:334)
org.testng.SuiteRunner.runSequentially(SuiteRunner.java:329)
org.testng.SuiteRunner.privateRun(SuiteRunner.java:291)
org.testng.SuiteRunner.run(SuiteRunner.java:240)
org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:51)
org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:85)
org.testng.TestNG.runSuitesSequentially(TestNG.java:1197)
org.testng.TestNG.runSuitesLocally(TestNG.java:1122)
org.testng.TestNG.run(TestNG.java:1030)
org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:76)
org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeMulti(TestNGDirectoryTestSuite.java:161)
org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.execute(TestNGDirectoryTestSuite.java:101)
org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:115)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:601)
org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:103)
org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:74)
========== Test
import static org.hamcrest.MatcherAssert.assertThat;
import static org.hamcrest.Matchers.equalTo;
import java.util.Locale;
import org.testng.annotations.Test;
import com.scispike.foundation.i18n.StringToLocaleConverter;
public class LocaleStringConverterTest {
StringToLocaleConverter converter = new StringToLocaleConverter();
public void testStringToLocale(Locale l) {
		String s = l.toString();
assertThat(converter.convert(s), equalTo(l));
	}
@Test
	public void testAllLocales() {
Locale[] locales = Locale.getAvailableLocales();
		for (Locale l : locales) {
			testStringToLocale(l);
		}
	}
}
========== StringToLocaleConverter
import java.util.Locale;
import org.apache.commons.lang3.LocaleUtils;
import org.springframework.core.convert.converter.Converter;
public class StringToLocaleConverter implements Converter<String, Locale> {
@Override
	public Locale convert(String source) {
		if (source == null) {
			return LocaleToStringConverter.DEFAULT;
		}
		return LocaleUtils.toLocale(source);
	}
}",org.apache.commons.lang3.LocaleUtils:toLocale(String)
FILE,SWARM,SWARM-528,2016-06-22T02:53:46.000-05:00,not work with @ArquillianResource URL baseURL,"@ArquillianResource 
  
 
 
 
 @ArquillianResource 
  
 
 
 
 @ArquillianResource
First Example
set swarm port use swarm.http.port via arquillian.xml e.g. use swarm.port.offset via arquillian.xml e.g.
<container qualifier=""wildfly-swarm"" default=""true"">
<configuration>
<property name=""javaVmArguments"">
-Dswarm.port.offset=1
</property>
</configuration>
</container>
start arquillian swarm container on specified port/offset
@ArquillianResource
private URL baseURL;
retrieve url return http
Second Example
set port property in arquillian.xml
<container qualifier=""wildfly-swarm"" default=""true"">
<configuration>
<property name=""port"">8081</property>
</configuration>
</container>
start swarm container on 8080 and
@ArquillianResource
private URL baseURL;
Third Example
combine port property not work e.g.
<container qualifier=""wildfly-swarm"" default=""true"">
<configuration>
<property name=""javaVmArguments"">
-Dswarm.port.offset=1
</property>
<property name=""port"">8081</property>
</configuration>
</container>
start container
@ArquillianResource
private URL baseURL;
use swarm.http.port",org.wildfly.swarm.arquillian.resources.SwarmURLResourceProvider
FILE,SWARM,SWARM-486,2016-05-28T18:25:37.000-05:00,not load project-stages.yml with arq not load project-stages.yml on classpath,"classpath(src/main/resources)  
 
 
 container.withStageConfig(Paths.get(""/tmp"", ""external-project-stages.yml"").toUri().toURL())
not load yml with Arquillian tests not load yml on classpath(src/main/resources)
attach error log in steps attach error log to section attach reproducer in steps attach reproducer to section
https://github.com/wildfly-swarm/wildfly-swarm-core/blob/1.0.0.CR3/container/api/src/main/java/org/wildfly/swarm/cli/CommandLine.java#L109 workaround
To load the yml explicitly like below.
container.withStageConfig(Paths.get(""/tmp"", ""external-project-stages.
yml"").
toUri().
toURL())",org.wildfly.swarm.container.ProjectStagesTest
FILE,eclipse-3.1,102427,2005-06-30T20:45:00.000-05:00,not import methods,"public class Helper {
    public static int getValue() {...}
}
  
import static Helper.*;

public class Doer {
    public void doit() {
        int i = getValue();
    }
}
 
 getValue() 
 getValue()
---
public class Helper {
public static int getValue() {...}
}
---
import static Helper.
*;
public class Doer {
public void doit() {
int i = getValue();
}
}
---
select getValue() in doit execute getValue() in doit get error",org.eclipse.jdt.internal.debug.eval.ast.engine.SourceBasedSourceGenerator
FILE,eclipse-3.1,103379,2005-07-11T15:37:00.000-05:00,leak time leak editor instance,"dispose()
Driver: eclipse-SDK-3.1-win32 with eclipse-test-framework-3.1
open editor close editor
We have a testcase that can demostrate the problem.
The testcase is really simple.
create new simple project create new file
open up new file in editor come editor with testcase
allocate size
So this String array can be GC-ed if the editor itself can be GC-ed.
run testcase with xmx256m run out_of memory
set String array in dispose() method set String array to null not run out_of memory",org.eclipse.ui.operations.OperationHistoryActionHandler
FILE,eclipse-3.1,103918,2005-07-14T17:25:00.000-05:00,create dynamic proxy in rich client,"public void start(BundleContext context) throws Exception {
  super.start(context);
  XmlBeanFactory bf = new XmlBeanFactory(
     new ClassPathResource(""/bug/beans.xml""));
  bf.getBean(""hang"");
}

  bf.getBean(""hang"")  
 bf.getBean()
I've tried to integrate my ecplipse-rcp application with springframework.
get % load need % load fall into infinit loop
contain following code
public void start(BundleContext context) throws Exception {
  super.start(context);
  XmlBeanFactory bf = new XmlBeanFactory(
     new ClassPathResource(""/bug/beans.
xml""));
  bf.getBean(""hang"");
}
The same code
executed outside eclipse-rcp works well and without problem.
bf.getBean() tries to create a proxy class for given interface with standard JDK
dynamic proxy facility (no cglib or any other byte code manipulation takes place).
I'm not sure but I think that this may be caused by classloaders.
My environment: 
  Eclipse Version: 3.1.0
  Build id: I20050627-1435
  OS: Linux 2.6.12
  Java: Sun jdk1.5.0_04
I attach a sample project which causes the 100% CPU load and rich client hang.",org.eclipse.core.runtime.internal.adaptor.ContextFinder
FILE,eclipse-3.1,300054,2010-01-19T10:12:00.000-06:00,copy changes from right copy changes to left,"public class Bug {
	void bar() {
		System.out.println();
	}
}
  System.out.println();
R3.5, R3.5.x and I20100112-0800.
start with new workspace
paste into Package explorer
public class Bug {
void bar() {
System.out.println();
}
}
delete System.out.println() save System.out.println()
compare current state
change from Right change to button
NOTE: step 6 is crucial: it only happens when the compare editor is focused on a method.",org.eclipse.compare.internal.Utilities
FILE,eclipse-3.1,76534,2004-10-18T22:57:00.000-05:00,not perform evaluations with constructor _ parameters not perform evaluations inside inner class,"createViewer(...)
disallow evaluations in inner classes take parameters in referenced constructor _ take parameters in inner classes take evaluations in referenced constructor _ take evaluations in inner classes
see CheckBoxTreeViewer create CheckBoxTreeViewer in breakpointsview #ce 15198
Is there anything we can do to allow evaluations in these kinds of classes?",org.eclipse.jdt.internal.debug.eval.ast.engine.SourceBasedSourceGenerator
FILE,eclipse-3.1,77234,2004-10-28T15:41:00.000-05:00,not see inherited method,"getTypeName() 
  
  
  
 getTypeName()   JavaExceptionBreakpoint

getTypeName()
create detail formatter for type JavaExceptionBreakpoint
debug RemoveBreakpointAction delete RemoveBreakpointAction
select JavaExceptionBreakpoint
get following in details pane
Detail formatter error:
The method getTypeName() is undefined for the type JavaExceptionBreakpoint
getTypeName() is declared on JavaBreakpoint, which JavaExceptionBreakpoint 
extends.",org.eclipse.jdt.internal.debug.ui.JavaDetailFormattersManager
FILE,eclipse-3.1,77573,2004-11-03T04:43:00.000-06:00,not propose static fields,"import static java.lang.Math
200411022000
Steps to reproduce:
write import static java.lang.Math. in cu","org.eclipse.jdt.internal.codeassist.CompletionEngine
org.eclipse.jdt.core.CompletionProposal
org.eclipse.jdt.core.CompletionRequestor"
FILE,eclipse-3.1,78740,2004-11-16T10:57:00.000-06:00,represent interface flags,"becomeDetailed()   

package org.example.jdom;

import org.eclipse.core.runtime.IPlatformRunnable;
import org.eclipse.jdt.core.Flags;
import org.eclipse.jdt.core.jdom.DOMFactory;
import org.eclipse.jdt.core.jdom.IDOMCompilationUnit;
import org.eclipse.jdt.core.jdom.IDOMType;

public class Test implements IPlatformRunnable
{
  public Object run(Object object)
  {
    DOMFactory factory = new DOMFactory();
    IDOMCompilationUnit jCompilationUnit =
factory.createCompilationUnit(""package x; /** @model */ interface X  {}"", ""NAME"");
    IDOMType jType = (IDOMType)jCompilationUnit.getFirstChild().getNextNode(); 
    System.err.println("""" + ((jType.getFlags() & Flags.AccInterface) != 0));
    jType.getComment();
    System.err.println("""" + ((jType.getFlags() & Flags.AccInterface) != 0));
    return new Integer(0);
  }
}
call getComment on IDOMType change flags from encoding encode type
package org.example.jdom;
import org.eclipse.core.runtime.IPlatformRunnable;
import org.eclipse.jdt.core.Flags;
import org.eclipse.jdt.core.jdom.DOMFactory;
import org.eclipse.jdt.core.jdom.IDOMCompilationUnit;
import org.eclipse.jdt.core.jdom.IDOMType;
public class Test implements IPlatformRunnable
{ public Object run(Object object)
{
DOMFactory factory = new DOMFactory();
IDOMCompilationUnit jCompilationUnit = factory.createCompilationUnit(""package x; /** @model */ interface X  {}"", ""NAME"");
IDOMType jType = (IDOMType)jCompilationUnit.getFirstChild().
getNextNode();
System.err.println("""" + ((jType.getFlags() & Flags.AccInterface) !
= 0));
jType.getComment();
System.err.println("""" + ((jType.getFlags() & Flags.AccInterface) !
= 0));
return new Integer(0);
}
}
This bug completely breaks EMF's JavaEcoreBuilder, which is a blocking problem for our clients and hence we see this as a blocking problem.",org.eclipse.jdt.internal.compiler.DocumentElementParser
FILE,eclipse-3.1,79957,2004-12-02T00:47:00.000-06:00,change input usingTableViewer,"Table table=new Table(shell,SWT.VIRTUAL);
TableViewer tv=new TableViewer(table);
tv.setContentProvider(new NetworkContentProvider());
tv.setLabelProvider(new NetworkLabelProvider());
tv.setInput(model);
 
 tv.setInput(model1);
I'm using the latest code for Table viewer with a private virtual manager class
in table viewer.
straight code
.
.
in a selection event handler for a button, i've to reset the model input
.
.
tv.setInput(model1);
.
.
throw null pointer exception
the stack trace was
java.lang.NullPointerException
at org.eclipse.jface.viewers.TableViewer$1.handleEvent(TableViewer.java:103)
at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:82)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:796)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:820)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:805)
at org.eclipse.swt.widgets.Table.wmNotifyChild(Table.java:3158)
at org.eclipse.swt.widgets.Control.WM_NOTIFY(Control.java:4040)
at org.eclipse.swt.widgets.Composite.WM_NOTIFY(Composite.java:722)
at org.eclipse.swt.widgets.Control.windowProc(Control.java:3025)
at org.eclipse.swt.widgets.Decorations.windowProc(Decorations.java:1400)
at org.eclipse.swt.widgets.Display.windowProc(Display.java:3349)
at org.eclipse.swt.internal.win32.OS.CallWindowProcW(Native Method)
at org.eclipse.swt.internal.win32.OS.CallWindowProc(OS.java:1403)
at org.eclipse.swt.widgets.Table.callWindowProc(Table.java:137)
at org.eclipse.swt.widgets.Control.windowProc(Control.java:3056)
at org.eclipse.swt.widgets.Display.windowProc(Display.java:3349)
at org.eclipse.swt.internal.win32.OS.DispatchMessageW(Native Method)
at org.eclipse.swt.internal.win32.OS.DispatchMessage(OS.java:1479)
at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2440)
at jface.viewers.TestJfaceVirtual.main(TestJfaceVirtual.java:49)",org.eclipse.jface.viewers.TableViewer
FILE,eclipse-3.1,81045,2004-12-14T20:13:00.000-06:00,change value,"public class Test {
	static class Inner {
	}
	public static void main(String[] args) {
		Inner inner= null;
		System.out.println(1);  //  <- breakpoint here
	}
}
public class Test { static class Inner {
} public static void main(String[] args) {
Inner inner= null;
System.out.println(1);  //  <- breakpoint here
}
}
debug to breakpoint","org.eclipse.jdt.internal.debug.ui.actions.JavaVariableValueEditor
org.eclipse.jdt.internal.debug.eval.ast.engine.ASTEvaluationEngine
org.eclipse.jdt.internal.debug.core.model.JDILocalVariable"
FILE,eclipse-3.1,83489,2005-01-22T17:33:00.000-06:00,select ] code select returns itype instead_of ITypeParameter,"class Test<T> {
  void foo(T t) {}
}
Using HEAD.
consider following test case
class Test<T> { void foo(T t) {}
}
select t in method declaration return itype",org.eclipse.jdt.internal.codeassist.SelectionEngine
FILE,eclipse-3.1,84194,2005-02-01T18:05:00.000-06:00,assist at end assist in import statements insert,"import org.eclipse.core.runtime.*;
Build: I-20050201
open Java file contain import statements contain Java file
import org.eclipse.core.runtime.
*;
delete * from end try * from end
see upon pressing press Enter insert down several lines under import statements insert down text under import statements
be in random position","org.eclipse.jdt.internal.ui.text.java.JavaTypeCompletionProposal
org.eclipse.jdt.internal.ui.text.java.ExperimentalResultCollector"
FILE,eclipse-3.1,84724,2005-02-08T13:41:00.000-06:00,find call sites for varargs constructor_s,"public class Test {
    public void foo() {
        Cell c= new Cell("""", """"); // calls Cell.Cell(String...)
    }
}
 class Cell {
    public Cell(String... args) { }
}
find call to varargs constructor _
highlight name invoke references
Bug manifests with integration build I2005-0202.
public class Test { public void foo() {
Cell c= new Cell("""", """"); // calls Cell.Cell(String...)
}
} class Cell { public Cell(String... args) { }
}",org.eclipse.jdt.internal.core.search.matching.ConstructorLocator
FILE,eclipse-3.1,84770,2005-02-09T06:46:00.000-06:00,fail in specific case,"public class FormatterTest {
  void doTest(
      ) {
     System.out.println(""("" + 
         Object.class + "")"");
  }
}
 
 toString()
Steps to reproduce:
make new class in default package
-----BEGIN-----
public class FormatterTest {
void doTest(
) {
System.out.println(""("" +
Object.class + "")"");
}
}
-----END-----
format by ctrl + shift + f
change Object.class to Object.class.toString()
format by ctrl + shift + f
have string operatation after keyword class",org.eclipse.jdt.internal.formatter.BinaryExpressionFragmentBuilder
FILE,eclipse-3.1,85344,2005-02-15T17:36:00.000-06:00,evaluate logical structure value in Java evaluate logical structure value for map,"public class Test {
  public static void main(String[] args) {
    Map<String, Integer> map= new HashMap<String, Integer>();
    System.out.println();     // <-- breakpoint here
  }
}

  entrySet()
public class Test { public static void main(String[] args) {
Map<String, Integer> map= new HashMap<String, Integer>();
}
}
get error expand map in variables view",org.eclipse.jdt.internal.debug.eval.ast.engine.BinaryBasedSourceGenerator
FILE,eclipse-3.1,85397,2005-02-16T08:20:00.000-06:00,produce error on constructor _,"strictfp enum Natural {
	ONE, TWO;
}

 
 strictfp enum Natural {
	ONE, TWO;
	
	private Natural() {
	}
}
I20050215-2300 (M5 test pass)
have code
strictfp enum Natural {
ONE, TWO;
}
not allow strictfp on enum actual
have code
strictfp enum Natural {
ONE, TWO;
private Natural() {
}
}
report wrong modifier with type name show error for constructor _","org.eclipse.jdt.internal.compiler.lookup.SyntheticMethodBinding
org.eclipse.jdt.internal.ui.typehierarchy.TypeHierarchyViewPart
org.eclipse.jdt.internal.compiler.lookup.MethodScope"
FILE,eclipse-3.1,85402,2005-02-16T08:50:00.000-06:00,assist ] NPE while trying complete on empty annotation,"import e.Team;
   @Author(name={Team.DAVID, Team.JEROME})
    
  public class Test {
	@Author(name=Team.PHILIPPE) void foo() {}
	@Author int t;
  }
  
  import e.Team;
  public @interface Author {
	Team[] name() default Team.FREDERIC;
  }
  
  package e;
  public enum Team {
	PHILIPPE, DAVID, JEROME, FREDERIC;
  }

 
 ResultCollector.accept(CompletionProposal)
Using build 3.1 M5 candidate (I20040215-2300).
have following test case
Test.java:
import e.Team;
@Author(name={Team.DAVID, Team.JEROME})
@| // <-- Try to complete here: NPE
public class Test {
@Author(name=Team.PHILIPPE) void foo() {}
@Author int t;
}
Author.java:
import e.Team;
public @interface Author {
Team[] name() default Team.FREDERIC;
}
Team.java:
package e;
public enum Team {
PHILIPPE, DAVID, JEROME, FREDERIC;
}
complete at caret position
name for CompletionProposal","org.eclipse.jdt.internal.codeassist.complete.CompletionOnAnnotationOfType
org.eclipse.jdt.internal.codeassist.CompletionEngine
org.eclipse.jdt.internal.codeassist.complete.CompletionParser"
FILE,eclipse-3.1,85672,2005-02-17T05:53:00.000-06:00,unfold folded region with line delimiter,"package folding;

class Test {
    
}
I20050215-2300 (m5 test pass)
have code
""package folding;
class Test {
}""  <-- no delimiter on last line
put caret brace region fold region
put caret on last line unfold type
Not a regression - it is like this in 3.0",org.eclipse.jface.text.source.projection.ProjectionViewer
FILE,eclipse-3.1,85734,2005-02-17T12:28:00.000-06:00,debug view excessively for debug,"Runtime.exec(...)
I20050217-0800, KDE 3.3.2, GTK+ 2.4.14, X.Org 6.8.0, Linux 2.6.10
set breakpoint on Runtime.exec(...) start debugging session on eclipse
I
wish I could show you the effect; it is most disturbing.
:)","org.eclipse.debug.internal.ui.views.RemoteTreeViewer
org.eclipse.debug.internal.ui.views.launch.LaunchViewer
org.eclipse.debug.internal.ui.views.launch.LaunchViewEventHandler
org.eclipse.debug.internal.ui.views.RemoteTreeContentManager"
FILE,eclipse-3.1,86000,2005-02-21T14:47:00.000-06:00,produce invalid JPEG images,"package com.ibm.test.image;

import org.eclipse.swt.*;
import org.eclipse.swt.graphics.*;

public class ImageLoaderTest {
		
	public static void main(String[] args) {
		ImageLoader loader;
		String dir=""c:\\image-problems\\"";
		String files[]={
				""s34i3p04"",
				""s34n3p04"",
				""s35i3p04"",
				""s35n3p04"",
				""s36i3p04"",
				""s36n3p04"",
				""s37i3p04"",
				""s37n3p04"",
				""s38i3p04"",
				""s38n3p04"",
				""s39i3p04"",
				""s39n3p04""
		};
		
		try {
			for (int i=0; i<files.length; i++) {
			String filein  = dir+files[i]+"".png"";
			String fileout = dir+files[i]+"".jpg"";
			
			loader = new ImageLoader();
			loader.load(filein);
			loader.save(fileout,SWT.IMAGE_JPEG);
			}
		} catch (SWTException e) {
		  e.printStackTrace();
		}
	}
}
produce bad JPG images
I have only verified this with JPEG output.
test as JPEG
produce proper JPG images expected
The attached Zip file contains
 only those files that did not save correctly to JPEG.
package com.ibm.test.image;
import org.eclipse.swt.
*;
import org.eclipse.swt.graphics.
*;
public class ImageLoaderTest {
		
	public static void main(String[] args) {
		ImageLoader loader;
		String dir=""c:\\image-problems\\"";
		String files[]={
				""s34i3p04"",
				""s34n3p04"",
				""s35i3p04"",
				""s35n3p04"",
				""s36i3p04"",
				""s36n3p04"",
				""s37i3p04"",
				""s37n3p04"",
				""s38i3p04"",
				""s38n3p04"",
				""s39i3p04"",
				""s39n3p04""
		};
		
		try {
			for (int i=0; i<files.length; i++) {
			String filein  = dir+files[i]+"".
png"";
			String fileout = dir+files[i]+"".
jpg"";
			
			loader = new ImageLoader();
			loader.load(filein);
			loader.save(fileout,SWT.IMAGE_JPEG);
			}
		} catch (SWTException e) {
		  e.printStackTrace();
		}
	}
}","org.eclipse.ui.internal.WorkbenchIntroManager
org.eclipse.swt.internal.image.JPEGFileFormat"
FILE,eclipse-3.1,87171,2005-03-04T14:19:00.000-06:00,declare node use type parameters not work for methods/fields,"public class Inline<T> {
	void foo(T t) {
		System.out.println(t);
	}
}

 class Use {
	public static void main(String[] args) {
		Inline<String> i= null;
		i.foo(""Eclipse"");
	}
}

  i.foo(""Eclipse"");
 
 root.findDeclaringNode(methodBinding);
public class Inline<T> {
	void foo(T t) {
		System.out.println(t);
	}
}
class Use {
	public static void main(String[] args) {
		Inline<String> i= null;
		i.foo(""Eclipse"");
	}
}
take method binding of invocation foo
take root node represent whole CU
call root.findDeclaringNode(methodBinding)
contain corresponding declaration
use type parameters happen for fields","org.eclipse.jdt.core.dom.CompilationUnit
org.eclipse.jdt.core.dom.DefaultBindingResolver"
FILE,eclipse-3.1,87569,2005-03-09T16:41:00.000-06:00,obtain image switch to Debug perspective,"class which implements java.io.Serializable
I20050308-1510
create Java project create class use add generated serial version ID quickfix Switch to Debug perspective
3XMTHREADINFO      ""main"" (TID:0x02A08A00, sys_thread_t:0x000356F4, state:CW,
native ID:0x000009F4) prio=6
4XESTACKTRACE          at java/lang/Throwable.printStackTrace(Throwable.java:241)
4XESTACKTRACE          at
org/eclipse/core/runtime/CoreException.printStackTrace(CoreException.java:94)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseLog.getStackTrace(EclipseLog.java:316)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseLog.writeStack(EclipseLog.java:372)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseLog.writeLog(EclipseLog.java:337)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseLog.log(EclipseLog.java:208)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/PlatformLogWriter.logging(PlatformLogWriter.java:35)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform$1.run(InternalPlatform.java:831)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform.run(InternalPlatform.java:1015)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform.log(InternalPlatform.java:834)
4XESTACKTRACE          at org/eclipse/core/internal/runtime/Log.log(Log.java:56)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DebugUIPlugin.log(DebugUIPlugin.java:497)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DebugUIPlugin.log(DebugUIPlugin.java:506)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImageKey(DefaultLabelProvider.java:133)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:57)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
...
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/DebugElementHelper.getImageDescriptor(DebugElementHelper.java:55)
4XESTACKTRACE          at
org/eclipse/debug/ui/DebugElementWorkbenchAdapter.getImageDescriptor(DebugElementWorkbenchAdapter.java:37)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DefaultLabelProvider.getImage(DefaultLabelProvider.java:61)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getDefaultImage(DelegatingModelPresentation.java:198)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/DelegatingModelPresentation.getImage(DelegatingModelPresentation.java:150)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/DebugViewInterimLabelProvider.getImage(DebugViewInterimLabelProvider.java:62)
4XESTACKTRACE          at
org/eclipse/jface/viewers/DecoratingLabelProvider.getImage(DecoratingLabelProvider.java:82)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/RemoteTreeViewer.doUpdateItem(RemoteTreeViewer.java:448)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer$UpdateItemSafeRunnable.run(AbstractTreeViewer.java:86)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform.run(InternalPlatform.java:1015)
4XESTACKTRACE          at org/eclipse/core/runtime/Platform.run(Platform.java:757)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.doUpdateItem(AbstractTreeViewer.java:490)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer$UpdateItemSafeRunnable.run(StructuredViewer.java:352)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform.run(InternalPlatform.java:1015)
4XESTACKTRACE          at org/eclipse/core/runtime/Platform.run(Platform.java:757)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer.updateItem(StructuredViewer.java:1655)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.updateChildren(AbstractTreeViewer.java:1621)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.internalRefreshStruct(AbstractTreeViewer.java:1109)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.internalRefresh(AbstractTreeViewer.java:1086)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.internalRefresh(AbstractTreeViewer.java:1047)
4XESTACKTRACE          at
org/eclipse/jface/viewers/AbstractTreeViewer.internalRefresh(AbstractTreeViewer.java:1034)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer$7.run(StructuredViewer.java:1172)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer.preservingSelection(StructuredViewer.java:1109)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer.refresh(StructuredViewer.java:1170)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/LaunchViewer.refresh(LaunchViewer.java:80)
4XESTACKTRACE          at
org/eclipse/jface/viewers/StructuredViewer.refresh(StructuredViewer.java:1129)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/AbstractDebugEventHandler.refresh(AbstractDebugEventHandler.java:255)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/AbstractDebugEventHandler.viewBecomesVisible(AbstractDebugEventHandler.java:348)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/AbstractDebugEventHandlerView.becomesVisible(AbstractDebugEventHandlerView.java:69)
4XESTACKTRACE          at
org/eclipse/debug/internal/ui/views/launch/LaunchView.becomesVisible(LaunchView.java:1061)
4XESTACKTRACE          at
org/eclipse/debug/ui/AbstractDebugView$DebugViewPartListener.partVisible(AbstractDebugView.java:162)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartListenerList2$7.run(PartListenerList2.java:168)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/InternalPlatform.run(InternalPlatform.java:1015)
4XESTACKTRACE          at org/eclipse/core/runtime/Platform.run(Platform.java:757)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartListenerList2.fireEvent(PartListenerList2.java:54)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartListenerList2.firePartVisible(PartListenerList2.java:166)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage$1.propertyChange(WorkbenchPage.java:179)
4XESTACKTRACE          at
org/eclipse/ui/internal/LayoutPart.setVisible(LayoutPart.java:305)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartPane.setVisible(PartPane.java:331)
4XESTACKTRACE          at
org/eclipse/ui/internal/ViewPane.setVisible(ViewPane.java:614)
4XESTACKTRACE          at
org/eclipse/ui/internal/presentations/PresentablePart.setVisible(PresentablePart.java:126)
4XESTACKTRACE          at
org/eclipse/ui/internal/presentations/newapi/PresentablePartFolder.select(PresentablePartFolder.java:266)
4XESTACKTRACE          at
org/eclipse/ui/internal/presentations/newapi/LeftToRightTabOrder.select(LeftToRightTabOrder.java:65)
4XESTACKTRACE          at
org/eclipse/ui/internal/presentations/newapi/TabbedStackPresentation.selectPart(TabbedStackPresentation.java:391)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartStack.refreshPresentationSelection(PartStack.java:1051)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartStack.createControl(PartStack.java:536)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartStack.createControl(PartStack.java:473)
4XESTACKTRACE          at
org/eclipse/ui/internal/PartSashContainer.createControl(PartSashContainer.java:485)
4XESTACKTRACE          at
org/eclipse/ui/internal/PerspectiveHelper.activate(PerspectiveHelper.java:230)
4XESTACKTRACE          at
org/eclipse/ui/internal/Perspective.onActivate(Perspective.java:773)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage.setPerspective(WorkbenchPage.java:2829)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage.busySetPerspective(WorkbenchPage.java:845)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage.access$10(WorkbenchPage.java:830)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage$13.run(WorkbenchPage.java:2980)
4XESTACKTRACE          at
org/eclipse/swt/custom/BusyIndicator.showWhile(BusyIndicator.java:69)
4XESTACKTRACE          at
org/eclipse/ui/internal/WorkbenchPage.setPerspective(WorkbenchPage.java:2978)
4XESTACKTRACE          at
org/eclipse/ui/internal/PerspectiveBarContributionItem.select(PerspectiveBarContributionItem.java:109)
4XESTACKTRACE          at
org/eclipse/ui/internal/PerspectiveBarManager$1.widgetSelected(PerspectiveBarManager.java:145)
4XESTACKTRACE          at
org/eclipse/swt/widgets/TypedListener.handleEvent(TypedListener.java:89)
4XESTACKTRACE          at
org/eclipse/swt/widgets/EventTable.sendEvent(EventTable.java:82)
4XESTACKTRACE          at org/eclipse/swt/widgets/Widget.sendEvent(Widget.java:842)
4XESTACKTRACE          at
org/eclipse/swt/widgets/Display.runDeferredEvents(Display.java:2894)
4XESTACKTRACE          at
org/eclipse/swt/widgets/Display.readAndDispatch(Display.java:2527)
4XESTACKTRACE          at
org/eclipse/ui/internal/PerspectiveBarManager.handleChevron(PerspectiveBarManager.java:161)
4XESTACKTRACE          at
org/eclipse/ui/internal/PerspectiveSwitcher$9.widgetSelected(PerspectiveSwitcher.java:766)
4XESTACKTRACE          at
org/eclipse/swt/widgets/TypedListener.handleEvent(TypedListener.java:89)
4XESTACKTRACE          at
org/eclipse/swt/widgets/EventTable.sendEvent(EventTable.java:82)
4XESTACKTRACE          at org/eclipse/swt/widgets/Widget.sendEvent(Widget.java:842)
4XESTACKTRACE          at
org/eclipse/swt/widgets/Display.runDeferredEvents(Display.java:2894)
4XESTACKTRACE          at
org/eclipse/swt/widgets/Display.readAndDispatch(Display.java:2527)
4XESTACKTRACE          at
org/eclipse/ui/internal/Workbench.runEventLoop(Workbench.java:1514)
4XESTACKTRACE          at
org/eclipse/ui/internal/Workbench.runUI(Workbench.java:1478)
4XESTACKTRACE          at
org/eclipse/ui/internal/Workbench.createAndRunWorkbench(Workbench.java:297)
4XESTACKTRACE          at
org/eclipse/ui/PlatformUI.createAndRunWorkbench(PlatformUI.java:143)
4XESTACKTRACE          at
org/eclipse/ui/internal/ide/IDEApplication.run(IDEApplication.java:103)
4XESTACKTRACE          at
org/eclipse/core/internal/runtime/PlatformActivator$1.run(PlatformActivator.java:228)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseStarter.run(EclipseStarter.java:338)
4XESTACKTRACE          at
org/eclipse/core/runtime/adaptor/EclipseStarter.run(EclipseStarter.java:151)
4XESTACKTRACE          at sun/reflect/NativeMethodAccessorImpl.invoke0(Native
Method)
4XESTACKTRACE          at
sun/reflect/NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:85)
4XESTACKTRACE          at
sun/reflect/NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:58)
4XESTACKTRACE          at
sun/reflect/DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:60)
4XESTACKTRACE          at java/lang/reflect/Method.invoke(Method.java:391)
4XESTACKTRACE          at
org/eclipse/core/launcher/Main.invokeFramework(Main.java:268)
4XESTACKTRACE          at org/eclipse/core/launcher/Main.basicRun(Main.java:260)
4XESTACKTRACE          at org/eclipse/core/launcher/Main.run(Main.java:887)
4XESTACKTRACE          at org/eclipse/core/launcher/Main.main(Main.java:871)",org.eclipse.debug.internal.ui.DefaultLabelProvider
FILE,eclipse-3.1,87665,2005-03-10T11:38:00.000-06:00,open details with errors,"testOpenJavaEditor1()
http://fullmoon.rtp.raleigh.ibm.com/downloads/drops/M-3.0.2RC2-200502161722/performance/org.eclipse.jdt.text.php?
scroll down to performance.OpenJavaEditorStressTest#testOpenJavaEditor1()
Observe: red x for RHEL 3.0 Sun 1.4.2_06.
Looks like a bug regarding the handling of negative numbers.","org.eclipse.swt.printing.PrintDialog
org.eclipse.swt.widgets.MessageBox"
FILE,eclipse-3.1,89632,2005-03-30T13:10:00.000-06:00,evaluate in Snippet editor,"Collection<String> c = new ArrayList<String>();
        c.add(""a"");
        c.add(""b"");
        c.add(""c"");

        for (Iterator<String> i = c.iterator(); i.hasNext(); )
            if (i.next().length() == 4)
            {
                String x = i.next();
                System.out.println(x);
            }
        
        return c;

 
   
  run()
Collection<String> c = new ArrayList<String>();
c.add(""a"");
c.add(""b"");
c.add(""c"");
for (Iterator<String> i = c.iterator(); i.hasNext(); )
if (i.next().
length() == 4)
{
String x = i.next();
System.out.println(x);
} return c;
add testcase to snippet editor
do set imports include java.util.
resolve collection resolve iterator
try inspect result in following error
java.lang.VerifyError: arguments are not type compatible (class: CodeSnippet_2 method: run()V) at pc: 57
at java.lang.Class.verifyImpl(Native Method)
at java.lang.Class.verify(Class.java:254)
at java.lang.Class.initialize(Class.java:317)
at java.lang.Class.forNameImpl(Native Method)
at java.lang.Class.forName(Class.java:128)
at org.eclipse.jdt.internal.debug.ui.snippeteditor.ScrapbookMain1.eval
(ScrapbookMain1.java:20)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke
(NativeMethodAccessorImpl.java:46)
at sun.reflect.DelegatingMethodAccessorImpl.invoke
(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:611)
at org.eclipse.jdt.internal.debug.ui.snippeteditor.ScrapbookMain.evalLoop
(ScrapbookMain.java:54)
at org.eclipse.jdt.internal.debug.ui.snippeteditor.ScrapbookMain.main
(ScrapbookMain.java:35)",org.eclipse.jdt.internal.eval.CodeSnippetMessageSend
FILE,eclipse-3.1,90289,2005-04-05T09:17:00.000-05:00,call IStackFrame.getVariables(),"IStackFrame.getVariables()
M6 driver
add Suspsend VM breakpoint to IStackFrame.getVariables() add Suspsend VM breakpoint on call
show duplicates as result show duplicates of local variables","org.eclipse.debug.internal.ui.views.variables.VariablesViewEventHandler
org.eclipse.debug.internal.ui.views.registers.RegistersView
org.eclipse.debug.internal.ui.views.registers.RegistersViewEventHandler
org.eclipse.debug.internal.ui.views.expression.ExpressionViewEventHandler"
FILE,eclipse-3.1,91098,2005-04-12T06:07:00.000-05:00,not mark occurrences,"String a;
String[] b;
String[][] c;
String a;
String[] b;
String[][] c;
put cursor on String put cursor on string [ ]
put cursor on string [ ] [ ]
It
looks like there is a missing loop when removing square brackets ;o)
I use 3.1M6.
Best regards,
Cyril",org.eclipse.jdt.core.dom.ASTConverter
FILE,eclipse-3.1,91346,2005-04-13T16:43:00.000-05:00,mark occurrences not find for marking,"{buildDirectory}
<project name=""project"" default=""default"">
	<property name=""buildDirectory"" location=""C:\buildDirectory"" />
	<target name=""default"">
		<available property=""${buildDirectory}"" file=""available2.xml"" />
		<echo message=""${C:\buildDirectory2}""></echo>
	</target>
</project>
not mark property declaration occurrence",org.eclipse.ant.internal.ui.model.AntPropertyNode
FILE,eclipse-3.1,92451,2005-04-22T16:36:00.000-05:00,assist failure cast + arrays,"public class Test {
	public static void main(String[] args) {
		java.util.List elements = null;
		// code assist works on this line
		new Test(Test.toStrings((Test[])elements.toArray(new Test
[0])));
		//code assist fails on this line
	}
	public Test(Object object) {
	}
	public static Object toStrings(Test[] objects) {
		return null;
	}
}
I20050419
J2SE 5 (but also fails in JDK 1.4)
fail in following class
public class Test { public static void main(String[] args) { java.util.List elements = null;
// code assist works on this line new Test(Test.toStrings((Test[])elements.toArray(new Test
[0])));
//code assist fails on this line
} public Test(Object object) {
} public static Object toStrings(Test[] objects) { return null;
}
}",org.eclipse.jdt.internal.codeassist.complete.CompletionParser
FILE,eclipse-3.1,93249,2005-04-29T05:49:00.000-05:00,not propose full method stub,"IRunnableWithProgress runnable= new IRunnableWithProgress() {
};

  
  
 public void run(org.eclipse.core.runtime.IProgressMonitor monitor) throws
InvocationTargetException, InterruptedException
take revision of BuildPathAction
add following in run
IRunnableWithProgress runnable= new IRunnableWithProgress() {
};
public void run(org.eclipse.core.runtime.IProgressMonitor monitor) throws
InvocationTargetException, InterruptedException","org.eclipse.jdt.internal.codeassist.CompletionEngine
org.eclipse.jdt.internal.ui.text.java.OverrideCompletionProposal"
FILE,eclipse-3.1,94216,2005-05-09T20:04:00.000-05:00,not work for generic types,"interface IGeneric<T> {
}
 public class Generic<T> implements IGeneric<T> {
    public static void main(String[] args) {
        IGeneric<String> gen= new Generic<String>();
        System.out.println();  // <-- breakpoint here
    }
}
interface IGeneric<T> {
} public class Generic<T> implements IGeneric<T> { public static void main(String[] args) {
IGeneric<String> gen= new Generic<String>();
System.out.println();  // <-- breakpoint here
}
}
declare type open concrete type for gen","org.eclipse.jdt.internal.debug.ui.actions.OpenVariableDeclaredTypeAction
org.eclipse.jdt.internal.debug.ui.actions.OpenVariableConcreteTypeAction"
FILE,eclipse-3.1,94465,2005-05-10T14:33:00.000-05:00,modify value in Variables view,"String [] elms= { ""abc"", ""cde"", ""xyz"" };
String [] elms= { ""abc"", ""cde"", ""xyz"" };
I have a string array.
expand array in variables expand first element
value in Change primitive Value dialog
result in java dump
Got the following error in the console:
JVMDG217: Dump Handler is Processing Signal 11 - Please Wait.
JVMDG303: JVM Requesting Java core file
JVMDG304: Java core file written to D:\eclipse3.1\I20050509
\eclipse\workspace\YetAnotherProj\javacore.20050510.142923.2576.txt
JVMDG215: Dump Handler has Processed Exception Signal 11.
Runnign IBM JVM 1.4.2","org.eclipse.jdt.internal.debug.ui.JDIModelPresentation
org.eclipse.jdt.internal.debug.ui.actions.JavaObjectValueEditor
org.eclipse.jdt.internal.debug.ui.actions.ActionMessages"
FILE,eclipse-3.1,95096,2005-05-13T06:16:00.000-05:00,assist popup complete imported method name,"import static java.lang.Math
I20050513-0010
Steps to reproduce:
import static java.lang.Math.
constrain proposals to members","org.eclipse.jdt.internal.ui.text.java.JavaMethodCompletionProposal
org.eclipse.jdt.internal.ui.text.java.LazyJavaCompletionProposal"
FILE,eclipse-3.1,95152,2005-05-13T12:14:00.000-05:00,not find synthetic constructor _,"InputReadJob readJob = new InputReadJob(streamsProxy);
Build: I20050513-0010
add org.eclipse.debug.ui by clicking add org.eclipse.debug.ui to search path ( i.e. click add to java
search "" in plugins view
open type on processconsole
go to line
InputReadJob readJob = new InputReadJob(streamsProxy);
highlight InputReadJob constructor _ hit f3
-> It opens a new class file editor, positioned at the top of the file.
5) The outline view in this editor has the constructor_
InputReadJob(ProcessConsole, IStreamsProxy).
click entry in outline view not jump to constructor _
not handle synthetic addition of enclosing class not handle synthetic addition by compiler
break kind of navigation break kind to corresponding constructor _","org.eclipse.ant.internal.ui.views.AntViewDropAdapter
org.eclipse.ant.internal.ui.launchConfigurations.AntLaunchShortcut
org.eclipse.ant.internal.ui.AntUtil
org.eclipse.jdt.internal.core.search.matching.ConstructorLocator
org.eclipse.jdt.internal.core.search.indexing.BinaryIndexer
org.eclipse.jdt.internal.core.index.DiskIndex
org.eclipse.jdt.internal.core.search.matching.ConstructorPattern"
FILE,eclipse-3.1,96440,2005-05-24T11:11:00.000-05:00,determine sizes lay out times,"table.getClientArea()
20050522
See Bug 93611
When we attempt to layout a table we are scaling columns with
table.getClientArea().
width.
In M6 this returned the width of the table - post
M6 it is returning a much smaller value and making all of our columns very small
in the Table Layout.
put breakpoint in jface TableLayout class
see client area size
do in m6",org.eclipse.jface.preference.PreferencePage
FILE,eclipse-3.1,96489,2005-05-24T14:40:00.000-05:00,have border,"layout.addStandaloneView(BrowserApp.BROWSER_VIEW_ID, false,
IPageLayout.RIGHT, .25f, IPageLayout.ID_EDITOR_AREA);
build N20050523
change BrowserPerspectiveFactory have following instead_of regular addView layout.addStandaloneView ( BrowserApp.BROWSER_VIEW_ID
IPageLayout.RIGHT, .25f, IPageLayout.ID_EDITOR_AREA);
show history view
have border
This is a regression from 3.0.2.","org.eclipse.ui.presentations.WorkbenchPresentationFactory
org.eclipse.ui.internal.presentations.defaultpresentation.EmptyTabFolder"
FILE,eclipse-3.1,97722,2005-05-31T16:41:00.000-05:00,dialog problems,"@

Dialog
crop error message at bottom
@@
Dialog font used: Trebuchet MS, size 11",org.eclipse.ant.internal.ui.preferences.AddCustomDialog
FILE,eclipse-3.1,98147,2005-06-02T13:09:00.000-05:00,not show children,"package xy;
public class Try {
	String fName;
	int fID;
	
	public Try(String name, int id) {
		fName= name;
		fID= id;
	}
	
	public static void main(String[] args) {
		Try t= new Try(""Hello"", 5);
		callee(t, t);
	}
	
	static void callee(Try t1, Try t2) {
		boolean same= t1.equals(t2); //breakpoint here
	}
	
}
N20050602-0010
show fName show fID
package xy;
public class Try {
String fName;
int fID;
public Try(String name, int id) { fName= name;
fID= id;
} public static void main(String[] args) {
Try t= new Try(""Hello"", 5);
callee(t, t);
} static void callee(Try t1, Try t2) { boolean same= t1.equals(t2); //breakpoint here
}
}",org.eclipse.debug.internal.ui.views.RemoteTreeViewer
FILE,eclipse-3.1,98740,2005-06-07T13:25:00.000-05:00,refresh children on project,"String folder = ""/temp"";//$NON-NLS-1$
String projName = ""project"";//$NON-NLS-1$ 
IProjectDescription description = ResourcesPlugin.getWorkspace
().loadProjectDescription(projPath);
IProject project = ResourcesPlugin.getWorkspace().getRoot().getProject
(description.getName());
project.create(description, new NullProgressMonitor());

  project.open()  
 The members()  
 if (info.isSet(ICoreConstants.M_CHILDREN_UNKNOWN))
			workspace.refreshManager.refresh(this);
take existing simple project on disk import project into workspace import project by performing create with code
String folder = ""/temp"";//$NON-NLS-1$
String projName = ""project"";//$NON-NLS-1$
IProjectDescription description = ResourcesPlugin.getWorkspace
().
loadProjectDescription(projPath);
IProject project = ResourcesPlugin.getWorkspace().
getRoot().
getProject
(description.getName());
project.create(description, new NullProgressMonitor());
not open project with project.open() API
This is the key to the issue.
create project by API create project by UI
start background refresh job for closed project stick in infinite loop
I believe the offending code is in the class org.eclipse.core.internal.resources.Container.
because the projects members are not known.
call members on iproject
If you override this method in Project and do not refresh for closed projects, the problem goes away.
load existing Java projects by performing load existing Java projects on disk perform create
get refresh infinite loops on next UI gesture
We want the projects in the workspace, so we create them but do not open them, as open is very expensive.
This worked fine in Eclipse 3.0.","org.eclipse.core.internal.resources.Container
org.eclipse.core.internal.resources.Resource"
FILE,eclipse-3.1,99355,2005-06-10T09:48:00.000-05:00,extract method trips,"package p;

class Container<T>
{
   private final T m_t;

   public Container(T t)
   {
      m_t = t;
   }

   T get()
   {
      return m_t;
   }
}

class GenericContainer
{
   private final Container<?> m_c;

   public GenericContainer(Container<?> c) 
   {
      m_c = c;
   }

   public Container<?> getC()
   {
      return m_c;
   }
}

public class A
{
   GenericContainer createContainer()
   {
      final Container<String> innerContainer = new Container<String>(""hello"");
      final Container<Container<String>> outerContainer = new
Container<Container<String>>(innerContainer);
      return new GenericContainer(outerContainer);
   }
   
   void method()
   {
      final GenericContainer createContainer = createContainer();
      @SuppressWarnings(""unchecked"")
      final Container<Container<String>> c = (Container<Container<String>>)
createContainer.getC();
      //extract method from here
      final Container<String> container = c.get();
      final String string = container.get();
      //to here
   }
}
 
 

package p;

class Container<T>
{
   private final T m_t;

   public Container(T t)
   {
      m_t = t;
   }

   T get()
   {
      return m_t;
   }
}

class GenericContainer
{
   private final Container<?> m_c;

   public GenericContainer(Container<?> c) 
   {
      m_c = c;
   }

   public Container<?> getC()
   {
      return m_c;
   }
}

public class A
{
   GenericContainer createContainer()
   {
      final Container<String> innerContainer = new Container<String>(""hello"");
      final Container<Container<String>> outerContainer = new
Container<Container<String>>(innerContainer);
      return new GenericContainer(outerContainer);
   }
   
   void method()
   {
      final GenericContainer createContainer = createContainer();
      @SuppressWarnings(""unchecked"")
      final Container<Container<String>> c = (Container<Container<String>>)
createContainer.getC();
      //extract method from here
      extractedMethod(c);
      //to here
   }

   private void extractedMethod(final final final Container<Container<String>> c)
   {
      final Container<String> container = c.get();
      final String string = container.get();
   }
}
extract method
declare paramater with many final modifiers
-------------------------------------
package p;
class Container<T>
{ private final T m_t;
public Container(T t)
{ m_t = t;
}
T get()
{ return m_t;
}
}
class GenericContainer
{ private final Container<?> m_c;
public GenericContainer(Container<?> c)
{ m_c = c;
}
public Container<?> getC()
{ return m_c;
}
}
public class A
{
GenericContainer createContainer()
{ final Container<String> innerContainer = new Container<String>(""hello"");
final Container<Container<String>> outerContainer = new
Container<Container<String>>(innerContainer);
return new GenericContainer(outerContainer);
} void method()
{ final GenericContainer createContainer = createContainer();
@SuppressWarnings(""unchecked"")
final Container<Container<String>> c = (Container<Container<String>>)
createContainer.getC();
//extract method from here final Container<String> container = c.get();
final String string = container.get();
//to here
}
}
----------------------------------------------- results in
-----------------------------------------------
package p;
class Container<T>
{ private final T m_t;
public Container(T t)
{ m_t = t;
}
T get()
{ return m_t;
}
}
class GenericContainer
{ private final Container<?> m_c;
public GenericContainer(Container<?> c)
{ m_c = c;
}
public Container<?> getC()
{ return m_c;
}
}
public class A
{
GenericContainer createContainer()
{ final Container<String> innerContainer = new Container<String>(""hello"");
final Container<Container<String>> outerContainer = new
Container<Container<String>>(innerContainer);
return new GenericContainer(outerContainer);
} void method()
{ final GenericContainer createContainer = createContainer();
@SuppressWarnings(""unchecked"")
final Container<Container<String>> c = (Container<Container<String>>)
createContainer.getC();
//extract method from here extractedMethod(c);
//to here
}
private void extractedMethod(final final final Container<Container<String>> c)
{ final Container<String> container = c.get();
final String string = container.get();
}
}
-----------------------------------------------------------
notice final modifiers in extractedMethod signature",org.eclipse.jdt.core.dom.ASTConverter
FILE,eclipse-3.1,99693,2005-06-13T11:29:00.000-05:00,invalid during display,"private static void doGenerics() {
		List<Integer> list = new ArrayList<Integer>();
		for (int i = 0; i < 1000; i++) {
			int num = rand.nextInt(10000) + 1;
			list.add(num);
		}
		
		int max = 0;
//start eval
		for (Integer integer : list) { // BREAKPOINT HERE
			max = Math.max(max, integer);
		}
		System.out.println(max);
//end eval
	}
debug following method to breakpoint
private static void doGenerics() {
List<Integer> list = new ArrayList<Integer>();
for (int i = 0; i < 1000; i++) { int num = rand.nextInt(10000) + 1;
list.add(num);
} int max = 0;
//start eval for (Integer integer : list) { // BREAKPOINT HERE max = Math.max(max, integer);
}
System.out.println(max);
//end eval
}
eval eval comments end eval comments
watch Variables view see lot of stack frames
Can we be smarter about not requesting and/or cancelling requests when the current stack frame is not valid?","org.eclipse.debug.internal.ui.views.variables.VariablesViewEventHandler
org.eclipse.debug.internal.ui.views.expression.ExpressionViewEventHandler"
FILE,WFCORE,WFCORE-267,2014-11-19T19:47:31.000-06:00,print output use cli client jar,"INFO: {




    ""outcome"" => ""success"",




    ""result"" => [




        ""core-service"",




        ""deployment"",




        ""deployment-overlay"",




        ""extension"",




        ""interface"",




        ""path"",




        ""socket-binding-group"",




        ""subsystem"",




        ""system-property""




    ]




}




{




    ""outcome"" => ""success"",




    ""result"" => [




        ""core-service"",




        ""deployment"",




        ""deployment-overlay"",




        ""extension"",




        ""interface"",




        ""path"",




        ""socket-binding-group"",




        ""subsystem"",




        ""system-property""




    ]




}
use CLI client jar
print log messages to standard
look something
[standalone@localhost:9999 /] :read-children-types
Nov 19, 2014 8:57:19 AM org.jboss.as.cli.impl.CommandContextImpl printLine
INFO: {
""outcome"" => ""success"",
""result"" => [
""core-service"",
""deployment"",
""deployment-overlay"",
""extension"",
""interface"",
""path"",
""socket-binding-group"",
""subsystem"",
""system-property""
]
}
{
""outcome"" => ""success"",
""result"" => [
""core-service"",
""deployment"",
""deployment-overlay"",
""extension"",
""interface"",
""path"",
""socket-binding-group"",
""subsystem"",
""system-property""
]
}",org.jboss.as.cli.CommandLineMain
FILE,WFCORE,WFCORE-495,2015-01-12T08:48:29.000-06:00,not startup to wflyctl0212,"file(standalone.xml)  file(standalone.xml)
not startup to wflyctl0212
firstly deploy
deploy 2nd time
show after server restart
15:26:26,913 INFO  [org.jboss.as] (MSC service thread 1-8) WFLYSRV0049: WildFly Full 9.0.0.Alpha2-SNAPSHOT (WildFly Core 1.0.0.
Alpha15) starting
15:26:27,133 ERROR [org.jboss.as.controller.management-operation] (Controller Boot Thread) WFLYCTL0013: Operation (""add"") failed - address: ([(""deployment"" => ""xxx.war"")]) - failure description: ""WFLYCTL0212: Duplicate resource [(\""deployment\"" => \""xxx.war\"")]""
15:26:27,136 FATAL [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0056: Server boot has failed in an unrecoverable manner; exiting.
See previous messages for details.
15:26:27,138 INFO  [org.jboss.as.server] (Thread-2) WFLYSRV0220: Server shutdown has been requested.
15:26:27,153 INFO  [org.jboss.as] (MSC service thread 1-1) WFLYSRV0050: WildFly Full 9.0.0.Alpha2-SNAPSHOT (WildFly Core 1.0.0.
Alpha15) stopped in 4ms
steps to reproduce:
start wildfly
see error message
do full-replace-deployment operation not remove full-replace-deployment operation from configuration file(standalone.xml)
have xxx.war in standalone/data/content configuration file(standalone.xml)
cause duplicate resource error",org.jboss.as.server.deployment.DeploymentFullReplaceHandler
FILE,WFCORE,WFCORE-626,2015-04-06T15:53:19.000-05:00,create list elements,"clear(name=attribute)
  get(name=attribute, index=0)
  add(name=attribute, value=test)
  get(name=attribute, index=0)
consider following sequence of operations
:list-clear(name=attribute)
:list-get(name=attribute, index=0)
:list-add(name=attribute, value=test)
:list-get(name=attribute, index=0)
return <undefined> expected
return <undefined>
create missing element at index operate on index","org.jboss.as.controller.operations.global.ListOperations
org.jboss.as.controller.operations.global.MapOperations"
FILE,WFCORE,WFCORE-716,2015-05-27T10:21:36.000-05:00,check at stage,"attribute(name=security-realm)




 {




    ""outcome"" => ""success"",




    ""response-headers"" => {




        ""operation-requires-reload"" => true,




        ""process-state"" => ""reload-required""




    }




 
 attribute(name=security-domain, value=MgMtDom)




 {




    ""outcome"" => ""success"",




    ""response-headers"" => {




        ""operation-requires-reload"" => true,




        ""process-state"" => ""reload-required""




    }
check e.g. check reload-required capabilities check requirements check state be in state
[standalone@localhost:9990 /] .
/core-service=management/management-interface=http-interface:undefine-attribute(name=security-realm)
{
""outcome"" => ""success"",
""response-headers"" => {
""operation-requires-reload"" => true,
""process-state"" => ""reload-required""
}
}
reference non-existent capability
[standalone@localhost:9990 /] .
/core-service=management/management-interface=http-interface:write-attribute(name=security-domain, value=MgMtDom)
{
""outcome"" => ""success"",
""response-headers"" => {
""operation-requires-reload"" => true,
""process-state"" => ""reload-required""
}
}
11:21:18,567 ERROR [org.jboss.as.controller.management-operation] (Controller Boot Thread) WFLYCTL0013: Operation (""add"") failed - address: ([
(""core-service"" => ""management""),
(""management-interface"" => ""http-interface"")
]): java.lang.IllegalStateException: WFLYCTL0364: Capability 'org.wildfly.security.security-domain.
MgMtDom' is unknown.
at org.jboss.as.controller.ModelControllerImpl$CapabilityRegistryImpl.getCapabilityRegistration(ModelControllerImpl.java:1388)",org.jboss.as.controller.CapabilityReferenceRecorder
FILE,WFCORE,WFCORE-815,2015-07-13T07:57:45.000-05:00,have more ancestors with same submodules,"add(name=includes, value=mail-01)
  add(name=includes, value=mail-02)

 
 {




    ""outcome"" => ""failed"",




    ""failure-description"" => {""domain-failure-description"" => ""WFLYCTL0401: Profile 'mail-01' defines subsystem 'mail' which is also defined in its ancestor profile 'mail-02'. Overriding subsystems is not supported""} 
 add(name=includes, value=mail-01)
  add(name=includes, value=mail-02)
Description of problem:
have more ancestors with same submodules
lead to wflyctl0212
Hierarchical composition of profiles was added to AS with EAP7-281 and WFCORE-382
How reproducible:
Always
Steps to Reproduce:
get fresh EAP
.
/domain.sh
.
/jboss-cli.sh -c
/profile=mail-01:add
/profile=mail-02:add
/profile=mail-01/subsystem=mail:add
/profile=mail-02/subsystem=mail:add
/profile=default-new:add
/profile=default-new:list-add(name=includes, value=mail-01)
/profile=default-new:list-add(name=includes, value=mail-02)
Actual results:
Expected results:
{
""outcome"" => ""failed"",
""failure-description"" => {""domain-failure-description"" => ""WFLYCTL0401: Profile 'mail-01' defines subsystem 'mail' which is also defined in its ancestor profile 'mail-02'.
Overriding subsystems is not supported""},
""rolled-back"" => true
}
Workaround:
Add any subsystem to default-new profile:
/profile=mail-01:add
/profile=mail-02:add
/profile=mail-01/subsystem=mail:add
/profile=mail-02/subsystem=mail:add
/profile=default-new:add
/profile=default-new/subsystem=jdr:add
/profile=default-new:list-add(name=includes, value=mail-01)
/profile=default-new:list-add(name=includes, value=mail-02)","org.jboss.as.domain.controller.operations.ProfileIncludesHandlerTestCase
org.jboss.as.domain.controller.operations.SocketBindingGroupIncludesHandlerTestCase
org.jboss.as.host.controller.logging.HostControllerLogger"
FILE,WFCORE,WFCORE-955,2015-08-27T14:34:07.000-05:00,set parent of profile set parent to non-existent profile not respond after attempt,"add()
 
 {




    ""outcome"" => ""failed"",




    ""failure-description"" => ""java.lang.NullPointerException:null""




}




 
 add()
Description of problem:
set parent of profile set parent to non-existent profile not respond after attempt
set parent of socket-binding-group set parent to non-existent socket-binding-group not respond after attempt
This works correctly on wildfly-core (2.0.0.
Beta4).
But this occurs on wildfly (master branch) and on EAP 7.0.0.
DR9. It may be some integration issue.
Priority of this jira tends to be critical.
How reproducible:
Always
Steps to Reproduce (profile):
get fresh EAP
.
/domain.sh
.
/jboss-cli.sh
/profile=new:add()
/profile=new:write-attribute(name=includes,value=[nonsence])
/profile=new:remove
[domain@localhost:9990 /] /profile=new:write-attribute(name=includes,value=[nonsence])
{
""outcome"" => ""failed"",
""failure-description"" => ""java.lang.NullPointerException:null""
}
[domain@localhost:9990 /] /profile=new:remove
server needs to be restarted
Expected results:
[domain@localhost:9990 /] /profile=new:write-attribute(name=includes,value=[nonsence])
{
""outcome"" => ""failed"",
""failure-description"" => {""domain-failure-description"" => ""WFLYCTL0369: Required capabilities are not available:
org.wildfly.domain.profile.nonsence in context 'profiles'""},
""rolled-back"" => true
}
[domain@localhost:9990 /] /profile=new:remove
{
""outcome"" => ""success"",
""result"" => undefined,
""server-groups"" => undefined
}
Steps to reproduce (socket-binding-group):
get fresh EAP
.
/domain.sh
.
/jboss-cli.sh
/profile=new:add()
/socket-binding-group=testt:add(default-interface=public,includes=[nonsence])
/profile=new:remove","org.jboss.as.controller.OperationContextImpl
org.jboss.as.controller.AbstractOperationContext
org.jboss.as.controller.logging.ControllerLogger
org.jboss.as.controller.SocketCapabilityResolutionUnitTestCase
org.jboss.as.controller.capability.registry.IncludingResourceCapabilityScope
org.jboss.as.controller.AbstractCapabilityResolutionTestCase"
FILE,WFCORE,WFCORE-1007,2015-09-24T06:45:11.000-05:00,remove extension,"migrate()




 {




    ""outcome"" => ""success"",




    ""result"" => {""migration-warnings"" => []}




 
 migrate()




 {




    ""outcome"" => ""success"",




    ""result"" => {""migration-warnings"" => []}




 
 migrate()




 {




    ""outcome"" => ""success"",




    ""result"" => {""migration-warnings"" => []}
use migration operation fill console log with warning messages
WARN  [org.jboss.as.controller] (management-handler-thread - 1) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [(""subsystem"" => ""jacorb"")]
This is the same either for jacorb or web or messaging subsystem.
do sequence of operation
[standalone@localhost:9999 /] /subsystem=jacorb:migrate()
{
""outcome"" => ""success"",
""result"" => {""migration-warnings"" => []}
}
[standalone@localhost:9999 /] /subsystem=messaging:migrate()
{
""outcome"" => ""success"",
""result"" => {""migration-warnings"" => []}
}
[standalone@localhost:9999 /] /subsystem=we
web  webservices  weld
[standalone@localhost:9999 /] /subsystem=web
web  webservices
[standalone@localhost:9999 /] /subsystem=web:migrate()
{
""outcome"" => ""success"",
""result"" => {""migration-warnings"" => []}
}
2015-09-24 08:41:09,729 WARN  [org.jboss.as.controller] (management-handler-thread - 1) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [(""subsystem"" => ""jacorb"")]
2015-09-24 08:43:13,229 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""jms-queue"" => ""DLQ"")
]
2015-09-24 08:43:13,230 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""jms-queue"" => ""ExpiryQueue"")
]
2015-09-24 08:43:13,230 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""pooled-connection-factory"" => ""hornetq-ra"")
]
2015-09-24 08:43:13,230 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""connection-factory"" => ""RemoteConnectionFactory"")
]
2015-09-24 08:43:13,231 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""connection-factory"" => ""InVmConnectionFactory"")
]
2015-09-24 08:43:13,231 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""address-setting"" => ""#"")
]
2015-09-24 08:43:13,231 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""security-setting"" => ""#""),
(""role"" => ""guest"")
]
2015-09-24 08:43:13,232 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""security-setting"" => ""#"")
]
2015-09-24 08:43:13,232 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""in-vm-acceptor"" => ""in-vm"")
]
2015-09-24 08:43:13,232 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-acceptor"" => ""netty-throughput""),
(""param"" => ""direct-deliver"")
]
2015-09-24 08:43:13,233 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-acceptor"" => ""netty-throughput""),
(""param"" => ""batch-delay"")
]
2015-09-24 08:43:13,233 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-acceptor"" => ""netty-throughput"")
]
2015-09-24 08:43:13,233 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-acceptor"" => ""netty"")
]
2015-09-24 08:43:13,234 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""in-vm-connector"" => ""in-vm"")
]
2015-09-24 08:43:13,234 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-connector"" => ""netty-throughput""),
(""param"" => ""batch-delay"")
]
2015-09-24 08:43:13,234 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-connector"" => ""netty-throughput"")
]
2015-09-24 08:43:13,235 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default""),
(""remote-connector"" => ""netty"")
]
2015-09-24 08:43:13,235 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""messaging""),
(""hornetq-server"" => ""default"")
]
2015-09-24 08:43:13,235 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [(""subsystem"" => ""messaging"")]
2015-09-24 08:43:20,957 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""web""),
(""configuration"" => ""jsp-configuration"")
]
2015-09-24 08:43:20,957 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""web""),
(""configuration"" => ""static-resources"")
]
2015-09-24 08:43:20,958 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""web""),
(""configuration"" => ""container"")
]
2015-09-24 08:43:20,958 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""web""),
(""virtual-server"" => ""default-host"")
]
2015-09-24 08:43:20,958 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [
(""subsystem"" => ""web""),
(""connector"" => ""http"")
]
2015-09-24 08:43:20,959 WARN  [org.jboss.as.controller] (management-handler-thread - 7) WFLYCTL0357: Notification of type resource-removed is not described for the resource at the address [(""subsystem"" => ""web"")]","org.jboss.as.controller.AbstractOperationContext
org.jboss.as.controller.logging.ControllerLogger"
FILE,WFCORE,WFCORE-1027,2015-10-01T18:16:10.000-05:00,scop roles,"{roles=master-monitor}




 
 {




                ""directory-grouping"" => ""by-server"",




                ""domain-controller"" => {""local"" => {} 
  
 {""org.jboss.as.jmx"" => undefined} 
 {




                    ""management"" => undefined,




                    ""public"" => undefined,




                    ""unsecure"" => undefined




                } 
 {""default"" => undefined} 
 {""jmx"" => undefined} 
 {roles=slave-maintainer}




 
 {roles=slave-maintainer}




 
  
 {""org.jboss.as.jmx"" => undefined} 
 {




                ""management"" => undefined,




                ""public"" => undefined,




                ""unsecure"" => undefined




            } 
 {""default"" => undefined} 
 {""jmx"" => undefined}
set up host scop roles follow https://gist.github.com/heiko-braun/0dc810ed04db8739defd
use role select master select role show filtered resources appear in results
[domain@localhost:9990 /] /host=*:read-resource{roles=master-monitor}
{
""outcome"" => ""success"",
""result"" => [
{
""address"" => [(""host"" => ""master"")],
""outcome"" => ""success"",
""result"" => {
""directory-grouping"" => ""by-server"",
""domain-controller"" => {""local"" => {}},
""management-major-version"" => 4,
""management-micro-version"" => 0,
""management-minor-version"" => 0,
""master"" => true,
""name"" => ""master"",
""namespaces"" => [],
""organization"" => undefined,
""product-name"" => ""WildFly Core"",
""product-version"" => ""2.0.0.CR6-SNAPSHOT"",
""release-codename"" => ""Kenny"",
""release-version"" => ""2.0.0.CR6-SNAPSHOT"",
""schema-locations"" => [],
""core-service"" => {
""host-environment"" => undefined,
""platform-mbean"" => undefined,
""management"" => undefined,
""discovery-options"" => undefined,
""ignored-resources"" => undefined,
""patching"" => undefined,
""module-loading"" => undefined
},
""extension"" => {""org.jboss.as.jmx"" => undefined},
""interface"" => {
""management"" => undefined,
""public"" => undefined,
""unsecure"" => undefined
},
""jvm"" => {""default"" => undefined},
""path"" => undefined,
""server"" => {
""server-one"" => undefined,
""server-two"" => undefined,
""server-three"" => undefined
},
""server-config"" => {
""server-one"" => undefined,
""server-two"" => undefined,
""server-three"" => undefined
},
""socket-binding-group"" => undefined,
""subsystem"" => {""jmx"" => undefined},
""system-property"" => undefined
}
},
{
""address"" => [(""host"" => ""localhost"")],
""outcome"" => ""success"",
""result"" => undefined
}
]
}
use role select slave select role get proper access-control header
[domain@localhost:9990 /] /host=*:read-resource{roles=slave-maintainer}
{
""outcome"" => ""success"",
""result"" => [{
""address"" => [(""host"" => ""localhost"")],
""outcome"" => ""success"",
""result"" => undefined
}],
""response-headers"" => {""access-control"" => [{
""absolute-address"" => [],
""relative-address"" => [],
""filtered-children-types"" => [""host""]
}]}
The same output on master with WFCORE-994 applied:
[domain@localhost:9990 /] /host=*:read-resource{roles=slave-maintainer}
{
""outcome"" => ""success"",
""result"" => [{
""address"" => [(""host"" => ""slave"")],
""outcome"" => ""success"",
""result"" => {
""directory-grouping"" => ""by-server"",
""domain-controller"" => {""remote"" => {
""protocol"" => undefined,
""port"" => undefined,
""host"" => undefined,
""username"" => undefined,
""ignore-unused-configuration"" => undefined,
""admin-only-policy"" => undefined,
""security-realm"" => ""ManagementRealm""
}},
""management-major-version"" => 4,
""management-micro-version"" => 0,
""management-minor-version"" => 0,
""master"" => false,
""name"" => ""slave"",
""namespaces"" => [],
""organization"" => undefined,
""product-name"" => undefined,
""product-version"" => undefined,
""release-codename"" => ""Kenny"",
""release-version"" => ""2.0.0.CR6-SNAPSHOT"",
""schema-locations"" => [],
""core-service"" => {
""host-environment"" => undefined,
""platform-mbean"" => undefined,
""management"" => undefined,
""discovery-options"" => undefined,
""ignored-resources"" => undefined,
""patching"" => undefined,
""module-loading"" => undefined
},
""extension"" => {""org.jboss.as.jmx"" => undefined},
""interface"" => {
""management"" => undefined,
""public"" => undefined,
""unsecure"" => undefined
},
""jvm"" => {""default"" => undefined},
""path"" => undefined,
""server"" => {
""server-one"" => undefined,
""server-two"" => undefined
},
""server-config"" => {
""server-one"" => undefined,
""server-two"" => undefined
},
""socket-binding-group"" => undefined,
""subsystem"" => {""jmx"" => undefined},
""system-property"" => undefined
}
}],
""response-headers"" => {""access-control"" => [{
""absolute-address"" => [],
""relative-address"" => [],
""filtered-children-types"" => [""host""]
}]}
}","org.jboss.as.test.integration.domain.rbac.RBACProviderHostScopedRolesTestCase
org.jboss.as.test.integration.domain.rbac.AbstractHostScopedRolesTestCase
org.jboss.as.controller.operations.global.GlobalOperationHandlers
org.jboss.as.test.integration.domain.rbac.JmxRBACProviderHostScopedRolesTestCase
org.jboss.as.test.integration.domain.rbac.ListRoleNamesTestCase
org.jboss.as.test.integration.domain.rbac.WildcardReadsTestCase"
FILE,WFCORE,WFCORE-1214,2015-12-11T23:17:45.000-06:00,header to domain servers,"{blocking-timeout=5;rollback-on-runtime-failure=false}  
 {

[Host Controller] 10:53:40,697 INFO  [stdout] (management-handler-thread - 3)     ""blocking-timeout"" => ""5"",

[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""rollback-on-runtime-failure"" => ""false"",

[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""caller-type"" => ""user"",

[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""access-mechanism"" => ""NATIVE""

[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3) }
add request headers to op not propagate to servers not propagate during domain rollout
add stdout printing be on various processes
[domain@localhost:9990 /] deploy ~/tmp/helloworld.
war --headers={blocking-timeout=5;rollback-on-runtime-failure=false} --all-server-groups
log on HC
[Host Controller] 10:53:40,697 INFO  [stdout] (management-handler-thread - 3) ""composite"" headers:
{
[Host Controller] 10:53:40,697 INFO  [stdout] (management-handler-thread - 3)     ""blocking-timeout"" => ""5"",
[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""rollback-on-runtime-failure"" => ""false"",
[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""caller-type"" => ""user"",
[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3)     ""access-mechanism"" => ""NATIVE""
[Host Controller] 10:53:40,698 INFO  [stdout] (management-handler-thread - 3) }
[Host Controller] 10:53:40,727 INFO  [org.jboss.as.repository] (management-handler-thread - 3) WFLYDR0001: Content added at location /Users/bstansberry/dev/wildfly/wildfly-core/dist/target/wildfly-core-2.0.5.
Final-SNAPSHOT/domain/data/content/6f/cd9eae343ed6d5aa9fffa83012d155b1ef911c/content
[Server:server-one] 10:53:40,772 INFO  [stdout] (ServerService Thread Pool  11) ""composite"" headers: null
[Server:server-two] 10:53:40,772 INFO  [stdout] (ServerService Thread Pool  11) ""composite"" headers: null
The HC logs, then the servers report.
The user-specified headers are not included.
Invoke the same op without the batch and this is logged:
[Host Controller] 10:43:50,400 INFO  [stdout] (management-handler-thread - 4) ""composite"" headers: {
[Host Controller] 10:43:50,401 INFO  [stdout] (management-handler-thread - 4)     ""blocking-timeout"" => ""5"",
[Host Controller] 10:43:50,401 INFO  [stdout] (management-handler-thread - 4)     ""rollback-on-runtime-failure"" => ""false"",
[Host Controller] 10:43:50,401 INFO  [stdout] (management-handler-thread - 4)     ""caller-type"" => ""user"",
[Host Controller] 10:43:50,401 INFO  [stdout] (management-handler-thread - 4)     ""access-mechanism"" => ""NATIVE""
[Host Controller] 10:43:50,401 INFO  [stdout] (management-handler-thread - 4) }
[Host Controller] 10:43:50,425 INFO  [org.jboss.as.repository] (management-handler-thread - 4) WFLYDR0001: Content added at location /Users/bstansberry/dev/wildfly/wildfly-core/dist/target/wildfly-core-2.0.5.
Final-SNAPSHOT/domain/data/content/6f/cd9eae343ed6d5aa9fffa83012d155b1ef911c/content
[Server:server-two] 10:43:50,464 INFO  [stdout] (ServerService Thread Pool -- 11) ""composite"" headers: {
[Server:server-two] 10:43:50,464 INFO  [stdout] (ServerService Thread Pool -- 11)     ""blocking-timeout"" => ""5"",
[Server:server-two] 10:43:50,464 INFO  [stdout] (ServerService Thread Pool -- 11)     ""rollback-on-runtime-failure"" => ""false"",
[Server:server-one] 10:43:50,464 INFO  [stdout] (ServerService Thread Pool -- 11) ""composite"" headers: {
[Server:server-two] 10:43:50,464 INFO  [stdout] (ServerService Thread Pool -- 11)     ""access-mechanism"" => ""NATIVE"",
[Server:server-one] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11)     ""blocking-timeout"" => ""5"",
[Server:server-two] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11)     ""domain-uuid"" => ""216d2e99-dba5-4c89-8020-b0c16bd553c5""
[Server:server-one] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11)     ""rollback-on-runtime-failure"" => ""false"",
[Server:server-two] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11) }
[Server:server-one] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11)     ""access-mechanism"" => ""NATIVE"",
[Server:server-one] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11)     ""domain-uuid"" => ""216d2e99-dba5-4c89-8020-b0c16bd553c5""
[Server:server-one] 10:43:50,465 INFO  [stdout] (ServerService Thread Pool -- 11) }
Expected headers are present.
note deploy
involve use among other places involve use of composite","org.jboss.as.domain.controller.operations.coordination.DomainRolloutStepHandler
org.jboss.as.domain.controller.operations.coordination.OperationCoordinatorStepHandler"
FILE,WFCORE,WFCORE-701,2015-05-19T15:06:17.000-05:00,report between server-config resource report between server resource,"attribute(name=status)




 {




    ""outcome"" => ""success"",




    ""result"" => ""FAILED""




}




  attribute(name=server-state)




 {




    ""outcome"" => ""success"",




    ""result"" => ""STOPPED""




}
fail in way
run domain.sh find pid of server process kill <thepid>
[domain@localhost:9990 /] /host=master/server-config=server-two:read-attribute(name=status)
{
""outcome"" => ""success"",
""result"" => ""FAILED""
}
[domain@localhost:9990 /] /host=master/server=server-two:read-attribute(name=server-state)
{
""outcome"" => ""success"",
""result"" => ""STOPPED""
}",org.jboss.as.host.controller.ManagedServer
FILE,WFCORE,WFCORE-1570,2016-05-27T12:51:56.000-05:00,save name id attribute discrepancy,"group(rolling-to-servers=false,max-failed-servers=1)  group(rolling-to-servers=true,max-failure-percentage=20)  
 {rollout id=my-rollout-plan}
use rollout plans for EAP deployment scenarios create own named rollout-plan for ease
apply rollout command refer with name
There is minor discrepancy in the way I create and use such rollout plan though.
use command
rollout-plan add --name=my-rollout-plan --content={rollout main-server-group(rolling-to-servers=false,max-failed-servers=1),other-server-group(rolling-to-servers=true,max-failure-percentage=20) rollback-across-groups=true}
see name attribute name rollout plan
use following command
deploy /path/to/test-application.
war --all-server-groups --headers={rollout id=my-rollout-plan}
see id attribute
Note: examples are used from our documentation.
Note: I do not know whether I am missing something but I was not able to retrieve more info how to use rollout header operation in deploy command directly in CLI.","org.jboss.as.cli.parsing.operation.header.RolloutPlanState
org.jboss.as.cli.parsing.operation.header.RolloutPlanHeaderCallbackHandler
org.jboss.as.cli.operation.impl.RolloutPlanCompleter"
FILE,WFCORE,WFCORE-1578,2016-06-07T05:13:13.000-05:00,add local | remote-destination-outbound-socket-binding,"{remote|local} 
   add()




    add(host=localhost,port=8765)




 
   add(socket-binding-ref=http)




 
  
  
     
  
 
  
 {remote|local}
have with particular name
use same name as_of existing socket-binding resource parse configuration
See:
create own socket-binding resource perform own socket-binding resource
/socket-binding-group=standard-sockets/socket-binding=myBinding:add()
/socket-binding-group=standard-sockets/remote-destination-outbound-socket-binding=myBinding:add(host=localhost,port=8765)
or
/socket-binding-group=standard-sockets/local-destination-outbound-socket-binding=myBinding:add(socket-binding-ref=http)
reload
crash with following stacktrace
17:31:40,447 INFO  [org.jboss.as.connector.deployers.jdbc] (MSC service thread 1-7) WFLYJCA0019: Stopped Driver service with driver-name = h2
17:31:40,453 INFO  [org.wildfly.extension.undertow] (MSC service thread 1-8) WFLYUT0008: Undertow HTTP listener default suspending
17:31:40,454 INFO  [org.wildfly.extension.undertow] (MSC service thread 1-8) WFLYUT0007: Undertow HTTP listener default stopped, was bound to 127.0.0.1:8080
17:31:40,454 INFO  [org.wildfly.extension.undertow] (MSC service thread 1-3) WFLYUT0004: Undertow 1.3.21.Final-redhat-1 stopping
17:31:40,458 INFO  [org.jboss.as.mail.extension] (MSC service thread 1-7) WFLYMAIL0002: Unbound mail session [java:jboss/mail/Default]
17:31:40,461 INFO  [org.jboss.as] (MSC service thread 1-5) WFLYSRV0050: JBoss EAP 7.0.0.
GA (WildFly Core 2.1.2.Final-redhat-1) stopped in 22ms
17:31:40,461 INFO  [org.jboss.as] (MSC service thread 1-5) WFLYSRV0049: JBoss EAP 7.0.0.
GA (WildFly Core 2.1.2.Final-redhat-1) starting
17:31:40,489 ERROR [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0055: Caught exception during boot: org.jboss.as.controller.persistence.ConfigurationPersistenceException: WFLYCTL0085: Failed to parse configuration
at org.jboss.as.controller.persistence.XmlConfigurationPersister.load(XmlConfigurationPersister.java:131)
at org.jboss.as.server.ServerService.boot(ServerService.java:356)
at org.jboss.as.controller.AbstractControllerService$1.run(AbstractControllerService.java:299)
at java.lang.Thread.run(Thread.java:745)
Caused by: javax.xml.stream.XMLStreamException: ParseError at [row,col]:[410,9]
Message: WFLYCTL0042: A socket-binding or a outbound-socket-binding myBinding already declared has already been declared in socket-binding-group standard-sockets
at org.jboss.as.server.parsing.StandaloneXml_4.
parseSocketBindingGroup(StandaloneXml_4.java:518)
at org.jboss.as.server.parsing.StandaloneXml_4.
readServerElement(StandaloneXml_4.java:254)
at org.jboss.as.server.parsing.StandaloneXml_4.
readElement(StandaloneXml_4.java:141)
at org.jboss.as.server.parsing.StandaloneXml.readElement(StandaloneXml.java:103)
at org.jboss.as.server.parsing.StandaloneXml.readElement(StandaloneXml.java:49)
at org.jboss.staxmapper.XMLMapperImpl.processNested(XMLMapperImpl.java:110)
at org.jboss.staxmapper.XMLMapperImpl.parseDocument(XMLMapperImpl.java:69)
at org.jboss.as.controller.persistence.XmlConfigurationPersister.load(XmlConfigurationPersister.java:123)
... 3 more
17:31:40,490 FATAL [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0056: Server boot has failed in an unrecoverable manner; exiting.
See previous messages for details.
17:31:40,491 INFO  [org.jboss.as.server] (Thread-2) WFLYSRV0220: Server shutdown has been requested.
17:31:40,496 INFO  [org.jboss.as] (MSC service thread 1-2) WFLYSRV0050: JBoss EAP 7.0.0.
GA (WildFly Core 2.1.2.Final-redhat-1) stopped in 3ms
After this occurs, one needs to fix .
/standalone/configuration/standalone.xml manually by removing duplicate resources.
Note: not sure whether CLI component is appropriate, please change if there is better component for this.","org.jboss.as.controller.logging.ControllerLogger
org.jboss.as.server.services.net.LocalDestinationOutboundSocketBindingAddHandler
org.jboss.as.server.services.net.SocketBindingAddHandler
org.jboss.as.server.services.net.RemoteDestinationOutboundSocketBindingAddHandler"
FILE,WFCORE,WFCORE-1635,2016-07-05T07:04:51.000-05:00,fail in batch,"add(path=log, relative-to=""jboss.server.base.dir"", auto-deploy-exploded=false, scan-enabled=false)




  attribute(name=scan-interval, value=6000)




 
 
 add(path=log, relative-to=""jboss.server.base.dir"", auto-deploy-exploded=false, scan-enabled=false)




  attribute(name=scan-interval, value=6000)
create new deployment-scanner alter attribute do in single batch
run commands without batch run batch on CLI embed-server
reproduce
batch
/subsystem=deployment-scanner/scanner=scan:add(path=log, relative-to=""jboss.server.base.dir"", auto-deploy-exploded=false, scan-enabled=false)
/subsystem=deployment-scanner/scanner=scan:write-attribute(name=scan-interval, value=6000)
run-batch
fails with
08:09:19,076 ERROR [org.jboss.as.controller.management-operation] (management-handler-thread - 4) WFLYCTL0013: Operation (""write-attribute"") failed - address: ([
(""subsystem"" => ""deployment-scanner""),
(""scanner"" => ""scan"")
]): java.lang.IllegalStateException
at org.jboss.as.server.deployment.scanner.DeploymentScannerService.getValue(DeploymentScannerService.java:234)
at org.jboss.as.server.deployment.scanner.DeploymentScannerService.getValue(DeploymentScannerService.java:62)
at org.jboss.msc.service.ServiceControllerImpl.getValue(ServiceControllerImpl.java:1158)
at org.jboss.as.controller.OperationContextImpl$OperationContextServiceController.getValue(OperationContextImpl.java:2282)
at org.jboss.as.server.deployment.scanner.AbstractWriteAttributeHandler.applyUpdateToRuntime(AbstractWriteAttributeHandler.java:58)
at org.jboss.as.controller.AbstractWriteAttributeHandler$1.execute(AbstractWriteAttributeHandler.java:104)
at org.jboss.as.controller.AbstractOperationContext.executeStep(AbstractOperationContext.java:890)
at org.jboss.as.controller.AbstractOperationContext.processStages(AbstractOperationContext.java:659)
at org.jboss.as.controller.AbstractOperationContext.executeOperation(AbstractOperationContext.java:370)
at org.jboss.as.controller.OperationContextImpl.executeOperation(OperationContextImpl.java:1344)
at org.jboss.as.controller.ModelControllerImpl.internalExecute(ModelControllerImpl.java:392)
at org.jboss.as.controller.ModelControllerImpl.execute(ModelControllerImpl.java:217)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler.doExecute(ModelControllerClientOperationHandler.java:208)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler.access$300(ModelControllerClientOperationHandler.java:130)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler$1$1.run(ModelControllerClientOperationHandler.java:152)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler$1$1.run(ModelControllerClientOperationHandler.java:148)
at java.security.AccessController.doPrivileged(AccessController.java:686)
at javax.security.auth.Subject.doAs(Subject.java:569)
at org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:92)
at org.jboss.as.controller.remote.ModelControllerClientOperationHandler$ExecuteRequestHandler$1.execute(ModelControllerClientOperationHandler.java:148)
at org.jboss.as.protocol.mgmt.AbstractMessageHandler$ManagementRequestContextImpl$1.doExecute(AbstractMessageHandler.java:363)
at org.jboss.as.protocol.mgmt.AbstractMessageHandler$AsyncTaskRunner.run(AbstractMessageHandler.java:472)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at java.lang.Thread.run(Thread.java:785)
at org.jboss.threads.JBossThread.run(JBossThread.java:320)
using the embed server works
embed-server
batch
/subsystem=deployment-scanner/scanner=scan:add(path=log, relative-to=""jboss.server.base.dir"", auto-deploy-exploded=false, scan-enabled=false)
/subsystem=deployment-scanner/scanner=scan:write-attribute(name=scan-interval, value=6000)
run-batch
Setting only as minor as there is no real use case behind this (scan-interval can be set while adding a new scanner) - run into it quite accidentally.
No regression against previous release.",org.jboss.as.server.deployment.scanner.AbstractWriteAttributeHandler
FILE,WFCORE,WFCORE-1590,2016-06-12T14:18:43.000-05:00,ignore setMinSize(0),"static final SimpleAttributeDefinition REPLACEMENT = new SimpleAttributeDefinitionBuilder(ElytronDescriptionConstants.REPLACEMENT, ModelType.STRING, false)




        .setAllowExpression(true)




        .setMinSize(0)




        .setFlags(AttributeAccess.Flag.RESTART_RESOURCE_SERVICES)




        .build();






 
 add(pattern=""@ELYTRON.ORG"", replacement="""", replace-all=true)
static final SimpleAttributeDefinition REPLACEMENT = new SimpleAttributeDefinitionBuilder(ElytronDescriptionConstants.REPLACEMENT, ModelType.STRING, false)
.
setAllowExpression(true)
.
setMinSize(0)
.
setFlags(AttributeAccess.Flag.RESTART_RESOURCE_SERVICES)
.
build();
use empty string as parameter
[standalone@localhost:9990 /] .
/subsystem=elytron/regex-name-rewriter=strip-realm:add(pattern=""@ELYTRON.
ORG"", replacement="""", replace-all=true)
{
""outcome"" => ""failed"",
""failure-description"" => ""WFLYCTL0113: '' is an invalid value for parameter replacement.
Values must have a minimum length of 1 characters"",
""rolled-back"" => true
}","org.jboss.as.controller.operations.validation.BytesValidator
org.jboss.as.controller.SimpleAttributeDefinitionUnitTestCase
org.jboss.as.controller.test.WriteAttributeOperationTestCase
org.jboss.as.controller.AbstractAttributeDefinitionBuilder
org.jboss.as.controller.AttributeDefinition"
FILE,WFCORE,WFCORE-1765,2016-09-05T16:22:02.000-05:00,remove deployment-scanner element from configuration,"{xml}
         {xml}
not show hint remove deployment scanner element from configuration
Config:
{xml}
<subsystem xmlns=""urn:jboss:domain:deployment-scanner:2.0"">
<!-- deployment-scanner path=""deployments"" relative-to=""jboss.server.base.dir"" scan-interval=""5000"" runtime-failure-causes-rollback=""${jboss.deployment.scanner.rollback.on.failure:false}""/ -->
</subsystem>{xml}
ERROR [org.jboss.as.controller.management-operation] (ServerService Thread Pool  34) WFLYCTL0403: Unexpected failure during execution of the following operation(s): []: java.lang.NullPointerException
at org.jboss.as.controller.AbstractOperationContext$Step.access$300(AbstractOperationContext.java:1185)
at org.jboss.as.controller.AbstractOperationContext.executeResultHandlerPhase(AbstractOperationContext.java:767)
at org.jboss.as.controller.AbstractOperationContext.executeDoneStage(AbstractOperationContext.java:753)
at org.jboss.as.controller.AbstractOperationContext.processStages(AbstractOperationContext.java:680)
at org.jboss.as.controller.AbstractOperationContext.executeOperation(AbstractOperationContext.java:370)
at org.jboss.as.controller.ParallelBootOperationStepHandler$ParallelBootTask.run(ParallelBootOperationStepHandler.java:359)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at java.lang.Thread.run(Thread.java:745)
at org.jboss.threads.JBossThread.run(JBossThread.java:320)",org.jboss.as.controller.ParallelBootOperationStepHandler
FILE,WFCORE,WFCORE-1793,2016-09-14T08:08:21.000-05:00,overwrite existing content with overwrite = true pass content by file path,"{""outcome"" => ""success""}




 
 {""outcome"" => ""success""}




 
 {""outcome"" => ""success""}




  {path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt} 
  
 {path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt} 
  
 {path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt}
overwrite content in managed exploded deployments produce following errors upon overwriting
CLI
[standalone@localhost:9990 /] deploy /home/mjurc/testing/eap7-204/jboss-kitchensink-ear.
ear
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:undeploy
{""outcome"" => ""success""}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:explode
{""outcome"" => ""success""}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:deploy
{""outcome"" => ""success""}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:add-content(content=[{path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt}], overwrite=true)
{
""outcome"" => ""failed"",
""failure-description"" => ""org.jboss.as.repository.ExplodedContentException: WFLYDR0021: Error updating content of exploded deployment"",
""rolled-back"" => true
}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:add-content(content=[{path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt}], overwrite=false)
{
""outcome"" => ""failed"",
""failure-description"" => ""org.jboss.as.repository.ExplodedContentException: WFLYDR0021: Error updating content of exploded deployment"",
""rolled-back"" => true
}
[standalone@localhost:9990 /] /deployment=jboss-kitchensink-ear.
ear:add-content(content=[{path=/home/mjurc/testing/eap7-204/test.txt, target-path=test.txt}])
{
""outcome"" => ""failed"",
""failure-description"" => ""org.jboss.as.repository.ExplodedContentException: WFLYDR0021: Error updating content of exploded deployment"",
""rolled-back"" => true
}
Server
09:41:36,029 WARN  [org.jboss.as.repository] (management-handler-thread - 5) java.nio.file.FileAlreadyExistsException: /home/mjurc/testing/wildfly-core/build/target/wildfly-core-3.0.0.
Alpha8-SNAPSHOT/standalone/data/content/content7797527203290314566/content/test.txt
09:45:27,505 WARN  [org.jboss.as.repository] (management-handler-thread - 12) java.nio.file.FileAlreadyExistsException: /home/mjurc/testing/wildfly-core/build/target/wildfly-core-3.0.0.
Alpha8-SNAPSHOT/standalone/data/content/content721393778736298367/content/test.txt
09:45:36,352 WARN  [org.jboss.as.repository] (management-handler-thread - 10) java.nio.file.FileAlreadyExistsException: /home/mjurc/testing/wildfly-core/build/target/wildfly-core-3.0.0.
Alpha8-SNAPSHOT/standalone/data/content/content344811471223714239/content/test.txt
This issue does not seem to arise when the content is passed to the server by input stream index.","org.jboss.as.server.controller.resources.DeploymentAttributes
org.jboss.as.server.deployment.ExplodedDeploymentAddContentHandler"
FILE,WFCORE,WFCORE-1864,2016-10-13T09:12:31.000-05:00,add command not remove whitespaces from dependencies,"{{
...
    <dependencies>
        <module name=""org.a""/>
        <module name="" org.b ""/>
    </dependencies>
...
}}
run module add for running result in following dependencies
{{
...
<dependencies>
<module name=""org.a""/>
<module name="" org.b ""/>
</dependencies>
...
}}","org.jboss.as.cli.handlers.module.ASModuleHandler
org.jboss.as.test.integration.management.cli.ModuleTestCase"
FILE,WFCORE,WFCORE-1908,2016-10-31T08:13:57.000-05:00,write attribute have access type metric have attribute,"attribute(name=message-count, value=5)




 {




    ""outcome"" => ""failed"",




    ""failure-description"" => ""WFLYCTL0048: Attribute message-count is not writable"",




    ""rolled-back"" => true




}
suggest attributes
/subsystem=messaging-activemq/server=default/jms-queue=DLQ:write-attribute(name=<TAB>
consumer-count  delivering-count  entries  legacy-entries  message-count  messages-added  scheduled-count
From executing :read-resource-description we can see, attributes consumer-count, delivering-count, message-count, messages-added, scheduled-count are of type metric.
write metric attribute for example message-count print non writable error on attempt
[standalone@localhost:9990 jms-queue=q] :write-attribute(name=message-count, value=5)
{
""outcome"" => ""failed"",
""failure-description"" => ""WFLYCTL0048: Attribute message-count is not writable"",
""rolled-back"" => true
}","org.jboss.as.cli.impl.AttributeNamePathCompleter
org.jboss.as.cli.parsing.test.AttributeNamePathCompletionTestCase
org.jboss.as.cli.Util"
FILE,WFCORE,WFCORE-1936,2016-11-04T10:57:06.000-05:00,not match reality for socket-binding not match reality for *,"description(recursive=true)
But reality is different.
change such attributes
The attributes are defined as ""restart-required"" => ""no-services"", see /socket-binding-group=standard-sockets:read-resource-description(recursive=true)","org.jboss.as.server.services.net.OutboundSocketBindingResourceDefinition
org.jboss.as.controller.resource.AbstractSocketBindingResourceDefinition"
FILE,WFCORE,WFCORE-1959,2016-11-08T16:28:30.000-06:00,deploy empty managed exploded deployment in domain deploy empty managed exploded deployment to server group,"{empty=true} 
 add()
create on domain controller fail with following
[domain@localhost:9990 /] /deployment=empty-deployment.jar:add(content=[{empty=true}])
{
""outcome"" => ""success"",
""result"" => undefined,
""server-groups"" => undefined
}
[domain@localhost:9990 /] /server-group=main-server-group/deployment=empty-deployment.jar:add()
{
""outcome"" => ""failed"",
""result"" => undefined,
""failure-description"" => {""WFLYDC0074: Operation failed or was rolled back on all servers.
Server failures:"" => {""server-group"" => {""main-server-group"" => {""host"" => {""master"" => {
""server-one"" => ""WFLYSRV0201: Cannot have more than one of [bytes, input-stream-index, hash, url, empty]"",
""server-two"" => ""WFLYSRV0201: Cannot have more than one of [bytes, input-stream-index, hash, url, empty]""
}}}}}},
""rolled-back"" => true,
""server-groups"" => {""main-server-group"" => {""host"" => {""master"" => {
""server-one"" => {""response"" => {
""outcome"" => ""failed"",
""failure-description"" => ""WFLYSRV0201: Cannot have more than one of [bytes, input-stream-index, hash, url, empty]"",
""rolled-back"" => true
}},
""server-two"" => {""response"" => {
""outcome"" => ""failed"",
""failure-description"" => ""WFLYSRV0201: Cannot have more than one of [bytes, input-stream-index, hash, url, empty]"",
""rolled-back"" => true
}}
}}}}
}",org.jboss.as.domain.controller.operations.coordination.ServerOperationResolver
METHOD,atunes-1.10.0,231,2008-10-04T18:31:26.000-05:00,not add image read repository,"public boolean isSupportsInternalImage()
How to reproduce:
read by older version
add image
Result:
Problem:
return false never set to true",net.sourceforge.atunes.kernel.modules.repository.audio.AudioFile:supportsInternalPicture()
CLASS,solr-4.4.0,SOLR-5295,2013-10-02T00:09:02.000-05:00,create maxShardsPerNode number of replicas,"{quote}
 
  
  
  
 {quote}
As reported by Brett Hoerner on solr-user:
http://www.mail-archive.com/solr-user@lucene.apache.org/msg89545.html
{quote}
It seems that changes in 4.5 collection configuration now require users to set a maxShardsPerNode (or it defaults to 1).
Maybe this was the case before, but with the new CREATESHARD API it seems a very restrictive.
create simple test collection on machines set maxShardsPerNode at collection creation time set machines at collection creation time
make shards
Everything is good.
Now I want a 4th shard, it seems impossible to create because the cluster
""knows"" I should only have 1 shard per node.
Yet my problem doesn't require more hardware, I just my new shard to exist on one of the existing servers.
create collection with shards set maxShardsPerNode
Everything is good.
add replicas
{quote}",solr.core.src.java.org.apache.solr.cloud.OverseerCollectionProcessor
CLASS,solr-4.4.0,SOLR-5296,2013-10-02T00:20:01.000-05:00,create collection with implicit router add shard ranges to shard,"{quote}
 {quote}
create collection with implicit router add shard ranges to shard
use Example a from SolrCloud wiki
http://localhost:8983/solr/admin/collections?action=CREATE&name=myimplicitcollection3&numShards=2&maxShardsPerNode=5&router.name=implicit&shards=s1,s2&replicationFactor=2
{quote}
""myimplicitcollection3"":{
""shards"":{
""s1"":{
""range"":""80000000-ffffffff"",
""state"":""active"",
""replicas"":{
""core_node1"":{
""state"":""active"",
""base_url"":""http://192.168.1.5:8983/solr"",
""core"":""myimplicitcollection3_s1_replica2"",
""node_name"":""192.168.1.5:8983_solr""},
""core_node3"":{
""state"":""active"",
""base_url"":""http://192.168.1.5:7574/solr"",
""core"":""myimplicitcollection3_s1_replica1"",
""node_name"":""192.168.1.5:7574_solr"",
""leader"":""true""}}},
""s2"":{
""range"":""0-7fffffff"",
""state"":""active"",
""replicas"":{
""core_node2"":{
""state"":""active"",
""base_url"":""http://192.168.1.5:8983/solr"",
""core"":""myimplicitcollection3_s2_replica2"",
""node_name"":""192.168.1.5:8983_solr""},
""core_node4"":{
""state"":""active"",
""base_url"":""http://192.168.1.5:7574/solr"",
""core"":""myimplicitcollection3_s2_replica1"",
""node_name"":""192.168.1.5:7574_solr"",
""leader"":""true""}}}},
""maxShardsPerNode"":""5"",
""router"":{""name"":""implicit""},
""replicationFactor"":""2""}
{quote}
do right thing",solr.core.src.java.org.apache.solr.cloud.Overseer
FILE,AMQP,AMQP-190,2011-09-10T20:24:17.000-05:00,synchronize with TransactionManager,"convertAndSend()
use RabbitTemplate to exchange use RabbitTemplate to convertAndSend() get own "" shiny new channel not handle more channels
See Forum Reference for more info.
The problem is not observed on the consumer side (e.g. MessageListenerContainer).
Its observed on the publishing side, (e.g. RabbitTemplate).
It is observed both if I use the RabbitTemplate, natively... or if I use spring-integration and the <int-amqp:outbound-channel-adapter...> tag.
BTW, the observed ""channel leak"" goes away when I choose channelTransacted=false.
I will look to supply a simple recreate, if I can scrounge the time.","org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer
org.springframework.amqp.rabbit.core.RabbitTemplatePerformanceIntegrationTests
org.springframework.amqp.rabbit.connection.ConnectionFactoryUtils
org.springframework.amqp.rabbit.connection.RabbitResourceHolder"
FILE,AMQP,AMQP-502,2015-06-19T03:02:33.000-05:00,route key not create fanout binding due_to missing,"@RabbitListener(




      bindings = @QueueBinding(




          value = @Queue(




              autoDelete = ""true""




          ),




          exchange = @Exchange(




              type = ""fanout"",




              value = ""mytest.broadcast"",




              autoDelete = ""true""




          ),




          key = ""#""




      )




  )




  public void processBroadcast(String data) {




    int i = 0;




  }






 
  
  
  
     
 
     
 
  
  
  
  
  
   {}   
     
 
     
 
     
 
  
     
 
     
 
     
 
     
 
     
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   {}   
  
     
 
      
   {}
use spring-cloud-starter-bus-amqp reference spring-amqp 1.4.3 in terms reference spring-cloud-starter-bus-amqp in terms
declare rabbitlistener
@RabbitListener(
bindings = @QueueBinding(
value = @Queue(
autoDelete = ""true""
),
exchange = @Exchange(
type = ""fanout"",
value = ""mytest.broadcast"",
autoDelete = ""true""
),
key = ""#""
)
)
public void processBroadcast(String data) {
int i = 0;
}
get error
If i try another exchange type, the binding works.
Edit: It also does not work if omit the key.
11:53:20.977 DEBUG   org.springframework.amqp.rabbit.core.RabbitAdmin - Initializing declarations
11:53:20.980  INFO   org.springframework.amqp.rabbit.core.RabbitAdmin - Auto-declaring a non-durable or auto-delete Exchange (mytest.broadcast) durable:false, auto-delete:true.
It will be deleted by the broker if it shuts down, and can be redeclared by closing and reopening the connection.
11:53:20.980  INFO   org.springframework.amqp.rabbit.core.RabbitAdmin - Auto-declaring a non-durable, auto-delete, or exclusive Queue (5df237ec-13d4-4aab-a0ff-772707bd7d03) durable:false, auto-delete:false, exclusive:true.
It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost.
11:53:20.982 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Creating cached Rabbit Channel from AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:20.982 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Executing callback on RabbitMQ Channel: Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:20.982 DEBUG   org.springframework.amqp.rabbit.core.RabbitAdmin - declaring Exchange 'mytest.broadcast'
11:53:20.984 DEBUG   org.springframework.amqp.rabbit.core.RabbitAdmin - declaring Queue '5df237ec-13d4-4aab-a0ff-772707bd7d03'
11:53:20.989 DEBUG   org.springframework.amqp.rabbit.core.RabbitAdmin - Binding destination [5df237ec-13d4-4aab-a0ff-772707bd7d03 (QUEUE)] to exchange [mytest.broadcast] with routing key [null]
11:53:20.991 DEBUG    o.s.a.r.listener.SimpleMessageListenerContainer - Recovering consumer in 5000 ms.
11:53:20.991 DEBUG    o.s.a.r.listener.SimpleMessageListenerContainer - Starting Rabbit listener container.
11:53:20.992 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Starting consumer Consumer: tags=[{}], channel=null, acknowledgeMode=AUTO local queue size=0
11:53:20.998 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Started on queue '5df237ec-13d4-4aab-a0ff-772707bd7d03' with tag amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA: Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:20.998 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - ConsumeOK : Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:20.999 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:21.093  INFO             mytest.server.Server - Started Server in 16.957 seconds (JVM running for 18.151)
11:53:22.003 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:23.004 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:24.009 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:25.013 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:26.017 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:26.071  WARN    o.s.a.r.listener.SimpleMessageListenerContainer - Consumer raised exception, processing can restart if the connection factory supports it
org.springframework.amqp.UncategorizedAmqpException: java.lang.IllegalStateException: Invalid configuration: 'routingKey' must be non-null.
at org.springframework.amqp.rabbit.support.RabbitExceptionTranslator.convertRabbitAccessException(RabbitExceptionTranslator.java:66) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.RabbitAccessor.convertRabbitAccessException(RabbitAccessor.java:110) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitTemplate.doExecute(RabbitTemplate.java:1124) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:1101) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:1077) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitAdmin.initialize(RabbitAdmin.java:381) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitAdmin$11.onCreate(RabbitAdmin.java:323) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.CompositeConnectionListener.onCreate(CompositeConnectionListener.java:32) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.createConnection(CachingConnectionFactory.java:446) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.ConnectionFactoryUtils$1.createConnection(ConnectionFactoryUtils.java:80) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.ConnectionFactoryUtils.doGetTransactionalResourceHolder(ConnectionFactoryUtils.java:130) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.connection.ConnectionFactoryUtils.getTransactionalResourceHolder(ConnectionFactoryUtils.java:67) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.start(BlockingQueueConsumer.java:451) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1107) ~[spring-rabbit-1.5.0.M1.jar:na]
at java.lang.Thread.run(Thread.java:745) [na:1.8.0_20-ea]
Caused by: java.lang.IllegalStateException: Invalid configuration: 'routingKey' must be non-null.
at com.rabbitmq.client.impl.AMQImpl$Queue$Bind.<init>(AMQImpl.java:1577) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.AMQP$Queue$Bind$Builder.build(AMQP.java:870) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueBind(ChannelN.java:918) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueBind(ChannelN.java:61) ~[amqp-client-3.5.1.jar:na]
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_20-ea]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_20-ea]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_20-ea]
at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_20-ea]
at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:633) ~[spring-rabbit-1.5.0.M1.jar:na]
at com.sun.proxy.$Proxy0.queueBind(Unknown Source) ~[na:na]
at org.springframework.amqp.rabbit.core.RabbitAdmin.declareBindings(RabbitAdmin.java:480) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitAdmin.access$300(RabbitAdmin.java:54) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitAdmin$12.doInRabbit(RabbitAdmin.java:386) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.core.RabbitTemplate.doExecute(RabbitTemplate.java:1118) ~[spring-rabbit-1.5.0.M1.jar:na]
... 12 common frames omitted
11:53:26.071  INFO    o.s.a.r.listener.SimpleMessageListenerContainer - Restarting Consumer: tags=[{}], channel=null, acknowledgeMode=AUTO local queue size=0
11:53:26.071 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Closing Rabbit Channel: null
11:53:26.072 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Executing callback on RabbitMQ Channel: Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:26.072 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Publishing message on exchange [errors], routingKey = [org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.WARN]
11:53:26.072 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Starting consumer Consumer: tags=[{}], channel=null, acknowledgeMode=AUTO local queue size=0
11:53:26.075 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Creating cached Rabbit Channel from AMQChannel(amqp://stinger@10.0.10.34:5672/,2)
11:53:26.077 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
11:53:26.079 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Detected closed channel on exception.
Re-initializing: null
11:53:26.080  WARN     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Failed to declare queue:493eb6d6-8340-44a8-b73f-ab93446407dc
11:53:26.081 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Executing callback on RabbitMQ Channel: Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:26.081 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Publishing message on exchange [errors], routingKey = [org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.WARN]
11:53:26.081  WARN     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Queue declaration failed; retries left=3
org.springframework.amqp.rabbit.listener.BlockingQueueConsumer$DeclarationException: Failed to declare queue(s):[493eb6d6-8340-44a8-b73f-ab93446407dc]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:554) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.start(BlockingQueueConsumer.java:465) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1107) [spring-rabbit-1.5.0.M1.jar:na]
at java.lang.Thread.run(Thread.java:745) [na:1.8.0_20-ea]
Caused by: java.io.IOException: null
at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:106) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:102) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:124) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:873) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:61) ~[amqp-client-3.5.1.jar:na]
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_20-ea]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_20-ea]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_20-ea]
at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_20-ea]
at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:633) ~[spring-rabbit-1.5.0.M1.jar:na]
at com.sun.proxy.$Proxy0.queueDeclarePassive(Unknown Source) ~[na:na]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:544) ~[spring-rabbit-1.5.0.M1.jar:na]
... 3 common frames omitted
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:67) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:33) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:348) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.privateRpc(AMQChannel.java:221) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:118) ~[amqp-client-3.5.1.jar:na]
... 12 common frames omitted
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
at com.rabbitmq.client.impl.ChannelN.asyncShutdown(ChannelN.java:478) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.processAsync(ChannelN.java:315) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.handleCompleteInboundCommand(AMQChannel.java:144) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.handleFrame(AMQChannel.java:91) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:552) ~[amqp-client-3.5.1.jar:na]
... 1 common frames omitted
11:53:26.081 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Executing callback on RabbitMQ Channel: Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:26.081 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Publishing message on exchange [errors], routingKey = [org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.WARN]
11:53:27.018 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:28.022 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:29.025 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:30.030 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:31.034 DEBUG     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Retrieving delivery for Consumer: tags=[{amq.ctag-Gai8Uo2Q0SYYJDbSopNtLA=5df237ec-13d4-4aab-a0ff-772707bd7d03}], channel=Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1), acknowledgeMode=AUTO local queue size=0
11:53:31.086 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Channel shutdown: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
11:53:31.086 DEBUG   o.s.a.rabbit.connection.CachingConnectionFactory - Detected closed channel on exception.
Re-initializing: null
11:53:31.088  WARN     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Failed to declare queue:493eb6d6-8340-44a8-b73f-ab93446407dc
11:53:31.089 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Executing callback on RabbitMQ Channel: Cached Rabbit Channel: AMQChannel(amqp://stinger@10.0.10.34:5672/,1)
11:53:31.089 DEBUG  o.springframework.amqp.rabbit.core.RabbitTemplate - Publishing message on exchange [errors], routingKey = [org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.WARN]
11:53:31.089  WARN     o.s.amqp.rabbit.listener.BlockingQueueConsumer - Queue declaration failed; retries left=2
org.springframework.amqp.rabbit.listener.BlockingQueueConsumer$DeclarationException: Failed to declare queue(s):[493eb6d6-8340-44a8-b73f-ab93446407dc]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:554) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.start(BlockingQueueConsumer.java:465) ~[spring-rabbit-1.5.0.M1.jar:na]
at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1107) [spring-rabbit-1.5.0.M1.jar:na]
at java.lang.Thread.run(Thread.java:745) [na:1.8.0_20-ea]
Caused by: java.io.IOException: null
at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:106) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:102) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:124) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:873) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:61) ~[amqp-client-3.5.1.jar:na]
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_20-ea]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_20-ea]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_20-ea]
at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_20-ea]
at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:633) ~[spring-rabbit-1.5.0.M1.jar:na]
at com.sun.proxy.$Proxy0.queueDeclarePassive(Unknown Source) ~[na:na]
at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:544) ~[spring-rabbit-1.5.0.M1.jar:na]
... 3 common frames omitted
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:67) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:33) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:348) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.privateRpc(AMQChannel.java:221) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:118) ~[amqp-client-3.5.1.jar:na]
... 12 common frames omitted
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method<channel.close>(reply-code=404, reply-text=NOT_FOUND - no queue '493eb6d6-8340-44a8-b73f-ab93446407dc' in vhost '/', class-id=50, method-id=10)
at com.rabbitmq.client.impl.ChannelN.asyncShutdown(ChannelN.java:478) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.ChannelN.processAsync(ChannelN.java:315) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.handleCompleteInboundCommand(AMQChannel.java:144) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQChannel.handleFrame(AMQChannel.java:91) ~[amqp-client-3.5.1.jar:na]
at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:552) ~[amqp-client-3.5.1.jar:na]
... 1 common frames omitted","org.springframework.amqp.rabbit.annotation.EnableRabbitIntegrationTests
org.springframework.amqp.rabbit.annotation.RabbitListenerAnnotationBeanPostProcessor"
FILE,AMQP,AMQP-653,2016-10-08T02:53:08.000-05:00,not take advantage of registered converters,"@Bean




Jackson2JsonMessageConverter jackson2JsonMessageConverter() {




	return new Jackson2JsonMessageConverter();




}
use RabbitTemplate in Spring boot application register Spring AMQP message converter
@Bean
Jackson2JsonMessageConverter jackson2JsonMessageConverter() {
return new Jackson2JsonMessageConverter();
}
look up converters switch to RabbitMessagingTemplate
Looking inside Spring Boot, there doesn't appear to be any wiring that offers to hook up message converters either.","org.springframework.amqp.rabbit.core.RabbitMessagingTemplateTests
org.springframework.amqp.rabbit.core.RabbitMessagingTemplate"
FILE,AMQP,AMQP-656,2016-10-15T00:25:46.000-05:00,use @Argument within @RabbitListener refer to default exchange,"@Argument 
 @RabbitListener(bindings =




        @QueueBinding(




            value = @Queue(




                value = ""app.events.myEvent"",




                durable = ""true"",




                exclusive = ""false"",




                autoDelete = ""false"",




                arguments = {




                        @Argument(name=""x-dead-letter-exchange"", value = """"),




                        @Argument(name=""x-dead-letter-routing-key"", value=""app.dlq"")




                }),




            exchange = @Exchange(value=""amq.topic"", durable = ""true"", type = ""topic""),




            key=""event.app.myEvent.v1""




        ))






 
 @Bean




    public Queue appMyEventQueue() {




        return QueueBuilder.durable(""app.events.myEvent"")




            .withArgument(""x-dead-letter-exchange"", """")




            .withArgument(""x-dead-letter-routing-key"", deadLetterQueue().getName())




            .build();




    }
use @Argument annotations refer to default exchange
configure queue use default exchange as part
@RabbitListener(bindings =
@QueueBinding(
value = @Queue(
value = ""app.events.myEvent"",
durable = ""true"",
exclusive = ""false"",
autoDelete = ""false"",
arguments = {
@Argument(name=""x-dead-letter-exchange"", value = """"),
@Argument(name=""x-dead-letter-routing-key"", value=""app.dlq"")
}),
exchange = @Exchange(value=""amq.topic"", durable = ""true"", type = ""topic""),
key=""event.app.myEvent.v1""
))
not send empty string
I tried being creative with using things like SPEL that would evaluate to an empty string, but same result.
If I use bean configs I am able to get the configuration I want using something like the following, the issue is just with the annotation based config.
@Bean
public Queue appMyEventQueue() {
return QueueBuilder.durable(""app.events.myEvent"")
.
withArgument(""x-dead-letter-exchange"", """")
.
withArgument(""x-dead-letter-routing-key"", deadLetterQueue().
getName())
.
build();
}","org.springframework.amqp.rabbit.annotation.EnableRabbitIntegrationTests
org.springframework.amqp.rabbit.annotation.RabbitListenerAnnotationBeanPostProcessor"
FILE,DATACMNS,DATACMNS-157,2012-04-20T01:24:38.000-05:00,extend interface,"@Query 
 @NoRepositoryBean




public interface EntityRepository<T> extends JpaRepository<T, Long> {









	T findByDealer(Dealer dealer);




}









 public interface CarRepository extends EntityRepository<PersonalSiteVehicle> {









	@Override




	@Query(""select p from PersonalSiteVehicle p join p.detail d join d.enrichable e where e.dealer = ?1"")




	PersonalSiteVehicle findByDealer(Dealer dealer);




}






 
  @Query
define interface method in super repository interface implement in extending interface
This does not work.
@NoRepositoryBean
public interface EntityRepository<T> extends JpaRepository<T, Long> {
T findByDealer(Dealer dealer);
}
public interface CarRepository extends EntityRepository<PersonalSiteVehicle> {
@Override
@Query(""select p from PersonalSiteVehicle p join p.detail d join d.enrichable e where e.dealer = ?
1"")
PersonalSiteVehicle findByDealer(Dealer dealer);
}
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'carRepository': FactoryBean threw exception on object creation; nested exception is java.lang.IllegalArgumentException: Could not create query metamodel for method public abstract java.lang.Object nl.inmotiv.indi.repository.EntityRepository.findByDealer(nl.inmotiv.indi.domain.Dealer)!
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:149)
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:102)
at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1442)
at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:248)
at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:848)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:790)
at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:707)
at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:478)
... 32 more
Caused by: java.lang.IllegalArgumentException: Could not create query metamodel for method public abstract java.lang.Object nl.inmotiv.indi.repository.EntityRepository.findByDealer(nl.inmotiv.indi.domain.Dealer)!
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:95)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateIfNotFoundQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:164)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$AbstractQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:71)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.<init>(RepositoryFactorySupport.java:269)
at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:142)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:114)
at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.getObject(RepositoryFactoryBeanSupport.java:38)
at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:142)
... 40 more
Caused by: java.lang.IllegalArgumentException: No property dealer found for type class nl.inmotiv.indi.domain.PersonalSiteVehicle
at org.springframework.data.mapping.PropertyPath.<init>(PropertyPath.java:73)
at org.springframework.data.mapping.PropertyPath.<init>(PropertyPath.java:92)
at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:319)
at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:301)
at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:265)
at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:239)
at org.springframework.data.repository.query.parser.Part.<init>(Part.java:70)
at org.springframework.data.repository.query.parser.PartTree$OrPart.<init>(PartTree.java:180)
at org.springframework.data.repository.query.parser.PartTree$Predicate.buildTree(PartTree.java:260)
at org.springframework.data.repository.query.parser.PartTree$Predicate.<init>(PartTree.java:240)
at org.springframework.data.repository.query.parser.PartTree.<init>(PartTree.java:71)
at org.springframework.data.jpa.repository.query.PartTreeJpaQuery.<init>(PartTreeJpaQuery.java:57)
at org.springframework.data.jpa.repository.query.JpaQueryLookupStrategy$CreateQueryLookupStrategy.resolveQuery(JpaQueryLookupStrategy.java:93)
not use @Query annotation in sub interface","org.springframework.data.repository.core.support.DefaultRepositoryInformationUnitTests
org.springframework.data.repository.core.support.DefaultRepositoryInformation"
FILE,DATACMNS,DATACMNS-233,2012-09-14T07:38:12.000-05:00,return null for null sources return null for empty strings,"@javax.validation.constraints.NotNull  @javax.persistence.ManyToOne
I've noticed an important issue related to automatic web binding of String id to Domain class.
imagine use case have Order domain class have ManyToOne reference to customer have Order domain class to customer
post new Order
Failed to convert property value of type java.lang.String to required type org.mycomp.domain.Customer for property customer; nested exception is org.springframework.core.convert.ConversionFailedException: Failed to convert from type java.lang.String to type @javax.
validation.constraints.NotNull @javax.
persistence.ManyToOne org.mycomp.domain.Customer for value '; nested exception is org.springframework.dao.InvalidDataAccessApiUsageException: The given id must not be null!
; nested exception is java.lang.IllegalArgumentException: The given id must not be null!
And note that for optional references this even might even cause a complete blocker?
<form:select path=""customer"">
<form:option value="""" label=""Select"" />
<form:options items=""${customers}"" itemValue=""id""></form:options>
</form:select>","org.springframework.data.repository.support.DomainClassConverterUnitTests
org.springframework.data.repository.support.DomainClassConverter"
FILE,DATACMNS,DATACMNS-257,2012-11-29T02:29:27.000-06:00,not deal with uppercase fields,"@Id 
 class Foo{




  




  @Id




  private String UID;









  //code omitted




}
not execute MongoOperations.findOne method contain @Id field
class Foo{
@Id
private String UID;
//code omitted
}
Steps to reproduce:
create entity in example code snippet
call MongoOperations.findOne find by calling
get exception get step
java.lang.IllegalArgumentException: No property uID found on com.xxxxxxxxxxxxx.TemplateDefinitionObject!
at org.springframework.data.mapping.context.AbstractMappingContext.getPersistentPropertyPath(AbstractMappingContext.java:225)
at org.springframework.data.mongodb.core.convert.QueryMapper.getPath(QueryMapper.java:202)
at org.springframework.data.mongodb.core.convert.QueryMapper.determineKey(QueryMapper.java:221)
at org.springframework.data.mongodb.core.convert.QueryMapper.getMappedObject(QueryMapper.java:87)
at org.springframework.data.mongodb.core.MongoTemplate.doFindOne(MongoTemplate.java:1307)
at org.springframework.data.mongodb.core.MongoTemplate.findById(MongoTemplate.java:516)
at org.springframework.data.mongodb.core.MongoTemplate.findById(MongoTemplate.java:509)
at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.findOne(SimpleMongoRepository.java:99)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:616)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.executeMethodOn(RepositoryFactorySupport.java:334)
at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.invoke(RepositoryFactorySupport.java:319)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)
at $Proxy37.findOne(Unknown Source)
at com.xxxxxxxx.ShortTest.testFoo(ShortTest.java:65)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:616)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:74)
at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:83)
at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:72)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:231)
at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)
at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:71)
at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:174)
at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)","org.springframework.data.mapping.PropertyPath
org.springframework.data.mapping.PropertyPathUnitTests"
FILE,DATACMNS,DATACMNS-509,2014-05-08T08:39:02.000-05:00,break JSON conversion,"{




    final Set<Pos> allPos = posService.findAll();




    return ImmutableSortedSet.copyOf(allPos);




}






 
 {""name: ""pos1""}  {""name: ""pos2""} 
  
     {""name: ""pos1""}  {""name: ""pos2""}
address NullableWrapper fail since upgrade return with contents contain with NullableWrapper
have MVC method
public Callable<Set<Pos>> get(.....) {
final Set<Pos> allPos = posService.findAll();
return ImmutableSortedSet.copyOf(allPos);
}
get in JSON format get of pos get on wire
[{""name: ""pos1""}, {""name: ""pos2""}]
get NullableWrapper with Spring data JPA get NullableWrapper with contents
[valueType: ""java.util.ArrayList"", value: [{""name: ""pos1""}, {""name: ""pos2""}]]","org.springframework.data.repository.core.support.DummyRepositoryFactory
org.springframework.data.repository.core.support.RepositoryFactorySupport
org.springframework.data.repository.core.support.RepositoryFactorySupportUnitTests"
FILE,DATACMNS,DATACMNS-511,2014-05-22T00:04:43.000-05:00,cause infinite loop,"public class User extends AbstractTenantUser<User, Role, Permission, Tenant> {




    ...




}




 public abstract class AbstractTenantUser<USER extends AbstractTenantUser<USER, ROLE, PERMISSION, TENANT>, ROLE extends AbstractRole<USER, PERMISSION>, PERMISSION extends AbstractPermission<USER>, TENANT extends AbstractTenant<USER>> extends AbstractUser<USER, ROLE, PERMISSION> implements TenantEntity<TENANT> {




    ...




}




 public abstract class AbstractUser<USER extends AbstractUser<USER, ROLE, PERMISSION>, ROLE extends AbstractRole<USER, PERMISSION>, PERMISSION extends AbstractPermission<USER>> extends AuditingDateBaseEntity<USER> {




    ...




}




 public abstract class AbstractPermission<USER extends AbstractUser<USER, ?, ?>> extends AuditingDateBaseEntity<USER> {




    ...




}




 public abstract class AuditingDateBaseEntity<USER extends AbstractUser<USER, ?, ?>> extends AbstractDateBaseEntity implements AuditingEntity<USER> {




    ...




}




 public abstract class AbstractDateBaseEntity extends AbstractBaseEntity implements DateEntity {




    ...




}




 public abstract class AbstractBaseEntity implements BaseEntity {




    ...




}
After updating from Codd SR2 to Dijkstra I could not run my tests.
After debugging the issue I found that the problem lies in AbstractMappingContext.addPersistentEntity.
This method is never called in Codd SR2 due to initialize not being triggered.
use few abstract MappedSuperclasses not work few abstract MappedSuperclasses have circular references have few abstract MappedSuperclasses
public class User extends AbstractTenantUser<User, Role, Permission, Tenant> {
...
}
public abstract class AbstractTenantUser<USER extends AbstractTenantUser<USER, ROLE, PERMISSION, TENANT>, ROLE extends AbstractRole<USER, PERMISSION>, PERMISSION extends AbstractPermission<USER>, TENANT extends AbstractTenant<USER>> extends AbstractUser<USER, ROLE, PERMISSION> implements TenantEntity<TENANT> {
...
}
public abstract class AbstractUser<USER extends AbstractUser<USER, ROLE, PERMISSION>, ROLE extends AbstractRole<USER, PERMISSION>, PERMISSION extends AbstractPermission<USER>> extends AuditingDateBaseEntity<USER> {
...
}
public abstract class AbstractPermission<USER extends AbstractUser<USER, ?
, ?
>> extends AuditingDateBaseEntity<USER> {
...
}
public abstract class AuditingDateBaseEntity<USER extends AbstractUser<USER, ?
, ?
>> extends AbstractDateBaseEntity implements AuditingEntity<USER> {
...
}
public abstract class AbstractDateBaseEntity extends AbstractBaseEntity implements DateEntity {
...
}
public abstract class AbstractBaseEntity implements BaseEntity {
...
}
I hope this gives enough insight into the problem and hopefully you can fix this soon.",org.springframework.data.util.TypeVariableTypeInformation
FILE,DATACMNS,DATACMNS-616,2014-12-17T02:25:54.000-06:00,not access private fields,"@Entity




@RevisionEntity(ExtendedRevisionListener.class)




@Table(name = ""revinfo"")




public class ExtendedRevision implements Serializable  
 @Id




	@GeneratedValue




	@Column(name = ""REV"")




	@RevisionNumber




	private Integer id;









	 @RevisionTimestamp




	@Temporal(TemporalType.TIMESTAMP)




	@Column(name = ""REVTSTMP"", nullable = false)




	private Date date;









	 @Column(nullable = false, length = 15)




	private String username;









	 public Integer getId() {




		return id;




	}









	 public Date getDate() {




		return date;




	}









	 public String getUsername() {




		return username;




	}









	 public void setUsername(String username) {




		this.username = username;




	}
use custom Envers revision class
@Entity
@RevisionEntity(ExtendedRevisionListener.class)
@Table(name = ""revinfo"")
public class ExtendedRevision implements Serializable {
@Id
@GeneratedValue
@Column(name = ""REV"")
@RevisionNumber
private Integer id;
@RevisionTimestamp
@Temporal(TemporalType.TIMESTAMP)
@Column(name = ""REVTSTMP"", nullable = false)
private Date date;
@Column(nullable = false, length = 15)
private String username;
public Integer getId() {
return id;
}
public Date getDate() {
return date;
}
public String getUsername() {
return username;
}
public void setUsername(String username) {
this.username = username;
}
trigger error
java.lang.IllegalStateException: Could not access method: Class org.springframework.util.ReflectionUtils can not access a member of class ExtendedRevision with modifiers ""private""
at org.springframework.util.ReflectionUtils.handleReflectionException(ReflectionUtils.java:262)
at org.springframework.util.ReflectionUtils.getField(ReflectionUtils.java:132)
at org.springframework.data.util.AnnotationDetectionFieldCallback.getValue(AnnotationDetectionFieldCallback.java:82)
at org.springframework.data.history.AnnotationRevisionMetadata.<init>(AnnotationRevisionMetadata.java:54)
I assume the fields have to be made accessible from the field callback.",org.springframework.data.util.AnnotationDetectionFieldCallback
FILE,DATACMNS,DATACMNS-683,2015-04-13T05:31:25.000-05:00,enable Spring break @ModelAttribute binding in Spring MVC,"package be.vdab.web;









import org.springframework.context.annotation.ComponentScan;




import org.springframework.context.annotation.Configuration;




import org.springframework.data.web.config.EnableSpringDataWebSupport;




import org.springframework.web.servlet.config.annotation.EnableWebMvc;




import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;









// enkele imports




@Configuration




@EnableWebMvc




@EnableSpringDataWebSupport




@ComponentScan




public class CreateControllerBeans extends WebMvcConfigurerAdapter {




}






  






package be.vdab.web;









import org.springframework.stereotype.Controller;




import org.springframework.web.bind.annotation.ModelAttribute;




import org.springframework.web.bind.annotation.RequestMapping;




import org.springframework.web.bind.annotation.RequestMethod;




import org.springframework.web.servlet.ModelAndView;









import be.vdab.entities.Person;









@Controller




@RequestMapping(value = ""/"")




public class PersonController {




	private static final String TOEVOEGEN_VIEW = ""/WEB-INF/JSP/index.jsp"";














	@RequestMapping(method=RequestMethod.GET)




	ModelAndView get() {




		return new ModelAndView(TOEVOEGEN_VIEW).addObject(new Person());




	}




	




	@RequestMapping(method = RequestMethod.POST)




	String post(@ModelAttribute Person person) {




	  if (person == null) {




		  throw new IllegalArgumentException(""person IS NULL"");




	  }




	  return ""redirect:/"";




	}



















}






 
    
 
 
 
    
 @EnableSpringDataWebSupport   
 @ModelAttribute
config class give following Java
package be.vdab.web;
import org.springframework.context.annotation.ComponentScan;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.web.config.EnableSpringDataWebSupport;
import org.springframework.web.servlet.config.annotation.EnableWebMvc;
import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;
// enkele imports
@Configuration
@EnableWebMvc
@EnableSpringDataWebSupport
@ComponentScan
public class CreateControllerBeans extends WebMvcConfigurerAdapter {
}
package be.vdab.web;
import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.ModelAttribute;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestMethod;
import org.springframework.web.servlet.ModelAndView;
import be.vdab.entities.Person;
@Controller
@RequestMapping(value = ""/"")
public class PersonController {
private static final String TOEVOEGEN_VIEW = ""/WEB-INF/JSP/index.jsp"";
@RequestMapping(method=RequestMethod.GET)
ModelAndView get() {
return new ModelAndView(TOEVOEGEN_VIEW).
addObject(new Person());
}
@RequestMapping(method = RequestMethod.POST)
String post(@ModelAttribute Person person) {
if (person == null) {
throw new IllegalArgumentException(""person IS NULL"");
}
return ""redirect:/"";
}
}
and following JSP
<%@page contentType=""text/html"" pageEncoding=""UTF-8"" session=""false""%>
<%@taglib prefix=""form"" uri=""http://www.springframework.org/tags/form"" %>
<!doctype html>
<html lang=""nl"">
<head>
<title>Add person</title>
</head>
<body>
<form:form action="""" method=""post"" commandName=""person"">
<form:label path=""name"">Name:</form:label>
<form:input path=""name"" autofocus=""true""/>
<input type=""submit"">
</form:form>
</body>
</html>
throw InvalidArgumentException
Observation 1:
This worked up to and including spring-data-jpa 1.7.2.
RELEASE
Observation 2:
The bug disappears when @EnableSpringDataWebSupport is put in comment in CreateControllerBeans.java
Observation 3:
The bug disappears when @ModelAttribute is put in comment in PersonController.java
You can clone a project that shows the bug from https://github.com/desmethans/springDataJpaError.git","org.springframework.data.repository.support.DomainClassConverterUnitTests
org.springframework.data.repository.support.DomainClassConverter"
CLASS,derby-10.9.1.0,DERBY-5407,2011-09-12T08:50:38.000-05:00,produce unusable DDL for VARCHAR FOR BIT DATA columns run across network,"varchar( 20 )  
 
 
 VARCHAR ()
omit length specification for VARCHAR FOR BIT DATA columns report in private correspondence run across network
bring up server
connect 'jdbc:derby://localhost:8246/memory:db;create=true';
create table t( a varchar( 20 ) for bit data );
run dblook across network
java -org.apache.derby.tools.dblook -d ""jdbc:derby://localhost:8246/memory:db""
produce following DDL for table
CREATE TABLE ""APP"".
""T"" (""A"" VARCHAR () FOR BIT DATA);
use embedded database produce usable DDL include length specification for VARCHAR FOR BIT DATA column include usable DDL for VARCHAR FOR BIT DATA column","java.testing.org.apache.derbyTesting.functionTests.tests.lang.SystemCatalogTest
java.engine.org.apache.derby.catalog.types.BaseTypeIdImpl"
CLASS,derby-10.9.1.0,DERBY-6053,2013-01-25T09:02:53.000-06:00,use prepared statement for Connection.setTransactionIsolation use regular statement for Connection.setTransactionIsolation,"client.am.Connection setTransactionIsolation()   setTransactionIsolation()   
 private Statement setTransactionIsolationStmt = null;
 
  
 createStatementX(java.sql.ResultSet.TYPE_FORWARD_ONLY,
                            java.sql.ResultSet.CONCUR_READ_ONLY,
                            holdability());
 
 private void setTransactionIsolationX(int level)
 
 setTransactionIsolationStmt.executeUpdate(
                ""SET CURRENT ISOLATION = "" + levelString);


 
   

import java.sql.*;
import java.net.*;
import java.io.*;
import org.apache.derby.drda.NetworkServerControl;

/**
 * Client template starts its own NetworkServer and runs some SQL against it.
 * The SQL or JDBC API calls can be modified to reproduce issues
 * 
 */public class SetTransactionIsolation {
    public static Statement s;
    
    public static void main(String[] args) throws Exception {
        try {
            // Load the driver. Not needed for network server.
            
            Class.forName(""org.apache.derby.jdbc.ClientDriver"");
            // Start Network Server
            startNetworkServer();
            // If connecting to a customer database. Change the URL
            Connection conn = DriverManager
                    .getConnection(""jdbc:derby://localhost:1527/wombat;create=true"");
            // clean up from a previous run
            s = conn.createStatement();
            try {
                s.executeUpdate(""DROP TABLE T"");
            } catch (SQLException se) {
                if (!se.getSQLState().equals(""42Y55""))
                    throw se;
            }

            for (int i = 0; i < 50000; i++) {
		conn.setTransactionIsolation(Connection.TRANSACTION_REPEATABLE_READ);
		conn.setTransactionIsolation(Connection.TRANSACTION_SERIALIZABLE);

	    }
            
            // rs.close();
            // ps.close();
            runtimeInfo();
            conn.close();
            // Shutdown the server
            shutdownServer();
        } catch (SQLException se) {
            while (se != null) {
                System.out.println(""SQLState="" + se.getSQLState()
                        + se.getMessage());
                se.printStackTrace();
                se = se.getNextException();
            }
        }
    }
    
    /**
     * starts the Network server
     * 
     */
    public static void startNetworkServer() throws SQLException {
        Exception failException = null;
        try {
            
            NetworkServerControl networkServer = new NetworkServerControl(
                    InetAddress.getByName(""localhost""), 1527);
            
            networkServer.start(new PrintWriter(System.out));
            
            // Wait for the network server to start
            boolean started = false;
            int retries = 10; // Max retries = max seconds to wait
            
            while (!started && retries > 0) {
                try {
                    // Sleep 1 second and then ping the network server
                    Thread.sleep(1000);
                    networkServer.ping();
                    
                    // If ping does not throw an exception the server has
                    // started
                    started = true;
                } catch (Exception e) {
                    retries--;
                    failException = e;
                }
                
            }
            
            // Check if we got a reply on ping
            if (!started) {
                throw failException;
            }
        } catch (Exception e) {
            SQLException se = new SQLException(""Error starting network  server"");
            se.initCause(failException);
            throw se;
        }
    }
    
    public static void shutdownServer() throws Exception {
        NetworkServerControl networkServer = new NetworkServerControl(
                InetAddress.getByName(""localhost""), 1527);
        networkServer.shutdown();
    }
    
    public static void runtimeInfo() throws Exception {
        NetworkServerControl networkServer = new NetworkServerControl(
                InetAddress.getByName(""localhost""), 1527);
        System.out.println(networkServer.getRuntimeInfo());
    }
    
}
o.a.d.client.am.Connection setTransactionIsolation() uses a Statement which  it builds up each time for setTransactionIsolation()  is called.
private Statement setTransactionIsolationStmt = null;
...
setTransactionIsolationStmt =
                    createStatementX(java.sql.ResultSet.TYPE_FORWARD_ONLY,
                            java.sql.ResultSet.CONCUR_READ_ONLY,
                            holdability());
....
private void setTransactionIsolationX(int level)
...
            setTransactionIsolationStmt.executeUpdate(
                ""SET CURRENT ISOLATION = "" + levelString);
show repeated calls to setTransactionIsolation
import java.sql.
*;
import java.net.
*;
import java.io.
*;
import org.apache.derby.drda.NetworkServerControl;
/**
* Client template starts its own NetworkServer and runs some SQL against it.
* The SQL or JDBC API calls can be modified to reproduce issues
*
*/public class SetTransactionIsolation {
public static Statement s;
public static void main(String[] args) throws Exception {
try {
// Load the driver.
Not needed for network server.
Class.forName(""org.apache.derby.jdbc.ClientDriver"");
// Start Network Server
startNetworkServer();
// If connecting to a customer database.
Change the URL
Connection conn = DriverManager
.
getConnection(""jdbc:derby://localhost:1527/wombat;create=true"");
// clean up from a previous run
s = conn.createStatement();
try {
s.executeUpdate(""DROP TABLE T"");
} catch (SQLException se) {
if (!
se.getSQLState().
equals(""42Y55""))
throw se;
}
for (int i = 0; i < 50000; i++) {
		conn.setTransactionIsolation(Connection.TRANSACTION_REPEATABLE_READ);
		conn.setTransactionIsolation(Connection.TRANSACTION_SERIALIZABLE);
}
// rs.close();
// ps.close();
runtimeInfo();
conn.close();
// Shutdown the server
shutdownServer();
} catch (SQLException se) {
while (se !
= null) {
System.out.println(""SQLState="" + se.getSQLState()
+ se.getMessage());
se.printStackTrace();
se = se.getNextException();
}
}
}
/**
* starts the Network server
*
*/
public static void startNetworkServer() throws SQLException {
Exception failException = null;
try {
NetworkServerControl networkServer = new NetworkServerControl(
InetAddress.getByName(""localhost""), 1527);
networkServer.start(new PrintWriter(System.out));
// Wait for the network server to start
boolean started = false;
int retries = 10; // Max retries = max seconds to wait
while (!
started && retries > 0) {
try {
// Sleep 1 second and then ping the network server
Thread.sleep(1000);
networkServer.ping();
// If ping does not throw an exception the server has
// started
started = true;
} catch (Exception e) {
retries--;
failException = e;
}
}
// Check if we got a reply on ping
if (!
started) {
throw failException;
}
} catch (Exception e) {
SQLException se = new SQLException(""Error starting network  server"");
se.initCause(failException);
throw se;
}
}
public static void shutdownServer() throws Exception {
NetworkServerControl networkServer = new NetworkServerControl(
InetAddress.getByName(""localhost""), 1527);
networkServer.shutdown();
}
public static void runtimeInfo() throws Exception {
NetworkServerControl networkServer = new NetworkServerControl(
InetAddress.getByName(""localhost""), 1527);
System.out.println(networkServer.getRuntimeInfo());
}
}",java.client.org.apache.derby.client.am.Connection
FILE,COMPRESS,COMPRESS-189,2012-06-26T21:30:39.000-05:00,read bytes read from nested zip file,"ZipFile zipFile = new ZipFile(""C:/test.ZIP"");
    for (Enumeration<ZipArchiveEntry> iterator = zipFile.getEntries(); iterator.hasMoreElements(); ) {
      ZipArchiveEntry entry = iterator.nextElement();
      InputStream is = new BufferedInputStream(zipFile.getInputStream(entry));
      ZipArchiveInputStream zipInput = new ZipArchiveInputStream(is);
      ZipArchiveEntry innerEntry;
      while ((innerEntry = zipInput.getNextZipEntry()) != null){
        if (innerEntry.getName().endsWith(""XML""))
{

          //zipInput.read();

          System.out.println(IOUtils.toString(zipInput));

        }
      }
    }
run error underlying input stream run following code return bytes
return bytes
This only happens the first time read is called, subsequent calls work as expected i.e. the following code actually works correctly with that line uncommented!
produce behavious
If this is not the correct way of processing a zip file of zip files please let me know.
iterate over entries look at master table
Is there anyway of instantiating a ZipFile from a zip file inside another zip file without first extracting the nested zip file?
ZipFile zipFile = new ZipFile(""C:/test.ZIP"");
for (Enumeration<ZipArchiveEntry> iterator = zipFile.getEntries(); iterator.hasMoreElements(); ) {
ZipArchiveEntry entry = iterator.nextElement();
InputStream is = new BufferedInputStream(zipFile.getInputStream(entry));
ZipArchiveInputStream zipInput = new ZipArchiveInputStream(is);
ZipArchiveEntry innerEntry;
while ((innerEntry = zipInput.getNextZipEntry()) !
= null){ if (innerEntry.getName().
endsWith(""XML""))
{
//zipInput.read();
System.out.println(IOUtils.toString(zipInput));
}
}
}","org.apache.commons.compress.archivers.zip.ZipArchiveInputStreamTest
org.apache.commons.compress.archivers.zip.ZipArchiveInputStream"
FILE,COMPRESS,COMPRESS-309,2015-02-18T17:22:16.000-06:00,read to full buffer,"BZip2CompressorInputStream.read(buffer, offset, length)  
 @Test

	public void testApacheCommonsBZipUncompression () throws Exception {

		// Create a big random piece of data

		byte[] rawData = new byte[1048576];

		for (int i=0; i<rawData.length; ++i) {

			rawData[i] = (byte) Math.floor(Math.random()*256);

		}



		// Compress it

		ByteArrayOutputStream baos = new ByteArrayOutputStream();

		BZip2CompressorOutputStream bzipOut = new BZip2CompressorOutputStream(baos);

		bzipOut.write(rawData);

		bzipOut.flush();

		bzipOut.close();

		baos.flush();

		baos.close();



		// Try to read it back in

		ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());

		BZip2CompressorInputStream bzipIn = new BZip2CompressorInputStream(bais);

		byte[] buffer = new byte[1024];

		// Works fine

		Assert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));

		// Fails, returns -1 (indicating the stream is complete rather than that the buffer 

		// was full)

		Assert.assertEquals(0, bzipIn.read(buffer, 1024, 0));

		// But if you change the above expected value to -1, the following line still works

		Assert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));

		bzipIn.close();

	}
use Kryo serialization have negative affects
@Test
public void testApacheCommonsBZipUncompression () throws Exception {
// Create a big random piece of data
byte[] rawData = new byte[1048576];
for (int i=0; i<rawData.length; ++i) {
rawData[i] = (byte) Math.floor(Math.random()*256);
}
// Compress it
ByteArrayOutputStream baos = new ByteArrayOutputStream();
BZip2CompressorOutputStream bzipOut = new BZip2CompressorOutputStream(baos);
bzipOut.write(rawData);
bzipOut.flush();
bzipOut.close();
baos.flush();
baos.close();
// Try to read it back in
ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());
BZip2CompressorInputStream bzipIn = new BZip2CompressorInputStream(bais);
byte[] buffer = new byte[1024];
// Works fine
Assert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));
return ( indicate stream
Assert.assertEquals(0, bzipIn.read(buffer, 1024, 0));
// But if you change the above expected value to -1, the following line still works
Assert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));
bzipIn.close();
}",org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream
FILE,swt-3.1,104150,2005-07-16T19:58:00.000-05:00,click on empty space click on grid lines,"table.getLinesVisible()  
 table.setLinesVisible(true)
SWT-win32, v3138 (3.1-final)
use table cursor have potential of table regions have kinds of table regions separate table cursor from table selection
Expected behaviour:
snippet with added table.setLinesVisible(true)",org.eclipse.swt.custom.TableCursor
FILE,swt-3.1,84609,2005-02-07T13:35:00.000-06:00,have NPE while calling call pack() on last column,"lvtTable.getColumn(0).pack();
lvtTable.getColumn(1).pack();
lvtTable.getColumn(2).pack();

   
 parent.getColumns()
follow code have columns
// refresh table on new data lvtTable.getColumn(0).
pack();
lvtTable.getColumn(1).
pack();
lvtTable.getColumn(2).
pack();
catch NPE in TableColumn return array with elements get on third call
My system is WinXP, Eclipse Version: 3.1.0, Build id: I20050202-0800, JDK 1.5.0.
1","org.eclipse.swt.widgets.TableColumn
org.eclipse.swt.widgets.Table"
FILE,swt-3.1,86000,2005-02-21T14:47:00.000-06:00,produce invalid JPEG images,"package com.ibm.test.image;

import org.eclipse.swt.*;
import org.eclipse.swt.graphics.*;

public class ImageLoaderTest {
		
	public static void main(String[] args) {
		ImageLoader loader;
		String dir=""c:\\image-problems\\"";
		String files[]={
				""s34i3p04"",
				""s34n3p04"",
				""s35i3p04"",
				""s35n3p04"",
				""s36i3p04"",
				""s36n3p04"",
				""s37i3p04"",
				""s37n3p04"",
				""s38i3p04"",
				""s38n3p04"",
				""s39i3p04"",
				""s39n3p04""
		};
		
		try {
			for (int i=0; i<files.length; i++) {
			String filein  = dir+files[i]+"".png"";
			String fileout = dir+files[i]+"".jpg"";
			
			loader = new ImageLoader();
			loader.load(filein);
			loader.save(fileout,SWT.IMAGE_JPEG);
			}
		} catch (SWTException e) {
		  e.printStackTrace();
		}
	}
}
produce bad JPG images
I have only verified this with JPEG output.
test as JPEG
produce proper JPG images expected
The attached Zip file contains
 only those files that did not save correctly to JPEG.
package com.ibm.test.image;
import org.eclipse.swt.
*;
import org.eclipse.swt.graphics.
*;
public class ImageLoaderTest {
		
	public static void main(String[] args) {
		ImageLoader loader;
		String dir=""c:\\image-problems\\"";
		String files[]={
				""s34i3p04"",
				""s34n3p04"",
				""s35i3p04"",
				""s35n3p04"",
				""s36i3p04"",
				""s36n3p04"",
				""s37i3p04"",
				""s37n3p04"",
				""s38i3p04"",
				""s38n3p04"",
				""s39i3p04"",
				""s39n3p04""
		};
		
		try {
			for (int i=0; i<files.length; i++) {
			String filein  = dir+files[i]+"".
png"";
			String fileout = dir+files[i]+"".
jpg"";
			
			loader = new ImageLoader();
			loader.load(filein);
			loader.save(fileout,SWT.IMAGE_JPEG);
			}
		} catch (SWTException e) {
		  e.printStackTrace();
		}
	}
}",org.eclipse.swt.internal.image.JPEGFileFormat
FILE,swt-3.1,87997,2005-03-14T19:21:00.000-06:00,cause NPE,"TableEdtior.dispose( )  
  
   

import org.eclipse.swt.custom.TableEditor;
import org.eclipse.swt.events.*;
import org.eclipse.swt.widgets.*;

public class Test
{
    public static void main( String[ ] args )
    {
        Shell shell = new Shell( );
        Table table = new Table( shell, 0 );
        new TableColumn( table, 0 );
        TableItem item = new TableItem( table, 0 );
        final TableEditor editor = new TableEditor( table );
        final Text text = new Text( table, 0 );
        editor.setEditor( text, item, 0 );
        item.addDisposeListener( new DisposeListener( ) {
            public void widgetDisposed( DisposeEvent e )
            {
                text.dispose( );
                editor.dispose( ); // Triggers a NPE
            }
        } );
        shell.dispose( );
    }
}
Found in 3.1 I20050308-0835.
TableEdtior.dispose( ) calls methods on it's owning Table to remove some
listeners from the table's columns.
be in process result in NPE
prevent from trying prevent from adding add dispose listener on Table add dispose listener on TableItem try dispose listener on Table try dispose listener on TableItem dispose of associated editor
set dispose listener on parent throw instead_of NPE
This leaves
no place to hook to trigger the disposal of the TableEditor.
import org.eclipse.swt.custom.TableEditor;
import org.eclipse.swt.events.
*;
import org.eclipse.swt.widgets.
*;
public class Test
{
    public static void main( String[ ] args )
    {
        Shell shell = new Shell( );
        Table table = new Table( shell, 0 );
        new TableColumn( table, 0 );
        TableItem item = new TableItem( table, 0 );
        final TableEditor editor = new TableEditor( table );
        final Text text = new Text( table, 0 );
        editor.setEditor( text, item, 0 );
        item.addDisposeListener( new DisposeListener( ) {
            public void widgetDisposed( DisposeEvent e )
            {
                text.dispose( );
                editor.dispose( ); // Triggers a NPE
            }
        } );
        shell.dispose( );
    }
}","org.eclipse.swt.widgets.Tree
org.eclipse.swt.widgets.Table"
FILE,swt-3.1,97651,2005-05-31T14:43:00.000-05:00,mark cheese,"Tree.redraw() 
 public static void main(String[] args) {
	final Display display = new Display();
	final Shell shell = new Shell(display);
	shell.setBounds(10, 10, 300, 300);
	final Tree tree = new Tree(shell, SWT.NONE);
	tree.setBounds(10, 10, 200, 200);
	new TreeItem(tree, SWT.NONE).setText(""pre-root"");
	TreeItem root1 = new TreeItem(tree, SWT.NONE);
	root1.setText(""root"");
	TreeItem child = new TreeItem(root1, SWT.NONE);
	child.setText(""child"");
	Button button = new Button(shell, SWT.PUSH);
	button.setBounds(230,10,30,30);
	button.addSelectionListener(new SelectionAdapter() {
		public void widgetSelected(SelectionEvent e) {
			tree.redraw();
		}
	});
	root1.setExpanded(true);
	tree.setInsertMark(root1, false);
	shell.open();
	while (!shell.isDisposed()) {
		if (!display.readAndDispatch()) display.sleep();
	}
	display.dispose();
}
3.1RC1
run snippet
be under root item
collapse root item
except for pointy ends
press button to right do Tree.redraw() note Tree.redraw()
expand root item copy insert mark to child item copy insert mark to initial location
public static void main(String[] args) { final Display display = new Display();
final Shell shell = new Shell(display);
shell.setBounds(10, 10, 300, 300);
final Tree tree = new Tree(shell, SWT.NONE);
tree.setBounds(10, 10, 200, 200);
new TreeItem(tree, SWT.NONE).
setText(""pre-root"");
TreeItem root1 = new TreeItem(tree, SWT.NONE);
root1.setText(""root"");
TreeItem child = new TreeItem(root1, SWT.NONE);
child.setText(""child"");
Button button = new Button(shell, SWT.PUSH);
button.setBounds(230,10,30,30);
button.addSelectionListener(new SelectionAdapter() { public void widgetSelected(SelectionEvent e) { tree.redraw();
}
});
root1.setExpanded(true);
tree.setInsertMark(root1, false);
shell.open();
while (! shell.isDisposed()) { if (! display.readAndDispatch()) display.sleep();
} display.dispose();
}","org.eclipse.swt.dnd.TreeDragUnderEffect
org.eclipse.swt.widgets.Tree"
CLASS,pig-0.8.0,PIG-1776,2010-12-17T16:28:09.000-06:00,change statement corresponding to alias change statement corresponding after explain do dump give incorrect result for changing,"{code}
 
  
 {code}
{code}
grunt> a = load '/tmp/t2.
txt' as (str:chararray, num1:int, alph : chararray);
grunt> dump a;
(ABC,1,a)
(ABC,1,b)
(ABC,1,a)
(ABC,2,b)
(DEF,1,d)
(XYZ,1,x)
grunt> c = foreach b  generate group.str, group.
$1, COUNT(a.alph) ;          
grunt> dump c; -- gives correct results
(ABC,1,3)
(ABC,2,1)
(DEF,1,1)
(XYZ,1,1)
grunt> c = foreach b  generate group.
$0 , (CHARARRAY)group.
$1;                                                                                 
grunt> explain c;
...
...
grunt> c = foreach b  generate group.str, group.
$1, COUNT(a.alph) ;
grunt> dump c;             
(ABC,1,0)
(ABC,2,0)
(DEF,1,0)
(XYZ,1,0)
{code}","src.org.apache.pig.PigServer
src.org.apache.pig.newplan.logical.relational.LOLoad
test.org.apache.pig.test.TestUDFContext"
CLASS,pig-0.8.0,PIG-1813,2011-01-20T10:25:01.000-06:00,throw ERROR while refer map in result,"flatten(org.myudf.GETFIRST(value))  
 PigStorage()
register myudf.jar;
A = load 'input' MyZippedStorage('\u0001') as ($inputSchema);
B = foreach A generate id , value  ;
C = foreach B generate id , org.myudf.ExplodeHashList( (chararray)value, '\u0002', '\u0004', '\u0003') as value;
D = FILTER C by value is not null;
E = foreach D generate id , flatten(org.myudf.GETFIRST(value)) as hop;
F = foreach E generate id , hop#'rmli' as rmli:bytearray ;
store F into 'output.bz2' using PigStorage();
run with pig run with pig run if pig.usenewlogicalplan=false.
org.apache.pig.backend.executionengine.ExecException: ERROR 1075: Received a bytearray from the UDF. Cannot determine how to convert the bytearray to map.
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POCast.getNext(POCast.java:952)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POMapLookUp.processInput(POMapLookUp.java:87)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POMapLookUp.getNext(POMapLookUp.java:98)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POMapLookUp.getNext(POMapLookUp.java:117)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.processPlan(POForEach.java:346)
at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.getNext(POForEach.java:291)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.runPipeline(PigMapBase.java:236)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.map(PigMapBase.java:231)
at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.map(PigMapBase.java:53)
at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)
at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:638)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:314)
at org.apache.hadoop.mapred.Child$4.run(Child.java:217)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1062)
at org.apache.hadoop.mapred.Child.main(Child.java:211)","src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc
test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.newplan.logical.relational.LOGenerate"
CLASS,pig-0.8.0,PIG-1858,2011-02-17T02:27:48.000-06:00,result frontend exception,"{code}
 
 PigStorage()  
 {
        Pvs = order B by pvs;
        Const = org.vivek.MyAnotherUDF(Pvs.pvs).(count,sum);
        generate Const.sum as sum;
        } 
   ;
{code}
register myinput use PigStorage() generate pvs as avg foreach by pvs
(count,sum);
        generate Const.sum as sum;
        };
store D into 'out_D';
{code}
The script is failing during compilation of the plan.
The usage of the udf inside the foreach is causing the problem.
The udf implements algebraic and the 
output schema is also defined.
ERROR 2042: Error in new logical plan.
Try -Dpig.usenewlogicalplan=false.
org.apache.pig.impl.logicalLayer.FrontendException: ERROR 2042: Error in new logical plan. Try -Dpig.usenewlogicalplan=false.
at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.compile(HExecutionEngine.java:309)
at org.apache.pig.PigServer.compilePp(PigServer.java:1364)
at org.apache.pig.PigServer.executeCompiledLogicalPlan(PigServer.java:1206)
at org.apache.pig.PigServer.execute(PigServer.java:1200)
at org.apache.pig.PigServer.access$100(PigServer.java:128)
at org.apache.pig.PigServer$Graph.execute(PigServer.java:1527)
at org.apache.pig.PigServer.executeBatchEx(PigServer.java:372)
at org.apache.pig.PigServer.executeBatch(PigServer.java:339)
at org.apache.pig.tools.grunt.GruntParser.executeBatch(GruntParser.java:112)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:169)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:141)
at org.apache.pig.tools.grunt.Grunt.exec(Grunt.java:90)
at org.apache.pig.Main.run(Main.java:500)
at org.apache.pig.Main.main(Main.java:107)
Caused by: java.lang.NullPointerException
at org.apache.pig.newplan.ReverseDependencyOrderWalker.walk(ReverseDependencyOrderWalker.java:70)
at org.apache.pig.newplan.PlanVisitor.visit(PlanVisitor.java:50)
at org.apache.pig.newplan.logical.optimizer.SchemaResetter.visit(SchemaResetter.java:105)
at org.apache.pig.newplan.logical.relational.LOGenerate.accept(LOGenerate.java:229)
at org.apache.pig.newplan.DependencyOrderWalker.walk(DependencyOrderWalker.java:75)
at org.apache.pig.newplan.logical.optimizer.SchemaResetter.visit(SchemaResetter.java:94)
at org.apache.pig.newplan.logical.relational.LOForEach.accept(LOForEach.java:71)
at org.apache.pig.newplan.DependencyOrderWalker.walk(DependencyOrderWalker.java:75)
at org.apache.pig.newplan.PlanVisitor.visit(PlanVisitor.java:50)
at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.compile(HExecutionEngine.java:261)
... 13 more
trun off new logical plan
The issue is observed in both 0.8 and 0.9",test.org.apache.pig.test.TestEvalPipeline2
CLASS,pig-0.8.0,PIG-1868,2011-02-24T00:42:05.000-06:00,have complex data types from udf,"{code}
 
 {
 Tuples = order B1 by ts;
 generate Tuples;
} 
   { t: ( previous, current, next ) } 
 as id;
dump C3;
{code}

 
 {code}
 
 {code}

  on C1 ;
{code}
C1: {seq: {t: (previous: (id: chararray,ts: int,url: chararray),current: (id: chararray,ts: int,url: chararray),next: (id: chararray,ts: int,url: chararray))}}
{code}
The new logical plan fails when I have complex data types returning from my eval function.
{code}
register myudf.jar;   
B1 = load 'myinput' as (id:chararray,ts:int,url:chararray);
B2 = group B1 by id;
B = foreach B2 {
 Tuples = order B1 by ts;
 generate Tuples;
};
C1 = foreach B generate TransformToMyDataType(Tuples,-1,0,1) as seq: { t: ( previous, current, next ) };
C2 = foreach C1 generate FLATTEN(seq);
C3 = foreach C2 generate  current.id as id;
dump C3;
{code}
match uid for project code } fail on c3
turn off new logical plan use pig","src.org.apache.pig.newplan.logical.relational.LogicalSchema
test.org.apache.pig.test.TestSchema"
CLASS,pig-0.8.0,PIG-1963,2011-04-04T17:18:24.000-05:00,take input from order-by not get results in nested foreach,"{code}
 
 explain d;
dump d;
{code}
not use secondary sort for order-by
b = cogroup a1 by f1, a2 by f1;
d = foreach b {
   sort1 = order a1 by f2;
   sort2 = order a2 by f2; -- secondary sort not getting used here, MYCONCATBAG gets results in wrong order
   generate group, MYCONCATBAG(sort1.f1), MYCONCATBAG(sort2.f2);
}
-- explain d;
dump d;
{code}","test.org.apache.pig.test.TestAccumulator
src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.AccumulatorOptimizer"
CLASS,pig-0.8.0,PIG-1979,2011-04-08T02:24:01.000-05:00,not find matching uid fail with ERROR,"{code}
 
  
    
    
      
     PigStorage() 
  
  
  
   PigStorage() ;
{code}

   
  
    
 {code}

 import java.io.IOException;
import org.apache.pig.EvalFunc;
import org.apache.pig.data.*;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.logicalLayer.schema.Schema.FieldSchema;

public class MyExtractor extends EvalFunc<DataBag>
{
  @Override
	public Schema outputSchema(Schema arg0) {
	  try {
			return Schema.generateNestedSchema(DataType.BAG, DataType.CHARARRAY);
		} catch (FrontendException e) {
			System.err.println(""Error while generating schema. ""+e);
			return new Schema(new FieldSchema(null, DataType.BAG));
		}
	}

  @Override
  public DataBag exec(Tuple inputTuple)
    throws IOException
  {
    try {
      Tuple tp2 = TupleFactory.getInstance().newTuple(1);
      tp2.set(0, (inputTuple.get(0).toString()+inputTuple.hashCode()));
      DataBag retBag = BagFactory.getInstance().newDefaultBag();
      retBag.add(tp2);
      return retBag;
    }
    catch (Exception e) {
      throw new IOException("" Caught exception"", e);
    }
  }
}

 {code}
format IS NOT NULL AND format c02 = FILTER BY result
= '' ;
c03 = FOREACH c02 GENERATE url, formatted, FLATTEN(usage);
c04 = FOREACH c03 GENERATE usage::domain AS domain, url, formatted;
doc_001 = FOREACH c04 GENERATE domain,url, FLATTEN(MyExtractor(formatted)) AS category;
doc_004_1 = GROUP doc_001 BY (domain,url);
doc_005 = FOREACH doc_004_1 GENERATE group.domain as domain, group.url as url, doc_001.
category as category;
STORE doc_005 INTO 'out_final' USING PigStorage();
review1 = FOREACH c04 GENERATE domain,url, MyExtractor(formatted) AS rev;
review2 = FILTER review1 BY SIZE(rev)>0;
joinresult = JOIN review2 by (domain,url), doc_005 by (domain,url);
finalresult = FOREACH joinresult GENERATE  doc_005::category;
STORE finalresult INTO 'out_final' using PigStorage();
{code}
build plan fail in building fail while applying apply for logical optimization rule
ERROR org.apache.pig.tools.grunt.Grunt - ERROR 2229: Couldn't find matching uid -1 for project (Name: Project Type: bytearray Uid: 106 Input: 0 Column: 5)
include doc_005
This is field is orginated from the udf org.vivek.udfs.MyExtractor (source given below).
{code}
import java.io.IOException;
import org.apache.pig.EvalFunc;
import org.apache.pig.data.
*;
import org.apache.pig.impl.logicalLayer.FrontendException;
import org.apache.pig.impl.logicalLayer.schema.Schema;
import org.apache.pig.impl.logicalLayer.schema.Schema.FieldSchema;
public class MyExtractor extends EvalFunc<DataBag>
{
  @Override
	public Schema outputSchema(Schema arg0) {
	  try {
			return Schema.generateNestedSchema(DataType.BAG, DataType.CHARARRAY);
		} catch (FrontendException e) {
			System.err.println(""Error while generating schema. ""
+e);
			return new Schema(new FieldSchema(null, DataType.BAG));
		}
	}
@Override
  public DataBag exec(Tuple inputTuple)
    throws IOException
  {
    try {
      Tuple tp2 = TupleFactory.getInstance().
newTuple(1);
      tp2.set(0, (inputTuple.get(0).
toString()+inputTuple.hashCode()));
      DataBag retBag = BagFactory.getInstance().
newDefaultBag();
      retBag.add(tp2);
      return retBag;
    }
    catch (Exception e) {
      throw new IOException("" Caught exception"", e);
    }
  }
}
{code}
disable AddForEach rule disable t AddForEach go through fine","test.org.apache.pig.test.TestEvalPipeline2
src.org.apache.pig.newplan.logical.expression.DereferenceExpression"
CLASS,pig-0.8.0,PIG-730,2009-03-24T14:36:45.000-05:00,combine schema with nested bag combine schema from union,"flatten(outlinks.target);
  flatten(outlinks.target);
grunt> a = load 'foo' using BinStorage as (url:chararray,outlinks:{t:(target:chararray,text:chararray)});
grunt> b = union (load 'foo' using BinStorage as (url:chararray,outlinks:{t:(target:chararray,text:chararray)})), (load 'bar' using BinStorage as (url:chararray,outlinks:{t:(target:chararray,text:chararray)}));
grunt> c = foreach a generate flatten(outlinks.target);
grunt> d = foreach b generate flatten(outlinks.target);
give error
use outlinks.t.target works for d use outlinks.t.target works for c.
2009-03-24 13:15:05,376 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1000: Error during parsing.
Invalid alias: target in {t: (target: chararray,text: chararray)}
Details at logfile: /echo/olston/data/pig_1237925683748.
log
grunt> quit
$ cat pig_1237925683748.log
ERROR 1000: Error during parsing. Invalid alias: target in {t: (target: chararray,text: chararray)}
org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1000: Error during parsing. Invalid alias: target in {t: (target: chararray,text: chararray)}
at org.apache.pig.PigServer.parseQuery(PigServer.java:317)
at org.apache.pig.PigServer.registerQuery(PigServer.java:276)
at org.apache.pig.tools.grunt.GruntParser.processPig(GruntParser.java:529)
at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:280)
at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:99)
at org.apache.pig.tools.grunt.Grunt.run(Grunt.java:69)
at org.apache.pig.Main.main(Main.java:321)
Caused by: org.apache.pig.impl.logicalLayer.parser.ParseException: Invalid alias: target in {t: (target: chararray,text: chararray)}
at org.apache.pig.impl.logicalLayer.parser.QueryParser.AliasFieldOrSpec(QueryParser.java:6042)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.ColOrSpec(QueryParser.java:5898)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.BracketedSimpleProj(QueryParser.java:5423)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.BaseEvalSpec(QueryParser.java:4100)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.UnaryExpr(QueryParser.java:3967)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.CastExpr(QueryParser.java:3920)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.MultiplicativeExpr(QueryParser.java:3829)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.AdditiveExpr(QueryParser.java:3755)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.InfixExpr(QueryParser.java:3721)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.FlattenedGenerateItem(QueryParser.java:3617)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.FlattenedGenerateItemList(QueryParser.java:3557)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.GenerateStatement(QueryParser.java:3514)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.NestedBlock(QueryParser.java:2985)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.ForEachClause(QueryParser.java:2395)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.BaseExpr(QueryParser.java:1028)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.Expr(QueryParser.java:804)
at org.apache.pig.impl.logicalLayer.parser.QueryParser.Parse(QueryParser.java:595)
at org.apache.pig.impl.logicalLayer.LogicalPlanBuilder.parse(LogicalPlanBuilder.java:60)
at org.apache.pig.PigServer.parseQuery(PigServer.java:310)
... 6 more","src.org.apache.pig.impl.logicalLayer.schema.Schema
src.org.apache.pig.newplan.logical.expression.DereferenceExpression
src.org.apache.pig.newplan.logical.relational.LogicalSchema
test.org.apache.pig.test.TestSchema"
CLASS,hibernate-3.5.0b2,HHH-4617,2009-11-28T11:42:08.000-06:00,use materialized blobs with Postgresql cause error,"@Lob
have entity with byte [ ] property annotated have entity as @Lob lazy fetch type read OID value instead_of bytes read OID value under given oid be of type oid read column in application
It's behavior like to read / write bytea.
create oid column","org.hibernate.type.CharacterArrayClobType
org.hibernate.type.MaterializedClobType
org.hibernate.type.PrimitiveCharacterArrayClobType
org.hibernate.type.WrappedMaterializedBlobType
org.hibernate.type.MaterializedBlobType
org.hibernate.test.lob.MaterializedBlobTest
org.hibernate.type.BlobType
org.hibernate.type.ClobType
org.hibernate.test.lob.ClobLocatorTest
org.hibernate.dialect.Dialect
org.hibernate.cfg.annotations.SimpleValueBinder
org.hibernate.dialect.PostgreSQLDialect
org.hibernate.Hibernate"
CLASS,hibernate-3.5.0b2,HHH-5042,2010-03-26T05:06:09.000-05:00,not increment hibernate_sequences.next_hi_value exhaust current lo-range,"class MultipleHiLoPerTableGenerator 
 IntegralDataTypeHolder value;
 
 int lo;

 
  
  
 IntegralDataTypeHolder hiVal = (IntegralDataTypeHolder) doWorkInNewTransaction( session );

   
  
 varchar(255) 
     varchar(255)
This bug is new in 3.5
In version 3.5 class MultipleHiLoPerTableGenerator.java was modified introducing a new increment variable
IntegralDataTypeHolder value;
along with int lo;
if ( lo > maxLo ) {
IntegralDataTypeHolder hiVal = (IntegralDataTypeHolder) doWorkInNewTransaction( session );
deliver numbers without update hibernate_sequences
duplicate keys insert new objects on concerning table
IMPORTANT ADVICE TO RUN THE TESTCASE:
run without hbm2ddl.auto property
create table A (oid bigint not null, name varchar(255), version integer not null, primary key (oid), unique (name))
create table hibernate_sequences ( sequence_name varchar(255),  sequence_next_hi_value integer )","org.hibernate.id.SequenceHiLoGenerator
org.hibernate.id.enhanced.OptimizerFactory
org.hibernate.id.SequenceGenerator
org.hibernate.id.MultipleHiLoPerTableGenerator"
METHOD,openjpa-2.0.1,OPENJPA-1627,2010-04-12T05:21:13.000-05:00,use wrong columns in SQL,"@OneToMany(fetch = FetchType.LAZY, cascade = {CascadeType.PERSIST})
	@ElementJoinColumn(name=""maccno"", referencedColumnName=""maccno"")
	@OrderBy(value = ""_id._processDate ASC, _id._tranSequenceNumber ASC"")
	private LinkedList<Transaction> _transactions;



      
 @EmbeddedId
	private TransactionId _id;
	
	 @Column(name = ""mtrancde"")
	private int _transactionCode;
	
	 @Column(name = ""mamount"")
	private BigDecimal _amount;
	
	 @Column(name = ""mdesc"")
	private String _description;
	


	 @Column(name = ""mactdate"")
	private Date _actualDate;
	
	 @Column(name = ""mbranch"")
	private int _branch;



   
 @Embeddable
public class TransactionId  
 @Column(name = ""maccno"")
	private String _accountNumber;
	
	 @Column(name = ""mprocdate"")
	private Date _processDate;
	
	 @Column(name = ""mtranseqno"")
	private int _tranSequenceNumber;
Typical bank example, Account with Transactions.
It is a legacy db so Transaction has compound key - represented by TransactionId class.
be for columns map in transaction entity NOT
have following fragment ....
@OneToMany(fetch = FetchType.LAZY, cascade = {CascadeType.PERSIST})
	@ElementJoinColumn(name=""maccno"", referencedColumnName=""maccno"")
	@OrderBy(value = ""_id.
_processDate ASC, _id.
_tranSequenceNumber ASC"")
	private LinkedList<Transaction> _transactions;
_processDate and _tranSequenceNumber are defined in the TransactionId class.
Transaction has the following fragment....
@EmbeddedId
	private TransactionId _id;
	
	@Column(name = ""mtrancde"")
	private int _transactionCode;
	
	@Column(name = ""mamount"")
	private BigDecimal _amount;
	
	@Column(name = ""mdesc"")
	private String _description;
@Column(name = ""mactdate"")
	private Date _actualDate;
	
	@Column(name = ""mbranch"")
	private int _branch;
And TransactionId defines the primary key columns....
@Embeddable
public class TransactionId {
	
	@Column(name = ""maccno"")
	private String _accountNumber;
	
	@Column(name = ""mprocdate"")
	private Date _processDate;
	
	@Column(name = ""mtranseqno"")
	private int _tranSequenceNumber;
do on columns map in transaction
executing prepstmnt 23188098 SELECT t0.maccno, t0.mprocdate, t0.mtranseqno, t0.mactdate, t0.mamount, t0.mbranch, t0.mchqcash, t0.mdesc,
 t0.mtmnlno, t0.mtrancde, t0.mtrnfeed 
FROM transaction t0 
WHERE t0.maccno = ?
ORDER BY t0.mamount ASC, t0.mbranch ASC [params=(String) 000734123]
ORDER BY t0.mprocdate ASC, t0.mtranseqno ASC [params=(String) 000734123]
Thanks
Michael","org.apache.openjpa.jdbc.meta.JDBCRelatedFieldOrder:order(Select, ClassMapping, Joins)"
METHOD,openjpa-2.0.1,OPENJPA-526,2008-02-27T13:28:05.000-06:00,cause sqlexception,"public class Exam 
 @Lob 
 @Column(name = ""text"", nullable = false)  
 private String text;
 
 With nullable = false
lead to bug
Here are the differences with nullable = true:
INSERT INTO exam (id, text) VALUES (?
, ?)
[params=(long) 1, (Clob) oracle.sql.CLOB@d402dd]
SELECT t0.text FROM exam t0 WHERE t0.id = ?
FOR UPDATE [params=(long) 1]
With nullable = false:
INSERT INTO exam (id, text) VALUES (?
, ?)
[params=(long) 1, (Reader) java.io.StringReader@1603522]
SELECT t0.text FROM exam t0 WHERE t0.id = ?
FOR UPDATE [params=(long) 1] [code=1400, state=23000]
Here's the full stack trace:
[2008-02-27 10:43:51,232][main][org.apache.openjpa.lib.log.Log4JLogFactory$LogAdapter:72][DEBUG] <t 11050211, conn 32112901> executing prepstmnt 15029693 INSERT INTO exam (id, last_updated_by, comments, sustained_on, text, version, course_id, professor_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?) [params=(long) 11, (String) test, (null) null, (Date) 2008-02-27, (Reader) java.io.StringReader@da9ea4, (int) 1, (long) 1, (long) 8]
[2008-02-27 10:43:51,248][main][org.apache.openjpa.lib.log.Log4JLogFactory$LogAdapter:72][DEBUG] <t 11050211, conn 32112901> [16 ms] spent
[2008-02-27 10:43:51,248][main][org.apache.openjpa.lib.log.Log4JLogFactory$LogAdapter:72][DEBUG] <t 11050211, conn 32112901> executing prepstmnt 24422114 SELECT t0.text FROM exam t0 WHERE t0.id = ? FOR UPDATE [params=(long) 11]
[2008-02-27 10:43:51,279][main][org.apache.openjpa.lib.log.Log4JLogFactory$LogAdapter:72][DEBUG] <t 11050211, conn 32112901> [31 ms] spent
[2008-02-27 10:43:51,279][main][org.apache.openjpa.lib.log.Log4JLogFactory$LogAdapter:76][DEBUG] An exception occurred while ending the transaction.  This exception will be re-thrown.
<openjpa-1.0.2-r420667:627158 fatal store error> org.apache.openjpa.util.StoreException: The transaction has been rolled back.  See the nested exceptions for details on the errors that occurred.
at org.apache.openjpa.kernel.BrokerImpl.newFlushException(BrokerImpl.java:2108)
at org.apache.openjpa.kernel.BrokerImpl.flush(BrokerImpl.java:1955)
at org.apache.openjpa.kernel.BrokerImpl.flushSafe(BrokerImpl.java:1853)
at org.apache.openjpa.kernel.BrokerImpl.beforeCompletion(BrokerImpl.java:1771)
at org.apache.openjpa.kernel.LocalManagedRuntime.commit(LocalManagedRuntime.java:81)
at org.apache.openjpa.kernel.BrokerImpl.commit(BrokerImpl.java:1293)
at org.apache.openjpa.kernel.DelegatingBroker.commit(DelegatingBroker.java:861)
at org.apache.openjpa.persistence.EntityManagerImpl.commit(EntityManagerImpl.java:408)
at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:438)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:662)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:632)
at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:319)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:116)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:631)
at com.intellapps.university.service.impl.ServiceDahImpl$$EnhancerByCGLIB$$81ecf35d.insertExam(<generated>)
at com.intellapps.university.service.impl.ServiceImpl.insertExam(ServiceImpl.java:98)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:585)
at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:301)
at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:182)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:149)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:106)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:204)
at $Proxy17.insertExam(Unknown Source)
at com.intellapps.university.app.Main.testInsertExamWithLongText(Main.java:103)
at com.intellapps.university.app.Main.main(Main.java:203)
Caused by: <openjpa-1.0.2-r420667:627158 nonfatal store error> org.apache.openjpa.util.StoreException: Exhausted Resultset
at org.apache.openjpa.jdbc.sql.DBDictionary.newStoreException(DBDictionary.java:3946)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:97)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:83)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:59)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:96)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:72)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager.flush(JDBCStoreManager.java:514)
at org.apache.openjpa.kernel.DelegatingStoreManager.flush(DelegatingStoreManager.java:130)
... 29 more
Caused by: java.sql.SQLException: Exhausted Resultset
at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:112)
at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:146)
at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:208)
at oracle.jdbc.driver.ScrollableResultSet.getOracleObject(ScrollableResultSet.java:510)
at oracle.jdbc.driver.ScrollableResultSet.getCLOB(ScrollableResultSet.java:1446)
at oracle.jdbc.driver.UpdatableResultSet.getCLOB(UpdatableResultSet.java:1639)
at oracle.jdbc.driver.UpdatableResultSet.getClob(UpdatableResultSet.java:982)
at org.apache.commons.dbcp.DelegatingResultSet.getClob(DelegatingResultSet.java:515)
at org.apache.openjpa.lib.jdbc.DelegatingResultSet.getClob(DelegatingResultSet.java:576)
at org.apache.openjpa.jdbc.meta.strats.MaxEmbeddedClobFieldStrategy.putData(MaxEmbeddedClobFieldStrategy.java:69)
at org.apache.openjpa.jdbc.meta.strats.MaxEmbeddedLobFieldStrategy.customUpdate(MaxEmbeddedLobFieldStrategy.java:162)
at org.apache.openjpa.jdbc.meta.strats.MaxEmbeddedLobFieldStrategy.customInsert(MaxEmbeddedLobFieldStrategy.java:140)
at org.apache.openjpa.jdbc.meta.FieldMapping.customInsert(FieldMapping.java:684)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager$CustomMapping.execute(AbstractUpdateManager.java:358)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:94)
... 32 more
NestedThrowables:
<openjpa-1.0.2-r420667:627158 nonfatal store error> org.apache.openjpa.util.ReferentialIntegrityException: ORA-01400: cannot insert NULL into (""TEST"".""EXAM"".""TEXT"")
{prepstmnt 15029693 INSERT INTO exam (id, last_updated_by, comments, sustained_on, text, version, course_id, professor_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?) [params=(long) 11, (String) test, (null) null, (Date) 2008-02-27, (Reader) java.io.StringReader@da9ea4, (int) 1, (long) 1, (long) 8]} [code=1400, state=23000]
FailedObject: com.intellapps.university.core.model.Exam@1417690
at org.apache.openjpa.jdbc.sql.DBDictionary.newStoreException(DBDictionary.java:3944)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:97)
at org.apache.openjpa.jdbc.sql.SQLExceptions.getStore(SQLExceptions.java:67)
at org.apache.openjpa.jdbc.kernel.PreparedStatementManagerImpl.flushInternal(PreparedStatementManagerImpl.java:108)
at org.apache.openjpa.jdbc.kernel.PreparedStatementManagerImpl.flush(PreparedStatementManagerImpl.java:73)
at org.apache.openjpa.jdbc.kernel.OperationOrderUpdateManager.flushPrimaryRow(OperationOrderUpdateManager.java:203)
at org.apache.openjpa.jdbc.kernel.OperationOrderUpdateManager.flush(OperationOrderUpdateManager.java:89)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:89)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:72)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager.flush(JDBCStoreManager.java:514)
at org.apache.openjpa.kernel.DelegatingStoreManager.flush(DelegatingStoreManager.java:130)
at org.apache.openjpa.kernel.BrokerImpl.flush(BrokerImpl.java:1955)
at org.apache.openjpa.kernel.BrokerImpl.flushSafe(BrokerImpl.java:1853)
at org.apache.openjpa.kernel.BrokerImpl.beforeCompletion(BrokerImpl.java:1771)
at org.apache.openjpa.kernel.LocalManagedRuntime.commit(LocalManagedRuntime.java:81)
at org.apache.openjpa.kernel.BrokerImpl.commit(BrokerImpl.java:1293)
at org.apache.openjpa.kernel.DelegatingBroker.commit(DelegatingBroker.java:861)
at org.apache.openjpa.persistence.EntityManagerImpl.commit(EntityManagerImpl.java:408)
at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:438)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:662)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:632)
at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:319)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:116)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:631)
at com.intellapps.university.service.impl.ServiceDahImpl$$EnhancerByCGLIB$$81ecf35d.insertExam(<generated>)
at com.intellapps.university.service.impl.ServiceImpl.insertExam(ServiceImpl.java:98)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:585)
at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:301)
at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:182)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:149)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:106)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:204)
at $Proxy17.insertExam(Unknown Source)
at com.intellapps.university.app.Main.testInsertExamWithLongText(Main.java:103)
at com.intellapps.university.app.Main.main(Main.java:203)
Caused by: org.apache.openjpa.lib.jdbc.ReportingSQLException: ORA-01400: cannot insert NULL into (""TEST"".""EXAM"".""TEXT"")
{prepstmnt 15029693 INSERT INTO exam (id, last_updated_by, comments, sustained_on, text, version, course_id, professor_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?) [params=(long) 11, (String) test, (null) null, (Date) 2008-02-27, (Reader) java.io.StringReader@da9ea4, (int) 1, (long) 1, (long) 8]} [code=1400, state=23000]
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator.wrap(LoggingConnectionDecorator.java:192)
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator.access$800(LoggingConnectionDecorator.java:57)
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator$LoggingConnection$LoggingPreparedStatement.executeUpdate(LoggingConnectionDecorator.java:858)
at org.apache.openjpa.lib.jdbc.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:269)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager$CancelPreparedStatement.executeUpdate(JDBCStoreManager.java:1363)
at org.apache.openjpa.jdbc.kernel.PreparedStatementManagerImpl.flushInternal(PreparedStatementManagerImpl.java:97)
... 36 more
NestedThrowables:
java.sql.SQLException: ORA-01400: cannot insert NULL into (""TEST"".""EXAM"".""TEXT"")
at oracle.jdbc.driver.DatabaseError.throwSqlException(DatabaseError.java:112)
at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:331)
at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:288)
at oracle.jdbc.driver.T4C8Oall.receive(T4C8Oall.java:745)
at oracle.jdbc.driver.T4CPreparedStatement.doOall8(T4CPreparedStatement.java:216)
at oracle.jdbc.driver.T4CPreparedStatement.executeForRows(T4CPreparedStatement.java:966)
at oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1170)
at oracle.jdbc.driver.OraclePreparedStatement.executeInternal(OraclePreparedStatement.java:3339)
at oracle.jdbc.driver.OraclePreparedStatement.executeUpdate(OraclePreparedStatement.java:3423)
at org.apache.commons.dbcp.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:102)
at org.apache.openjpa.lib.jdbc.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:269)
at org.apache.openjpa.lib.jdbc.LoggingConnectionDecorator$LoggingConnection$LoggingPreparedStatement.executeUpdate(LoggingConnectionDecorator.java:856)
at org.apache.openjpa.lib.jdbc.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:269)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager$CancelPreparedStatement.executeUpdate(JDBCStoreManager.java:1363)
at org.apache.openjpa.jdbc.kernel.PreparedStatementManagerImpl.flushInternal(PreparedStatementManagerImpl.java:97)
at org.apache.openjpa.jdbc.kernel.PreparedStatementManagerImpl.flush(PreparedStatementManagerImpl.java:73)
at org.apache.openjpa.jdbc.kernel.OperationOrderUpdateManager.flushPrimaryRow(OperationOrderUpdateManager.java:203)
at org.apache.openjpa.jdbc.kernel.OperationOrderUpdateManager.flush(OperationOrderUpdateManager.java:89)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:89)
at org.apache.openjpa.jdbc.kernel.AbstractUpdateManager.flush(AbstractUpdateManager.java:72)
at org.apache.openjpa.jdbc.kernel.JDBCStoreManager.flush(JDBCStoreManager.java:514)
at org.apache.openjpa.kernel.DelegatingStoreManager.flush(DelegatingStoreManager.java:130)
at org.apache.openjpa.kernel.BrokerImpl.flush(BrokerImpl.java:1955)
at org.apache.openjpa.kernel.BrokerImpl.flushSafe(BrokerImpl.java:1853)
at org.apache.openjpa.kernel.BrokerImpl.beforeCompletion(BrokerImpl.java:1771)
at org.apache.openjpa.kernel.LocalManagedRuntime.commit(LocalManagedRuntime.java:81)
at org.apache.openjpa.kernel.BrokerImpl.commit(BrokerImpl.java:1293)
at org.apache.openjpa.kernel.DelegatingBroker.commit(DelegatingBroker.java:861)
at org.apache.openjpa.persistence.EntityManagerImpl.commit(EntityManagerImpl.java:408)
at org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:438)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:662)
at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:632)
at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:319)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:116)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:631)
at com.intellapps.university.service.impl.ServiceDahImpl$$EnhancerByCGLIB$$81ecf35d.insertExam(<generated>)
at com.intellapps.university.service.impl.ServiceImpl.insertExam(ServiceImpl.java:98)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:585)
at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:301)
at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:182)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:149)
at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:106)
at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:171)
at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:204)
at $Proxy17.insertExam(Unknown Source)
at com.intellapps.university.app.Main.testInsertExamWithLongText(Main.java:103)
at com.intellapps.university.app.Main.main(Main.java:203)","org.apache.openjpa.persistence.kernel.common.apps.Lobs:getId()
org.apache.openjpa.persistence.kernel.common.apps.Lobs:getLob()
org.apache.openjpa.persistence.kernel.common.apps.Lobs:Lobs(String, int)
org.apache.openjpa.persistence.kernel.common.apps.Lobs:setLob(String)
org.apache.openjpa.jdbc.sql.OracleDictionary:setNull(PreparedStatement, int, int, Column)"
METHOD,adempiere-3.1.0,1240,2008-05-16T03:03:55.000-05:00,produce produc,"Production Quantity= 2
when is necesary serialize, then the line must be put 1 each line.
in this case the production  cant  apply.
Step reproduce
create row in tab Production header create row for production patio
create row in tab Production plan create row for Patio
create production line click on create/post production button
verify in the production line tab.
give serial in attribute set instance field create other row similar in Patio furniture set product set in movement quantity
click on create/post production button
change click to dont balanced change click on postet button
Regards,
Layda Salas - globalqss http://globalqss.com",org.compiere.acct.Doc_Production:createFacts(MAcctSchema)
FILE,CONFIGURATION,CONFIGURATION-241,2006-12-02T00:03:48.000-06:00,not generate events,"clearProperty() 
 ConfigurationFactory configurationFactory = new ConfigurationFactory();
   
 configurationFactory.setConfigurationURL(configFileURL);
Configuration configuration = ConfigurationFactory.getConfiguration();
configuration.addConfigurationListener(new ConfigurationListener() {
    public void configurationChanged(ConfigurationEvent e) 
{
        System.out.println(e.getPropertyName() + "": "" + e.getPropertyValue());
    }
});
System.out.println(configuration.getProperty(""name.first"")); // prints ""Mike""
 configuration.claerProperty(""name.first"")  ; // no output whatsoever
System.out.println(configuration.getProperty(""name.first"")); // prints ""null""
load configuration information from multiple sources register listener with resulting configuration object
not receive clear property events
receive other events clear property
I've tried setting ""details"" to true, which had no effect.
ConfigurationFactory configurationFactory = new ConfigurationFactory();
URL configFileURL = ... get the config file ...
configurationFactory.setConfigurationURL(configFileURL);
Configuration configuration = ConfigurationFactory.getConfiguration();
configuration.addConfigurationListener(new ConfigurationListener() { public void configurationChanged(ConfigurationEvent e)
{
System.out.println(e.getPropertyName() + "": "" + e.getPropertyValue());
}
});
System.out.println(configuration.getProperty(""name.first"")); // prints ""Mike"" configuration.claerProperty(""name.first"")); // no output whatsoever
System.out.println(configuration.getProperty(""name.first"")); // prints ""null""","org.apache.commons.configuration.TestCompositeConfiguration
org.apache.commons.configuration.CompositeConfiguration"
FILE,CONFIGURATION,CONFIGURATION-332,2008-07-04T15:54:10.000-05:00,not persist properties add through DataConfiguration,"public void testSaveWithDataConfiguration() throws ConfigurationException
{
    File file = new File(""target/testsave.properties"");
    if (file.exists()) {
        assertTrue(file.delete());
    }

    PropertiesConfiguration config = new PropertiesConfiguration(file);

    DataConfiguration dataConfig = new DataConfiguration(config);

    dataConfig.setProperty(""foo"", ""bar"");
    assertEquals(""bar"", config.getProperty(""foo""));
    config.save();

    // reload the file
    PropertiesConfiguration config2 = new PropertiesConfiguration(file);
    assertFalse(""empty configuration"", config2.isEmpty());
}
There is a regression in Commons Configuration with PropertiesConfiguration wrapped into a DataConfiguration.
add through DataConfiguration
Commons Configuration 1.4 wasn't affected by this issue.
fail on last assertion
public void testSaveWithDataConfiguration() throws ConfigurationException
{
File file = new File(""target/testsave.
properties"");
if (file.exists()) { assertTrue(file.delete());
}
PropertiesConfiguration config = new PropertiesConfiguration(file);
DataConfiguration dataConfig = new DataConfiguration(config);
dataConfig.setProperty(""foo"", ""bar"");
assertEquals(""bar"", config.getProperty(""foo""));
config.save();
// reload the file
PropertiesConfiguration config2 = new PropertiesConfiguration(file);
assertFalse(""empty configuration"", config2.isEmpty());
}","org.apache.commons.configuration.TestPropertiesConfiguration
org.apache.commons.configuration.DataConfiguration"
FILE,CONFIGURATION,CONFIGURATION-347,2008-11-05T21:06:22.000-06:00,iterate over keys of file-based configuration cause ConcurrentModificationException,"getKeys()
return iterator in getKeys() method
This behavior is very confusing because ConcurrentModificationExceptions are typically related to multi-threading access.
perform iteration access configuration access only instance","org.apache.commons.configuration.TestFileConfiguration
org.apache.commons.configuration.AbstractFileConfiguration"
FILE,CONFIGURATION,CONFIGURATION-408,2010-02-11T01:01:05.000-06:00,save URL as property value,"public static void main(String[] args)
  {
    try
    {

      PropertiesConfiguration config = new PropertiesConfiguration();     

      File newProps = new File(""foo.properties"");

      config.setProperty(""foo"", ""http://www.google.com/"");     

      config.save(newProps);

      

    }
    catch (Exception e){}
  }
save URL as property value
ie:
foo = http:\/\/www.google.com\/
public static void main(String[] args)
{ try
{
PropertiesConfiguration config = new PropertiesConfiguration();
File newProps = new File(""foo.properties"");
config.setProperty(""foo"", ""http://www.google.com/"");
config.save(newProps);
} catch (Exception e){}
}",org.apache.commons.configuration.TestPropertiesConfiguration
METHOD,math,MATH-1021,2013-08-10T00:00:22.000-05:00,suffer from integer overflow,"HypergeometricDistribution.sample()  
 {code}
 import org.apache.commons.math3.distribution.HypergeometricDistribution;

public class Foo {
  public static void main(String[] args) {
    HypergeometricDistribution a = new HypergeometricDistribution(
        43130568, 42976365, 50);
    System.out.printf(""%d %d%n"", a.getSupportLowerBound(), a.getSupportUpperBound()); // Prints ""0 50""
    System.out.printf(""%d%n"",a.sample());                                             // Prints ""-50""
  }
}
 {code}

  HypergeometricDistribution.getNumericalMean()  
 {code}
 return (double) (getSampleSize() * getNumberOfSuccesses()) / (double) getPopulationSize();
{code}
 
 {code}
 return getSampleSize() * ((double) getNumberOfSuccesses() / (double) getPopulationSize());
{code}
Hi, I have an application which broke when ported from commons math 2.2 to 3.2.
return sample use with large integer values
{code}
import org.apache.commons.math3.distribution.HypergeometricDistribution;
public class Foo {
  public static void main(String[] args) {
    HypergeometricDistribution a = new HypergeometricDistribution(
        43130568, 42976365, 50);
    System.out.printf(""%d %d%n"", a.getSupportLowerBound(), a.getSupportUpperBound()); // Prints ""0 50""
    System.out.printf(""%d%n"",a.sample());                                             // Prints ""-50""
  }
}
{code}
In the debugger, I traced it as far as an integer overflow in HypergeometricDistribution.getNumericalMean() -- instead of doing
{code}
return (double) (getSampleSize() * getNumberOfSuccesses()) / (double) getPopulationSize();
{code}
it could do:
{code}
return getSampleSize() * ((double) getNumberOfSuccesses() / (double) getPopulationSize());
{code}
This seemed to fix it, based on a quick test.",org.apache.commons.math3.distribution.HypergeometricDistribution:getNumericalMean()
METHOD,math,MATH-358,2010-03-24T17:25:37.000-05:00,go past specified end of integration range,"{code}
   public void testMissedEvent() throws IntegratorException, DerivativeException {
          final double t0 = 1878250320.0000029;
          final double t =  1878250379.9999986;
          FirstOrderDifferentialEquations ode = new FirstOrderDifferentialEquations() {
            
            public int getDimension() {
                return 1;
            }
            
            public void computeDerivatives(double t, double[] y, double[] yDot)
                throws DerivativeException {
                yDot[0] = y[0] * 1.0e-6;
            }
        };

        DormandPrince853Integrator integrator = new DormandPrince853Integrator(0.0, 100.0,
                                                                               1.0e-10, 1.0e-10);

        double[] y = { 1.0 };
        integrator.setInitialStepSize(60.0);
        double finalT = integrator.integrate(ode, t0, y, t, y);
        Assert.assertEquals(t, finalT, 1.0e-6);
    }

 {code}
End of integration range in ODE solving is handled as an event.
In some cases, numerical accuracy in events detection leads to error in events location.
cover 60s cover integration range in fact
{code}
public void testMissedEvent() throws IntegratorException, DerivativeException {
final double t0 = 1878250320.0000029;
final double t =  1878250379.9999986;
FirstOrderDifferentialEquations ode = new FirstOrderDifferentialEquations() {
public int getDimension() {
return 1;
}
public void computeDerivatives(double t, double[] y, double[] yDot)
throws DerivativeException {
yDot[0] = y[0] * 1.0e-6;
}
};
DormandPrince853Integrator integrator = new DormandPrince853Integrator(0.0, 100.0,
1 0e-10, 1.0e-10);
double[] y = { 1.0 };
        integrator.setInitialStepSize(60.0);
        double finalT = integrator.integrate(ode, t0, y, t, y);
        Assert.assertEquals(t, finalT, 1.0e-6);
    }
{code}","org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator:integrate(FirstOrderDifferentialEquations, double, double[], double, double[])
org.apache.commons.math.ode.nonstiff.RungeKuttaIntegrator:integrate(FirstOrderDifferentialEquations, double, double[], double, double[])"
METHOD,math,MATH-60,2006-05-14T04:20:21.000-05:00,illogical result,"Fraction parse(String source, 
ParsePostion pos)  class ProperFractionFormat  
 ProperFractionFormat properFormat = new ProperFractionFormat();
result = null;
String source = ""1 -1 / 2"";
ParsePosition pos = new ParsePosition(0);

//Test 1 : fail 
 public void testParseNegative(){
 
   String source = ""-1 -2 / 3"";
   ParsePosition pos = new ParsePosition(0);

   Fraction actual = properFormat.parse(source, pos);
   assertNull(actual);
}

// Test2: success
 public void testParseNegative(){
 
   String source = ""-1 -2 / 3"";
   ParsePosition pos = new ParsePosition(0);

   Fraction actual = properFormat.parse(source, pos);  // return Fraction 1/3
   assertEquals(1, source.getNumerator());
   assertEquals(3, source.getDenominator());
}

 
 parse(String, ParsePosition)
Hello,
I find illogical returned result from function ""Fraction parse(String source,
ParsePostion pos)"" (in class ProperFractionFormat of the Fraction Package) of the Commons Math library.
see following code segment for more details
""
ProperFractionFormat properFormat = new ProperFractionFormat();
result = null;
String source = ""1 -1 / 2"";
ParsePosition pos = new ParsePosition(0);
//Test 1 : fail public void testParseNegative(){
String source = ""-1 -2 / 3"";
ParsePosition pos = new ParsePosition(0);
Fraction actual = properFormat.parse(source, pos);
assertNull(actual);
}
// Test2: success public void testParseNegative(){
String source = ""-1 -2 / 3"";
ParsePosition pos = new ParsePosition(0);
Fraction actual = properFormat.parse(source, pos);  // return Fraction 1/3 assertEquals(1, source.getNumerator());
assertEquals(3, source.getDenominator());
}
""
pass in following inputs
return Fraction for inputs
parse numberator/ denominator properly incase input string provide invalid numerator/denominator
Thank you!","org.apache.commons.math.fraction.ProperFractionFormat:parse(String, ParsePosition)"
METHOD,math,MATH-949,2013-03-15T18:11:56.000-05:00,report iterations,"LevenbergMarquardtOptimizer.getIterations()     BaseOptimizer.incrementEvaluationsCount()

 
 {noformat}
     @Test
    public void testGetIterations() {
        // setup
        LevenbergMarquardtOptimizer otim = new LevenbergMarquardtOptimizer();

        // action
        otim.optimize(new MaxEval(100), new Target(new double[] { 1 }),
                new Weight(new double[] { 1 }), new InitialGuess(
                        new double[] { 3 }), new ModelFunction(
                        new MultivariateVectorFunction() {
                            @Override
                            public double[] value(double[] point)
                                    throws IllegalArgumentException {
                                return new double[] { FastMath.pow(point[0], 4) };
                            }
                        }), new ModelFunctionJacobian(
                        new MultivariateMatrixFunction() {
                            @Override
                            public double[][] value(double[] point)
                                    throws IllegalArgumentException {
                                return new double[][] { { 0.25 * FastMath.pow(
                                        point[0], 3) } };
                            }
                        }));

        // verify
        assertThat(otim.getEvaluations(), greaterThan(1));
        assertThat(otim.getIterations(), greaterThan(1));
    }

 {noformat}
not report correct number of iterations
A quick look at the code shows that only SimplexOptimizer calls BaseOptimizer.incrementEvaluationsCount()
put test case
{noformat}
    @Test
    public void testGetIterations() {
        // setup
        LevenbergMarquardtOptimizer otim = new LevenbergMarquardtOptimizer();
// action
otim.optimize(new MaxEval(100), new Target(new double[] { 1 }),
new Weight(new double[] { 1 }), new InitialGuess(
new double[] { 3 }), new ModelFunction(
new MultivariateVectorFunction() {
@Override
public double[] value(double[] point)
throws IllegalArgumentException {
return new double[] { FastMath.pow(point[0], 4) };
}
}), new ModelFunctionJacobian(
new MultivariateMatrixFunction() {
@Override
public double[][] value(double[] point)
throws IllegalArgumentException {
return new double[][] { { 0.25 * FastMath.pow(
point[0], 3) } };
}
}));
// verify
        assertThat(otim.getEvaluations(), greaterThan(1));
        assertThat(otim.getIterations(), greaterThan(1));
    }
{noformat}","org.apache.commons.math3.optim.nonlinear.scalar.gradient.NonLinearConjugateGradientOptimizer:doOptimize()
org.apache.commons.math3.optim.nonlinear.scalar.noderiv.CMAESOptimizer:doOptimize()
org.apache.commons.math3.optim.nonlinear.vector.jacobian.GaussNewtonOptimizer:doOptimize()
org.apache.commons.math3.optim.nonlinear.scalar.noderiv.SimplexOptimizer:doOptimize()
org.apache.commons.math3.optim.BaseOptimizer:BaseOptimizer(ConvergenceChecker<PAIR>)
org.apache.commons.math3.optim.nonlinear.scalar.noderiv.PowellOptimizer:doOptimize()
org.apache.commons.math3.optim.nonlinear.vector.jacobian.LevenbergMarquardtOptimizer:doOptimize()"
CLASS,mahout-0.8,MAHOUT-1314,2013-08-18T09:07:48.000-05:00,throw NullPointerException set REDUCE_STREAMING_KMEANS to true,"return input.getCentroid();  
 input.getCentroid()  clone();
set REDUCE_STREAMING_KMEANS option to true fail with NullPointerException
the problem is in the reduce method itself: on line 60 ( return input.getCentroid(); )
similar to line 81.
java.lang.NullPointerException
at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:191)
at org.apache.mahout.math.random.WeightedThing.<init>(WeightedThing.java:31)
at org.apache.mahout.math.neighborhood.BruteSearch.searchFirst(BruteSearch.java:133)
at org.apache.mahout.clustering.ClusteringUtils.estimateDistanceCutoff(ClusteringUtils.java:100)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansThread.call(StreamingKMeansThread.java:64)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:66)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:1)
at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:176)
at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:650)
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:418)
at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:260)
happen time set REDUCE_STREAMING_KMEANS to true set time to true",core.src.main.java.org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer
CLASS,mahout-0.8,MAHOUT-1358,2013-11-18T01:58:22.000-06:00,throw IllegalArgumentException set REDUCE_STREAMING_KMEANS to true,"{Code}

 {Code}

  StreamingKMeansThread.call()

 {Code}
     Iterator<Centroid> datapointsIterator = datapoints.iterator();
    if (estimateDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
      List<Centroid> estimatePoints = Lists.newArrayListWithExpectedSize(NUM_ESTIMATE_POINTS);
      while (datapointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) {
        estimatePoints.add(datapointsIterator.next());
      }
      estimateDistanceCutoff = ClusteringUtils.estimateDistanceCutoff(estimatePoints, searcher.getDistanceMeasure());
    }

    StreamingKMeans clusterer = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);
    while (datapointsIterator.hasNext()) {
      clusterer.cluster(datapointsIterator.next());
    }
{Code}
throw following error for running cluster with REDUCE_STREAMING_KMEANS
{Code}
java.lang.IllegalArgumentException: Must have nonzero number of training and test vectors.
Asked for %.1f %% of %d vectors for test [10.000000149011612, 0]
at com.google.common.base.Preconditions.checkArgument(Preconditions.java:120)
at org.apache.mahout.clustering.streaming.cluster.BallKMeans.splitTrainTest(BallKMeans.java:176)
at org.apache.mahout.clustering.streaming.cluster.BallKMeans.cluster(BallKMeans.java:192)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.getBestCentroids(StreamingKMeansReducer.java:107)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:73)
at org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer.reduce(StreamingKMeansReducer.java:37)
at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:177)
at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:649)
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:418)
at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:398)
{Code}
cause issue
{Code}
Iterator<Centroid> datapointsIterator = datapoints.iterator();
if (estimateDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
List<Centroid> estimatePoints = Lists.newArrayListWithExpectedSize(NUM_ESTIMATE_POINTS);
while (datapointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) { estimatePoints.add(datapointsIterator.next());
} estimateDistanceCutoff = ClusteringUtils.estimateDistanceCutoff(estimatePoints, searcher.getDistanceMeasure());
}
StreamingKMeans clusterer = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);
while (datapointsIterator.hasNext()) { clusterer.cluster(datapointsIterator.next());
}
{Code}
The code is using the same iterator twice, and it fails on the second use for obvious reasons.",core.src.main.java.org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansThread
