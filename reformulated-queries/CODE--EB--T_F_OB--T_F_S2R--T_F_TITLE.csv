Dataset,System,Bug ID,Creation Date,Title,Description,Ground Truth
FILE,swt-3.1,104150,2005-07-16T19:58:00.000-05:00,click on empty space click on grid lines,"table.getLinesVisible()  
 table.setLinesVisible(true)
use table cursor have potential of table regions have kinds of table regions separate table cursor from table selection
No matter which part of the table the user clicks on, the table cursor should follow the table selection as closely as possible if the selection is changed as a result of the click.
snippet with added table.setLinesVisible(true)",org.eclipse.swt.custom.TableCursor
FILE,swt-3.1,86000,2005-02-21T14:47:00.000-06:00,produce invalid JPEG images,"package com.ibm.test.image;

import org.eclipse.swt.*;
import org.eclipse.swt.graphics.*;

public class ImageLoaderTest {
		
	public static void main(String[] args) {
		ImageLoader loader;
		String dir=""c:\\image-problems\\"";
		String files[]={
				""s34i3p04"",
				""s34n3p04"",
				""s35i3p04"",
				""s35n3p04"",
				""s36i3p04"",
				""s36n3p04"",
				""s37i3p04"",
				""s37n3p04"",
				""s38i3p04"",
				""s38n3p04"",
				""s39i3p04"",
				""s39n3p04""
		};
		
		try {
			for (int i=0; i<files.length; i++) {
			String filein  = dir+files[i]+"".png"";
			String fileout = dir+files[i]+"".jpg"";
			
			loader = new ImageLoader();
			loader.load(filein);
			loader.save(fileout,SWT.IMAGE_JPEG);
			}
		} catch (SWTException e) {
		  e.printStackTrace();
		}
	}
}
produce bad JPG images
test as JPEG
Many files were tested and the majority 
 did produced the proper JPG images as expected.",org.eclipse.swt.internal.image.JPEGFileFormat
FILE,swt-3.1,88829,2005-03-22T20:41:00.000-06:00,not fire enough Move events,"Table.setColumnOrder(new int[] {4,1,2,3,0});
start with columns
do Table.setColumnOrder
swap positions fire SWT.Move events for columns
-> but Move should have been fired for all of the columns since the width of the first displayed column changed, and therefore all of the other columns are auto-shifted accordingly",org.eclipse.swt.widgets.Table
FILE,swt-3.1,97651,2005-05-31T14:43:00.000-05:00,mark cheese,"Tree.redraw() 
 public static void main(String[] args) {
	final Display display = new Display();
	final Shell shell = new Shell(display);
	shell.setBounds(10, 10, 300, 300);
	final Tree tree = new Tree(shell, SWT.NONE);
	tree.setBounds(10, 10, 200, 200);
	new TreeItem(tree, SWT.NONE).setText(""pre-root"");
	TreeItem root1 = new TreeItem(tree, SWT.NONE);
	root1.setText(""root"");
	TreeItem child = new TreeItem(root1, SWT.NONE);
	child.setText(""child"");
	Button button = new Button(shell, SWT.PUSH);
	button.setBounds(230,10,30,30);
	button.addSelectionListener(new SelectionAdapter() {
		public void widgetSelected(SelectionEvent e) {
			tree.redraw();
		}
	});
	root1.setExpanded(true);
	tree.setInsertMark(root1, false);
	shell.open();
	while (!shell.isDisposed()) {
		if (!display.readAndDispatch()) display.sleep();
	}
	display.dispose();
}
run snippet
be under root item
collapse root item
except for pointy ends
This line should not go away because it belongs to the ""root"" item, not to the ""child"" item, but if it really wants to go away, then its end tips should not be left
press button to right do Tree.redraw() note Tree.redraw()
expand root item copy insert mark to child item copy insert mark to initial location","org.eclipse.swt.dnd.TreeDragUnderEffect
org.eclipse.swt.widgets.Tree"
METHOD,lang,LANG-363,2007-10-23T07:12:48.000-05:00,not escape /' into '\/ make IE render page,"document.getElementById(""test"")   document.getElementById(""test"") 
  
 String s = ""<script>alert('aaa');</script>"";
  String str = org.springframework.web.util.JavaScriptUtils.javaScriptEscape(s);
  System.out.println(""Spring JS Escape : ""+str);
  str = org.apache.commons.lang.StringEscapeUtils.escapeJavaScript(s);
  System.out.println(""Apache Common Lang JS Escape : ""+ str);
If Javascripts including'/', IE will parse the scripts uncorrectly, actually '/' should be escaped to '\/'.
value = '<script>alert(\'aaa\');</script>';this expression will make IE render page uncorrect, it should be document.getElementById(""test"").
find difference run below codes","org.apache.commons.lang.StringEscapeUtils:escapeJavaStyleString(Writer, String, boolean)"
FILE,AMQP,AMQP-340,2013-11-18T09:41:01.000-06:00,not consider wrong RabbitMQ credentials as fatal error,"start()  
 SimpleMessageListenerContainer.run()
connect AmqpInboundChannelAdapter to RabbitMQ not detect real reason continue real reason restart consumer in endless loop
return as AmqpInboundChannelAdapter user return after pause
It would be nice to have a notification (exception) about wrong credentials right away (there is a comprehensive rabbit client exception that gets swallowed in SimpleMessageListenerContainer.run())","org.springframework.amqp.rabbit.listener.BlockingQueueConsumer
org.springframework.amqp.rabbit.listener.MessageListenerContainerLifecycleIntegrationTests
org.springframework.amqp.rabbit.support.RabbitExceptionTranslator"
CLASS,hibernate-3.5.0b2,HHH-4617,2009-11-28T11:42:08.000-06:00,use materialized blobs with Postgresql cause error,"@Lob
have entity with byte [ ] property annotated have entity as @Lob lazy fetch type read OID value instead_of bytes read OID value under given oid be of type oid read column in application
create oid column
The proper behavior for dealing in PostgreSQL (and this behavior is in Hibernate 3.4) is to use oids.","org.hibernate.type.CharacterArrayClobType
org.hibernate.type.MaterializedClobType
org.hibernate.type.PrimitiveCharacterArrayClobType
org.hibernate.type.WrappedMaterializedBlobType
org.hibernate.type.MaterializedBlobType
org.hibernate.test.lob.MaterializedBlobTest
org.hibernate.type.BlobType
org.hibernate.type.ClobType
org.hibernate.test.lob.ClobLocatorTest
org.hibernate.dialect.Dialect
org.hibernate.cfg.annotations.SimpleValueBinder
org.hibernate.dialect.PostgreSQLDialect
org.hibernate.Hibernate"
FILE,DATACMNS,DATACMNS-233,2012-09-14T07:38:12.000-05:00,DomainClassConverter should gracefully return null for null sources or empty strings,"@javax.validation.constraints.NotNull  @javax.persistence.ManyToOne
imagine use case have Order domain class have ManyToOne reference to customer have Order domain class to customer
post new Order
I think it should not try to convert to Domain class if id is null or empty.","org.springframework.data.repository.support.DomainClassConverterUnitTests
org.springframework.data.repository.support.DomainClassConverter"
CLASS,derby-10.9.1.0,DERBY-6053,2013-01-25T09:02:53.000-06:00,Client should use a prepared statement rather than regular statement for Connection.setTransactionIsolation,"client.am.Connection setTransactionIsolation()   setTransactionIsolation()   
 private Statement setTransactionIsolationStmt = null;
 
  
 createStatementX(java.sql.ResultSet.TYPE_FORWARD_ONLY,
                            java.sql.ResultSet.CONCUR_READ_ONLY,
                            holdability());
 
 private void setTransactionIsolationX(int level)
 
 setTransactionIsolationStmt.executeUpdate(
                ""SET CURRENT ISOLATION = "" + levelString);


 
   

import java.sql.*;
import java.net.*;
import java.io.*;
import org.apache.derby.drda.NetworkServerControl;

/**
 * Client template starts its own NetworkServer and runs some SQL against it.
 * The SQL or JDBC API calls can be modified to reproduce issues
 * 
 */public class SetTransactionIsolation {
    public static Statement s;
    
    public static void main(String[] args) throws Exception {
        try {
            // Load the driver. Not needed for network server.
            
            Class.forName(""org.apache.derby.jdbc.ClientDriver"");
            // Start Network Server
            startNetworkServer();
            // If connecting to a customer database. Change the URL
            Connection conn = DriverManager
                    .getConnection(""jdbc:derby://localhost:1527/wombat;create=true"");
            // clean up from a previous run
            s = conn.createStatement();
            try {
                s.executeUpdate(""DROP TABLE T"");
            } catch (SQLException se) {
                if (!se.getSQLState().equals(""42Y55""))
                    throw se;
            }

            for (int i = 0; i < 50000; i++) {
		conn.setTransactionIsolation(Connection.TRANSACTION_REPEATABLE_READ);
		conn.setTransactionIsolation(Connection.TRANSACTION_SERIALIZABLE);

	    }
            
            // rs.close();
            // ps.close();
            runtimeInfo();
            conn.close();
            // Shutdown the server
            shutdownServer();
        } catch (SQLException se) {
            while (se != null) {
                System.out.println(""SQLState="" + se.getSQLState()
                        + se.getMessage());
                se.printStackTrace();
                se = se.getNextException();
            }
        }
    }
    
    /**
     * starts the Network server
     * 
     */
    public static void startNetworkServer() throws SQLException {
        Exception failException = null;
        try {
            
            NetworkServerControl networkServer = new NetworkServerControl(
                    InetAddress.getByName(""localhost""), 1527);
            
            networkServer.start(new PrintWriter(System.out));
            
            // Wait for the network server to start
            boolean started = false;
            int retries = 10; // Max retries = max seconds to wait
            
            while (!started && retries > 0) {
                try {
                    // Sleep 1 second and then ping the network server
                    Thread.sleep(1000);
                    networkServer.ping();
                    
                    // If ping does not throw an exception the server has
                    // started
                    started = true;
                } catch (Exception e) {
                    retries--;
                    failException = e;
                }
                
            }
            
            // Check if we got a reply on ping
            if (!started) {
                throw failException;
            }
        } catch (Exception e) {
            SQLException se = new SQLException(""Error starting network  server"");
            se.initCause(failException);
            throw se;
        }
    }
    
    public static void shutdownServer() throws Exception {
        NetworkServerControl networkServer = new NetworkServerControl(
                InetAddress.getByName(""localhost""), 1527);
        networkServer.shutdown();
    }
    
    public static void runtimeInfo() throws Exception {
        NetworkServerControl networkServer = new NetworkServerControl(
                InetAddress.getByName(""localhost""), 1527);
        System.out.println(networkServer.getRuntimeInfo());
    }
    
}
It would be better for performance and also for avoid possible garbage collection issues, to have a single prepared statement with a parameter marker.
show repeated calls to setTransactionIsolation",java.client.org.apache.derby.client.am.Connection
METHOD,openjpa-2.0.1,OPENJPA-1627,2010-04-12T05:21:13.000-05:00,use wrong columns in SQL,"@OneToMany(fetch = FetchType.LAZY, cascade = {CascadeType.PERSIST})
	@ElementJoinColumn(name=""maccno"", referencedColumnName=""maccno"")
	@OrderBy(value = ""_id._processDate ASC, _id._tranSequenceNumber ASC"")
	private LinkedList<Transaction> _transactions;



      
 @EmbeddedId
	private TransactionId _id;
	
	 @Column(name = ""mtrancde"")
	private int _transactionCode;
	
	 @Column(name = ""mamount"")
	private BigDecimal _amount;
	
	 @Column(name = ""mdesc"")
	private String _description;
	


	 @Column(name = ""mactdate"")
	private Date _actualDate;
	
	 @Column(name = ""mbranch"")
	private int _branch;



   
 @Embeddable
public class TransactionId  
 @Column(name = ""maccno"")
	private String _accountNumber;
	
	 @Column(name = ""mprocdate"")
	private Date _processDate;
	
	 @Column(name = ""mtranseqno"")
	private int _tranSequenceNumber;
The problem is that the order by in the generated SQL is for columns mapped in the transaction entity NOT the TransacionId as expected.
have following fragment ....
do on columns map in transaction
(no idea why it chose mamount, mbranch)
The last line should be:","org.apache.openjpa.jdbc.meta.JDBCRelatedFieldOrder:order(Select, ClassMapping, Joins)"
CLASS,zookeeper-3.4.5,ZOOKEEPER-1781,2013-10-03T20:19:27.000-05:00,set snapCount,"int randRoll = r.nextInt(snapCount/2);
{code}
set snapCount
In source code,  it maybe be supposed that snapCount must be 2 or more:",src.java.main.org.apache.zookeeper.server.ZooKeeperServer
CLASS,argouml-0.22,4200,2006-05-11T23:30:25.000-05:00,vanish in new package,"Model folder;
vanish in package
get defect
stand on main Model folder
click from droped meniu add package choose from droped meniu add package
rename package
release over package
the package remains unchanged (i expected it should become expandable like a
diagram in the tree);
see diagrams in selected package Properties owned Elements","org.argouml.ui.explorer.PerspectiveManager
org.argouml.ui.explorer.rules.GoModelElementToBehavior"
CLASS,solr-4.4.0,SOLR-5296,2013-10-02T00:20:01.000-05:00,create collection with implicit router add shard ranges to shard,"{quote}
 {quote}
create collection with implicit router add shard ranges to shard
use Example a from SolrCloud wiki
Collections with implicit router should not have shard ranges at all.
do right thing",solr.core.src.java.org.apache.solr.cloud.Overseer
FILE,DATAMONGO,DATAMONGO-505,2012-08-14T03:07:56.000-05:00,not work for collection values,"class Entity {









  Long id;




  @DBRef




  Property property;




}









 class Property {




  Long id;




}









 interface EntityRepository extends Repository<Entity, Long> {









  Entity findByPropertyIn(Property... property);




}






  findByProperty()
have following scenario
not translate given array into collection
treat value create DBRef
We need to unwrap the elements and convert them into DBRef instances one by one.","org.springframework.data.mongodb.repository.query.ConvertingParameterAccessor
org.springframework.data.mongodb.repository.query.ConvertingParameterAccessorUnitTests"
FILE,DATAMONGO,DATAMONGO-392,2012-02-07T04:28:15.000-06:00,update object not write type information for objects,"MappingMongoConverter.writeInternal(...)   addCustomTypeIfNecessary(...)     convertToMongoType(...)   removeTypeInfoRecursively(...)
use complex domain model consist complex domain model of instantiable domain classes
use 1.0.0
read from database store m5 version with object store type information with object
break application break RELEASE version save objects without type information read back to java model
call addCustomTypeIfNecessary(...) in turn call MappingMongoConverter.writeInternal(...) method in turn put type information into DBObject put addCustomTypeIfNecessary(...) into DBObject
call removeTypeInfoRecursively(...) during execution save under _ class key
The second point is that there should be a way to persist the type information inferred from runtime along the persisted object and not just the class definition.","org.springframework.data.mongodb.core.MongoTemplateTests
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-647,2013-04-09T17:29:02.000-05:00,ignore @Field annotation for field alias,"@Field(""sr"")
 
 List<Answer> findByQuestionIdOrderByScoreDesc(String questionId)
create method use query approach
have field inside Answer object call score annotate score
When the query is run, the database attempts to sort the results by ""score"" rather than my ""sr"" field name.",org.springframework.data.mongodb.core.convert.QueryMapperUnitTests
FILE,DATAMONGO,DATAMONGO-987,2014-07-14T12:01:52.000-05:00,get data use MongoTemplate problem with lazy loading,"@Document 
 @Document




class Parent {




     @Id




     private String id;




     private String name;




     @DBref(lazy=true)




     private Child child;









    // getters and setters ommited




}






 
 @Document




class Child {




      @Id




       private String id;




       private String name;




      //getters and setters ommited




}






 
 Parent parent = new Parent();




parent.setName(""Daddy"");




mongoTemplate.save(parent); //ok, it is persisted like we expected.




// Than we try to load this same entity from the database




Criteria criteria = Criteria.where(""_id"").is(parent.getId());




Parent persisted = mongoTemplate.findOne(new Query(criteria), Parent.class);




// The child attribute should be null, right?




assertNull(persisted.getChild()); // it fails
call Parent call child reference on entity class
The following situation should never happen:
mongoTemplate.save(parent); //ok, it is persisted like we expected.
load same entity from database
// The child attribute should be null, right?
attach project with junit test reproduce project with junit test","org.springframework.data.mongodb.core.convert.MappingMongoConverter
org.springframework.data.mongodb.core.convert.DbRefMappingMongoConverterUnitTests"
FILE,DATAMONGO,DATAMONGO-1088,2014-11-07T03:08:58.000-06:00,not remove _ class property on collection,"@Query(value = ""{ embedded : { $in : ?0} }"")




	List<Foo> findByEmbeddedIn2(Collection<EmbeddedObject> c)
generate incorrect query
Query should be without _class property e.g.:
attach test project demonstrate bug","org.springframework.data.mongodb.core.convert.MappingMongoConverter
org.springframework.data.mongodb.core.MongoTemplate"
FILE,DATAMONGO,DATAMONGO-1123,2014-12-17T09:39:36.000-06:00,not return matching elements return max of documents,"public GeoResults<MyObject> findByTypeAndLocationNear(MyObjectType type, Point p, Distance distance) {




   final NearQuery nearQuery = NearQuery.near(p).maxDistance(distance);




   log.info(""{}"",nearQuery.toDBObject());




   return mongoTemplate.geoNear(nearQuery, MyObject.class);




}






   
 {@link GeoResults}   {@link NearQuery}
have following query
I expect 1000 ""matching"" documents But i only get 100.
restrict result",org.springframework.data.mongodb.core.MongoOperations
FILE,DATAMONGO,DATAMONGO-1126,2014-12-21T06:03:21.000-06:00,keyword query findByInId with pageable,"getTotalElements()   getTotalPages()  
 @Document




public class Item {









    @Id




    private String id;




    private String type;




}












 public interface ItemRepository extends MongoRepository<Item, String> {









    Page<Item> findByIdIn(Collection ids, Pageable pageable);




    Page<Item> findByTypeIn(Collection types, Pageable pageable);




}












 @RunWith(SpringJUnit4ClassRunner.class)




@ContextConfiguration(classes = {MongoDbConfig.class})




@TransactionConfiguration(defaultRollback = false)




public class TestPageableIdIn {









    @Autowired




    private ItemRepository itemRepository;




    




    private List<String> allIds = new LinkedList<>();









    @Before




    public void setUp() {




        itemRepository.deleteAll();




        String[] types = {""SWORD"", ""SHIELD"", ""ARMOUR""};









        // 10 items per type




        for (String type : types) {




            for (int i = 0; i < 10; i++) {




                String id = UUID.randomUUID().toString();




                allIds.add(id);




                itemRepository.save(new Item(id, type));




            }




        }




    }









    @Test




    public void testPageableIdIn() {




        




        Pageable pageable = new PageRequest(0, 5);




        




        // expect 5 Items returned, total of 10 Items(SWORDS) in 2 Pages




        Page<Item> results = itemRepository.findByTypeIn(Arrays.asList(""SWORD""), pageable);




        Assert.assertEquals(5, results.getContent().size());




        Assert.assertEquals(10, results.getTotalElements());




        Assert.assertEquals(2, results.getTotalPages());




        




        // expect 5 Items returned, total of 30 Items in 6 Pages




        results = itemRepository.findByIdIn(allIds, pageable);




        Assert.assertEquals(5, results.getContent().size());




        Assert.assertEquals(30, results.getTotalElements()); // this is returning 0




        Assert.assertEquals(6, results.getTotalPages());     // this is returning 0




    }




}
use with identifiers make query pageable
get other page
use for testing
create types in total create types per types create items in total create items per types
// expect 5 Items returned, total of 10 Items(SWORDS) in 2 Pages
// expect 5 Items returned, total of 30 Items in 6 Pages
return //
return //","org.springframework.data.mongodb.repository.Person
org.springframework.data.mongodb.repository.query.AbstractMongoQueryUnitTests
org.springframework.data.mongodb.core.MongoOperations
org.springframework.data.mongodb.core.MongoTemplate
org.springframework.data.mongodb.repository.query.AbstractMongoQuery"
FILE,DATAMONGO,DATAMONGO-1263,2015-07-30T09:03:41.000-05:00,involve generic types,"class Book  
 class AbstractProduct  
 class ProductWrapper    
 class Catalog
involve generic types not infer type information at startup time result in missing indexes
define class Catalog with list
infer type infromation from ProductWrapper class definition inherit from AbstractProduct create index name inside catalog define on Book class not create Book class as Spring data Mongo
Spring Data MongoDB should be able to infer type information from the list declaration ( List<ProductWrapper<Book>> ), becoming aware that Catalog contains a list of Books, hence indexes defined on Book should be created.
define wrapper class as ProductWrapper<T> create indexes on Catalog.books2.content.","org.springframework.data.mongodb.core.index.MongoPersistentEntityIndexResolver
org.springframework.data.mongodb.core.index.MongoPersistentEntityIndexResolverUnitTests"
FILE,DATAMONGO,DATAMONGO-1406,2016-04-04T18:59:49.000-05:00,not use @Field field name nest fields with nested keywords nest fields in combination,";






@Document(collection = ""Computer"")




public class Computer




{




   @Id




   private String _id;









   private String batchId;









  @Field(""stat"")




   private String status;









   @Field(""disp"")




   private List<Monitor> displays;









   //setters and getters




}









public class Monitor {




   @Field(""res"")




   private String resolution;









  // setters/getters




}






   
 protected <S, T> List<T> doFind(String collectionName, DBObject query, DBObject fields, Class<S> entityClass,




			CursorPreparer preparer, DbObjectCallback<T> objectCallback)









 DBObject mappedQuery = queryMapper.getMappedObject(query, entity);






  @Field   
  
  
 
  
  @Field
have document class
call in MongoTemplate.java
resolve to stat
submit to mongo
not get data call resolution
note query input to getMappedObject
convert to value
The correct query from getMappedObject should be:
operate queries on fields","org.springframework.data.mongodb.core.convert.QueryMapper
org.springframework.data.mongodb.core.convert.QueryMapperUnitTests"
METHOD,eclipse-2.0,31779,2003-02-13T09:55:00.000-06:00,[resources] UnifiedTree should ensure file/folder exists,"getStat()
find new file from file system
not exist for different reasons
execute refresh operations appear to user
find file at first moment find file in file system assume file at first moment assume file in file system create corresponding resource in workspace
not find folder corresponding at second refresh not find folder corresponding in file system not find folder corresponding to resource remove from workspace","org.eclipse.core.internal.localstore.UnifiedTree:addChildrenFromFileSystem(UnifiedTreeNode, String, Object[], int)
org.eclipse.core.internal.localstore.UnifiedTree:createChildNodeFromFileSystem(UnifiedTreeNode, String, String)"
CLASS,jedit-4.3,1999448,2008-08-23T10:28:24.000-05:00,fold expantion,"{\{\{ hello

something

\}
fold with buffer
remove l
I
think it should not expand folds since the fold level
is not changed.","org.gjt.sp.jedit.textarea.BufferHandler
org.gjt.sp.jedit.textarea.DisplayManager
org.gjt.sp.jedit.textarea.TextArea"
CLASS,pig-0.11.1,PIG-2828,2012-07-19T05:03:16.000-05:00,null in DataType.compare,"Object field1 = o1.get(fieldNum);
                Object field2 = o2.get(fieldNum);
                if (!typeFound) {
                    datatype = DataType.findType(field1);
                    typeFound = true;
                }
                return DataType.compare(field1, field2, datatype, datatype);
use TOP contain null value generate following exception
So we need to judge the field1 whether is null.","src.org.apache.pig.data.DataType
src.org.apache.pig.builtin.TOP
test.org.apache.pig.test.TestNull"
CLASS,pig-0.11.1,PIG-3310,2013-05-03T02:59:57.000-05:00,not generate new uids for nested schema fields lead to miscomputations,"{code}
     
    
        
        
    
           as shop;

EXPLAIN K;
DUMP K;
{code}

 
 {code}
 
 {code}

 
 {code}
 
 {code}
 
        
      
  
 {code}
                  
              
              
              
              
              
 {code}

 
 {code}
                   
  
  
 {code}

     
 LOSplitOutput.getSchema()
consider following example
give wrongful output
The second column should be a member id so (1,2,3,4,5).",src.org.apache.pig.newplan.logical.relational.LOSplitOutput
CLASS,openjpa-2.0.1,OPENJPA-1918,2011-01-06T08:11:24.000-06:00,ignore class loader,"PersistenceUnitInfo.getClassLoader() 
 MetaDataRepository.preload()      
 PersistenceUnitInfo.getClassLoader()    
  
   PersistenceProvider.createContainerEntityManagerFactory()  MetaDatRepository.preload()
pass appliation class loeader as part pass appliation class loeader by returning return from PersistenceUnitInfo.getClassLoader()
However, the code in MetaDataRepository.preload() only uses the context class loader and not the class loader from PersistenceUnitInfo, which leades to ClassNotFoundExpcetions like mentioned at the end of this report.","org.apache.openjpa.meta.FieldMetaData
org.apache.openjpa.meta.MetaDataRepository
org.apache.openjpa.persistence.detach.NoVersionEntity"
CLASS,pig-0.8.0,PIG-730,2009-03-24T14:36:45.000-05:00,combine schema with nested bag combine schema from union,"flatten(outlinks.target);
  flatten(outlinks.target);
---> Would expect both C and D to work, but only C works.
give error
use outlinks.t.target works for d use outlinks.t.target works for c.
---> I don't care which one, but the same syntax should work for both!","src.org.apache.pig.impl.logicalLayer.schema.Schema
src.org.apache.pig.newplan.logical.expression.DereferenceExpression
src.org.apache.pig.newplan.logical.relational.LogicalSchema
test.org.apache.pig.test.TestSchema"
METHOD,math,MATH-1021,2013-08-10T00:00:22.000-05:00,suffer from integer overflow,"HypergeometricDistribution.sample()  
 {code}
 import org.apache.commons.math3.distribution.HypergeometricDistribution;

public class Foo {
  public static void main(String[] args) {
    HypergeometricDistribution a = new HypergeometricDistribution(
        43130568, 42976365, 50);
    System.out.printf(""%d %d%n"", a.getSupportLowerBound(), a.getSupportUpperBound()); // Prints ""0 50""
    System.out.printf(""%d%n"",a.sample());                                             // Prints ""-50""
  }
}
 {code}

  HypergeometricDistribution.getNumericalMean()  
 {code}
 return (double) (getSampleSize() * getNumberOfSuccesses()) / (double) getPopulationSize();
{code}
 
 {code}
 return getSampleSize() * ((double) getNumberOfSuccesses() / (double) getPopulationSize());
{code}
It looks like the HypergeometricDistribution.sample() method doesn't work as well as it used to with large integer values -- the example code below should return a sample between 0 and 50, but usually returns -50.",org.apache.commons.math3.distribution.HypergeometricDistribution:getNumericalMean()
METHOD,math,MATH-358,2010-03-24T17:25:37.000-05:00,go past specified end of integration range,"{code}
   public void testMissedEvent() throws IntegratorException, DerivativeException {
          final double t0 = 1878250320.0000029;
          final double t =  1878250379.9999986;
          FirstOrderDifferentialEquations ode = new FirstOrderDifferentialEquations() {
            
            public int getDimension() {
                return 1;
            }
            
            public void computeDerivatives(double t, double[] y, double[] yDot)
                throws DerivativeException {
                yDot[0] = y[0] * 1.0e-6;
            }
        };

        DormandPrince853Integrator integrator = new DormandPrince853Integrator(0.0, 100.0,
                                                                               1.0e-10, 1.0e-10);

        double[] y = { 1.0 };
        integrator.setInitialStepSize(60.0);
        double finalT = integrator.integrate(ode, t0, y, t, y);
        Assert.assertEquals(t, finalT, 1.0e-6);
    }

 {code}
The following test case shows the end event is not handled properly and an integration that should cover a 60s range in fact covers a 160s range, more than twice the specified range.","org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator:integrate(FirstOrderDifferentialEquations, double, double[], double, double[])
org.apache.commons.math.ode.nonstiff.RungeKuttaIntegrator:integrate(FirstOrderDifferentialEquations, double, double[], double, double[])"
FILE,WFCORE,WFCORE-626,2015-04-06T15:53:19.000-05:00,create list elements,"clear(name=attribute)
  get(name=attribute, index=0)
  add(name=attribute, value=test)
  get(name=attribute, index=0)
consider following sequence of operations
return <undefined> expected
The expected result of #4 is ""test"".
return <undefined>
create missing element at index operate on index","org.jboss.as.controller.operations.global.ListOperations
org.jboss.as.controller.operations.global.MapOperations"
FILE,WFCORE,WFCORE-815,2015-07-13T07:57:45.000-05:00,have more ancestors with same submodules,"add(name=includes, value=mail-01)
  add(name=includes, value=mail-02)

 
 {




    ""outcome"" => ""failed"",




    ""failure-description"" => {""domain-failure-description"" => ""WFLYCTL0401: Profile 'mail-01' defines subsystem 'mail' which is also defined in its ancestor profile 'mail-02'. Overriding subsystems is not supported""} 
 add(name=includes, value=mail-01)
  add(name=includes, value=mail-02)
have more ancestors with same submodules
lead to wflyctl0212
get fresh EAP
No errors.","org.jboss.as.domain.controller.operations.ProfileIncludesHandlerTestCase
org.jboss.as.domain.controller.operations.SocketBindingGroupIncludesHandlerTestCase
org.jboss.as.host.controller.logging.HostControllerLogger"
FILE,WFCORE,WFCORE-1007,2015-09-24T06:45:11.000-05:00,remove extension,"migrate()




 {




    ""outcome"" => ""success"",




    ""result"" => {""migration-warnings"" => []}




 
 migrate()




 {




    ""outcome"" => ""success"",




    ""result"" => {""migration-warnings"" => []}




 
 migrate()




 {




    ""outcome"" => ""success"",




    ""result"" => {""migration-warnings"" => []}
use migration operation fill console log with warning messages
do sequence of operation
I think that the migration operation should not show those warnings.","org.jboss.as.controller.AbstractOperationContext
org.jboss.as.controller.logging.ControllerLogger"
FILE,WFCORE,WFCORE-1027,2015-10-01T18:16:10.000-05:00,scop roles,"{roles=master-monitor}




 
 {




                ""directory-grouping"" => ""by-server"",




                ""domain-controller"" => {""local"" => {} 
  
 {""org.jboss.as.jmx"" => undefined} 
 {




                    ""management"" => undefined,




                    ""public"" => undefined,




                    ""unsecure"" => undefined




                } 
 {""default"" => undefined} 
 {""jmx"" => undefined} 
 {roles=slave-maintainer}




 
 {roles=slave-maintainer}




 
  
 {""org.jboss.as.jmx"" => undefined} 
 {




                ""management"" => undefined,




                ""public"" => undefined,




                ""unsecure"" => undefined




            } 
 {""default"" => undefined} 
 {""jmx"" => undefined}
set up host scop roles follow https://gist.github.com/heiko-braun/0dc810ed04db8739defd
use role select master select role show filtered resources appear in results
use role select slave select role get proper access-control header
master-monitor should behave the same as slave-maintainer.","org.jboss.as.test.integration.domain.rbac.RBACProviderHostScopedRolesTestCase
org.jboss.as.test.integration.domain.rbac.AbstractHostScopedRolesTestCase
org.jboss.as.controller.operations.global.GlobalOperationHandlers
org.jboss.as.test.integration.domain.rbac.JmxRBACProviderHostScopedRolesTestCase
org.jboss.as.test.integration.domain.rbac.ListRoleNamesTestCase
org.jboss.as.test.integration.domain.rbac.WildcardReadsTestCase"
FILE,WFCORE,WFCORE-1572,2016-05-27T16:20:10.000-05:00,contain whitespace,"{rollout id=foo}
contain space (
war --all-server-groups --headers={rollout id=foo}) and if user hits tab after the whitespace, suggestions are generated based on the command, rather than the current argument's name.","org.jboss.as.cli.parsing.DefaultStateWithEndCharacter
org.jboss.as.cli.parsing.ParserUtil
org.jboss.as.cli.parsing.test.CommandTestCase"
FILE,WFCORE,WFCORE-1570,2016-05-27T12:51:56.000-05:00,save name id attribute discrepancy,"group(rolling-to-servers=false,max-failed-servers=1)  group(rolling-to-servers=true,max-failure-percentage=20)  
 {rollout id=my-rollout-plan}
use rollout plans for EAP deployment scenarios create own named rollout-plan for ease
apply rollout command refer with name
use command
see name attribute name rollout plan
use following command
see id attribute
Yes, this is really minor issue, but I think that these two attributes used in aforementioned commands should be unified (preferably to name instead of id) as user might be confused when using it.","org.jboss.as.cli.parsing.operation.header.RolloutPlanState
org.jboss.as.cli.parsing.operation.header.RolloutPlanHeaderCallbackHandler
org.jboss.as.cli.operation.impl.RolloutPlanCompleter"
FILE,WFCORE,WFCORE-1578,2016-06-07T05:13:13.000-05:00,add local | remote-destination-outbound-socket-binding,"{remote|local} 
   add()




    add(host=localhost,port=8765)




 
   add(socket-binding-ref=http)




 
  
  
     
  
 
  
 {remote|local}
have with particular name
use same name as_of existing socket-binding resource parse configuration
create own socket-binding resource perform own socket-binding resource
crash with following stacktrace
If there is a problem for those resources to have same names I would welcome that names are checked during the add operation already regarding to all resources in socket-binding and {remote|local}-destination-outbound-socket-binding.","org.jboss.as.controller.logging.ControllerLogger
org.jboss.as.server.services.net.LocalDestinationOutboundSocketBindingAddHandler
org.jboss.as.server.services.net.SocketBindingAddHandler
org.jboss.as.server.services.net.RemoteDestinationOutboundSocketBindingAddHandler"
FILE,WFCORE,WFCORE-1864,2016-10-13T09:12:31.000-05:00,add command not remove whitespaces from dependencies,"{{
...
    <dependencies>
        <module name=""org.a""/>
        <module name="" org.b ""/>
    </dependencies>
...
}}
run module add for running result in following dependencies
The module name in dependencies should be stripped of leading and trailing whitespaces.","org.jboss.as.cli.handlers.module.ASModuleHandler
org.jboss.as.test.integration.management.cli.ModuleTestCase"
FILE,WFCORE,WFCORE-1908,2016-10-31T08:13:57.000-05:00,write attribute have access type metric have attribute,"attribute(name=message-count, value=5)




 {




    ""outcome"" => ""failed"",




    ""failure-description"" => ""WFLYCTL0048: Attribute message-count is not writable"",




    ""rolled-back"" => true




}
suggest attributes
write metric attribute for example message-count print non writable error on attempt
CLI should not suggest writing attributes that are not writable.","org.jboss.as.cli.impl.AttributeNamePathCompleter
org.jboss.as.cli.parsing.test.AttributeNamePathCompletionTestCase
org.jboss.as.cli.Util"
FILE,WFCORE,WFCORE-1936,2016-11-04T10:57:06.000-05:00,not match reality for socket-binding not match reality for *,"description(recursive=true)
fixed-port attribute of socket-binding and fixed-source-port attributes of *-destination-outbound-socket-binding define in its description that there is not necessary to do reload or restart for any of them.
change such attributes","org.jboss.as.server.services.net.OutboundSocketBindingResourceDefinition
org.jboss.as.controller.resource.AbstractSocketBindingResourceDefinition"
FILE,eclipse-3.1,85397,2005-02-16T08:20:00.000-06:00,produce error on constructor _,"strictfp enum Natural {
	ONE, TWO;
}

 
 strictfp enum Natural {
	ONE, TWO;
	
	private Natural() {
	}
}
have code
expected: strictfp is not allowed on the enum type actual: no error is reported
have code
expected: the wrong modifier is reported with the type name 'Natural' actual: the error is shown for the constructor_","org.eclipse.jdt.internal.compiler.lookup.SyntheticMethodBinding
org.eclipse.jdt.internal.ui.typehierarchy.TypeHierarchyViewPart
org.eclipse.jdt.internal.compiler.lookup.MethodScope"
FILE,eclipse-3.1,85672,2005-02-17T05:53:00.000-06:00,unfold folded region with line delimiter,"package folding;

class Test {
    
}
have code
put caret brace region fold region
put caret on last line unfold type
expected: caret is right after the closing brace actual: everything from after the *opening* brace is selected",org.eclipse.jface.text.source.projection.ProjectionViewer
FILE,eclipse-3.1,86000,2005-02-21T14:47:00.000-06:00,produce invalid JPEG images,"package com.ibm.test.image;

import org.eclipse.swt.*;
import org.eclipse.swt.graphics.*;

public class ImageLoaderTest {
		
	public static void main(String[] args) {
		ImageLoader loader;
		String dir=""c:\\image-problems\\"";
		String files[]={
				""s34i3p04"",
				""s34n3p04"",
				""s35i3p04"",
				""s35n3p04"",
				""s36i3p04"",
				""s36n3p04"",
				""s37i3p04"",
				""s37n3p04"",
				""s38i3p04"",
				""s38n3p04"",
				""s39i3p04"",
				""s39n3p04""
		};
		
		try {
			for (int i=0; i<files.length; i++) {
			String filein  = dir+files[i]+"".png"";
			String fileout = dir+files[i]+"".jpg"";
			
			loader = new ImageLoader();
			loader.load(filein);
			loader.save(fileout,SWT.IMAGE_JPEG);
			}
		} catch (SWTException e) {
		  e.printStackTrace();
		}
	}
}
produce bad JPG images
test as JPEG
Many files were tested and the majority 
 did produced the proper JPG images as expected.","org.eclipse.ui.internal.WorkbenchIntroManager
org.eclipse.swt.internal.image.JPEGFileFormat"
FILE,eclipse-3.1,95096,2005-05-13T06:16:00.000-05:00,assist popup complete imported method name,"import static java.lang.Math
import static java.lang.Math.
-> Instead of constraining the proposals to all members with prefix a, the popup closes","org.eclipse.jdt.internal.ui.text.java.JavaMethodCompletionProposal
org.eclipse.jdt.internal.ui.text.java.LazyJavaCompletionProposal"
FILE,eclipse-3.1,96489,2005-05-24T14:40:00.000-05:00,have border,"layout.addStandaloneView(BrowserApp.BROWSER_VIEW_ID, false,
IPageLayout.RIGHT, .25f, IPageLayout.ID_EDITOR_AREA);
change BrowserPerspectiveFactory have following instead_of regular addView layout.addStandaloneView ( BrowserApp.BROWSER_VIEW_ID
show history view
have border
Standalone views should still have their border, just not the title or min/max buttons if showTitle==false.","org.eclipse.ui.presentations.WorkbenchPresentationFactory
org.eclipse.ui.internal.presentations.defaultpresentation.EmptyTabFolder"
FILE,eclipse-3.1,97722,2005-05-31T16:41:00.000-05:00,dialog problems,"@

Dialog
crop error message at bottom
The name text and location combo should be left aligned.",org.eclipse.ant.internal.ui.preferences.AddCustomDialog
FILE,eclipse-3.1,98740,2005-06-07T13:25:00.000-05:00,refresh children on project,"String folder = ""/temp"";//$NON-NLS-1$
String projName = ""project"";//$NON-NLS-1$ 
IProjectDescription description = ResourcesPlugin.getWorkspace
().loadProjectDescription(projPath);
IProject project = ResourcesPlugin.getWorkspace().getRoot().getProject
(description.getName());
project.create(description, new NullProgressMonitor());

  project.open()  
 The members()  
 if (info.isSet(ICoreConstants.M_CHILDREN_UNKNOWN))
			workspace.refreshManager.refresh(this);
take existing simple project on disk import project into workspace import project by performing create with code
not open project with project.open() API
create project by API create project by UI
start background refresh job for closed project stick in infinite loop
call members on iproject
load existing Java projects by performing load existing Java projects on disk perform create
get refresh infinite loops on next UI gesture
The end user will open them by using the open project UI when needed.","org.eclipse.core.internal.resources.Container
org.eclipse.core.internal.resources.Resource"
CLASS,mahout-0.8,MAHOUT-1314,2013-08-18T09:07:48.000-05:00,throw NullPointerException set REDUCE_STREAMING_KMEANS to true,"return input.getCentroid();  
 input.getCentroid()  clone();
set REDUCE_STREAMING_KMEANS option to true fail with NullPointerException
it should be input.getCentroid().
clone();
happen time set REDUCE_STREAMING_KMEANS to true set time to true",core.src.main.java.org.apache.mahout.clustering.streaming.mapreduce.StreamingKMeansReducer
